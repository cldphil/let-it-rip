{
  "id": "http://arxiv.org/abs/2506.05178v1",
  "title": "Associative Memory and Generative Diffusion in the Zero-noise Limit",
  "summary": "Connections between generative diffusion and continuous-state associative\nmemory models are studied. Morse-Smale dynamical systems are emphasized as\nuniversal approximators of gradient-based associative memory models and\ndiffusion models as white-noise perturbed systems thereof. Universal properties\nof associative memory that follow from this description are described and used\nto characterize a generic transition from generation to memory as noise levels\ndiminish. Structural stability inherited by Morse-Smale flows is shown to imply\na notion of stability for diffusions at vanishing noise levels. Applied to one-\nand two-parameter families of gradients, this indicates stability at all but\nisolated points of associative memory learning landscapes and the learning and\ngeneration landscapes of diffusion models with gradient drift in the zero-noise\nlimit, at which small sets of generic bifurcations characterize qualitative\ntransitions between stable systems. Examples illustrating the characterization\nof these landscapes by sequences of these bifurcations are given, along with\nstructural stability criterion for classic and modern Hopfield networks\n(equivalently, the attention mechanism).",
  "authors": [
    "Joshua Hess",
    "Quaid Morris"
  ],
  "published": "2025-06-05T15:51:47Z",
  "updated": "2025-06-05T15:51:47Z",
  "categories": [
    "cs.LG",
    "cond-mat.dis-nn",
    "math.DS",
    "nlin.AO",
    "q-bio.NC"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.05178v1",
  "full_text": "--- Page 1 ---\narXiv:2506.05178v1  [cs.LG]  5 Jun 2025Associative Memory and Generative Diffusion in the\nZero-noise Limit\nJoshua Hess jmh4003@med.cornell.edu\nComputational & Systems Biology\nSloan Kettering Institute, Memorial Sloan Kettering Cancer Center\nTri-Institutional Training Program in Computational Biology and Medicine\nNew York, NY 10065-4896, USA\nQuaid Morris morrisq@mskcc.org\nComputational & Systems Biology\nSloan Kettering Institute, Memorial Sloan Kettering Cancer Center\nNew York, NY 10065-4896, USA\nAbstract\nConnections between generative diffusion and continuous-state associative memory models\nare studied. Morse-Smale dynamical systems are emphasized as universal approximators of\ngradient-based associative memory models and diffusion models as white-noise perturbed\nsystems thereof. Universal properties of associative memory that follow from this de-\nscription are described and used to characterize a generic transition from generation to\nmemory as noise levels diminish. Structural stability inherited by Morse-Smale flows is\nshown to imply a notion of stability for diffusions at vanishing noise levels. Applied to\none- and two-parameter families of gradients, this indicates stability at all but isolated\npoints of associative memory learning landscapes and the learning and generation land-\nscapes of diffusion models with gradient drift in the zero-noise limit, at which small sets of\ngeneric bifurcations characterize qualitative transitions between stable systems. Examples\nillustrating the characterization of these landscapes by sequences of these bifurcations are\ngiven, along with structural stability criterion for classic and modern Hopfield networks\n(equivalently, the attention mechanism).\nKeywords: associative memory, diffusion models, Morse-Smale dynamical systems, zero-\nnoise limits, small random perturbations\nContents\n1 Introduction 2\n1.1 Dynamical systems and associative memory . . . . . . . . . . . . . . . . . . 4\n1.2 Generative diffusion models . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.3 Overview of main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2 Associative memory and Morse-Smale gradients 11\n2.1 Stable associative memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.2 Universal approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.3 Generic properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3 Zero-noise limits and stability 17\n©2025 Joshua Hess and Quaid Morris.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ .\n--- Page 2 ---\nHess and Morris\n3.1 Generic zero-noise limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.2 Physical measures and resonance . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.3 Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n4 Generation, learning, and stable families of gradients 24\n4.1 Large deviations and stochastic flows . . . . . . . . . . . . . . . . . . . . . . 25\n4.2 Stable families and bifurcations . . . . . . . . . . . . . . . . . . . . . . . . . 27\n5 Applications and examples 32\n5.1 Assumptions and generic conditions . . . . . . . . . . . . . . . . . . . . . . 32\n5.2 Energy-based models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.3 Hopfield networks and Boltzmann machines . . . . . . . . . . . . . . . . . . 36\n5.4 Modern Hopfield networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n5.5 Denoising diffusion models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n6 Conclusion and discussion 45\nTerminology\nBymanifold we mean a closed smooth finite-dimensional manifold M. By smooth we mean\nC∞unless indicated otherwise. The boundary of Mis denoted by ∂M. By closed manifold\nwe mean that the boundary ∂Mis empty. The space of Crvector fields in a manifold\nMis denoted by χr(M) and the space of Crdiffeomorphisms by Diffr(M). A subset\nof these spaces being open ordense is understood with respect to the compact-open Cr\ntopology, defined in §2.2. Vector fields and flows are assumed at least C1and are defined on\nclosed manifolds or compact subsets D⊂Rndiffeomorphic to a closed n-dimensional disc\nwith flows pointing inwards and intersecting the boundary ∂Dtransversally. Real-valued\nfunctions are assumed at least C2. The tangent bundle on a manifold Mis denoted TM\nand the tangent space at a point x∈MbyTxM.\nLet (M, g) be a Riemannian manifold and ( M,B, µ) a Borel probability space. We take\nthe natural Borel σ-fieldBon (M, g) generated by Borel sets A∈ B that coincide with\nthe open sets of M. Borel probability measures are assumed to be absolutely continuous\nwith respect to the volume element dvolg=p\n|g|dx1∧...∧dxm, where |g|= det( gij) is the\ndeterminant of the metric tensor. This does not apply to atomic measures.\n1 Introduction\nAssociative memory refers to the ability to recall stored information based on partial input\n(Dayan and Abbott (2005)). These models, originally inspired by neuroscience and Hebbian\nlearning theory, were developed in a binary state setting with relatively limited memory\ncapacity (Hopfield (1982)), but have since become integral components of modern deep\nlearning systems (Krotov (2023)). For example, the Hopfield model’s memory capacity was\nincreased in Krotov and Hopfield (2016) and Demircigil et al. (2017), and an extension\nwas subsequently developed that is actually equivalent to the attention mechanism of the\ntransformer, an architecture behind state-of-the-art natural language processing models\n(Vaswani et al. (2017); Ramsauer et al. (2020); see §5.4). These results were also studied in\n2\n--- Page 3 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nthe context of the entire transformer block in Hoover et al. (2023a). Conversely, diffusion\nmodels generate data from a learned probability distribution, but their history dates back to\nthe Boltzmann machine (Ackley et al. (1985)), a probabilistic version of the Hopfield model,\nand have become best-in-class for tasks such as image generation (Rombach et al. (2022);\nRamesh et al. (2022); Cao et al. (2024)). Similarities between the random and deterministic\nmodels have long been known, and interest in these connections has resurfaced in the context\nof modern models (e.g., Hoover et al. (2023b)).\nSpurious memories arise in associative memory models as unintended fixed points. Their\nbehavior is well studied using probabilistic approaches (e.g., Gayrard (2025)), and they have\nalso recently been observed in diffusion models (Pham et al. (2025)). Continuous-state as-\nsociative memory and diffusion models define deterministic and random dynamical systems,\nwhere high-gain activation functions in the former act similarly to a low-noise limit in the\nlatter. It is known that metastable states can emerge and disappear at varying noise magni-\ntudes in random systems, and relationships between the deterministic and random models\nare similarly well studied at low noise levels, owing largely to large-deviation estimates\nfrom the classic Freidlin-Wentsell (FW) theory of random dynamical systems (Ventsel and\nFreidlin (1970)), among others (e.g., Bovier et al. (2001, 2004)).\nThese probabilistic approaches are rigorous; however, most computations are local, in\nthe neighborhood of a fixed point, or consider transitions between pairs of them. Conse-\nquently, global descriptions of the robustness, stability, learning dynamics (e.g., memory\nformation), and universal properties of the orbit structure of these models are less devel-\noped. These core aspects of machine learning theory are historically related to the notion\nofgenericity . Ageneric oruniversal property is one that holds for ”almost all” systems of\ninterest – here, one that holds on an open and dense subset of a suitable function space (see\n§2.2). A property holding on a dense subset reflects its approximation power1; a property\nholding on an open subset reflects its robustness and stability (see §1.3).\nSearch for generic properties also progressed both geometric and probabilistic approaches\nto dynamical systems. On the geometric side, determining whether certain global notions of\nstability are generic stimulated work, largely driven by Smale’s school, which laid the basic\ntheory of the subject. Major results pertain to hyperbolic (e.g., Axiom A) and structurally\nstable systems (Smale (1967)). A special case of these systems, called Morse-Smale , are\nclosely related to the topology of manifolds (Smale (1960)), making the generic properties of\nthese models well-suited for geometric and topological arguments. A probabilistic approach\nto studying a system’s asymptotic behavior, largely rooted in ergodic theory, developed\nin parallel to counterexamples showing that these systems are not generic (e.g., Newhouse\n(1970); see also Palis (2000, 2005) for further context).\nHere, these topics are used together with the FW theory to describe the generic proper-\nties of these models and a generation-to-memory transition at diminishing noise levels from\na global viewpoint. In particular, Morse-Smale gradient systems (Smale (1960); §2.1) are\nemphasized as a generic class of associative memory models and diffusions as their white-\nnoise perturbed counterparts. Zero-noise-limiting descriptions of stationary measures and\ntrajectories of diffusion models are connected to those of associative memory models within\nthis class. Generic properties of associative memory that follow from the Morse-Smale\n1. See, e.g., classic work in Cybenko (1989), Theorem 1 for a proof of universal approximation using density\nexplicitly; see also Funahashi (1989), Theorems 1 and 2 for proofs implicitly using density.\n3\n--- Page 4 ---\nHess and Morris\nassumptions are used with other results from Morse theory to describe the stability and\nrobustness of stationary measures and trajectories of diffusions in the zero-noise limit. The\nMorse-Smale conditions are equivalent to the existence of a neighborhood of a gradient field\nin which all nearby models are topologically equivalent to it (structural stability). These\nisomorphisms are determined by homeomorphisms mapping the trajectories of two systems\nto each other, and particular focus is given to zero-noise-limiting behavior under these maps.\nBreakdowns of the Morse-Smale conditions for gradient systems are bifurcations that\nchange their topological or qualitative type. The learning and generation processes of\nthese models appear as one- and two-parameter families of gradients, which have well-\nstudied sets of generic bifurcations that we use to globally describe memory formation and\nthe learning and generation dynamics of diffusion models. Examples are given, including\nHopfield networks, energy-based models, and denoising diffusion models. Requirements to\nsatisfy the Morse-Smale assumptions are obtained for Hopfield-type networks.\nThis work provides a step towards understanding the global critical point structure\nand stability of continuous-state associative memory models using the bifurcation theory of\ngradients and the geometric theory of dynamical systems. In turn, a generic characterization\nof the topological properties of associative memory and diffusion-based generative models\nat vanishing noise levels is obtained, along with a characterization of their dynamics as they\nlearn to store and generate data. The primary results of this paper are summarized in §1.3.\n1.1 Dynamical systems and associative memory\nAssociative memories are often modeled as attractors of a dynamical system with basins\nof attraction containing points that evolve asymptotically to them. Memory recall consists\nof evolving the network to these fixed points given initial conditions. Therefore, small\nperturbations within a neighborhood of a memory decay over time, making these models\ncapable of pattern completion and error correction.\nWidely known models define gradient dynamical systems on Rnor compact subsets\nthereof, including all models of Hopfield type. More generally, let Mbe a manifold and\nϕX\nt:R×M→Mwith t∈Ra one-parameter group of diffeomorphisms generated by\na vector field X(§2.1). In the continuous state formulation, memories are asymptotically\nstable points p∈M, meaning that there is a neighborhood U(p) ofpsuch that for all q∈U,\nϕX\nt(q)→past→ ∞ . Asymptotic stability is an implicit defining property that can be\nfound with the introduction of the classic models in Hopfield (1982, 1984).\nIn general, if V∈Cr(M,R) is a smooth function ( r≥2) and Mis given a Riemannian\nmetric g=Pgijdxi⊗dxj, the derivative DV(x) :TxM→Rdefines a linear function on\nthe tangent space TxMatx∈Mand hence a smooth 1-form on M. The (inverse) metric\nconverts this 1-form to a vector field and defines a gradient system X:=−∇gV. It can be\nchecked that off critical points, where X(p) = 0, V\u0000\nϕX\nt(p)\u0001\ndecreases as tincreases. If pis\nan isolated minima of V, then pis asymptotically stable. Consequently, gradient systems\nare natural models of associative memory, and memory storage consists of finding a ”good”\nfunction Vwhose critical elements coincide with the set of memories to store.\n4\n--- Page 5 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n1.2 Generative diffusion models\nBroadly, generative models aim to learn a probability distribution µdata(dx) =pdata(x)dx\nover a set of data in Rn, with density pdata(x) absolutely continuous with respect to Lebesgue\nmeasure dx, by inferring an optimal set of parameters θ∗for a family of distributions\nµθ(dx) =pθ(x)dx(Cotler and Rezchikov (2023)). Rather than explicitly defining distribu-\ntions, diffusion models are defined implicitly as solutions to stochastic differential equations.\nConsider random perturbations to a dynamical system ˙ xt=b(xt) inRn:\ndxϵ\nt=b(xϵ\nt)dt+ϵσ(xϵ\nt)dwt, (1.2.1)\nwhere bis a vector field, wtis the standard n−dimensional Wiener process (Brownian\nmotion), σ(x) is an n×nmatrix, and ϵ >0 is a scalar ”noise level”. Solutions to (1.2.1) define\na diffusion Markov process Xϵ={xϵ\nt}T\nt=0, with t∈[0, T], given by transition probabilities\n{pϵ(·|x) :x∈Rn}that satisfy the Chapman-Kolmogorov equation,\npϵ(y, s|x, t0) =Z\nRnpϵ(y1, t1|x, t0)pϵ(y, s|y1, t1)dy1,\nfort0< t1< sand intermediate states y1. A diffusion process like Xϵis associated with a\nsecond-order differential operator, called the backwards Kolmogorov operator , given by\nLϵ=X\nbi∂\n∂xi+ϵ2\n2X\naij∂2\n∂xi∂xj, (1.2.2)\nwhere aij=σ(x)σ∗(x) and σ∗(x) is the adjoint of σ(x) (see Ventsel and Freidlin (1970)).\nTheforward Kolmogorov operator , denoted L∗ϵ, is the adjoint of Lϵ. We consider its action\non probability densities, giving the Fokker-Planck equation,\n∂p(x, t)\n∂t=X∂\n∂xi\u0002\nbip(x, t)\u0003\n+ϵ2\n2X ∂2\n∂xi∂xj\u0002\naijp(x, t)\u0003\n, (1.2.3)\nwhich induces a flow ∂tpt=L∗ϵptsolved by the transition density (given initial conditions)2.\nDiffusion models sample from pdatausing the flow ∂tptinduced by (1.2.1) and (1.2.3).\nOne class of models, which includes energy-based models ( §5.2) and Boltzmann machines\n(§5.3), uses forward diffusion processes that evolve an initial density p0, to a density pT\nwith 0 < T≤ ∞ andpdata≈pT. Another class generates data by learning the reverse of\na diffusion process that iteratively adds noise to data, motivated by the main theorem in\nAnderson (1982), which shows that diffusions admitting a transition density also admit a\nreverse-time process, which induces a flow from pTtop0:=pdata. Both model classes are\ndetermined by fixed points of the operator L∗ϵ.\nLetMbe the set of Borel probability measures on Rnwith the weak topology.\nDefinition 1 (Stationary and equilibrium distributions) .A probability measure µϵ∈ M\nis astationary orinvariant measure forXϵif for each Borel set Aandx∈Rn:\n2. We assume b(·) and σ(·) satisfy regularity and growth conditions to ensure a unique strong solution to\n(1.2.1) and for transition densities to satisfy the forward and backward Kolmogorov equations (see, e.g.,\nAnderson (1982), Section 3 for such conditions).\n5\n--- Page 6 ---\nHess and Morris\nµϵ(A) =R\npϵ(A, t|x)µϵ(dx)with t >0; that is, if it is a fixed point of L∗ϵ. It is called an\nequilibrium distribution ifR\nµϵ(dx) = 1 andpϵ(A, t|x)→µ(A)ast→ ∞ .\nIf an equilibrium distribution exists, it is unique. Stationary distributions are also\nequilibrium distributions up to a constant factor; see Kent (1978), Section 5.\nMore generally, the support of the density p(x) is a Riemannian n−manifold ( M, g). In\nlocal coordinates ( x1, ..., xn) onM, equations like (1.2.1) become:\ndxϵ\nt=bϵ(xϵ\nt)dt+ϵσ(xϵ\nt)dwt, (1.2.4)\nwhere bϵ(x) =b(x) +ϵ2\n2eb(x), with\nebi=q\ndet(gij)X\nj∂\n∂xj\u0014\ngijq\ndet(gij)\u0015\nandgij=σ(x)σ∗(x), which represents a drift correction taking into account the local\ncurvature of M. The operator generating a diffusion process Xϵsolving (1.2.4) is\nLϵf(x) =ϵ2\n2∆f(x) +⟨b(x),∇gf(x)⟩,\nwhere f∈C2(M), ∆ is the Laplace-Beltrami operator corresponding to the metric g, and\n∇gis the Riemannian gradient.\nIt is shown in §5 that the drift fields of many diffusion models are actually gradients.\nThat is, the drift b(xϵ\nt) in (1.2.4) is the gradient of a function V∈C2(M,R), so\ndxϵ\nt=−∇gVϵ(xϵ\nt)dt+ϵσ(xϵ\nt)dwt. (1.2.5)\nThe notation ∇gVϵemphasizes that the drift is the Riemannian gradient of Vwith drift\ncorrection. It is known that if diffusions solving (1.2.5) do not escape to infinity (i.e., they\narenonexplosive ), which is ensured if Mis compact3, then their stationary measures are\nBoltzmann-Gibbs distributions:\nµ(dx) =1\nZe−V(x)\nϵ2dvolg(x) with Z=Z\nMe−V(x)\nϵ2dvolg(x), (1.2.6)\nwhere µ(dx) absolutely continuous with respect to Lebesgue measure and Zis a constant\nfactor to ensure the density p(x) =Z−1·e−V(x)/ϵ2is normalized withR\nMp(x)dx= 1.\n1.3 Overview of main results\nExact samples can be drawn from a stationary distribution of a diffusion model by solving\na corresponding equation like (1.2.5) as t→ ∞ . Likewise, associative memory evolves\nnetwork states to fixed points in this limit. Like in the stochastic case, this asymptotic\nbehavior encodes information about invariant probability measures. Moreover, when ϵ= 0,\n(1.2.4) is the equation of a dynamical system and (1.2.5) a gradient system. Consequently,\nit is of interest to study the limiting behavior of diffusion processes with gradient drift as\n3. See also Kent (1978), Theorem 4.2 for Xϵbeing reversible, which implies the same result.\n6\n--- Page 7 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nnoise levels vanish, ϵ→0, and when time reaches ±∞. The trajectories of diffusions with\nvanishing, but small positive noise are studied when ϵ→0, while their invariant measures\nare studied when t→ ±∞ . The following two definitions summarize these ideas.\nTrajectories and stationary measures. Given an initial condition x=x0, the forwards\nKolmogorov equation implies that the transition density of a diffusion process is increasingly\ngoverned by the drift field as ϵ→0, making diffusion models with gradient drift small\nrandom perturbations of associative memory models:\nDefinition 2 (Small random perturbation, adapted from Cowieson and Young (2005)) .Let\nϕ:M→Mbe aCrdiffeomorphism for r≥1. A one-parameter family of Markov chains\n{Xϵ}ϵ>0, parameterized by ϵand given by transition probabilities {pϵ(·|x) :x∈M}is a\nsmall random perturbation ofϕifpϵ(·|x)→δϕ(x)uniformly as ϵ→0.\nThe flow ϕX\ntof a gradient system X=−∇gVis downhill off its set of critical points, since\nDVpX(·) =−||X(·)||2. Consequently, it has no closed orbits , i.e., trajectories diffeomorphic\ntoS1, and its only critical elements are singularities. By the Poincar´ e recurrence theorem4,\nany probability measure invariant under ϕX\ntmust assign zero measure to Borel sets Awith\nϕX\nt(A)∩A=∅when t→ ∞ , implying invariant measures for gradient flows concentrate\non their singularities; however, they are not absolutely continuous with respect to Lebesgue\nmeasure, in contrast to invariant measures for diffusions – the two are weakly related:\nDefinition 3 (Zero-noise limit, Cowieson and Young (2005)) .LetMbe a Riemannian\nmanifold and Mthe set of Borel probability measures on M. A probability measure µ∈ M\nis azero-noise limit of a small random perturbation Xϵofϕ:M→Mifµis a limit\npoint of the sequence {µϵ}asϵ→0in the weak topology on M, where µϵare stationary\nmeasures of Xϵ. That is,R\nMf(x)dµϵ(x) =R\nMf(x)dµ(x)asϵ→0for any continuous\nbounded function f∈C0\nb(M).\nStability and universal properties. The elements of a generic set of so-called Morse-\nSmale gradient systems have a finite number of critical points and satisfy two conditions\ndescribing their behavior at critical points (the Morse condition) and off critical points (the\nSmale condition). That these systems are generic implies that they can universally approx-\nimate any gradient–based associative memory model ( §2.2). Several universal properties of\nassociative memory are derived from the Morse-Smale conditions in §2.3.\nThe Morse condition implies that the critical points of these systems only display three\npossible types of behavior, each characterized by the index , or number of negative eigen-\nvalues of the Hessian matrix at these points. A critical element p∈Mis an attractor or\nrepellor if its index is the maximum possible value or zero, respectively; if it is neither an\nattractor or repellor, it is a saddle . These critical points are also isolated. Consequently,\nthe attractors (memories) of such systems are asymptotically stable ( §2.3.1).\nThe Smale condition is necessary for stability to model parameter perturbation. Given\naCrvector field Xon a manifold M, a vector field δXis called a Ckperturbation of\nsizeϵfork≤rif the difference between them and their kthorder partial derivatives are\nuniformly less than ϵat all points p∈M(Guckenheimer and Holmes (2013), Chapter 1.7)5.\n4. See Sinai (1989), Theorem 2.1 for a statement of the Poincar´ e recurrence theorem referred to here.\n5. A general definition can be made with respect to the compact-open topology on the set χr(M) ofCr\nvector fields on a manifold M.\n7\n--- Page 8 ---\nHess and Morris\nTwo vector fields X, Y∈χr(M) are topologically equivalent if there exists a home-\nomorphism h:M→Mthat maps orbits of Xto orbits of Ypreserving orientation. That\nis, there exist times t1, t2>0 such that h(ϕX\nt1(p)) = ϕY\nt2(h(p)) for any p∈M. Ifhpre-\nserves the time parametrization, it is called a conjugacy . Topologically equivalent systems\nnecessarily have the same critical points (modulo homeomorphism) whose indices agree.\nConsequently, topological equivalence captures when associative memory models are quali-\ntatively the same. Structural stability captures the notion that small model perturbations\nshould not change a model’s topological type:\nDefinition 4 (Structural stability) .A vector field X∈χr(M)isstructurally stable if\nthere exists an ϵ >0so that C1perturbations of size less than or equal to ϵare topologically\nequivalent to X. That is, there is a neighborhood UofXinχr(M)such that all Y∈Uare\ntopologically equivalent to X.\nUnlike asymptotic stability, structural stability is global, defined by the dynamical sys-\ntem itself. ”Robustness” of a vector field means that all nearby systems (in a neighborhood)\nare isomorphic to it. Importantly, a gradient system is structurally stable exactly when it\nis Morse-Smale.\nThe Morse-Smale assumptions are used to study the zero-noise limiting behavior of\ninvariant measures and trajectories of small random perturbations of gradient flows in §3\nand§4. An example is given below to illustrate these connections. Examples throughout\nare motivated by normal form polynomials (those with minimal parameters) for illustrative\npurposes, and they are vector fields and small random perturbations on globally attracting\nregions diffeomorphic to the closed n-dimensional disc D⊂Rn; that is, the set {x∈Rn:\n||x|| ≤1}with spherical boundary ∂D∼={x∈Rn:||x||= 1}that is assumed to intersect\nthese vector fields transversally. The transversality condition is generic ( §5).\nExample 1 (Bistable associative memory, Figure 1) .Consider storing two patterns β1, β2\nusing a dual-well potential in two variables v1, v2with quadratic terms in all other variables.\nAdd quartic terms on v1, v2to bound the dynamics with repellors at ±∞ so that the flow\npoints inward. Neuronal states evolve via gradient dynamics:\n˙vi=−nX\nj=1δij∂V(v)\n∂viwith V(v) =1\n4v4\n1+1\n4v4\n2−v2\n1+v2\n2+nX\ni=3v2\ni. (1.3.7)\nGiven a noise level ϵ >0, a diffusion process Xϵ={vϵ\nt}T\nt=0with t∈[0, T]can be con-\nstructed as solutions to (1.2.5) . As ϵ→0, the trajectories of Xϵconverge to those of the\ndeterministic gradient flow. This intuition is captured by saying that {Xϵ}ϵ>0is a small ran-\ndom perturbation of the gradient flow ϕX\nt. Invariant measures of Xϵare Boltzmann-Gibbs\ndistributions, µϵ(dv) = (Zϵ)−1·e−V(v)/ϵ2dvolg(v)withZϵ=R\nDe−V(v)/ϵ2dvolg(v).\nLearning and memory consolidation. Let (M, g) be a Riemannian manifold and X=\n−∇gVan associative memory model. In applications, the potential and the metric may be\nparameterized by neural networks with parameters θVandθg. Denote the parameter set by\nθ={θg, θV}. LetL:θ→Rbe a smooth loss function, and denote by θ∗a parameter set\nsolving min θL(θ) by, e.g., gradient descent ( §4). It is natural to ask whether this learning\nprocess through gradient-based updates can be characterized.\n8\n--- Page 9 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n2\n 1\n 0 1 22\n1\n012v1a\nb=0.05\n2\n 1\n 0 1 22\n1\n012=0.5\n2\n 1\n 0 1 22\n1\n012=1\n2\n 1\n 0 1 2\nv22\n1\n012v1c\n2\n 1\n 0 1 2\nv22\n1\n012\n2\n 1\n 0 1 2\nv22\n1\n012048121620V(v)\n0.000.250.500.751.001.251.501.752.002.25×103\n(dv)\n048121620V(v)\n0.000.250.500.751.001.251.501.752.002.25×105\n(dv)\n048121620V(v)\n0.00.81.62.43.24.04.85.66.4×106\n(dv)\nTrajectory Energy Probability Saddle Attractor / Memory Partial / Corrupted Pattern\nFigure 1: Small random perturbations andzero-noise limits . (a) Symbols representing\nphase portraits and probability measures throughout. (b)Trajectories (grey) of diffusion processes\nXϵat varying noise levels (left to right) overlayed on the energy surface (light blue interior, magenta\nexterior) of the associative memory model in Example 1. As ϵ→0 trajectories approach those of the\ngradient system in (1.3.7) – {Xϵ}aresmall random perturbations of the gradient flow. Attractors\nare memories (black circles). Recall from partial/corrupted patterns (white circles) is given by the\nasymptotic behavior of trajectories (black lines). (c)Invariant measures µϵ(dv) ofXϵare Boltzmann-\nGibbs distributions. As ϵ→0, the sequence {µϵ}converges to the zero-noise limit of{Xϵ}.\nAk−parameter family of gradients is a family of vector fields {Xη1,...,ηk}onMwith\nη∈Nk, where Nis ak−manifold6, for which there exists a family of functions {Vη1,...,ηk}\nand family of metrics {gη1,...,ηk}with Xη1,...,ηk=−∇gη1,...,ηkVη1,...,ηk. Memory consolidation,\nor learning to store memories, appears as a one-parameter family {Xη}η∈Rwhere η∈Ris\na time parameter of the learning process. Similarly, let Xt=−∇gtVtwith t∈Rbe a time-\nvarying model with potential and metric that smoothly vary with respect to t. Gradient\ndescent then produces a two-parameter family of gradients.\nShortly after the structural stability theory for gradients was established, Thom asked\nabout classifying bifurcations associated with the loss of stability of their parameterized fam-\nilies (Thom (1969, 1972); see §4.2.1). In contrast to Thom’s local approach, which focused\non parametrized potential functions, additional global bifurcations can occur, making the\nclassification of bifurcations for arbitrary k−parameter families of gradients difficult. How-\never, the one- and two-parameter cases are relatively simple. Only two bifurcations must\nbe considered for one-parameter families ( §4.2.2). The two-parameter case is more com-\nplicated, but the bifurcations are enumerable ( §4.2.3). Importantly, the parameter values\n6. The one-parameter families relax the assumption that Nis compact.\n9\n--- Page 10 ---\nHess and Morris\nwhere bifurcations occur are isolated , which implies that memory formation is characterized\nby ordered sequences of these topology-changing moves.\nTrajectories at vanishing noise levels. LetXϵbe a small random perturbation of ϕX\nt\nby white-noise perturbations as in (1.2.5). Likewise, let Xϵ,tbe obtained from a stochas-\ntic differential equation with time-varying drift. A similar question as above is: Can the\ngeneration and learning process of diffusion models be characterized?\nThe bifurcations of one- and two-parameter families topologically characterize memory\nformation. However, topological equivalence of flows and structural stability do not apply to\ndiffusions in the vanishing noise limit. An analogue of topological equivalence for diffusions\nin this limit is defined in §4.1 to address this shortcoming.\nZero-noise limits. A hope is that Boltzmann-Gibbs distributions of diffusion models\nencode the asymptotic behavior associative memory models in the zero-noise limit. Gener-\nically, this is not the case ( §3.2). However, gradients satisfying the Morse condition have\nwell-defined stable andunstable manifolds . Given a critical point p∈M, the sets\nWs(p) ={x∈M:ϕX\nt(x)→past→ ∞} and\nWu(p) ={x∈M:ϕX\nt(x)→past→ −∞}\nthat consist of those points that flow to past→ ±∞ , are called the stable manifold and\nunstable manifold ofp, respectively. By focusing on stable manifolds, the inconsistency\nabove can be relieved, and some information is retained ( §3.3).\nThe zero-noise limits of families of diffusions with Morse-Smale gradient drift show more\ninteresting behavior. By structural stability, the image of their zero-noise limiting measures\ncan be studied globally under homeomorphisms between topologically equivalent systems.\nWe detail the behavior of zero-noise limits under these maps, as discussed below.\nOne assumption and two generic conditions are imposed to obtain the following main results:\n(i) If V∈Cr(M,R), r≥2 is a Morse function, then on stable manifolds of critical\npoints, zero-noise limits of families {Xϵ}ϵ>0vary continuously with the weak topol-\nogy on Borel probability measures and the compact-open Crtopology on real-valued\nfunctions ( §3.3, Proposition 13). That is, on these invariant sets, zero-noise limits are\nrobust to perturbations to drift terms.\n(ii) If V∈Cr(M,R), r≥2 is a Morse-Smale function, regions of convergence of zero-noise\nlimits of families {Xϵ}ϵ>0vary continuously with the weak topology on Borel prob-\nability measures and the compact-open C1topology on flows ( §3.3, Proposition 17).\nThis is a global form of (i) obtained from the map between measures induced by a\nhomeomorphism between topologically equivalent systems. Caveats on the absolute\ncontinuity of the induced measure, or image under this map, must be considered.\nNecessary conditions for this measure to also be a zero-noise limit are given.\n(iii) Bifurcations of one- and two-parameter families of gradients describe memory forma-\ntion ( §4).\n(iv) The probability that (iii) does not hold in the zero-noise limit for diffusions with\ngradient drift vanishes ( §4.1).\n10\n--- Page 11 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n(v) Examples including energy-based models §5.2, Hopfield networks and Boltzmann ma-\nchines §5.3, modern Hopfield networks §5.4, and diffusion models §5.5, are given, along\nwith structural stability criteria for Hopfield and modern Hopfield networks.\nBriefly, (iv) says that learning processes of generative diffusion models are characterized by\nthe bifurcations in (iii) with a caveat that it is a probabilistic notion. This applies to diffu-\nsions with time-varying gradient drift, their learning dynamics, and generation dynamics.\n1.3.1 Overview\n§2 states the assumptions made for stable and reliable associative memory, followed by the\nuniversal approximation of these models by Morse-Smale gradients in §2.2. Generic proper-\nties of associative memory that follow from the Morse-Smale assumptions are described in\n§2.3. In §3, generic zero-noise limits of diffusions with gradient drift are studied along with\ntheir stability. In §4 trajectories in the zero-noise limit are studied along with parameterized\nfamilies of gradients and their bifurcations. §5 provides a few examples. Finally, §6 is a\ndiscussion and summary.\n2 Associative memory and Morse-Smale gradients\nMorse-Smale gradients were suggested to universally approximate gradient-based associa-\ntive memory models in §1.3. This assertion and its implications are detailed in §2.2. First, it\nis shown that the Morse-Smale conditions also arise naturally from basic properties that re-\nliable and stable associative memory models should satisfy. Generic properties of associative\nmemory that follow from this characterization are then detailed.\n2.1 Stable associative memory\nLetMbe a smooth n-manifold. In the dynamical systems view of associative memory, any\nx∈Mis an instantaneous condition of a dynamical system Xdefined by a set of differential\nequations. Suppose that an item p∈M, such as an image, word, sentence, etc., is stored\nin memory. The following are natural to impose for stable, reliable memory recall:\n1. The flow ϕX\ntgenerated by Xis globally defined for all time;\n2. If p∈Mis a memory and U∋pis an open neighborhood of p, then for any q∈U,\nthe orbit ϕX\nt(q) should intersect Ufor all time t >0. In other words, the dynamics\nare asymptotically confined to Uifpis a stored memory;\n3. The number of neurons and memories are finite (applicable even to models with large\nstorage capacity, e.g., Krotov and Hopfield (2016); Ramsauer et al. (2020));\n4. The critical elements and trajectories of Xare stable under small perturbations;\n5. Memories are singular points.\nCompactness (Condition 1). The time integration of a differential equation on a com-\npact manifold produces a one-parameter set of diffeomorphisms ϕX:R×M→M, or\nflow, ϕX\nt:M→Mgiven by a left action of the additive group of real numbers sending\n11\n--- Page 12 ---\nHess and Morris\np7→ϕX\nt(p). Given a time t≥0, the map ϕX\nt(p) solves the differential equation:\nd\ndtϕX\nt(p) =X\u0000\nϕX\nt(p)\u0001\n, ϕX\n0(p) =p . (2.1.8)\nSince Mis compact, by (1), the vector field Xiscomplete7; that is, ϕX\nt(M) is globally\ndefined for all time t∈R. Without a loss of generality8,Mis given the additional structure\nof a Riemannian metric g=Pgijdxi⊗dxj; the pair is denoted ( M, g).\nNon-wandering sets (Condition 2). This is understood more precisely as follows:\nDefinition 5 (Non-wandering set) .A point p∈Mis called a non-wandering point\nff there exists a neighborhood V∋pfor which ϕX\nt(V)∩V̸=∅for|t|> t0. The set of\nnon-wandering points is denoted Ω(X).\nCondition (2) states that the non-wandering set, Ω( X), should contain stored memories.\nThese need not be the only elements of Ω( X). It is reasonable to assume that any point\np∈Ω(X) that is nota stored memory is a critical point. This forbids complicated orbits,\nsuch as quasiperiodic motions that may have unpredictable dynamics.\nFiniteness (Condition 3). By (2), Ω( X) reduces to the set of critical elements of a\nvector field X, and by (3), the number of all such elements is finite9. Therefore, dynamical\nsystems that serve as models of associative memory are restricted – they are those with\nfinite numbers of critical elements.\nStructural and Ω-stability (Condition 4). For systems satisfying conditions (1)-(3),\nthere are a well-studied set of conditions to ensure that Xis structurally stable, satisfying\n(4). These systems, known as Morse-Smale systems, were developed in Smale (1960). The\nset of all such systems on Mis denoted S(M). Requiring that critical elements are stable\nto perturbation is evidently weaker than demanding stability of trajectories. This weaker\nnotion is well-captured by Ω −stability . Let X∈χr(M) and Ω( X) its non-wandering set.\nThe flow ϕX\ntis called Ω−stable if there is a neighborhood UofXsuch that for all Y∈ U,\nthe restriction ϕX\nt|Ω(X)is topologically equivalent to ϕY\nt|Ω(Y). It is generally clear that\nstructural stability implies Ω-stability.\nMemories as singularities (Condition 5). The non-wandering set Ω( X) of a Morse-\nSmale vector field Xconsists of a finite number of critical elements; however, these can\nbe singularities or closed orbits. It is difficult to imagine a widely applicable scenario\nwhere closed orbits are useful for reliable associative recall. Such behavior would introduce\nambiguity, as the dynamics would not converge to a single point.\nReliable models are therefore Morse-Smale systems whose critical elements are a finite\nset of singularities. These vector fields, referred to as Morse-Smale gradient fields , denoted\nG(M), are defined as follows:\n7. If Mis compact, any smooth vector field is complete; see, e.g., Lee (2013), Theorem 9.16 or Palis and\nDe Melo (2012), Proposition 1.3.\n8. Recall that any smooth manifold admits a Riemannian metric; see, e.g., Lee (2006), Chapter 3.\n9. Compactness implies that a Morse function has a finite number of critical points, so (1) and (3) are not\nindependent; see §2.3.1.\n12\n--- Page 13 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nDefinition 6 (Morse-Smale gradient) .A vector field X∈G(M)and is called Morse-\nSmale gradient field10if it satisfies the following:\n1.Ω(X)has finite cardinality and is equal to the union of the critical elements of X,\neach of which is a singular point;\n2. (Morse condition) the critical elements of Xare all hyperbolic;\n3. (Smale condition) if β1andβ2are critical elements of X, then Wu(β1)is transverse\ntoWs(β2).\nGiven X∈χr(M), a critical point p∈Mis ahyperbolic singularity if the spectrum\nofDXp:TpM→TpMis disjoint from the imaginary axis. Since gradients have no closed\norbits, this condition means that DXpdoes not have a zero eigenvalue. This condition also\nimplies that one can take the potential function V:M→RofXto be Morse , i.e., all its\ncritical points are non-degenerate – equivalently, hyperbolic. That the intersection of stable\nand unstable manifolds of distinct critical elements is transversal means that their tangent\nspaces span the tangent space of Mat their intersection. That is, if x∈Wu(βi)∩Ws(βj)\nforβi, βj∈Ω(X) critical elements, then TxM=TxWu(βi) +TxWs(βj).\n2.2 Universal approximation\nThat Morse-Smale gradients are stable and reliable models of associative memory was de-\nscribed in §2.1. The assertion that these systems are generic is now discussed with respect\nto the compact-open topology, which captures the notion that two vector fields should be\nclose if the vector fields and their rthorder partial derivatives are close at all points x∈M\non compact sets. The following definition is from Hirsch (2012), Chapter 2.1.\nDefinition 7 (Compact-open Crtopology) .LetM, N beCrmanifolds with 0≤r <∞\nandCr(M, N )the space of Crmaps from MtoN. The compact-open Crtopology on\nCr(M, N )has as a basis the following elements. Let (ϕ, U),(ψ, V)be charts on Mand\nNandf∈Cr(M, N ); let K⊂Ube a compact subset with f(K)⊂Vand0≤ϵ <∞.\nA weak subbasic neighborhood Nr(f; (ϕ, U),(ψ, V), K, ϵ )is defined to be a set of Crmaps\ng:M→Nsuch that g(K)⊂Vand\n||Dk(ψ◦f◦ϕ−1)(x)−Dk(ψ◦g◦ϕ−1)(x)||< ϵ\nfor all x∈ϕ(K)andk= 0, ..., r . A basis for C∞is obtained by taking the union of the\ntopologies induced by the inclusions C∞(M, N )→Cr(M, N ).\nThe set of Crdiffeomorphisms, Diffr(M), form a subspace of Cr(M, M ). Likewise, a\nvector field X∈χr(M) is a Crmap X:M→TM which assigns to each point p∈Ma\nvector X(p)∈TpM, so Definition 7 applies to Crvector fields as maps X∈Cr(M, TM ).\nThe set of real-valued functions Cr(M,R) can also be given the compact open topology. It\nis a classic result that Morse functions are open and dense for r≥2; see §B.\nGiven any Riemannian metric on a compact n−manifold M, Smale showed that S(M)∩\nGrad( M) =G(M) forms a dense open set in the space of gradient vector fields, Grad( M),\n10. The definition of S(M) allows Xto also have a finite number of closed orbits.\n13\n--- Page 14 ---\nHess and Morris\nwith the C1topology (Smale (1961); Palis (1969)). In fact, the Morse-Smale gradients form\na generic subset of Gradr(M) for any 1 ≤r≤ ∞11. Let ( U, h) be a coordinate chart at p.\nIn local coordinates ( x1, ..., xn), these systems are written as an inverse metric gij= (g)−1\nij\ntimes the gradient of a potential function V:M→R:˙xi=−Pn\nj=1gij∂V\n∂xj.\nThis equation is standard for computing Riemannian gradients – the inverse metric\nestablishes an isomorphism TM∼=T∗Mbetween the tangent bundle TM and its dual\nT∗M. The last term is a covector, ∂V /∂xj∈T∗\nxM. Contracting it with the inverse metric\nensures that the left-hand side is an element of TxMdefined independent of coordinates.\n2.3 Generic properties\nGeneric properties of associative memory that follow from the Morse-Smale conditions are\nnow described – we are not aware of such a discussion elsewhere. Properties of invariant\nmanifolds described in §2.3.2 are important in §3. Structural and Ω-stability ( §2.3.3) are\noften assumed in the remainder of the document.\n2.3.1 Asymptotic stability\nIn Hopfield (1982), asymptotically stability is emphasized as a defining property of associa-\ntive memory – if a sufficiently small perturbation is applied to neuronal states x∈UforU\na neighborhood of a stored memory p, the network evolves to restore past→ ∞ . Given\na Morse function V:M→Rand a nondegenerate critical point p∈M, the Morse lemma\nimplies that, at a non-degenerate critical point p∈M, there is a coordinate chart ( U, h),\ncalled a Morse chart , with U∋pandh(p) = 0, so that\n(V◦h−1)(x1, ..., x n) =V(p)−x2\n1−x2\n2...−x2\nλ+x2\nλ+1+...+x2\nn\nforx∈U, where h(x) = ( x1, ..., x m)∈h(U) and λis the index of Vatp(see, e.g.,\nMilnor (2016), Lemma 2.2). In these coordinates, the gradient of Vhas a unique zero at\np. Consequently, the critical points of Morse functions are isolated, and the attractors of\nthese gradient systems are asymptotically stable.\n2.3.2 Structure of invariant manifolds\nThe stable and unstable manifolds of gradients of Morse functions have two key properties\nthat are used to describe generic zero-noise limits in §3. First, they provide a finite de-\ncomposition of a compact manifold into their disjoint union. In addition, they have simple\ncharacterizations as embedded discs that vary continuously in a sense made precise below.\nDecomposition. LetX=−∇gVbe a gradient field of a Morse function V:M→R.\nSince Mis compact and the critical elements of Vare isolated, there are finitely many of\nthem: Crit( V) =Sn\ni=1βiforn >0 finite. Moreover, V(ϕX\nt(x)) is strictly decreasing off of\ncritical points, and by compactness, it is bounded below. Therefore, the ω−limit set of each\nx∈M, that is, the set ω(x) ={y∈M|ϕX\nt(x)→yast→ ∞} , is a single critical point.\nConsequently, every point x∈Mlies on the stable manifold of a unique critical point.\n11. See, e.g., Banyaga et al. (2004), Theorem 6.6 or Audin et al. (2014), Theorem 2.2.5 for accessible proofs\nthat the Morse-Smale gradients are generic.\n14\n--- Page 15 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nThe union of the stable manifolds covers M, and by uniqueness, any two stable man-\nifolds are disjoint: Ws(βi)∩Ws(βj) =∅for distinct βi, βj∈Crit(V). It follows that M\ndecomposes into a disjoint union M=Sn\ni=1Ws(βi) (Figure 2). The analogous result holds\nfor unstable manifolds by considering asymptotic orbits as t→ −∞ .\nStable Manifold Theorem. By the Hartman-Grobman theorem, if p∈Mis a hyper-\nbolic fixed point of a vector field X, then Xis locally (topologically) equivalent to its\nlinearization DXp(see Palis and De Melo (2012), Chapter 2.4). That is, DXpdefines a\nhyperbolic linear vector field L(TpM). Any such vector field induces a splitting of TpMinto\nstable and unstable directions, TpM=Es⊕Euwhere the stable directions have eigenvalues\nwith negative real part and the unstable directions have eigenvalues with positive real part\n(Palis and De Melo (2012), Proposition 2.15).\nLetL(TpM) =DXpand denote the splitting of the tangent space at punder Lby\nTpM=Es⊕Eu. Then for any q∈Es,Lt(q)→0 ast→ ∞ and for q∈Euast→ −∞ . That\nis, there is an adapted norm with max {||L|Es||,||L−1|Eu||}<1 so that L|Esis contracting\nandL|Euis expanding. For any other q /∈Es∪Eu, the magnitude ||Lt(q)|| → ∞ , so\nWs(0) = EsandWu(0) = Eu.\nThe local version of the Stable Manifold Theorem says that this behavior of DXpis\ncaptured in a neighborhood of p. That is, for a sufficiently small δ >0, there exist local\nstable and unstable manifolds of pof radius δdefined by the sets\nWs\nBδ(p) ={x∈B(p, δ) :ϕX\nt(x)∈B(p, δ) for t≥0}and\nWu\nBδ(p) ={x∈B(p, δ) :ϕX\n−t(x)∈B(p, δ) for t≥0},\nwhere B(p, δ) is a ball of radius δcentered at p, for which the following hold (adapted from\nPalis and De Melo (2012), Chapter 2.6):\n1.Ws\nBδ(p)⊂Ws(p) and Wu\nBδ(p)⊂Wu(p) are embedded topological discs in Mwith the\nsame regularity as Xwhose dimension is equal to the dimensions of the stable and\nunstable subspaces, EsandEu, respectively;\n2.Ws(p) =S\nt≥0ϕX\n−t(Ws\nBδ(p)) and Wu(p) =S\nt≥0ϕX\nt(Wu\nBδ(p)). Therefore, there exists\ninjective topological immersions φs:Es→Mandφu:Eu→Mwhose images are\nWs(p) and Wu(p), respectively.\nA standard proof of the global Stable Manifold Theorem establishes the first property and\nextends the results using the second. It is long but well-documented (e.g., Palis and De Melo\n(2012) and Shub (2013)); see Smale (1967) for more references.\nIfXis a Morse gradient field, the global version can be sharpened. Let V:M→R\nbe a Morse function, X=−∇gVa gradient field, and δ >0 such that the local stable\nmanifold theorem holds. Then for any x∈Ws\nBδ(p), the setS\nt≥0ϕX\nt(x) contains no critical\npoints except for p. A similar result holds for the unstable manifold Wu\nBδ(p). A classic\nresult in Morse theory implies that these sets extend to all of Ws(p) and Wu(p) smoothly\n(with the same regularity as X). Moreover, this extension, and thus Ws(p) and Wu(p),\nvary continuously in the Crtopology. These results give the following theorem.\nTheorem 8 (Stable Manifold Theorem for Morse functions) .LetX=−∇gVbe a gradient\nfield on a Riemannian n-manifold (M, g)with V∈Cr+1(M,R), r≥1a Morse function.\n15\n--- Page 16 ---\nHess and Morris\nLetp∈Mbe a hyperbolic fixed point of Vwith index λp, and Es(resp. Eu) the stable\n(resp. unstable) subspace of DXp=L. Then the following hold,\n1.Ws(p)is an embedded differentiable manifold in Mwith the same regularity as ϕX\nt,\nand the tangent space Tp(Ws(p))atpisEs; hence, Ws(p)andWu(p)are embedded\n(open) topological discs with dimensions n−λpandλp, respectively.\n2. Let D⊂Ws(p)be an embedded disc containing p. Then there is a neighborhood\nN ⊂ Diffr(M)in which all g∈ N have a unique hyperbolic fixed point pgcontained\nin a neighborhood U∋p. Hence, for any ϵ >0, there is a neighborhood ˜N ⊂ N ofϕX\nt\nsuch that, for each g∈˜N, there exists a disc Dg⊂Ws(pg)that is ϵ-Crclose to D.\nByϵ-Crclose , we mean that there exists a Crdiffeomorphism h:D→Dg⊂Msuch\nthatig◦his contained within an ϵ-neighborhood of iin the Crtopology where i:D ,→M\nandig:Dg,→Mare inclusions.\nTheorem 8 is applied in §3, and a few lemmas, adapted from Milnor (1965), Section 2,\nare used to prove it in §B. Refer to Banyaga et al. (2004), Chapter 4 for a detailed account\nof (1). Our proof of (1) is also motivated by Cohen et al. (2006), Chapter 6.3. The proof of\n(2) essentially shows that Morse functions are generic, as in Milnor (1965), Theorem 2.7.\n2.3.3 Structural and Ω−stability\nThe introduction of Morse-Smale systems in Smale (1960) was accompanied by a conjecture\nthat its elements were structurally stable. This is proven in the main theorem of Smale and\nPalis (1970) and applies to Morse-Smale gradients. In particular, a gradient vector field is\nstructurally stable if and only if it is Morse-Smale .\nFrom the definition of non-wandering set, a homeomorphism h:M→Mestablishing\na topological equivalence between orbits of X, Y∈χr(M) restricts to a homeomorphism\nbetween non-wandering sets: h|Ω(X)= Ω(Y). It is instructive to see that, for Morse-Smale\nsystems, with Ω( X) equal to the union of the set of critical elements, denoted Crit( X), the\nmap hrestricts to a homeomorphism h|Crit(X)= Crit( Y). This restriction is used in §3.3\n2.3.4 Hierarchical organization of associative memory\nFinally, associated with a Morse-Smale system is a directed acyclic graph (DAG) whose\nvertices are critical elements β1, ..., β nconnected by a directed edge, denoted βi≻βj, if\nthere is a trajectory from βitoβj(Figure 2). Equivalently, βi≻βjifWu(βi)∩Ws(βj)̸=∅.\nThe DAG for a Morse-Smale system defines a partial order on its set of critical elements.\nIt has the following properties (Meyer (1968); Smale (1960)):\n•(No self-connections) βi⊁βi;\n•(Transitive edges) if βi≻βjandβj≻βk, then βi≻βk;\n•(Ordered by index) if βi≻βj, then dim( Wu(βi))≥dim(Wu(βj))\nEquality in the relation dim( Wu(βi))≥dim(Wu(βj)) occurs only if βjis a closed orbit.\nThese DAGs are topological invariants in the following sense. Denote the partial order\nofX∈S(M) byP(X) and define a diagram isomorphism as a bijective, order- and index-\npreserving map ρ:P(X)→P(Y). If two Morse-Smale flows are topologically equivalent,\n16\n--- Page 17 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n2\n 1\n 0 1 22\n1\n012v1a\nB\nCA\n2\n 1\n 0 1 22\n1\n012b\nB\nCA\nB CAAAc\n2\n 0 2\nv23\n2\n1\n0123v1\nCE\nD\nAB\n2\n 0 2\nv23\n2\n1\n0123\nCE\nD\nAB\nC D EA B A B A B A B A B048121620V(v)\n081624324048V(v)Trajectory Energy Saddle Attractor / Memory Stable manifold\nFigure 2: Generic phase space decomposition and hierarchical organization (DAG)\nof associative memory. (a) Phase portraits of Morse-Smale gradients overlayed on their corre-\nsponding energy surfaces. The two attractor system (top) is the dual-well model of Example 1. A\ndual cusp geometry describes the three attractor system (bottom) and corresponds to the potential\nV=1\n10\u0000\nv4\n1+v4\n2−3v3\n2+ 7v2v2\n1+1\n10v2\n2−2v2\u0001\n. Saddles (white crosses) and attractors (black circles)\nare labeled alphabetically. (b)Decomposition of the phase space into disjoint stable manifolds of\neach critical element (red, green, and blue shades). (c)Invariant DAGs of the dual-well model (top)\nand dual cusp model (bottom). Nodes correspond to critical elements and are orded by their index.\nTop layer nodes correspond to index 1 saddle points with edges to index 0 attractors (memories).\nthen they are diagram isomorphic – their stable and unstable manifolds agree (modulo\nhomeomorphism), and their critical elements are in one-to-one correspondence with the\nsame indices. In addition, P(X) is stable up to diagram isomorphism under small Cr\nperturbations to X(Palis (1969)).\n3 Zero-noise limits and stability\nLetϕX\ntbe a gradient flow generated by X=−∇gVon a Riemannian manifold ( M, g).\nAttention is now turned to generic zero-noise limits of small random perturbations Xϵlike\n(1.2.5). The potential V∈Cr(M,R) is assumed Morse. The Smale condition is not always\nneeded, but it is used to obtain global results on the stability of zero-noise limits in §3.3.\n3.1 Generic zero-noise limits\nA simple hypothesis, apparent in Figure 1, is that zero-noise limits of a family {Xϵ}ϵ>0\nconcentrate on attractors of X. This is essentially correct, but more can be said. If V\n17\n--- Page 18 ---\nHess and Morris\nis Morse and Mis compact, then Mdecomposes into a union M=Sn\ni=1Ws(βi), where\n{β1, ..., β n}= Ω(X) are the isolated critical elements of X. Moreover, if µisϕX\nt-invariant,\nthen it must concentrate on Ω( X) by Poincar´ e recurrence, i.e., µ(Ω(X)) = 1. Since Ω( X) is\na discrete set, µshould be a weighted sum of Dirac delta functions centered on {β1, ..., β n}.\nThis is the content of Proposition 9.\nProposition 9 (Generic zero-noise limits.) .Let(M, g)be a Riemannian manifold and\nX=−∇gVa gradient vector field on MwithV∈Cr(M,R)a Morse function where r≥2;\nlet{Xϵ}ϵ>0be a family of small random perturbations of ϕX\ntwith invariant measures µϵfor\nXϵat a given ϵ >0. Then as ϵ→0,{µϵ}ϵ>0converges weakly to an invariant measure µ\nofϕX\ntconsisting of a weighted sum µ=Pn\niwiδβi, where {β1, ..., β n}= Ω(X).\nSince Mis compact, Xϵare non-explosive and admit invariant measures µϵ. Moreover,\nXis a gradient system, so the measures µϵcan be studied analytically through an appli-\ncation of a convenient inequality in Hwang (1980) that bounds the measure assigned by a\nBoltzmann-Gibbs distribution to high-energy states. The following proof is straightforward\n– apply this inequality on a stable manifold and extend it globally using the stable manifold\ndecomposition induced by the Morse condition.\nProof Since Mis compact, each Xϵadmits an invariant measure and M, the space of Borel\nprobability measures on Mwith the weak topology, is compact12. Since Mis compact, {µϵ}\nistight13. If the sequence {µϵ}does not converge, simply pass to a convergent subsequence\n{µϵn}. Therefore, {Xϵ}has a zero-noise limit, but it may not be unique. Call this limit µ′.\nIt remains to show that µ′isµas asserted. By definition of small random perturbation,\npϵ(·, x)→δϕX\nt(x)asϵ→0. Consider an invariant probability measure µ′on a stable manifold\nWs(βi). From the definition of invariant measure and small random perturbation:\nµϵ(Ws(βi)) =Z\nMpϵ(t, x, Ws(βi))µϵ(dvolg(x)) t >0, x∈M\n→Z\nMδϕX\nt(x)(Ws(βi))dµ′(x)\n→Z\nWs(βi)dµ′(x) as ϵ→0.\nSuppose µ′does not concentrate on {βi}. Let{am}be a sequence converging to inf xV(x) =\nβionWs(βi). By assumption, Pϵ(V(x)≥am)→P(V(x)≥am). But,\nPϵ(V(x)≥am) =\"Z\nWs(βi)e−(V(x))\nϵ2dvolg(x)#−1\"Z\nV(x)≥ame−(V(x))\nϵ2dvolg(x)#\n≤\"Z\nWs(βi)e−(V(x))\nϵ2dvolg(x)#−1\"Z\nV(x)<ame−(V(x)−am)\nϵ2 dvolg(x)#\n→0 as ϵ→0,\n12. See, e.g., Parthasarathy (2005), Page 45.\n13. By Prokhorov’s theorem; see Rezakhanlou (2015), Chapter 2.4.\n18\n--- Page 19 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nwhich implies that P(V(x)≥am) = 0. The complement of the set {x∈Ws(βi) :V(x)≥\nβi}is{βi}, implying that P(Ws(βi)) = 0, which is a contradiction, since P(Ws(βi)) = 1,\ni.e.,µ′is a valid probability measure on Ws(βi). Therefore µ′(Ws(βi)) has full measure\non{βi}. That is, the complement Ws(βi)\\ {βi}has measure zero, and it holds that\nµ′(Ws(βi)) =µ′({βi}). We may write,\nZ\nWs(βi)dµ′(x) =Z\nWs(βi)wiδβi(dvolg(x)).\nThe argument holds for the stable manifold of each critical element βi. Since the unionSn\ni=1Ws(βi) covers M, the complement has measure zero. Therefore,\nµ′=nX\niwiδβi andnX\niwi= 1,\nwhere the constraintPn\niwi= 1 ensures that µ′is a valid probability measure.\n3.2 Physical measures and resonance\nLetX=−∇gVbe a gradient system with V∈Cr(M,R), r≥2 a Morse function. Suppose\nthatµ=Pn\niwiδβiis the zero-noise limit of a family of small random perturbations {Xϵ}ϵ>0\nof the gradient flow ϕX\ntgenerated by X, according to Proposition 9.\nA na¨ ıve hope is that the coefficients wiare determined by the relative volumes of the\nstable manifolds Ws(βi) ofX. If a set Aof positive Lebesgue measure were chosen uni-\nformly at random, then the expected value of an observable f∈C0\nb(M,R) with respect to\nthis measure could be obtained from the asymptotic behavior ϕX\nt(A) when t→ ∞ . This\nnormalization would make µas ”close” as possible to normalized Lebesgue measure on\n(M, g). The idea of a physical measure makes this precise and more general:\nDefinition 10 (Physical measure, adapted from Young (2002)) .Letϕ:M→Mbe mea-\nsurable and µ∈ M an invariant probability measure under ϕ. Then µis called a physical\nmeasure if there exists a positive Lebesgue measure set A⊂Msuch that for any continuous\nobservable f∈C0\nb(M,R)andx∈A,limT→∞1\nTRT\n0f(ϕt(x))dt→R\nf dµ.\nThe interpretation commonly attributed to Kolmogorov is that physical measures are\nthose that are actually observable. In some cases, zero-noise limits are physical measures\n– refer to Young (2002), Section 2 for further remarks and Theorem 1 for its relationship\nto other conditions. However, there is no constraint that wi>0 for the zero-noise limit\nµ=Pn\niwiδβi. Actually, the inequality in the proof implies that µconcentrates on the\nattractor(s) with uniformly minimal energy; see Hwang (1980) for a related discussion.\nEvidently, if µ(Ws(βi))>0, i=a, bfor stable manifolds Ws(βa), Ws(βb) of distinct\ncritical points βa, βb, then the Morse function Vmust be resonant14. That is, there are at\nleast two equal critical values V(βa) and V(βb). It is easy to see that the zero-noise limit\nin this case is a uniform probability measure with equal weights waandwb.\n14. Figure 1 depicts a resonant Morse function and the zero-noise limit concentrating on the two attractors\nof the corresponding gradient system.\n19\n--- Page 20 ---\nHess and Morris\nNonresonant, or excellent , Morse functions are generic – they form an open and dense\nsubset of C2(M,R)15. Therefore, a zero-noise limit µ|Ws(βi)of{Xϵ}restricted to a stable\nmanifold Ws(βi) is generically not a physical measure. For example, if βi̸= inf xV(x) is not\nthe unique critical point with uniformly minimal critical value and A⊂Ws(βi) is a subset\nof positive Lebesgue measure, then the integralR\nf dµ will be zero, which is not equal to\nthe time average of an observable f:M→Runder the flow ϕX\nt(A) unless f(βi) is zero.\n3.3 Stability\nIn view of §3.2, the stability of zero-noise limits is now studied on stable manifolds of a\ngradient system of a Morse function and then globally, enabled by structural stability. On\nstable manifolds, these zero-noise limits are physical measures. First, it is known that\nzero-noise limits are closely related to the stochastic stability of Borel probability measures\n(Cowieson and Young (2005)).\nDefinition 11 (Stochastic stability) .Let(M, g)be a Riemannian manifold and Mthe set\nof Borel probability measures on Mwith the weak topology. A probability measure µ∈ M is\nstochastically stable with respect to small random perturbations from a class of Markov\nchains Fif for every family of small random perturbations {Xϵ}ϵ>0off, with Xϵ∈ F, the\ncollection of stationary measures {µϵ}ϵ>0converges weakly to µasϵ→0.\nThe following corollary is a consequence of Definition 11. It says that zero-noise limits\nfor small random perturbations of generic associative memory models are stochastically\nstable with respect to white-noise perturbations.\nCorollary 12 (Stochastic stability of zero-noise limits) .Let(M, g)be a Riemannian man-\nifold and X=−∇gVbe a gradient field with V∈Cr(M,R), r≥2a Morse function. Let F\nbe the collection of Markov diffusion processes generated by Brownian motion, and {Xϵ}ϵ>0\nbe a family of small random perturbations of the gradient flow ϕX\ntwithXϵ∈ F. Then the\nzero-noise limit µof{Xϵ}ϵ>0is stochastically stable.\nProof The small random perturbations {Xϵ}ϵ>0are arbitrary in Proposition 9. Apply the\ndefinition of stochastic stability.\nThe following proposition is motivated by Bowen and Ruelle (1975), Proposition 5.4\nand details the stability, or dependence, of zero-noise limits on stable manifolds to Cr+1\nperturbations to Morse functions. The proof follows from the Stable Manifold Theorem for\na Morse function (Theorem 8) combined with Proposition 9.\nProposition 13 (Continuous dependence of zero-noise limits) .LetϕX\ntbe a Morse gradient\nflow generated by X=−∇gVforV∈Cr+1(M,R), r≥1a Morse function. Denote the\nset of critical elements of Xby{βi, ..., β n}and let Ws(βa)be a stable manifold for βa,\na∈1, ..., n ; let{Xϵ}ϵ>0be a family of small random perturbations of X. Then the zero\nnoise limit of {Xϵ}ϵ>0onWs(βa)depends continuously on the Crflow ϕX\ntfor the weak\ntopology on measures and the compact-open Cr+1topology on real-valued functions.\n15. See, e.g., Milnor (1965), Lemma 2.8 or Nicolaescu et al. (2007), Chapter 1.2\n20\n--- Page 21 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nProof Letµ, and µ′be zero-noise limits for small random perturbations {Xϵ}ϵ>0and\n{X′ϵ}ϵ>0of the gradient flows ϕX\ntandϕX′\nt, respectively, with X′∈Gradr(M). We have\nto show that the sequence {µ′}converges to µweakly on Ws(βa) when V′→Vin the\nCr+1sense, where X′=−∇gV′. Let ( U1, ψ1), ...,(Uk, ψk) be a finite covering of M(by\ncompactness). Choose compact sets Ki⊂Uisuch thatS\niKicovers M. From Lemma 28,\nthere exists an α >0 so that all functions V′∈Cr+1(M,R) with\n||Dj(V◦ψ−1)(x)−Dj(V′◦ψ−1)(x)||< α\nhave non-degenerate critical elements on M, where x∈ψ(K) with K=Kifor some iand\nj= 0, ..., r + 1. This α-neighborhood of Vinduces a neighborhood of ∇gVinCr(M, TM )\nand similarly on flows by the uniqueness of the solutions to (2.1.8). That is, for V′within\nαofVin the Cr+1sense above, the flows ϕX\ntandϕX′\ntare within some η >0. For any\nδ≤η, non-degeneracy of critical points is preserved since V′is within αofV. Call this\nneighborhood U. Convergence in the compact-open Crtopology is uniform. Therefore for\nanyδ >0, there exists an N∈Z+, such that for all n≥N, it holds that\n||Dl(ψ◦ϕX′\nn\nt◦ψ−1)(x)−Dl(ψ◦ϕX\nt◦ψ−1)(x)||< δ\nforx∈ψ(Ki) for some Kiandl= 0, ..., r . Call this δ-neighborhood V. Let N=U ∩ V .\nThen for any ϕX′\nn\nt∈ N, the stable manifolds of its critical elements are well-defined, since\nthe set Crit( V′\nn) contains no degenerate critical points, and by Proposition 9, the zero-noise\nlimit µ′\nntakes the form of a weighted sum of Dirac delta functions. By the Stable Manifold\nTheorem for a Morse function (Theorem 8), δcan be chosen sufficiently small so the stable\nmanifold Ws(β′n\na) isϵ-Crclose to Ws(βa) for any ϵ >0. That is, Ws(β′n\na)→Ws(βa)\nin the Crsense as V′\nn→Vin the Cr+1sense, and β′n\na→βa. On Ws(βa),µis written\nµ=R\nWs(βa)waδβa(dvolg(x)) subject to the constraint µ(Ws(βa)) = 1. Simply, wa= 1.\nThe result follows immediately since β′n\na→βaand by Proposition 9, µ′\nnis similarly written\nµ′\nn=R\nWs(β′na)w′n\naδβ′na(dvolg(x)) with w′\na= 1. We have that for any f∈C0\nb(M),\nZ\nWs(β′na)f dµ′\nn=w′n\naf(β′n\na)→waf(βa) =Z\nWs(βa)f dµ.\nTherefore, the subsequence {µ′\nn}converges weakly to µ. To show that {µ′}converges weakly\ntoµ, proceed by contradiction. Suppose that {µ′}does not converge weakly to µ. Then\nthere exists a g∈C0\nb(Ws(βa)), a number δ >0, and a subsequence {µ′\nk}for which\n\f\f\f\f\fZ\nWs(βa)g dµ−Z\nWs(β′ka)g dµ′\nk\f\f\f\f\f≥δ\nfor all k≥1. Therefore no subsequence converges, which is a contradiction.\nIfXis Morse-Smale, the invariant measures of randomly perturbed and deterministic\nsystems can be studied globally. Since Xis structurally stable, there is a neighborhood\n21\n--- Page 22 ---\nHess and Morris\nN ⊂ χ1(M) ofXwhere each Y∈ N is topologically equivalent to X. For each Ythere is\na homeomorphism hY:M→Mtaking orbits of Yto orbits of Xpreserving orientation.\nAny homeomorphism h:M→Mis an automorphism of the measurable space ( M,B)\nas it is a measurable bijection with a measurable inverse. When ( M,B) is equipped with a\nprobability measure µY∈ M , it becomes a Borel probability space ( M,B, µY). The image\norpushforward ofµYunder his given by h#µY(A) =µY(h−1(A)) for A∈ B. Similarly, an\nisomorphism ψ: (MX,BX, µX)→(MY,BY, µY) between measure spaces is a measurable\nbijection with measurable inverse for which the measures agree: µX(A) =µY(ψ(A)) for\nallA∈ B X. Ifh:M→Mis a homeomorphism, then h: (M,B, µY)→(M,B, h#µY)\nis an isomorphism of measure spaces, since it is an isomorphism of measurable spaces and\nh#µX(h(A)) =µX(h−1(h(A))) = µX(A) for A∈ BX.\nRecall that a ϕX\nt-invariant measure µis a measure for which ϕX\nt#µ=µ. A flow ϕX\nt\nequipped with a ϕX\nt-invariant measure µdefines a flow over the measure space ( M,B, µ);\nsee Sinai (1989), Definition 1.4 for a definition of flows over measure spaces. We focus on\ngeneralizations of measure space isomorphisms to such flows.\nDefinition 14 (Metrically isomorphic16).Two flows on ϕX\ntandϕY\nton(M,B)with invari-\nant measures µXandµY, are called metrically conjugate if there exists invariant subsets\nM1⊂MandM2⊂Mwith µX(MX) =µY(MY) = 1 and an isomorphism of measure\nspaces h: (MX,BX, µX)→(MY,BY, µY)so that ϕY\nt(h(x)) = h(ϕX\nt(x))for all t∈Rand\nx∈MX. If there are times t1, t2so that h(ϕX\nt1(x)) =ϕY\nt2(h(x))for all t∈Randx∈MX,\nthen ϕX\ntandϕY\ntaremetrically equivalent .\nIf a flow ϕX\nton (M,B, µ) is topologically conjugate (resp. equivalent) to ϕY\nt, then it\nis metrically conjugate (resp. equivalent) to ϕY\ntas a flow on ( M,B, h#µX)17. Zero-noise\nlimits are now globally described using structural stability inherited by the Morse-Smale\ncondition. Two lemmas, proven in §A, are needed to prove Proposition 17.\nLemma 15 (Homeomorphisms preserve weak convergence) .Suppose that µandνare\nBorel probability measures on (M,B)and let {µn}be a sequence converging weakly to µ. If\nh:M→Mis a homeomorphism and h#µ=ν, then h#µnconverges weakly to ν.\nLemma 16 (Topological equivalence implies metric equivalence) .Let(M, g)be a compact\nRiemannian manifold, XaCrvector field on M, and µan invariant Borel probability\nmeasure under the flow generated by X. If Yis topologically equivalent to Xunder an\norientation preserving homeomorphism h:M→M, then h#µis invariant under the flow\ngenerated by Yandh: (M,B, µ)→(M,B, h#µ)is a metric equivalence between them as\nflows over measure spaces.\nProposition 17 (Continuous dependence of region of convergence) .LetϕX\ntbe a Morse-\nSmale gradient flow on a Riemannian manifold (M, g)and{Xϵ}ϵ>0small random pertur-\nbations of ϕX\ntwith zero-noise limit µ. A region of convergence of invariant measures {µϵ}\nto the zero-noise limit of {Xϵ}ϵ>0depends continuously on the CrflowϕX\nt, r≥1for the\nweak topology on measures and the compact-open C1topology on flows.\n16. Definition 14 adapts Sinai (1989), Definition 1.6, where metrically conjugate flows are called metrically\nisomorphic. ”Conjugate” and ”equivalent” are distinguished to agree with topologically conjugate and\nequivalent deterministic flows.\n17. See the proof of Lemma 16 in §A that shows that topological equivalence implies metric equivalence.\n22\n--- Page 23 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nProof Letµbe the (zero-noise) invariant measure of ϕX\nt. We aim to show that if ϕX′\nt→ϕX\nt\nin the C1sense, a region of convergence of the sequence {µϵ}toµvaries continuously in the\nweak topology on measures and the C1topology on flows. That is, we aim to show that if\nϕX′\nt→ϕX\nt, and the sequence of invariant measures {µϵ}ϵ>0converges weakly to µasϵ→0,\nthen a sequence {νϵ}converges weakly to a ϕX′\nt-invariant measure ν.\nSince ϕX\ntis Morse-Smale, it is structurally stable. Then there exists a neighborhood V\nofϕX\ntso that any ϕY\nt∈ Vis topologically equivalent to ϕX\nt. Since ϕX′\nt→ϕX\ntuniformly,\nfor any neighborhood UofϕX\ntthere exists an Nso that for all n≥Nthe flow ϕX′\nn\ntis in\nU. SetN=U ∩ V . Then each ϕX′\nm\nt∈ N is topologically equivalent to ϕX\nt. Therefore, each\nϕX′\nm\nt∈ N can be equipped with a homeomorphism hm:M→Mso that for times tandtm,\nthe following holds: hm(ϕX\nt(x)) =ϕX′\nm\ntm(hm(x)). Since hmis a topological equivalence, and\nµisϕX\nt-invariant, Lemma 16 implies that the image of µunder hm, denoted νm=hm#µ, is\ninvariant under ϕX′\nm\ntmso that hmestablishes a metric equivalence on flows over the measure\nspaces ( M,B, µ) and ( M,B, νm). Since µis the zero-noise limit of {Xϵ}ϵ>0, the sequence\n{µϵ}converges to µweakly, by definition. Given a convergent subsequence {µϵk}, define\nνϵkm=hm#µϵk. By Lemma 15, for each νm, we have that νϵkm→νm. Application of the\nsubsequence principle from Proposition 13 gives that νϵ\nm→νmfor each νm.\nLetX=−∇gVbe a Morse-Smale gradient field and {Xϵ}be a family of small random\nperturbations of ϕX\ntwith zero-noise limit µ. Proposition 17 says that there exists a neigh-\nborhood NofϕX\ntwere each ϕY\nt∈ N is topologically equivalent to ϕX\ntand can be equipped\nwith a homeomorphism that induces a commutative diagram on probability measures:\nµϵµ\nh#µϵνw\nϵ→0\nh# h#\nw\nwhere horizontal arrowsw− →indicate weak convergence in the limit of vanishing noise.\nRemark 18. The image of µϵunder h, that is, νϵ=h#µϵ, at a given noise-level ϵ >0,\nmay not be a Boltzmann-Gibbs distribution or even absolutely continuous with respect to\nLebesgue measure on (M, g).\nThe properties of νin Proposition 17 and whether it is a zero-noise limiting measure are\ngiven as follows. Since Mis compact and Vis Morse, the non-wandering set Ω( X) is a finite\nnumber of hyperbolic critical points {β1, ..., β n}. By Proposition 9, the zero-noise limit µ\nis a finite sum of delta functions: µ=Pn\ni=1wiδβi, withPn\ni=1wi= 1. Since ϕX\ntandϕY\nt\nare topologically equivalent, the restriction of hto Ω( X) gives h|Ω(X)= Ω(Y) where Ω( Y)\nis a union of a finite number of hyperbolic critical elements. That is, Ω( Y) =Sn\ni=1{β′\ni}=Sn\ni=1h({βi}). Since Ω( Y) is a finite union of hyperbolic critical elements, Y=−∇g′V′for\na Riemannian metric g′onMand a Morse function V′.\nGenerically, Vis an excellent Morse function, so the critical points of Xcan be ordered\nby their critical values: V(β1)> V(β2)> ... > V (βn). By definition of the pushforward\n23\n--- Page 24 ---\nHess and Morris\nmeasure, h#µ=µ(h−1(A)) for A∈ B. Consequently, h#µ=P\ni=1w′\niδh(βi)where w′\niis\nequal to the coefficient wifor which h−1(β′\ni) =βi. We obtain the following:\n1.νis the zero-noise limit for small random perturbations {Yϵ}ϵ>0of the flow ϕY\ntif and\nonly if βn= inf βiV′(h(βi)). That is, if and only if the critical element with uniformly\nminimal energy for the gradient system Xis that with minimal energy for Y.\n2. On a stable manifold Ws(βi) ofXwith i= 1, ...n, the limiting measure νcoincides\nwith the zero-noise limit µof the family of small random perturbations {Xϵ}ϵ>0.\n4 Generation, learning, and stable families of gradients\nThis section analyzes how qualitative changes, or bifurcations, of associative memory models\nand their small random perturbations capture their learning and generation dynamics. Let\n(M, g) be a Riemann manifold and denote the space of smooth symmetric (0 ,2)-tensors on\nMbyC∞(M, S2(T∗M)). The space of Riemannian metrics is an open subspace R(M)⊂\nC∞(M, S2(T∗M) (e.g., Tuschmann and Wraith (2015)). Let θ={θg, θV, θt}parameterize\na Riemannian metric gθ∈ R(M), a real-valued function Vθ∈C∞(M,R), and an optional\ntime parameter t∈R.\nLetL:θ→Rbe a smooth loss function. We consider four scenarios defined by families\nof vector fields Xθ:=−∇gθVθand diffusion processes with gradient drift like (1.2.5):\nExample 2 (Optimizing time-independent systems) .Gradient-descent in η∈Rwith re-\nspect to the parameters θ,\n˙θη=−∇θηL(θη),\nproduces a one-parameter family of gradients {Xθη}η∈R, with Xθη:=−∇gθηVθη, that vary\nsmoothly with η. For η1< η2, the family {Xθη}η∈[η1,η2]traces a curve in the space of smooth\nvector fields. For a fixed ϵ >0, a one-parameter family {Xϵ\nη}η∈Ris also obtained with\ndxϵ\nt=−∇gθηVϵ\nθη(xϵ\nt)dt+ϵση(xϵ\nt)dwt.\nExample 3 (Generation with time-varying drift) .Let{gt}t∈Rand{Vt}t∈Rvary smoothly\nwith time. Define Xt:=−∇gtVt. Solutions to the time-dependent equation,\ndxϵ\nt=−∇gtVϵ\nt(xϵ\nt)dt+ϵσt(xϵ\nt)dwt,\ndefine a family {Xϵ\nt}t∈R. Atϵ= 0, a one-parameter family of gradients is obtained.\nExample 4 (Optimizing time-varying associative memory) .When θg, θVvary smoothly\nin time t∈Rthey produce a one-parameter family of gradients, {Xθt}t∈R, where Xθt:=\n−∇gθtVθt. Gradient descent in ηgives a two-parameter family of gradients {Xθtη}t,η∈R\nvarying smoothly with both the (gradient descent) time index ηandt. For η1< η 2and\nt1< t2the family {Xθtη}(t,η)∈[t1,t2]×[η1,η2]sweeps out a two-parameter subset in χ∞(M).\nExample 5 (Optimizing time-varying diffusion models) .Building on Example 3, gradient\ndescent on θproduces a two-parameter family indexed by the ”inner” time t∈Rand ”outer”\noptimization time n∈R. Given a parameter value η, the dynamics are written,\ndxϵ\nt=−∇gθtηVϵ\nθtη(xϵ\nt)dt+ϵσθtη(xϵ\nt)dwt.\n24\n--- Page 25 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nAtϵ= 0, a two-parameter family of gradients is obtained, with Xθtn:=−∇gθtηVθtη.\nThese examples indicate that learning processes of associative memory models are one-\nparameter families of gradients, and the generation process of diffusions with time-varying\ndrift are one-parameter families. The learning processes of associative memory models and\ndiffusions with time-varying drift are two-parameter families. One arrives at the following\nquestion: Are one- and two-parameter families of gradients stable?\nThis section describes that stable families are actually abundant – one- and two-parameter\nfamilies of gradients are generically stable, and their points of instability are generically de-\nscribed by small sets of bifurcations. A statement is made for diffusion models, but first\nrequires a comparison of their trajectories to deterministic ones at vanishing noise levels.\n4.1 Large deviations and stochastic flows\nIt is convenient to view solutions to equations like (1.2.5) as stochastic flows , denoted by\nΦX,ϵfor an ϵ >0; see Kunita and Ghosh (1986). Let ( M, g) be a Riemannian manifold\nand Ω the space of continuous paths C0([0,∞), M) equipped with the Wiener measure\nassociated with Brownian motion on M. If 0 ≤s≤t≤Twith T > 0 and ω∈Ω, then\nΦX,ϵ\ns,t(·, ω) is a measurable map from Mto itself. Consequently, ΦX,ϵis a stochastic flow of\nmeasurable maps, here, more strictly, of homeomorphisms or diffeomorphisms.\nApath{xt}T\nt=0is a realization of the stochastic flow ΦX,ϵ(x0, ω) generated by Xϵfor an\ninitial condition x0∈Mandω∈Ω. That a family {Xϵ}ϵ>0is a small random perturbation\nimplies that the probability of observing a particular path should concentrate as ϵ→0.\nOriginal work on this topic by Ventsel and Freidlin (1970) is formulated through an action\nprinciple, where an action functional J[x] is defined by\nJ[x] =1\n2ZT\n0||˙xt−b(xt)||2dt ,\nwhere || · || is the Riemannian norm, and the bracket notation indicates that J[x] is a\nfunctional over all of xt; further details are available in, e.g., Touchette (2009), Chapter 6.\nThe large deviation principle states that the probability Pϵ[x] of observing a path {xt}T\nt=0\nthat deviates from an enclosing δ-tube is given by Pϵ[x]≍e−aϵJ[x], where the notation ≍\nindicates that the dominant part of P[x] is decaying exponentially; aϵdetermines the rate\nat which P[x] decays and is such that aϵ→ ∞ asϵ→0. For any number δ >0,\nP \nsup\n0≤t≤T|xϵ\nt−xt|< δ!\n≍e−aϵJ[x].\nImportantly, J[x] has a unique zero when the path is equal to the trajectory solving the\ndeterministic equations, denoted x∗\ntfor clarity. Since Pϵ[x] is dominated by e−aϵJ[x], which\ndecays exponentially as ϵ→0, the path converges in probability to the deterministic one in\nthis limit. That is, lim ϵ→0P(||xϵ\nt−x∗\nt||∞≥δ) = 0 for any number δ >0 in the supremum\nnorm|| · ||∞on the space of continuous paths C0([0, T], M).\nThis pathwise convergence is preserved by homeomorphisms that conjugate two limiting\ndeterministic flows; see §A for a proof:\n25\n--- Page 26 ---\nHess and Morris\nProposition 19 (Preservation of pathwise convergence) .Let(M, g)be a closed Riemannian\nmanifold; let {xt}T\nt=0and a path of a small random perturbation XϵofϕX\ntsuch that xϵ\ntP− →x∗\nt\nin probability as ϵ→0. Let h:M→Mis a homeomorphism that conjugates ϕX\ntandϕY\nt\nforYa vector field on M. Then h(xϵ\nt)P− →y∗\ntin probability as ϵ→0.\nThe image of a diffusion process under a homeomorphism may not be a diffusion process,\nbut it remains a continuous-time Markov process (Burke and Rosenblatt (1958), Corollary\n3). Let pϵ\nt(·|x) be the transition density of a transformed process satisfying the Chapman-\nKolmogorov equation. It can be shown from the definition of a pushforward measure and\nhomeomorphism that, if µϵis invariant for Xϵon (M, g), then h#µϵis invariant for the\nMarkov process with transition density pϵ\nt(·|x); see Proposition 17 for properties of h#µϵ.\nProposition 19 suggests an equivalence of stochastic flows that is ”pinned down” by their\nbehavior at diminishing noise levels. A modest relaxation of pathwise conjugacy is to require\nthat two stochastic flows converge in probability modulo orientation-preserving homeomor-\nphisms without a conserved time parametrization. This gives a notion of equivalence at\nvanishing noise levels comparable to topological equivalence of deterministic flows:\nDefinition 20 (Equivalent in the zero-noise limit) .Let(M, g)be a Riemannian manifold.\nTwo stochastic flows ΦX,ϵ\ntandΦY,ϵ\ntareequivalent in the zero-noise limit if:\n1. (Convergence in probability to deterministic flows) The stochastic flow ΦX,ϵ\ntconverges\nin probability to ϕX\ntasϵ→0, and {ΦY,ϵ\nt}converges in probability to ϕY\ntasϵ→0.\nThat is, for any t,δ >0, and x∈M,limϵ→0P\u0010\n∥ΦX,ϵ\nt(x,·)−ϕX\nt(x)∥ ≥δ\u0011\n= 0, and\nsimilarly for ΦY,ϵ\nt; and\n2. (Convergence in probability modulo homeomorphism) There exists a homeomorphism\nh:M→Mpreserving orientation and times t1, t2>0so that, for any T > 0and\nδ >0,limϵ→0P\u0010\n∥h(ΦX,ϵ\nt1(x,·))−ΦY,ϵ\nt2(h(x),·)∥ ≥δ\u0011\n= 0.\nThe definition is non-vacuous. It is well defined for stochastic flows that converge in\nprobability to deterministic ones at vanishing noise levels, satisfying (1). In fact, topological\nequivalence implies equivalence in the zero-noise limit; see §A for a proof:\nProposition 21. LetϕX\nt1, ϕY\nt2∈Diffr(M), r≥1be topologically equivalent flows on (M, g)\nunder a homeomorphism h:M→M. IfXϵandYϵare small random perturbations, then\nthe stochastic flows ΦX,ϵ\nt1andΦY,ϵ\nt2are equivalent in the zero-noise limit.\nThe content of Proposition 21 is summarized by the following commutative diagram:\nΦX,ϵ\nt1ϕX\nt1\nΦY,ϵ\nt2ϕY\nt2P\nϵ→0\nhP h\nP\nϵ→0\nHorizontal arrows denote convergence in probability as ϵ→0. The vertical arrow between\nstochastic flows indicates convergence in probability under the homeomorphism h, and the\ndownwards arrow between deterministic flows ϕX\ntandϕY\ntindicates topological equivalence.\n26\n--- Page 27 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nConversely, if two stochastic flows are equivalent in the zero-noise limit, then the prob-\nability that the deterministic (limiting) flows are not diminishes as ϵ→0. Consequently,\nthe probability that structural stability does not hold vanishes. Stability and bifurcations\nin the vanishing noise limit are understood in this manner in the rest of the document.\n4.2 Stable families and bifurcations\nRecall that a k-parameter family of gradients on a Riemannian manifold ( M, g) is a family\n{Xη1,...,ηk}η∈Nkwhere Nis a compact k−manifold for which there exists a family of\nfunctions {fη1,...,ηk}and family of metrics {gη1,...,ηk}such that Xη1,...,ηk=−∇gη1,...,ηkfη1,...,ηk.\nPairs ( {fη},{gη}) are given the compact-open C∞topology.\nLetχg\nk(M) be the set of k-parameter families on Mandπ:M×N→Nthe canonical\nprojection map. Two k-parameter families, {Xη},{Yη} ∈χg\nk(M), are called equivalent if\nthere exist homeomorphisms H:M×D→M×Dandψ:N→Nso that πH=ψπand for\neach η∈N,hηis an equivalence between {Xη}and{Yψ(η)}, where H(x, η) = (hη(x), ψ(η)).\n{Xη}is called stable if there exists a neighborhood {Xη} ∋ U in which all elements are\nequivalent to {Xη}. A value η= (d1, ..., d k) is called a regular parameter value for a\nk-parameter family of gradients {Xη}ifXηis (structurally) stable. Otherwise, it is called\nabifurcation value , and will be denoted by ¯ η.\n4.2.1 Comparison to universal unfoldings\nIt is worth comparing bifurcations of families of gradients to Thom’s work on universal\nunfoldings. Let X=−∇Vbe a a gradient system with a degenerate singularity p∈M,\nwhere the Hessian determinant |∂2V/∂x i∂xj|vanishes. Under an arbitrary perturbation\nδV, the local behavior (formally, the germ ) ofV+δVhas either infinite or finite topological\ntypes. In the finite case, there exists a k−parameter universal unfolding of the potential,\nV=V(p) +u1g1(p) +u2g2(p) +...+ukgk(p),\nfrom which any perturbation can be recovered up to topological equivalence (Thom (1969),\n§1.D). These unfoldings, describing local behavior of parameterized potentials, form the\nbasis of Thom’s approach and underpin catastrophe theory (e.g., Zeeman (2006)).\nContrastingly, loss of stability for families of gradients can occur due to local or global\ncriteria. A degenerate singularity indicates a loss of stability of a gradient system, but it\nis local. Additional global bifurcations can occur, even for one-parameter families. Generi-\ncally, these are due to non-transverse intersections of certain invariant manifolds, which are\ndiscussed in the following sections.\n4.2.2 One-parameter families of gradients\nOnly three bifurcations are needed to build a Morse-Smale system from the trivial one\n(Smale (1960); Rand et al. (2021)). Generically, only two arise at bifurcation values for\none-parameter families of gradients, described by the following theorem: the saddle-node\nbifurcation, a local bifurcation, and the heteroclinic flip, a global bifurcation.\nTheorem 22 (Palis and Takens (1983)) .The following properties are generic, and hold on\nan open and dense subset, for one-parameter families of gradients:\n27\n--- Page 28 ---\nHess and Morris\n1. The set of regular parameter values is open and dense in R;\n2. At a bifurcation value, the gradient X¯ηhas either exactly one (nonhyperbolic) saddle-\nnode singularity, while all other singularities are hyperbolic and all stable and unstable\nmanifolds intersect transversally, or it has exactly one orbit along which a stable and\nan unstable manifold intersect nontransversally, while all singularities are hyperbolic.\nA metric rescales and reorients space to align a potential gradient to a flow, but the non-\ndegeneracy of its critical elements is determined by the potential. Transversal intersections\nand orbits of tangency, on the other hand, are determined by the potential and the metric.\nSaddle-node bifurcation. In the supercritical case, a saddle-node bifurcation results\nin the appearance of a repelling or attracting critical element and an index 1 saddle as a\nparameter is varied. In the subcritical case, an attracting or repelling element is destroyed\nalong with the index 1 saddle. Let ηbe a bifurcation value for a one-parameter family of\ngradients {Xη}ands∈Ma nonhyperbolic singularity. For regular parameter values η\nnear η, there exists a one-dimensional center manifold Wc\nη(s) dependent on η(i.e., the zero\n3\n 2\n 1\n 0 1 2 33\n2\n1\n0123v1a=1\n3\n 2\n 1\n 0 1 2 33\n2\n1\n0123=0\n3\n 2\n 1\n 0 1 2 33\n2\n1\n0123=1\n3\n 2\n 1\n 0 1 2 3\nv23\n2\n1\n0123v1b\n3\n 2\n 1\n 0 1 2 3\nv23\n2\n1\n0123\n3\n 2\n 1\n 0 1 2 3\nv23\n2\n1\n0123081624324048V(v)\n0.000.150.300.450.600.750.901.051.201e5\n(dv)\n0816243240V(v)\n0.00.81.62.43.24.04.85.66.41e6\n(dv)\n081624324048V(v)\n0.000.150.300.450.600.750.901.051.201e5\n(dv)\nTrajectory Energy Probability Saddle Attractor / Memory Partial / Corrupted Pattern\nFigure 3: Saddle-node (fold) bifurcation. (a) Trajectories (grey) representing solutions to\nthe one-parameter family of gradients from Example 6 (left to right) overlayed on their respective\nenergy surfaces. As the parameter value η∈[−1,1] changes from η=−1 toη= 0 (left to middle),\nan attractor and saddle are born indicating a supercritical fold bifurcation. From η= 0 to η= 1,\nthe saddle and opposite attractor are destroyed, corresponding to the subcritical case. (b)Invariant\nmeasures µϵ(dv) of small random perturbations Xϵof each gradient flow from η=−1 toη= 1 with\nϵ= 1. As ϵ→0, the invariant measure will concentrate on the attractors.\n28\n--- Page 29 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\neigenspace of DXs)18. Restricted to Wc\nη(s),Xηtakes the form:\nXη(x) =\u0000\nax2−b(η−η)\u0001∂\n∂x+O\u0000\n|x|3+|x·(η−η)|+|η−η|2\u0001\n,\nwith a̸= 0. If b̸= 0 then the saddle-node unfolds generically (compare to §4.2.1). Restricted\nto a center manifold passing through s∈M, a saddle-node has the normal form ( η=η)\nXη(x) =ax2∂\n∂x+O\u0000\n|x|3\u0001\n.\nExample 6 (Saddle-node bifurcation, Figure 3) .Consider a one-parameter family of gra-\ndients {Xη}η∈[−1,1], where Xη:=−∇gηVηis a smoothly varying family of perturbations (in\nR) of the dual well model, adapted from Example 1, with gij=δijfixed for all η:\n˙vi=−nX\nj=1gij∂V(v, η)\n∂vjwith V(v, η) =1\n6v4\n1+1\n6v4\n2−1\n2v2v2\n1−1\n2v2+nX\ni=3v2\ni+η\u00126\n10v1\u0013\n.\nAsηvaries from η=−1toη= 0, a supercritical fold bifurcation produces a new saddle\npoint and attractor. From η= 0 toη= 1 a subcritical bifurcation eliminates the saddle\npoint and the opposite attractor. The disappearance and appearance of attractors is reflected\nin the stationary measures of small random perturbations Xϵ\nθηat a noise level of ϵ= 1.\nHeteroclinic flip bifurcation. Letp, q∈Mbe hyperbolic singularities and γ⊂Wu(p)∩\nWs(q) an orbit of tangency between their unstable and stable manifolds. Generically, γis\nquasi-transverse19. In this case, dim TrWu(p) + dim TrWs(q) = dim M−1 for r∈γ.\nAdditionally, in local coordinates ( x1, ..., x n) in a neighborhood of a point r∈γ,\nXη=∂\n∂x1,\nWu(p) = (x1, ..., x u,0, ...,0),and\nWs(q) = (x1, ..., x k,0, ...,0, xu+1, ..., x n−1, f(x2, ..., x k)),\nwhere u= dim Wu(p),k= dim ( TrWu(p)∩TrWs(q)) and fis a Morse function that\ncontrols the behavior of the intersection (Dias Carneiro and Palis (1989), Section 1b). The\nStable Manifold Theorem for a Morse function implies that Wu(p) and Ws(q) vary smoothly\nwith respect to ηnearby η. Consequently, for parameter values ηclose to η,fcan also\nbe written as a smoothly varying function fηdependent on η(Palis and Takens (1983),\nChapter 1, Section 2a). γunfolds generically if∂fη\n∂η(r)|η=η̸= 0.\nAheteroclinic connection between two critical elements p, qis an orbit that lies on the\nstable manifold Ws(q) and the unstable manifold Wu(p). A heteroclinic flip occurs when\nthese connections change, making it a global bifurcation. If a Morse-Smale gradient system\nundergoes this bifurcation, the unstable manifold Wu(s) of a source saddle s∈Mchanges\nbetween separate attractors by passing through a scenario where it intersects the stable\nmanifold Ws(˜s) of another saddle ˜ s∈M. This intermediate state generically corresponds\nto a quasi-transverse orbit of tangency (Palis and Takens (1983), Chapter 2).\n18. See, e.g., Guckenheimer and Holmes (2013), Chapter 3 on center manifolds.\n19. See Palis and Takens (1983), Chapter 2a or Newhouse and Palis (1973), Pages 306-307 about quasi-\ntransverse submanifolds.\n29\n--- Page 30 ---\nHess and Morris\n2\n 0 23\n2\n1\n0123v1a=1\n2\n 0 23\n2\n1\n0123=0\n2\n 0 23\n2\n1\n0123=1\n2\n 0 2\nv23\n2\n1\n0123v1b\n2\n 0 2\nv23\n2\n1\n0123\n2\n 0 2\nv23\n2\n1\n0123061218243036V(v)\n0.000.150.300.450.600.750.901.051e5\n(dv)\n061218243036V(v)\n0123456781e6\n(dv)\n061218243036V(v)\n0.000.150.300.450.600.750.901.051e5\n(dv)\nTrajectory Energy Probability Saddle Attractor / Memory Partial / Corrupted Pattern Saddle Connection\nFigure 4: Heteroclinic flip bifurcation. (a) Trajectories (grey) of the one-parameter family of\ngradients in Example 7 (left to right). As the parameter value ηchanges from η=−1 to η= 0\n(left to middle), the unstable manifold of a saddle (right-hand side) shifts from intersecting the\nstable manifold of the top attractor to intersecting the stable manifold of the other saddle, creating\na saddle-saddle connection (red line). From η= 0 to η= 1, the saddle connection is destroyed and\nthe unstable manifold of the right-hand side saddle intersects the stable manifold of the opposite\nattractor (bottom). The arc of gradient fields from η=−1 toη= 1 undergoes a heteroclinic flip\nbifurcation. (b)Invariant measures µϵ(dv) of small random perturbations Xϵwith ϵ= 1.\nExample 7 (Heteroclinic flip bifurcation, Figure 4) .Let{Xη}η∈Rbe a one-parameter family\nof gradients where Xη:=−∇gηVηis smoothly varying with respect to η. The system that\ndescribes a heteroclinic flip in Raju and Siggia (2023) is adapted to account for perturbations\nto both the metric and potential. Consider the one-parameter family of metrics,\ngηij=δij−6·(1−δij)η·G(v1;−1,1)·G(v2; 0,2)\nwith G(vi;µ, σ) =1√\n2πσ2exp\u0012\n−(vi−µ)2\n2σ2\u0013\n,\nwhere the function G(vi;µ, σ)is Gaussian with mean µand standard deviation σ. The\none-parameter family of potential functions {Vη}η∈[−1,1]is given by,\nV(v, η) =1\n5 \n1\n2v4\n1+1\n4v4\n2−v3\n2+ 2v2v2\n1−2v2\n2+3\n2v2+nX\ni=3v2\ni+1\n2ηv1!\n.\nFrom η=−1toη= 1, an orbit of tangency (a heteroclinic connection) between the saddle,\ns, on the left, and the saddle, ˜s, on the right, is born, altering the intersection of the unstable\n30\n--- Page 31 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nmanifold Wu(˜s)with the stable manifold Ws(βa)of the top left attractor βato the stable\nmanifold Ws(s). From η= 0toη= 1, the unstable manifold Wu(˜s)”flips” and intersects\nthe stable manifold Ws(βb)of the opposite attractor βb.\n4.2.3 Two-parameter families of gradients\nLet{Xη}be a two-parameter family on M,η= (η1, η2)∈Nwith Na compact surface.\nAnalogous to one-parameter families, the main theorem of Dias Carneiro and Palis (1989)\nshows that two-parameter families of gradients are generically stable (on an open dense\nsubset of χg\n2(M))20. In addition to the (two) bifurcations for one-parameter families, the\nbifurcations of two-parameter families consist of their combinations, along with additional\ncodimension two bifurcations. There are eleven possibilities.\nAdditional generic conditions are imposed to derive the codimension two bifurcations.\nThe main results are recapitulated below – refer to Dias Carneiro and Palis (1989) for a\ncomplete description and a rigorous treatment of the assumptions made. The first five\nbifurcations are derived from the codimension one bifurcations. Another three are due to\nthe breakdown of transversality conditions on invariant manifolds that are generic in the\none-parameter case. Finally, another case occurs as a codimension two singularity, and two\nremaining bifurcations are due to codimension two tangencies.\nOn codimension one bifurcations. Five possibilities at a bifurcation value ηare derived\nfrom the bifurcations of one-parameter families; two are the one-parameter bifurcations; an\nadditional three are simultaneous occurrences of two saddle-nodes, two quasi-transversal\norbits of tangency, or a quasi-transversal orbit of tangency and a saddle-node.\nCriticality. In the generic case, the multiplicity of the eigenvalues of a gradient system\nXηat a critical element are equal to one, so a smallest contracting and expanding direction\ncan be identified. Let p∈Mbe a hyperbolic singularity. The strong unstable manifold ,\nWuu(p), and strong stable manifold ,Wss(p), correspond to all positive (resp. negative)\neigenvalues except for the smallest. Generically, the strong stable manifolds (resp. unstable)\nand unstable (resp. stable) manifolds of distinct hyperbolic critical elements are transverse,\nornoncritical . Two additional bifurcations are due to criticality, i.e., the nontransverse\nintersection of these invariant manifolds.\nIn particular, a sixth possibility is first described by one quasi-transversal orbit of tan-\ngency between the unstable and stable manifolds of two hyperbolic critical elements Wu(p)\nandWs(q). In addition, there is a singularity swith Wu(s) nontransverse to Wss(p) or\nWuu(q) along a unique quasi-transversal orbit of tangency.\nA seventh possibility consists of a saddle-node whose strong stable (or unstable) manifold\nis nontransverse to the unstable manifold of another singularity. The nontransverse orbit\nin this scenario is quasi-transversal.\nQuasi-transverse stable and center-unstable manifolds. The eigenvalues of Xηat\nsingularities generically have a multiplicity of one, so there is also a center-stable manifold\nWcudefined by the smallest positive eigenvalue and all negative ones (similarly, stable Wcs).\nGenerically, Wcuis transverse to Wuu. An additional bifurcation occurs due to a quasi-\ntransversal orbit of tangency γ⊂Wu(p)∩Ws(q) with p, q∈Mhyperbolic singularities,\n20. One would hope that arbitrary k−parameter families are stable. This is not the case (Takens (1985)).\n31\n--- Page 32 ---\nHess and Morris\nalong which the center-unstable manifold Wcu(p) is not transversal to Ws(q) (it can be\nassumed quasi-transversal).\nCusp bifurcation. Letηbe a bifurcation value for {Xη}ands∈Ma nonhyperbolic\nsingularity. A ninth possibility encompasses a codimension two singularity with a cusp\ngeometry. As with the saddle-node, DXsgenerically has a zero eigenvalue with multiplic-\nity one. On a center manifold Wc(s) passing through s, the cusp has the normal form\nXη(x) =\u0000\nx3+O\u0000\n|x|4\u0001\u0001∂\n∂x. One has a standard picture for the cusp as two collapsing\nsaddle-nodes21.\nOrbit of tangency with cubic contact. Generically, the Morse function fin§4.2.2\ndescribing the interaction between invariant manifolds for a quasi-transverse orbit of tan-\ngency is quadratic; the contact is parabolic (Palis and Takens (1983)). A tenth bifurcation\nis due to a unique orbit of tangency between the unstable manifold Wu(p) and the stable\nmanifold Ws(p) of two hyperbolic critical elements p, q∈Mhaving cubic contact.\nCodimension two orbit of tangency. Finally, an eleventh possibility occurs due to a\ngenuine codimension two orbit of tangency. That is, there is an open and dense subset of\nχg\n2(M) such that if an element Xηhas an orbit of tangency γ⊂Wu(p)∩Ws(q) with\ndim [TrWu(p) +TrWs(q)] = dim M−2\nforr∈γ, then\ndimWu(p) + dim Ws(q) = dim M−1.\nThe tangency results from a lack of dimensions of the stable and unstable manifolds:\nu+s= dim M−1, where s= dim Ws(q) and u= dim Wu(p) (see Dias Carneiro and\nPalis (1989), Proposition 5).\n5 Applications and examples\nThis section first considers energy-based models in §5.2, followed by the Hopfield network\nand Boltzmann machine in §5.3. Modern Hopfield networks are described in §5.4. Finally,\ndiffusion models are described in §5.5. Providing conditions and methods to ensure struc-\ntural stability of these models is not within the scope of this document. However, the\nHopfield and modern Hopfield networks admit descriptions.\n5.1 Assumptions and generic conditions\nOne assumption and two generic conditions are imposed. The assumption is that flows\nremain in a closed manifold or globally attracting region diffeomorphic to a closed disc in\nRnwith C2boundary. The first condition requires that the boundary intersects the flows\ntransversally, ruling out bifurcations that occur at the boundary. The second condition is\nused to obtain structural stability criteria for classic and modern Hopfield networks via small\nmodifications to their energy functions in Morse charts, making the dynamics gradient-like .\n21. See Guckenheimer and Holmes (2013), Chapter 7 and Dias Carneiro and Palis (1989), §7 for more\ninformation on the cusp bifurcation.\n32\n--- Page 33 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n5.1.1 Generic condition 1: Transversal intersection with boundary\nA compact subset of Rnwith boundary transverse to a gradient field can always be con-\nstructed if there is a globally attracting region containing its critical points. Denote by\nDδ={x∈Rn:||x|| ≤ δ}the closed disc of radius δ > 0 inRn. with boundary\n∂Dδ={x∈Rn:||x||=δ}a smooth ( n−1)-dimensional sphere Sn−1\nδ⊂Rn.\nProposition 23. LetXbe a gradient field on RnandDC⊂Rna globally attracting\nregion with all critical points of Xin the interior of DC. Then there exists a region DC+δ\ncontaining DCwith boundary ∂DC+δtransverse to X.\nThe proof given in §C.1 is essentially an application of Thom’s transversality theorem\n(e.g., Palis and De Melo (2012), Theorem 3.4); specifically, that transversality is a dense\nproperty. That it is open also holds but is not necessary. Proposition 23 assumes that a\ndisc with positive radius contains all critical points of X. This is assumed for energy-based\nmodels and diffusion models, as they do not have explicitly defined energy functions.\n5.1.2 Generic condition 2: Gradient-like dynamics\nA modern view of the Morse-Smale conditions is through trajectory spaces of negative\ngradient flows. These spaces are central to Morse and Floer homology and provide a neat\ndescription of these conditions for a dense set of metrics given a Morse function. The follow-\ning is adapted from Schwarz (1993), Chapter 2, which we refer to for rigorous descriptions;\nsee, e.g., Milnor and Stasheff (1974), Chapters 2-3 about vector bundles.\nLetγx(t) =ϕX\nt(x) be a gradient flow map for a Morse function V:M→R; we are\ninterested in a space of (compact) curves with lim t→±∞ γ(t) =x∈Mand respectively,\ny∈M. Denote by Px,ythe set of curves which start at x∈Mand end at y∈M. That is,\nPx,y=\u001a\nγ:R∪ {±∞} → M: lim\nt→−∞γ(t) =xand lim\nt→+∞γ(t) =y\u001b\n.\nLetP1,2\nx,y⊂ P x,ybe those curves which are square integrable with weak first derivative and\nby convention, denote the extended real numbers by R=R∪{±∞} . Then, given a function\nV∈C∞(M,R) and critical points x, y∈Crit(V) as endpoints, the gradient field induces a\nsmooth section Fin the L2-Banach bundle,\nL2\nR\u0000\nP1,2∗\nx,yTM\u0001\n=[\ns∈P1,2\nx,yL2\nR(s∗TM)\nwhere L2\nRis a contravariant functor associating to sections of a smooth vector bundle ξon\nRa vector space of sections of ξalong with a Banach space topology from L2(R,Rn)22. The\nsection Fis given by,\nF:P1,2\nx,y→L2\nR\u0000\nP1,2∗\nx,yTM\u0001\n, s 7→d\ndts+∇V◦s ,\n22. The functor L2\nRis described in detail in Schwarz (1993), Appendix A.\n33\n--- Page 34 ---\nHess and Morris\nwhich can be understood as a map that sends a curve sfrom xtoyto the vector field\n˙s+∇s(t)Vover the image of the curve s. That is, it is a section of the induced bundle\ns∗TM. The zeros of the section Fare smooth curves that solve the differential equation,\nd\ndts=−∇V◦sand satisfy the condition that lim t→+∞s(t) =yand lim t→−∞ s(t) =x; see\nSchwarz (1993), Proposition 2.8 and 2.9. To summarize, Fis a section of a fiber bundle\nwith base space P1,2\nx,yand with fibers over a curve s∈ P1,2\nx,ybeing C0sections of s∗TM.\nDefinition 24 (Gradient-like field) .LetV:M→Rbe a Morse function on a Riemannian\nn-manifold (M, g). A vector field Xis a gradient-like field adapted to Vif,\n1.DVpX(p)≤0throughout the complement M\\Crit(V)with equality only at the set of\ncritical elements of VonM;\n2. For each critical point β∈Crit(V)with index λ, there is a smooth coordinate chart\naround βso that in local coordinates, ∇V=−\u0010Pλ\ni=1xi∂/∂x i\u0011\n+\u0010Pn\nj=λ+1xj∂/∂x j\u0011\n.\nIf (2) holds for a critical point βithe vector field Xis said to be in standard form nearβi.\nIfXis in standard form near all critical points of Vthe metric is called nice, orcompatible\nwith the Morse charts of V. It is shown below that there is always a gradient-like field for\na Morse function. The proof is in §B and is adapted from Cohen et al. (2006). Alternate\nproofs can be found in Audin et al. (2014), Chapter 2 or Milnor (1965), Lemma 3.2.\nProposition 25. Let(M, g 0)be a Riemannian manifold with metric g0andV∈C2(M,R)\na Morse function. The set of nice metrics for the pair (M, V )is dense in the L2space of\nRiemannian metrics on M.\nDefine Fx,y⊂ P1,2\nx,yas a subset that consists of gradient flow lines. That is,\nFx,y=\b\nγ∈ P1,2\nx,y:γ′(t) =−∇γ(t)V\t\n.\nThe difference between gradient and gradient-like fields is only at critical points. For\ngradient-like fields adapted to a Morse function, the Morse-Smale conditions are equiva-\nlent to the section Fbeing transverse to the zero section (in the L2-bundle), i.e, to the\nsurjectivity of the linearization of FatFx,y; see Audin et al. (2014), Theorem 10.1.523.\nGiven local coordinates around the image of a curve γ∈ Fx,y, with endpoints xandy,\nF(γ)i=dγi\ndt+X\njgij(γ(t))∂V\n∂xj= 0.\nLinearizing the gradient flow equation gives, for ϱ∈ P1,2\nx,y,\nDFA(ϱ)i=dϱi\ndt+X\nj,k∂gij\n∂xkϱk∂V\n∂xj+X\nj,kgij∂2V\n∂xj∂xkϱk= 0, (5.1.9)\nwhere the notation FAindicates that the linearization DFA(ϱ)ican be assigned a continuous\nfamily of endormorphisms of Rn,A∈C0(R,End(Rn)), that can be written as n×nmatrices.\n23. A version of the surjectivity of Fbeing equivalent to the Smale transversality condition using the Levi-\nCevita connection for a given metric can be found in Hutchings (2002).\n34\n--- Page 35 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nFor the local computation above,\nAik=X\nj\n∂gij\n∂xk∂V\n∂xj+X\nj,kgij∂2V\n∂xj∂xk\n,\nand substituting into (5.1.9) for DFAgives DFA(ϱ)i= ˙ϱi+P\nkAikϱk. The asymptotic\nbehavior of the family is given by the Hessian matrices at each critical point:\nlim\nt→−∞Aik(t) =X\njgij(x)∂2V\n∂xj∂xk(x) and lim\nt→+∞Aik(t) =X\njgij(y)∂2V\n∂xj∂xk(y).\n5.2 Energy-based models\nEnergy-based models are Boltzmann-Gibbs distributions24,pθ(x) = (Zθ)−1·e−Vθ(x)/ϵ2with\nZθ=R\ne−Vθ(x)/ϵ2dx, where Zθis the partition function, and Vθis a (smooth) real-valued\nfunction parameterized by a neural network with parameters θ. The noise-scaling parameter\nϵis typically set to one, and this is implicitly assumed below.\nA traditional approach to fitting pθ(x) to a data distribution pdata(x) is through maxi-\nmum likelihood estimation by maximizing the expected log-likelihood over the data distri-\nbution: max θEx∼pdata(x)[logpθ(x)]. However, the likelihood pθ(x) is intractable to compute,\ndue to the partition function Zθ. Similarly, the gradient of the log-probability of the model,\n∇θlogpθ=−∇θVθ(x)− ∇ θlogZθ,\nrequires computing Zθ; however, Markov chain Monte Carlo (MCMC) can be used to obtain\nunbiased estimates thereof. Specifically, ∇θlogZθcan be rewritten as,\n∇θlogZθ=Ex∼pθ(x)[−∇θVθ(x)].\nTherefore, if an exact sample ˜ x∼pθ(x) can be drawn from the model, then an unbiased\nsample of the gradient ∇θlogpθcan be obtained, allowing for the use of gradient ascent to\noptimize the model parameters θ. Many alternatives, like contrastive divergence (Hinton\n(2002)), have been developed to overcome difficulties with training these models (see Song\nand Kingma (2021)), but all are compatible with gradient-based optimization.\nA popular and relevant approach to drawing samples from an energy-based model is\nLangevin MCMC, which produces samples from probability distribution p(x) using the\nscore function ∇xlogp(x) in an overdamped Langevin equation (Parisi (1981)). The score\nfor energy-based models is the negative gradient of the energy: ∇xlogpθ(x) =−∇xVθ(x),\nmaking Langevin MCMC a discretization of the stochastic differential equation,\nd˜xϵ\nt=∇xlogp(xϵ\nt)|{z}\n−∇xVθ(x)dt+ϵ dw t,\n24. See Murphy (2023), Chapter 24 for a nice overview of energy-based models.\n35\n--- Page 36 ---\nHess and Morris\nFigure 5: Codimension one bifurcations during the learning dynamics of energy-based\ngenerative models. (a) Trajectories (grey) and critical points of a one-parameter family of gra-\ndients (left to right) derived from the potential of an energy-based model trained to generate four\ncentroids in R2using contrastive divergence. The model was pretrained to generate a centroid at\nthe origin. The energy was parameterized by a three-layer multilayer perceptron with the softplus\nactivation and a hidden dimensionality of 128, and was regularized by adding a quadratic term\n1\n2(max x||x||)2over the training data to encourage a barrier on the max norm of generated data. As\nthe optimization index increases from η0= 0 to ηfinal= 2999, a sequence bifurcations occur; shown\nare representative bifurcations during training. Additional bifurcations occur and are not shown.\nDAGs at parameter values are shown as insets. A supercritical saddle-node occurs from η= 0 to\nη= 301, creating two attractors. Another saddle-node creates a third attractor and index 1 saddle\nfrom η= 301 to η= 302. A heteroclinic flip appears to occur between η= 1496 to η= 1497,\ncausing the unstable manifold of the top saddle to change from intersecting the stable manifold of\nthe bottom left attractor to the bottom right attractor. A final supercritical saddle-node creates the\nfourth attractor.\nwhere ϵ >0 is re-introduced as a noise-scaling term. Given an energy-based model pθ(x),\na family {pϵ\nθ(x)}ϵ>0parameterized by ϵ >0 is a family of invariant measures {µϵ}ϵ>0as in\n§3. Langevin MCMC similarly produces a family of small random perturbations {Xϵ}ϵ>0.\nAsϵ→0, trajectories approach those of a gradient dynamical system X=−∇xVθ(x).\nIf the potential is smooth, gradient ascent yields one-parameter families {µϵ\nη}ϵ>0,η∈R\nand family {Xϵ\nη}ϵ>0,η∈R. By§4.1, when ϵ→0 the probability that a path generated by Xϵ\nη\ndeviates from the flow defined by the gradient drift field vanishes. From §4.2, the process by\nwhich energy-based models learn to fit pdatacan be generically characterized at vanishing\nnoise levels by ordered sequences of saddle-node or heteroclinic flip bifurcations (Figure 5).\n5.3 Hopfield networks and Boltzmann machines\nThe classic examples of associative memory and energy-based models, the Hopfield network\nand the Boltzmann machine, are now detailed.\n5.3.1 Hopfield networks\nConsider the continuous Hopfield network with Nneurons (Hopfield (1984)). Let fibe a\nsmooth and monotonically increasing activation function, vi=fi(ui) be the output of a\nfeature neuron given the input uifrom a hidden neuron, and f−1\ni(vi) =uithe inverse. The\ncommon sigmoid or hyperbolic tangent activation functions are considered here. Given a\nsymmetric connection matrix Wwith zero diagonal, the network’s energy function is,\nV(v) =−1\n2X\ni,jWijvivj+X\niBivi+X\niR−1\niZvi\n0f−1\ni(v)dv . (5.3.10)\n36\n--- Page 37 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nThe term R−1introduces delays in the output of feature neurons relative to hidden neurons.\nHere, R−1\ni= 1/ρi+P\njτ−1\nij, where τijis a resistance between neurons i, j, and ρiis an input\nresistance. The bias term Bis set to zero to simplify arithmetic; the following results hold\nthrough similar calculations otherwise. The dynamics of the hidden neurons are,\ndui\ndt=X\njWijvj−R−1\nif−1\ni(vi),\nwhich is the ithcomponent of the negative gradient of the potential V(v) with respect to\nfeature neurons in the standard metric gij=δij. The dynamics of feature neurons are\nactually also gradient but in a metric determined by the activation function. By definition,\nui=f−1\ni(vi), and applying the chain rule gives\ndvi\ndt=f′\ni(ui)·dui\ndt=−f′\ni(ui)·∂V\n∂vi=−f′\ni\u0000\nf−1\ni(vi)\u0001\n·∂V\n∂vi.\nThe term f′\ni(·) is always positive since fiis strictly increasing, so the first term in the final\nequality forms a diagonal matrix with positive entries. Therefore, the dynamics are gradient\nin a metric with inverse gij=f′\ni\u0000\nf−1\ni(vi)\u0001\nδij. A standard gradient system, ˙ vi=−∂V/∂v i,\ncan be obtained by a smooth change of coordinates25yi(v) = [ 1 /f′\ni\u0000\nf−1\ni(vi)\u0001\n]1/2.\nTransverse boundary. The range of the sigmoid and hyperbolic tangent functions are\nthe open intervals (0 ,1) and ( −1,1). Consequently, the phase space for feature neurons is\ndiffeomorphic to the open N-dimensional disc, denoted DN. Fixed points in feature states\noften lie in the corners of a hypercube, so we consider the dynamics on the closure DN,\nwhich is compact. The vector field is vacuously transversal to the boundary at v∈∂DN.\nSimilarly, the inverse of these activation functions approach ±∞ as their input ap-\nproaches the infimum and supremum of the open intervals (0 ,1) or ( −1,1). If R−1>0 and\nthe entries of Ware bounded, then the hidden state vector field points inwards, as the term\nR−1f−1(vi)→ ±∞ asviapproaches the infimum or supremum of its range. In this case, it\nis possible to identify a closed region containing all the system’s critical points, and, there-\nfore, a region satisfying Proposition 23. When R−1= 0, the hidden-state dynamics become\nlinear. Structural stability is equivalent to hyperbolicity for linear vector fields (Palis and\nDe Melo (2012), Chapter 2.2). This is reflected in Proposition 26.\nLinearized gradient flow equations. The structural stability of the Hopfield network\nis now discussed. Let γbe a gradient flow line whose endpoints are two critical points on\nhidden states. Consider Fu(γ) :γ7→d\ndtγ+∇V◦γwhere ∇Vis understood as the gradient\nwith respect to the feature neurons in the standard metric. Locally, around the image of γ,\n25. Analogous descriptions for a more general class of models can be found in Cohen and Grossberg (1983).\n37\n--- Page 38 ---\nHess and Morris\nthe linearization DFAuofFu(γ) is computed using (5.1.9)26:\nDFAu(γ)i=dγi\ndt+X\nj,k∂gij\n∂vkγk∂V\n∂vj+X\nj,kgij∂2V\n∂vj∂vkγk\n=−∂V\n∂vi+X\nj,kδij∂2V\n∂vj∂vkf−1\nk(vk)\n=X\njWijvj−R−1\nif−1\ni(vi) +X\nk\u0012\n−Wik+R−1\niδik1\nf′\ni(f−1\ni(vi))\u0013\nf−1\nk(vk),\nwhere γi(t) =uiandf−1\nk(vk) =γk(t). The second equality is obtained by substituting\ngij=δijand∂gij/∂vk= 0 together with the equality dγi/dt=−∂V/∂v i. The third equality\ncomes from substituting the equality dui/dt=−∂V/∂v iand computing ∂2V/∂v j∂vkusing\nthe equality of [ f−1\ni]′(vi) with 1 /f′\ni(f−1\ni(vi)).\nLetαbe a gradient flow line whose endpoints are two critical points on feature neuron\nstates. Consider Fv(α) :α7→d\ndtα+∇gV◦αwhere ∇gVis the Riemannian gradient in\nthe metric with inverse gij=f′(f−1(vi))δij. The metric is not constant, so the term with\npartial derivatives of its inverse does not vanish in the local formula for the linearization of\nFv(α). Since gijis diagonal, this term is only nonzero when i=j=k. Consequently, at\nthe image of α, where αi(t) =vi, the linearization of Fv(α) is,\nDFAv(α)i=dαi\ndt+∂gii\n∂viαi∂V\n∂vi+X\nj,kgij∂2V\n∂vj∂vkαk\n=f′\ni(f−1\ni(vi)))\nX\njWijvj−R−1\nif−1\ni(vi)\n\n+f′′(f−1(vi))\nf′(f−1(vi))vi\nX\nj−Wijvj+R−1\nif−1\ni(vi)\n\n+f′\ni(f−1\ni(vi))X\nk\u0012\n−Wik+R−1\niδik1\nf′\ni(f−1\ni(vi))\u0013\nvk.\nThe first term in the second equality is again obtained from dα/dt being a gradient flow\nline. The calculation of the second term is an application of the chain rule on the inverse\nmetric entries followed by the equality of [ f−1\ni]′(vi) with 1 /f′\ni(f−1\ni(vi)). The final equation\nis expanded by substituting the connection matrix and resistance terms as above.\nMorse condition. Recall that lim t→+∞γ(t) =u∗\nxand lim t→−∞ γ(t) =u∗\nyfor critical\npoints u∗\nx,yon hidden states and γ(t) a gradient flow line between them. Similarly, for\na curve α(t) on feature neurons, we have lim t→+∞γ(t) =v∗\naand lim t→−∞ γ(t) =v∗\nbfor\ncritical points v∗\na,b. The asymptotic behavior of DFAuandDFAvgives the Hessian matrices\n26. The notation Fu(γ) and DFAuare used to clarify that hidden state dynamics are considered.\n38\n--- Page 39 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nat these critical points. On hidden neurons,\nlim\nt→−∞Au;ik(t) =X\njδij∂2V\n∂vj∂vk(u∗\nx) =−Wik+R−1\niδik1\nf′\ni(u∗\nx;i),\nwhere u∗\nx;idenotes the ithcomponent of the critical point u∗\nx. A similar expression is\nobtained for lim t→+∞Av;ik(t) by replacing u∗\nx;iwith u∗\ny;i. On feature neurons,\nlim\nt→−∞Av;ik(t) =X\njgij(v∗\na)∂2V\n∂vj∂vk(v∗\na) =f′\ni\u0000\nf−1\ni(v∗\na;i)\u0001 \n−Wik+R−1\niδik1\nf′\ni(v∗\na;i)!\n,\nand similarly, the expression for lim t→+∞Av;ik(t) follows from substituting v∗\na;iwith v∗\nb;i.\nThe Morse condition is satisfied if these Hessian matrices at each critical point are\nfull rank. This is easily checked when R−1→0: if the resistance term R−1is zero and\nthe synaptic weight matrix Whas a zero eigenvalue, then the network is not structurally\nstable. This regime is common in applications that lack physical or biological motivation.\nProposition 26. The continuous Hopfield network with R−1\ni= 0is not structurally stable\nifλi= 0for any i= 1, ...N , where λiare eigenvalues of the synaptic weight matrix W.\nIt follows that the number of linearly independent stored patterns must be at least equal\nto the number of neurons for a Hopfield network with R−1= 0 to be structurally stable.\nRemark 27. Demanding that Wbe full rank is easy to satisfy. Suppose that a network\nhas a connection matrix Wwith eigenvalues λ1, ..., λ Nwith λi= 0for some i= 1, ..., N .\nThe eigendecomposition of WisW=QΛQTwhere Λis a diagonal matrix with Λii=λi\nfori= 1, ..., N . For any ϵ >0,ΛandWcan be modified by setting Λii= max( λi, ϵ)\nandW=QΣQT. The matrix Wis clearly full rank and it can be confirmed that it is\nsymmetric (i.e., WT=W) from the property that (QT)T=QandΛT=Λ. Since Wand\nWare symmetric square matrices, their eigenvalues coincide with their singular values. The\nFrobenius norm between WandWis then\n||W−W||=sX\ni=1(λi−λi)2=sX\nj:λj<ϵ(λj−ϵ)2,\nwhere the last equality is a sum over eigenvalues less than ϵ, which can be arbitrarily small.\nSmale condition. Let{u∗\n1, ...u∗\nn}and{v∗\n1, ...v∗\nm}be sets of hyperbolic singularities in\nhidden and feature states, respectively. On hidden neurons, choose non-overlapping Morse\ncharts ( U1, h1), ...,(Un, hn) in the neighborhoods of u∗\n1, ...u∗\nn. Let gE1, ..., g Enbe the standard\nEuclidean metric with respect to the coordinates in each chart, and let gEbe the standard\nmetric. Let B(u∗\n1, δ)⊂U1be a coordinate ball of radius δ >0 and B(u∗\n1, ϵ)⊂B(u∗\n1, δ) with\nϵ < δ . Choose a C∞bump function Λ : M→[0,1] with Λ( x) = 1 for x∈B(u∗\n1, δ) and\nΛ(x) = 0 for xin a neighborhood of the complement M\\B(u∗\n1, ϵ). The metric\ngu=gE(y)(1−Λ(y)) +gE1(y)Λ(y)\n39\n--- Page 40 ---\nHess and Morris\nis in standard form near u∗\n1on the Morse chart ( U1, h1) and can be extended globally\nas in the proof of Proposition 25. Proceed iteratively on the remaining Morse charts so\nthat guis compatible with ( U1, h1), ...,(Un, hn). The same procedure applied to suitable\nMorse charts for {v∗\n1, ...v∗\nm}gives a gradient-like field with metric gvfor feature neurons.\nIn this case, replace the standard metric gEin the equation above with g0, the metric on\nfeature neurons determined by the activation function f, foryin a Morse chart of v∗\ni. The\nstructural stability of these gradient-like systems, which have the same fixed points as the\noriginal network and differ by an arbitrarily small amount, are equivalent to the surjectivity\nof the linearizations DFAuandDFAu.\n5.3.2 Boltzmann machines\nThe Boltzmann machine is an energy-based model. Its energy function is exactly the Hop-\nfield network energy, and the probability of a network being in a configuration is given by,\nP(v) =Z−1·e−V(v)/Twith Z=R\ne−V(v)/Tdv, where T > 0 is a noise scaling, or ”tem-\nperature”, parameter. The classic formulation considers binary states vi={0,1}with an\nupdate rule that describes the probability of a neuron firing (Ackley et al. (1985)). Fol-\nlowing §5.2, a continuous-state formulation can be defined using an overdamped Langevin\nequation: duϵ\nt=−∇V(uϵ\nt)dt+√\nTdw t.\nIt is known that as T→0, the update rule of the Boltzmann machine is equivalent to\nthe update rule of the Hopfield network. When the Hopfield network is structurally stable\n(see§5.3.1 above), the results of this paper apply in the vanishing noise limit.\n5.3.3 Learning dynamics of Hopfield networks and Boltzmann machines\nConsider a Hopfield network with Nneurons, and let ξ={ζ1, ..., ζM},m∈ {1, ..., M },\nwith each ζm∈RN, be a set of Mpatterns. The connection matrix Wof the Hopfield\nnetwork is often trained to store ξusing a Hebbian learning rule (i.e., the outer product\nrule): W=1\nMPM\nm=1ζm(ζm)T. This rule was originally biologically motivated, but can be\nderived as an unconstrained quadratic program.\nConsider minimizing the objective L(W) =−1\n2PM\nm=1(ζm)TWζm. The function Lis\nconvex, and the (negative) gradient ∂L/∂W =PM\nm=1ζm(ζm)Tis the Hebbian rule up to\nrescaling. There is no constraint to bound L(W) below, but it is natural to constrain the\nFrobenius norm ||W|| ≤cforc >0, resulting in the convex problem,\nmin\nWL(W) =−1\n2MX\nm=1(ζm)TWζms.t.||W|| ≤c . (5.3.11)\nThe Frobenius norm constraint is natural in that the unique solution to (5.3.11) is scale-\ninvariant. For any c >0, the solution is cW∗, where W∗is the solution with unit norm.\nSimilarly, the energy V(v) =−c\n2P\ni,jW∗\nijvivjis a scalar multiple of the energy correspond-\ning to the weight matrix with unit norm, when R−1= 0. Algorithm 1 describes a projected\ngradient descent approach to train a Hopfield network in this manner.\nEven if the bias and resistance terms, BandR−1, are nonzero, Hebbian learning pro-\nduces a one-parameter family of matrices {W}η∈Rand gradients {Xη}η∈R. Generically, if η\nis a bifurcation value, Xηhas one nonhyperbolic singularity corresponding to a saddle-node\n40\n--- Page 41 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nFigure 6: Memory formation through Hebbian learning is generically described by\ncodimension one bifurcations in Hopfield networks. (a) Hidden neuron trajectories (grey)\nand critical points of a one-parameter family of gradients (left to right, indexed by η) produced by\ntraining a 2-neuron Hopfield network using Algorithm 1 to store two memories, ( −1,1) and (1 ,−1),\ninR2. Trajectories and critical points are overlayed on the energy surface of the Hopfield model\naccording to (5.3.10) using R−1= 0.85. The learning rate and convergence tolerance of Algorithm 1\nwere set to 0 .1 and 1 e−12, respectively. As the optimization index ηincreases from the initial state\nη0= 0 to the final state ηfinal= 147, a supercritical saddle-node bifurcation occurs, creating the\nstored memories. This bifurcation is reflected in the DAGs (insets) at each parameter value.\nor a heteroclinic orbit of tangency ( §4.2.2). Consequently, memory formation is described by\nordered sequences of these bifurcations. An example demonstrating a saddle-node bifurca-\ntion for a two-memory system trained using the Hebbian learning rule is shown in Figure 6,\nand a higher-dimensional example is described in Figure 10. Gradient-based approaches to\ntraining Boltzmann machines are standard, and this characterization applies to them in the\nzero-noise limit, as with energy-based models.\n5.4 Modern Hopfield networks\nDense associative memory was introduced in Krotov and Hopfield (2016), where the energy\nof the classic Hopfield network with binary states was modified to be V=−PM\nm=1F(vTξm)\nwhere F(x) =xnis a polynomial of order n∈Z+. The Hopfield model corresponds to\nn= 2. These models were shown to achieve a maximal storage capacity proportional to\nNn−1where Nis the number of neurons. The modern Hopfield network was considered in\nDemircigil et al. (2017) by setting F(x) = exp( x), which yields exponential storage in the\nnumber of neurons (2N/2).\nThe model with exponential interactions was further extended in Ramsauer et al. (2020).\nLetξ= (ξ1, ..., ξm) be a matrix containing a set of mpatterns, where ξm∈Rd, and let\nC= max m||ξm||. The energy of this network is\nV=−lse(β,ξTv)|{z}\nV1+1\n2vTv+1\nβlogM+1\n2C2\n| {z }\nV2where lse( β,ξ) =1\nβlog MX\nm=1exp(βξm)!\n.\nWe consider the update rule equivalent to the attention mechanism (Ramsauer et al. (2020),\nSection 2),\nvt+1=ξsoftmax\u0000\nβξTvt\u0001\n=−∇\u0000\n−lse(β,ξTv)\u0001\n=−∇(V1),\n41\n--- Page 42 ---\nHess and Morris\nobtained from a convex-concave procedure, where the energy is a sum of V1andV2(Yuille\nand Rangarajan (2001) and Ramsauer et al. (2020), Appendix A.1.4).\nTransverse boundary. The update rule vt+1converges to a globally attracting region\ndiffeomorphic to the closed d-dimensional disc: DC={x∈Rd:||x|| ≤ C}27. From\nProposition 23, a compact subset ˜DC+δ⊂Rdwith boundary ∂˜DC+δtransverse to the\ngradient flow for this update rule can always be constructed from a dense set of arbitrarily\nsmall modifications to ∂DC+δforδ >0.\nMorse condition. The Jacobian matrix D(vt+1) of the update rule is\nD(vt+1) =βξ\u0000\ndiag(p)−ppT\u0001\nξT=ξJsξTwith p= softmax( βξTv),\nwhere Jsthe Jacobian of the softmax (Ramsauer et al. (2020), Appendix A.1.5). The rank\nofD(vt+1) is bounded above by rank( ξ) and rank( Js). Consequently, if the number of\nlinearly independent patterns, say M, is less than the dimensionality, d, then singularities\nare nonhyperbolic and the network is not structurally stable. The codomain of the softmax\nis the probability simplex, which requires only M−1 parameters to describe. This implies\nthat the nullity of Jsis at least 1, and by the rank-nullity law, rank( Js)≤M−1 when\nJs:RM→RMis viewed as a linear map. Suppose that M=dand the patterns are\nlinearly independent so that ξis full rank. Then rank( Js) =d−1, which implies that\nrank( D(vt+1))≤d−1. Therefore, to ensure that all critical points are nondegenerate, it is\nnecessary that there be at least d+ 1 patterns with dof them linearly independent. This is\nactually sufficient to satisfy the Morse condition, since in this case, rank( ξJsξT) =d.\nSmale condition. Suppose that V1is Morse and {β1, ..., β n}is a set of hyperbolic sin-\ngularities. The update rule vt+1can be approximated by a gradient-like field adapted\ntoV1by choosing suitable Morse charts at each critical point and following the proof of\nProposition 25, which is not recapitulated for brevity. The stable and unstable manifolds\nWs(βj) and Wu(βi) are transverse when the section F:P1,2\nβi,βj→L2(P1,2∗\nβi,βjT˜DC+δ) inter-\nsects transversally the zero section, where ˜DC+δis the closed disc with boundary given by\nan inclusion map ˜ΨC+δ. In a coordinate patch at the image of a gradient flow line γ∈ F1,2\nβi,βj\noutside adapted subsets of Morse charts for βiandβj, the linearization DFAis\nDFA(γ)i=dγi\ndt+X\nj,kgij∂2V1\n∂vj∂vkγk=X\njξijsoftmax\u0000\nβξTvt\u0001\nj+X\nk\u0000\nξJsξT\u0001\nikvt;k,\nwhere\nsoftmax\u0000\nβξTvt\u0001\nj=e(βξTvt)j\nP\nm(βξTvt)m\nandγk(t) =vt;k. The first term of DFA(γ)iis obtained by substituting the update rule\nvt+1fordγi/dt, and the second is obtained using D(vt+1) in place of ∂2V/∂v j∂vk.\nLearning dynamics. This model is typically an intermediate neural network layer, defin-\ning the dynamics on an embedding space of a previous layer. The dynamics can be con-\n27. See Ramsauer et al. (2020), Appendix A.1.4 on global convergence of the update rule vt+1.\n42\n--- Page 43 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nFigure 7: Codimension one bifurcations of a modern Hopfield network. (a) Trajectories\n(grey) and critical points of a one-parameter family of networks (left to right) storing three patterns in\nR2: (0.95,0 +δ(η)), (−0.7,√\n3/2), and (0 .7,√\n3/2). The inverse temperature β(η) and perturbation\nδ(η) are made to vary smoothly with η∈[0,2] and constant for η > 2 using a combination of\nGaussian cumulative distribution (step) functions. As ηvaries in [0 ,2], a sequence of bifurcations\noccur, reflected in the DAGs at each parameter value (insets). Two supercritical saddle-nodes occur\nfrom η= 0 to η= 1 as βincreases, causing memories to form. From η= 1 to η= 2 a heteroclinic\nflip occurs by passing through an unstable intermediate state with a saddle-saddle connection along\nwhich the orbit is tangential (red line, DAG indicates node switching).\nsidered on ˜DC′+δ, where DC′+δis a closed disc with radius C′, where C′= max ηCis\nthe uniform maximum norm of the patterns to store over the gradient descent index η,\nand ˜DC′+δis constructed as in Proposition 23. Understood as a dynamical system on the\nclosed region ˜DC′+δ, the learning process is generically characterized by the bifurcations of\none-parameter families ( §4.2.2).\nMetastability and temperature. The ”inverse temperature” parameter βis analogous\nto a noise scaling parameter. When β→0 (high temperature), the softmax operation in\nthe update vt+1is evenly distributed over the patterns, producing a single attractor. As\nβincreases, the softmax operation becomes sharper, mimicking a low temperature regime.\nAn illustration of the two generic bifurcations that modern Hopfield networks can undergo\nas pattern positions and the inverse temperature smoothly vary with a parameter (e.g.,\noptimization index or other) is given in Figure 7.\n5.5 Denoising diffusion models\nModels in this section learn the reverse to diffusion processes that iteratively add noise to\nsamples from a data distribution pdatato some prior distribution pT, for T∈[0,∞). We\nconsider models whose forwards noising processes are Ornstein–Ulhenbeck processes that\nare solutions to stochastic differential equations in Rnlike\ndxϵ\nt=−1\n2βtxϵ\ntdt+√ϵtdwt, x 0∼pdata, (5.5.12)\nwhere t7→βtis a positive weight function, and ϵtis a time-dependent noise-scaling factor.\nViewed in the form of (1.2.1), the diffusion coefficient of (5.5.12) is the n×nidentity matrix.\nDenoising diffusion probabilistic models (Ho et al. (2020); Sohl-Dickstein et al. (2015))\nare shown in Song et al. (2020) to be discretizations of (5.5.12) ϵt=βtand are called\n43\n--- Page 44 ---\nHess and Morris\nvariance-preserving models. Song and colleagues also define sub-variance preserving models\nby defining the noise schedule ϵt=βt\u0010\n1−e−2Rt\n0βsds\u0011\n. Likewise, they define variance-\nexploding models as SDEs with zero drift and a noise schedule ϵt=d[σ2(t)]/dtwhere σ2(t)\nis obtained as the continuous limit of a Markov chain with a sequence {σi}N\ni=1of noise scales\nwhen N→ ∞ (Song et al. (2020), Appendix B).\nNoising dynamics. An additional noise scaling parameter δ >0 can be added to the\nright-hand sides of the stochastic equations. The drift term βtis affine (in fact, linear), and\nat a fixed time, it is constant, so its only fixed point is the origin. These forwards (noising)\nprocesses do not undergo nonlinear bifurcations in the δ→0 limit, but changes in the sign\nof the eigenvalues of Dβt(xt) can alter the system’s stable and unstable directions. The\nstructural stability of these systems as linear vector fields L:Rn→Rnis simple: they are\nstructurally stable if and only if they are hyperbolic .\nGeneration dynamics. Reverse processes to equations like (1.2.1) are solutions to re-\nverse stochastic differential equations of the form\ndxϵ\nt=\b\nb(xϵ\nt)− ∇ ·\u0002\nϵ2σ(xϵ\nt)σ∗(xϵ\nt)\u0003\n−ϵ2σ(xϵ\nt)σ∗(xϵ\nt)∇logpϵ\nt(xϵ\nt)\t\ndt+ϵσ(xϵ\nt)dwt.(5.5.13)\nThe reverse SDE of (5.5.12) becomes\ndxϵ\nt=\u001a\n−1\n2βtxϵ\nt−ϵt∇logpϵ\nt(xϵ\nt)\u001b\ndt+√ϵtdwt\n=−∇x\u00121\n4βt||xϵ\nt||2+ϵtlogpϵ\nt(xϵ\nt)\u0013\ndt+√ϵtdwt (5.5.14)\nafter substituting terms into (5.5.13). Evidently, the drift is the negative gradient of a\ntime-varying potential, Vt(x) =1\n4βt||xϵ\nt||2+ϵtlogpϵ\nt(xϵ\nt)+c, where cis an additive constant.\nIn the limit where ϵt→0 uniformly, a time-dependent gradient system is obtained.\nIt is more common to draw samples from pdatausing an ordinary differential equation\nderived from the forwards Kolmogorov equation, called the probability flow ODE (Song\net al. (2020), Appendix D). For (1.2.1), this deterministic ODE is\ndxϵ\nt=\u001a\nb(xϵ\nt)−1\n2∇ ·\u0002\nϵ2σ(xϵ\nt)σ∗(xϵ\nt)\u0003\n−1\n2ϵ2σ(xϵ\nt)σ∗(xϵ\nt)∇logpϵ\nt(xϵ\nt)\u001b\ndt , (5.5.15)\nwhose solutions are distributed according to the induced marginal densities ptof (1.2.1) for\nallt. The probability flow ODE for models with reverse SDEs like (5.5.14) is\ndxϵ\nt=\u001a\n−1\n2βtxϵ\nt−1\n2βt∇logpϵ\nt(xϵ\nt)\u001b\ndt\n=−∇x\u00121\n4βt||xϵ\nt||2+1\n2ϵtlogpϵ\nt(xϵ\nt)\u0013\ndt , (5.5.16)\nwhich is the negative gradient of Vt(x) =1\n4βt||xϵ\nt||2+1\n2ϵtlogpϵ\nt(xϵ\nt) +c, whose regularity\nis determined by the neural network parameterizing the score function, and which is evi-\ndently a model of associative memory. These equations describe variance and sub-variance\n44\n--- Page 45 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nFigure 8: Codimension one bifurcations characterize generation dynamics of denoising\ndiffusion models. (a) Trajectories (grey) and critical points of a one-parameter family of gradients\n(left to right) derived from the probability flow ODE of a variance-preserving denoising diffusion\nmodel with linear noise schedule trained to generate four centroids in R2. The model was pretrained\nto generate a single centroid centered at the origin. As time runs backwards from −1 to 0, a sequence\nsupercritical saddle-node bifurcations occur, reflected in the DAGs at each parameter value (insets).\nTwo supercritical saddle-nodes occur from t=−1 tot=−0.43. As tcontinues to increase, another\nsaddle-node occurs, creating an index 2 repellor and an index 1 saddle, visualized at t=−0.384,\nfollowed by an additional saddle node, visualized at t=−0.15.\npreserving models, while variance-exploding models are defined by removing the quadratic\nnorm-squared terms in (5.5.16), giving Vt(x) =1\n2ϵtlogpϵ\nt(xϵ\nt) +c.\nData generation consists of solving the probability flow ODE backwards in time. When\nthe time-varying score function is smooth, samples evolve via a smoothly-varying one-\nparameter family of gradients. Therefore, the generative process is generically characterized\nby ordered sequences of the bifurcations for one-parameter families ( §4.2.2). A denoising\ndiffusion model trained using the score matching objoective demonstrates this characteri-\nzation of the generative process in Figure 8.\nLearning dynamics ”Learning” to generate is generically characterized by the bifur-\ncations of two-parameter families ( §4.2.3). An illustration of the training and generation\ndynamics of the above model as a two-parameter family is given in Figure 11.\n6 Conclusion and discussion\nThis paper describes a generic generation-to-memory transition from generative diffusion to\nassociative memory as noise levels diminish. In particular, universal approximation proper-\nties, robustness or stability to perturbations of parameters or inputs, and learning dynamics\nof associative memory are generically described at a global level using the geometric ap-\nproach to dynamical systems theory. In parallel, these properties are applied to diffusions\nin the zero-noise limit by leveraging probabilistic approaches to dynamical systems.\nReliable and stable associative memory satisfies the conditions for gradient fields to be\nMorse-Smale. Conversely, current models can be universally approximated by this class of\nsystems. Memory retrieval is therefore generically downhill, and associated to each ”memory\nlandscape” is an invariant DAG defining connections between rest points (Figure 2). The\nMorse lemma implies that these models generically satisfy the asymptotic stability property\nfor reliable memory storage. In addition, they are structurally stable – their fixed-point\nand orbit structure is unchanged in a neighborhood of a model in use. This takes the local\n45\n--- Page 46 ---\nHess and Morris\nform of stability global, and it qualitatively describes the robustness of these systems to\nmodel parameter perturbations. Pragmatically, Morse-Smale gradient models of associative\nmemory can be written as an inverse Riemannian metric times the gradient of a potential,\nwhich broadens their applicability to more geometrically structured domains.\nGenerative diffusion appears as small random perturbations of associative memory, de-\nfined by stochastic differential equations with gradient drift (Figure 1). Their invariant\nmeasures are Boltzmann-Gibbs distributions that generically correspond to the stable man-\nifolds of the associative memory model defined by the drift field. The Morse condition\nimplies that these invariant measures are stable to stochastic and deterministic perturba-\ntions on stable manifolds. The Morse-Smale assumptions enable a global extension of these\nresults; though, the image of a Boltzmann-Gibbs distribution under a homeomorphism\nbetween topologically equivalent systems need not preserve its absolute continuity.\nMemory formation is characterized by breakdowns of the Morse-Smale assumptions. The\nlearning processes of associative memory appear as one-parameter families of gradients that\ntrace an arc in the space of gradient fields, and memory formation is generically described\nby the sequential occurrence of only two bifurcations (Figure 3 and Figure 4). The learning\nprocesses of time-dependent associative memory appear as two-parameter families that are\ncharacterized by eleven possible bifurcations ( §4.2.3). These results also apply directly to\ndiffusion models using probability flow ODEs for sample generation, viewed through this\ndeterministic lens, while large deviation type results from classic FW theory imply that\nstochastic flows of generative diffusion converge in probability to the flows of their gradient\ndrift fields at vanishing noise levels. We introduced a definition for stochastic flows in the\nzero-noise limit analogous to the topological equivalence of flows ( §4.1). Data generation\nfor models with time-varying drift can be understood through this construction by the\nbifurcations for one-parameter families. Their learning dynamics can be viewed through\nthe bifurcations for two-parameter families.\nOur results apply to classic models, including the Hopfield network and Boltzmann ma-\nchine, along with energy-based models and modern diffusion models ( §5). In particular, we\ngave explicit computations that determine when classic and modern Hopfield networks are\nnot structurally stable ( §5.3 and §5.4). Even some simple scenarios violate the Morse-Smale\nconditions for these models, and the results of the modern Hopfield network are directly\nrelevant to the attention mechanism. Although associative memory is generically struc-\nturally stable, it is not clear if the Morse-Smale constraints are computationally tractable\nto satisfy, in general. It is also not clear if the connections made between diffusion models\nand associative memory models can be used to enhance their performance.\nAcknowledgments and Disclosure of Funding\nJ.H. and Q.M. thank Dmitry Krotov for helpful comments and feedback. J.H. is supported\nby a National Science Foundation Graduate Research Fellowship under grant no. 1746886.\n46\n--- Page 47 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nAppendix A. Proofs on zero-noise limits and small random perturbations\nThe two lemmas from §3.3 are proven below.\nProof of Lemma 15 . By definition of weak convergence, for any continuous bounded\nfunction f:M→R, Z\nMf(x)dµn(x)→Z\nMf(x)dµ(x).\nSetνn=h#µnand recall that by assumption ν=h#µ. Consider a continuous bounded\nfunction g:M→R. Since gis bounded and continuous, and h:M→Mis a continuous\nbijection, the composition g◦h:M→Ris bounded and continuous. Combined with the\nequalities νn=h#µnandν=h#µ,\nZ\nMg(y)dνn(y) =Z\nM(g◦h)(x)dµn(x) andZ\nMg(y)dν(y) =Z\nM(g◦h)(x)dµ(x),\nfrom the definition of the pushforward measure. By assumption, µn→µweakly. Therefore,\nZ\nM(g◦h)(x)dµn(x)→Z\nM(g◦h)(x)dµ(x),\nwhich immediately implies that\nZ\nMg(y)dνn(y)→Z\nMg(y)dν(y).\nProof of Lemma 16 . That h: (M,B, µ)→(M,B, h#µ) is a measurable space isomor-\nphism is immediate, since it is a bijective measurable map with measurable inverse. By\ndefinition of pushforward measure h#µ(h(A)) =µ(h−1(h(A))) = µ(A) for A∈ B, sohis a\nmeasure space isomorphism. It remains to show that h#µis invariant under ϕY\nt. That is,\nwe need to show that h#µ(A) =h#µ((ϕY\nt)−1(A)). By definition,\nh#µ((ϕY\nt)−1(A)) =µ\u0000\nh−1((ϕY\nt)−1(A))\u0001\n(1.0.17)\nfor any t. By definition of topological equivalence, there are t1, t2so that h(ϕX\nt1(x)) =\nϕY\nt2(h(x)) for all x∈M. By definition,\n(ϕY\nt)−1(A) ={y∈M:ϕY\nt(y)∈A}.\nThat is, y∈(ϕY\nt)−1(A) if an only if ϕY\nt(y)∈A. Since y∈Mandh:M→Mis bijective,\nthere exists x∈Msuch that y=h(x). Then h(ϕX\nt1(x)) = ϕY\nt2(h(x)) = ϕY\nt2(y). Then\ny∈(ϕY\nt)−1(A) if and only if h(ϕX\nt1(x))∈A– that is, if and only if ϕX\nt1(x)∈h−1(A).\nApplying again the preimage definition, we have that y∈(ϕY\nt2)−1(A) if and only if for x\nwith y=h(x) we have that x∈(ϕX\nt1)−1(h−1(A)). By construction x=h−1(y), so\nh−1((ϕY\nt2)−1(x))∈A if and only if ( ϕX\nt1)−1(h−1(x))∈A .\n47\n--- Page 48 ---\nHess and Morris\nTherefore,\n(ϕX\nt1)−1(h−1(A)) =h−1((ϕY\nt2)−1(A)).\nSubstituting this into (1.0.17),\nh#µ((ϕY\nt2)−1(A)) =µ\u0000\n(ϕX\nt1)−1(h−1(A))\u0001\n.\nThat µis invariant under ϕX\ntmeans that µ(A) =µ((ϕX\nt)−1(A)) for A∈ B. Therefore,\nh#µ((ϕY\nt2)−1(A)) =µ\u0000\nh−1(A)\u0001\n=h#µ(A).\nProof of Proposition 19 . From the definition of convergence in probability,\nlim\nϵ→0P(||xϵ\nt−x∗\nt|| ≥δ) = 0\nforδ >0. We need to show that,\nlim\nϵ→0P(||h(xϵ\nt)−y∗\nt|| ≥δ′) = 0\nforδ′>0. The Heine-Cantor theorem implies that his uniformly continuous since Mis\ncompact. Uniform continuity implies that for any δ′>0, there exists a δ >0 such that for\nallx, y∈M:\n||h(x)−h(y)||< δ′with ||x−y||< δ .\nEquivalently, for any δ′>0 there exists a δ > 0 so that ||xϵ\nt−x∗\nt||< δ implies that\n||h(xϵ\nt)−y∗\nt||< δ′. The contrapositive of this implication implies a bound,\nP(||h(xϵ\nt)−y∗\nt|| ≥δ′)≤P(||xϵ\nt−x∗\nt|| ≥δ).\nBy convergence in probability of the right-hand side P(||xϵ\nt−x∗\nt|| ≥δ→0 when ϵ→0.\nProof of Proposition 21 . Since Xϵare small random perturbations, paths of xϵ\nt1con-\nverge in probability to the trajectories of ϕX\nt1; similarly for Yϵ. So, (1) is satisfied. We\nneed to show (2), that h(ΦX,ϵ\nt1(x,·))P− →ΦY,ϵ\nt2(h(x),·). From the definition of topological\nequivalence, h(ϕX\nt1(x)) = ϕY\nt2(h(x)) for x∈M. The left-hand side of this equality well-\ndefined, so Proposition 19 implies that h(xϵ\nt1)P− →h(x∗\nt1). Then, h(ΦX,ϵ\nt1(x,·))P− →h(ϕX\nt1(x)).\nMoreover, by (1), ΦY,ϵ\nt2(h(x),·)P− →ϕY\nt2(h(x)). Substitute h(ϕX\nt1(x)) = ϕY\nt2(h(x)) to obtain\nh(ΦX,ϵ\nt1(x,·))P− →ϕY\nt2(h(x)). So, for any δ >0,\nlim\nϵ→0P\u0010\n∥ΦY,ϵ\nt2(h(x),·)−ϕY,ϵ\nt2(h(x))∥ ≥δ\u0011\n= 0,and\nlim\nϵ→0P\u0010\n∥h(ΦX,ϵ\nt1(x,·))−ϕY,ϵ\nt2(h(x))∥ ≥δ\u0011\n= 0.\n48\n--- Page 49 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nThe norm in (2) satisfies the triangle inequality,\n∥h(ΦX,ϵ\nt1(x,·))−ΦY,ϵ\nt2(h(x),·)∥ ≤ ∥ ΦY,ϵ\nt2(h(x),·)−ϕY,ϵ\nt2(h(x))∥+∥h(ΦX,ϵ\nt1(x,·))−ϕY,ϵ\nt2(h(x))∥.\nConsequently, the probability P\u0010\n∥h(ΦX,ϵ\nt1(x,·))−ΦY,ϵ\nt2(h(x),·)∥ ≥δ\u0011\nobtained from the left-\nhand side is less than or equal to,\nP\u0010\n∥ΦY,ϵ\nt2(h(x),·)−ϕY,ϵ\nt2(h(x))∥+∥h(ΦX,ϵ\nt1(x,·))−ϕY,ϵ\nt2(h(x))∥ ≥δ\u0011\n≤P\u0010\n∥ΦY,ϵ\nt2(h(x),·)−ϕY,ϵ\nt2(h(x))∥ ≥α\u0011\n+P\u0010\n∥h(ΦX,ϵ\nt1(x,·))−ϕY,ϵ\nt2(h(x))∥ ≥κ\u0011\n,\nwhere the second inequality comes from the union bound (Boole’s inequality) for some\nα, κ > 0. Set α, κ=δ/2. Then the two terms in the last inequality are equal to 0 when\nϵ→0. Then lim ϵ→0P\u0010\n∥h(ΦX,ϵ\nt1(x,·))−ΦY,ϵ\nt2(h(x),·)∥ ≥δ\u0011\n= 0 as desired.\nAppendix B. Proofs on Morse theory\nA proof of the Stable Manifold theorem for a Morse function is now given. First, a couple\nof lemmas adapted from Milnor (1965) are stated.\nLemma 28. LetKbe a compact subset of an open set U⊂Rnand1≤r≤ ∞ . If\nf∈Cr(U,R)has only nondegenerate critical points in K, then there exists an η >0such\nthat if g∈Cr(U,R)and||Di(f−g)(x)||< ϵfor all x∈K, then ghas only nondegenerate\ncritical points in K.\nLemma 29. Letd:K→K′be a diffeomorphism of two compact subsets K⊂Uand\nK′⊂U′forU⊂RnandU′⊂Rn. For any ϵ >0, there exists a δ >0such that if a smooth\nmap f∈C∞(U′,R)satisfies ||Di(f)(x′)||< δat all points x′∈K′, then f◦dsatisfies\n||Di(f◦d)(x)||< ϵat all points x∈Kfori= 0,1,2, ..., r .\nProof of Theorem 8 . (1): Let Ma=V−1(−∞, a] ={q∈Ws(p) :V(q)≤a}anda, b∈R\nwith a < b . Then Mais diffeomorphic to Mbso long as V−1[a, b] is compact and contains\nno critical points28. Set ta(q) as the unique time where V(ϕX\nta(q)(q)) =aforq∈Mb. Then\nthe assignment q7→ϕX\nta(q)(q) is a diffeomorphism from MbtoMapushing MbtoMaalong\nthe trajectories of the gradient flow.\nLetBδ⊂Mbe a coordinate neighborhood of pwith radius δ >0. Let Es⊕Eube\nthe invariant splitting of TpMinto contracting and expanding directions defined by the\northonormal basis and adapted norm (above). We consider (1) for Ws(p). The proof\nforWu(p) is analogous. Set Bs\nβ=Bβ∩EsandBu\nβ=Bβ∩Eu. Choose βsufficiently\nsmall so that the local stable manifold theorem holds. Choose β >0 so that for x∈Bs\nβ,\nx1=· · ·=xλ= 0. Denote this subset of BβbyWs\nBβ. Since this basis\u0010\n∂\n∂x1, ...,∂\n∂xn\u0011\nforTpMis orthonormal, the tangent space TpWBβatpis the positive eigenspace of the\nHessian\u0000\n∂2V/∂x j∂xi\u0001\natp.\n28. see, e.g., Milnor (2016), Theorem 3.1 for an alternative proof which reparametrizes the gradient flow to\nbe constant within [ a, b] and vanish elsewhere.\n49\n--- Page 50 ---\nHess and Morris\nLetγx(t) =ϕX\nt(x) be a smooth gradient flow map. Order the eigenvalues of the Hessian\nso the first λpones are negative ( α1, ...α λp) and n−λpare positive ( βλp+1, ..., β λn). In Ws\nBβ,\nγi(t) =\u001aγi(0)e|αλi|t, λ i≤λp\nγi(0)e−|βλi|t, λ i> λp\nwhere γ(0) = xforx∈Ws\nBβandγidenotes the i-th component of γ.\nThis explicit formula for γi(t) inWs\nBβ⊂Ws(p) shows that it is a smoothly embedded\nsubmanifold of M(in accordance with the local stable manifold theorem). Any such open\nset extends smoothly throughout Ws(p). Let Ma\ns=Ws\nBβ∩Maand let Ws\nt=ϕX\n−t(x) for\nx∈Ws\nBβ. Then by the above, ϕX\ntapplied backwards in time is a diffeomorphism from\nMa\ns=Ws\nBβto some Ws\nt=Mb\ns. When t→ ∞ , the gradient flow traces out larger portions\nofWs(p). Since each element of Ws(p) is eventually in Ws\nBβ,\nWs(p) =[\nb>V(p)Mb\ns=[\ntWs\nt.\nSince Ws\nBβ⊂Ws(p) is an embedded submanifold of the same dimension, we have that it\nis an open neighborhood of pcontained in Ws(p) with tangent space Es. That the tangent\nspace of Ws(p) isEsfollows. That Ws(p) is an embedded submanifold of Mwith the same\nregularity as Xfollows from the regularity of the local stable manifolds composed with ϕX\nt.\nThe dimensionality similarly follows. This proves (1).\n(2): The proof follows Milnor (1965), Theorem 2.7 which shows that Morse functions\nare open and dense. Let ( U1, h1), ...,(Uk, hk) be a finite covering of M(by compactness).\nChoose compact sets Ki⊂Uisuch thatS\niKicovers M. By Lemma 28, there exists a\nneighborhood Niwhich has no degenerate critical points in Ki. Let N=Tm\niNibe a\nneighborhood of V∈Cr+1(M,R), then any g∈ N has no degenerate critical points on\nM=Sn\niKi. This shows that Morse functions are open in Cr+1(M,R).\nNow choose a neighborhood NofV∈Cr+1(M,R) and a smooth bump function Λ :\nM→[ 0,1 ] with Λ( x) = 1 for xin a neighborhood of K1and Λ( x) = 0 for xin a\nneighborhood of the complement M\\U1. Then generically, through an application of\nSard’s theorem, for almost all linear maps L:Rn→R, the map,\nV1(x) =V(x) + Λ( x)L(hi(x))\nwill have nondegenerate critical points on K1⊂U1; see Milnor (1965), Lemma A, Page 11.\nThe difference between V1(x) is supported on the compact subset K= supp Λ( x)⊂U1.\nL(x) =P\nilixiis linear, so this difference is written,\nid◦V1◦h−1\n1(x)−id◦V◦h−1(x)\nforx∈h1(K). Setting the coefficients lismall enough, it can be ensured that this difference,\nalong with the rthorder derivatives are smaller than any ϵ >0 on h1(K). Ifϵ >0 is small\nenough, V1∈ N by Lemma 29. Therefore V1has no degenerate critical points on K1, and by\nLemma 28, we may choose a neighborhood N1⊂ N so that any g∈ N 1has nondegenerate\n50\n--- Page 51 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\ncritical points in K1. This process can be repeated to obtain a V2∈ N 2⊂ N 1that has no\ndegenerate critical points on K2∪K1. Applying this process iteratively, Vk∈ N k⊂ N k−1⊂\n...⊂ N 1⊂ N which has no degenerate critical elements on K1∪...∪Kk.\nLetNbe an η-neighborhood of V∈Cr+1(M). That is, for each V′∈ N andi=\n0, ..., r + 1,\n||Di(V′◦h−1)(x)−Di(V◦h−1)(x)||< η .\nFrom above it follows that ηcan be made sufficiently small so that each V′∈ N has\nnondegenerate critical points onSk\niKk=M. The gradient fields X=−∇gVandX′=\n−∇gV′in the (fixed) Riemannian metric galso satisfy\n\f\f\f\f\f\f\f\fDi\u0012\ngij∂V◦h−1\n∂xj\u0013\n(x)−Di\u0012\ngij∂V′◦h−1\n∂xj\u0013\n(x)\f\f\f\f\f\f\f\f< δ\nfori= 0, ..., r and some δ >0, since derivatives of the metric on compact sets are bounded\nand so are the partial derivatives ∂V◦h−1/∂xjand∂V′◦h−1/∂xj. This difference is clearly\ncontrolled by the difference in the partial derivatives of VandV′; both are supported on\ncompact sets. Then as V′→Vin the Cr+1sense, X′→Xin the Crtopology. By definition,\nthe gradient flow ϕX\ntforX=−∇gVis determined by the unique solutions tod\ndtϕX\nt(p) =\nX(ϕX\nt(p)) given initial conditions; similarly for ϕX′\nt. From (1), Ws(p) =S\nb>V(p)Mb\ns=S\ntWs\nt. That is, Ws(p) is an embedded submanifold, and the inclusion Ws(p),→Mcan be\ntaken as gradient flow lines γx(t) (from the definition of stable manifold). Since any V′∈ N\nhas no degenerate critical points, the stable manifolds for the corresponding gradient system\nX′are well-defined. Since V′can be made arbitrarily close to VinN, so are their flow\nlines, and X′can be made so that it has exactly one critical point arbitrary close to that of\nXwith the same index. Denote by p′such a critical point and Ws(p′) the corresponding\nstable manifold for the flow ϕX′\nt. Then the gradient flow lines of ϕX′\ntcan be made within\nϵin the Crtopology to ϕX\ntfor any ϵ >0. That is, Ws(p′)→Ws(p) in the Crsense as\nV′→Vin the compact-open Cr+1topology. This shows (2).\nAppendix C. Applications\nC.1 Proofs on generic conditions\nThe following lemma is needed for a proof of Proposition 23:\nLemma 30 (Palis and De Melo (2012), Chapter 1.3) .LetS⊂Rnbe a submanifold and\nf∈C∞(M,Rn). The set of vectors u∈Rnfor which f+uis transversal to Sis residual.\nProof of Proposition 23 . Denote by Ψ δ:∂DC+δ,→Rnthe inclusion of the boundary\n∂DC+δinRn. We will show that, given a δ >0, the map Ψ δcan always be modified so that\nit intersects the gradient flow ϕX\nttransversally. For any δ, the set DC+δ\\DCcontains no\ncritical points. Therefore, defining Φ( x, tx) :=γx(tx) forx∈∂DC+2δgives a diffeomorphism\nΦ(x, tx) :∂DC+2δ→∂DC29.\n29. That Φ( x, tx) is a diffeomorphism follows from, e.g., Milnor (2016), Theorem 3.1.\n51\n--- Page 52 ---\nHess and Morris\nFigure 9: Intuition for Proposi-\ntion 23 . Critical points (filled black cir-\ncles, white cross) lie in the interior of\nthe disc DC(blue, magenta circles) with\nboundary ∂DC∼=Sn−1\nC(black exterior).\nFor a δ > 0, the disc DC+2δis diffeo-\nmorphic to DC; flow lines (grey) intersect\nDC+δ. In a neighborhood of an intersec-\ntion point (red circle), a bump function\nmodifies ∂DC+δ(inset) to intersect flow\nlines transversally if not already.Then for any x∈∂DC+2δ, there is a time tx\nthat the flow line γxintersects ∂DC+δ. That is,\nγx(tx)∩Sn−1\nC+δ={p}for some p∈Sn−1\nC+δ. The\nsphere Sn−1\nC+δis compact, so choose a finite cover\n(U1, h1), ...(Un, hn) and compact sets Ki⊂Uiso\nthat K1, ..., K ncover Sn−1\nC+δ. Choose a chart, say\n(V1, y1) with y1=idandy1:V1→Rnso that\nΨδ(K1)⊂V1. Choose a smooth bump function Λ :\nM→[0,1] with Λ( x) = 1 for xin a neighborhood\nofK1and Λ( x) = 0 for xin a neighborhood of the\ncomplement Sn−1\nC+δ\\U1. Consider the map\n˜Ψδ(x) = Λ( x)Ψu\nδ(x),\nwith u∈Rna vector and y1◦Ψu\nδ(x) =y1◦Ψδ(x)+\nu=id◦Ψδ(x) +u. By Lemma 30, there is a vector\nuwith arbitrarily small norm ||u||>0 so that y1◦\nΨδ(x)+uis transversal to y1(ϕX\nt)⊂Rn. Therefore\n˜Ψδis transversal to ϕX\ntonK1. That ˜Ψδ(x) remains\none-to-one is clear. The difference between ˜Ψδ(x)\nand Ψ δ(x),\ny1◦˜Ψδ◦h−1\n1(x)−y1◦Ψδ◦h−1\n1(x) = Λ◦h−1(x) +u ,\nis supported on the compact set K= supp Λ( x)⊂U1forx∈h1(K). Given an initial\nneighborhood N1of Ψ δinC∞(Sn−1\nC+δ,Rn), it is easy to see that ||u||can be sufficiently small\nso that ˜Ψδ(x)∈ N 1. Repeating this process for a second compact set K2gives a map\n˜Ψδ∈ N 2transverse to ϕX\ntonK2. Since ˜Ψδis transverse to ϕX\ntonU1,˜Ψδ∈ N 1∩ N 2is\ntransverse to ϕX\ntonK1∪K2. Repeating this again produces a map ˜Ψδ∈ N 1∩...∩ N n\nwhich is transverse to ϕX\ntonK1∪...∪Kn.\nProof of Proposition 25 . Since Mis compact, Crit( V) ={β1, ..., β n}is a finite number of\ncritical elements. Let ( U1, h1), ...,(Un, hn) be Morse charts in the neighborhoods of β1, ..., β n\nandgE1, ..., g Enthe standard euclidean metric with respect to the coordinates ( y1, ..., yn) in\neach chart. Since these critical points are isolated, we may assume that ( U1, h1), ...,(Un, hn)\nare non-overlapping. Let B(β1, δ)⊂U1be a coordinate ball of radius δ >0 and B(β1, ϵ)⊂\nB(β1, δ) with ϵ < δ (which can be arbitrarily small). Choose a smooth ( C∞) bump function\nΛ :M→[0,1] with Λ( x) = 1 for x∈B(β1, δ) and Λ( x) = 0 for xin a neighborhood of the\ncomplement M\\B(β1, ϵ). Then the metric\ng=g0(y)(1−Λ(y)) +gE1(y)Λ(y)\nis a metric on U1, since the set of symmetric positive definite bilinear forms is a convex set\nand this is convex linear combination. Therefore, the metric gis in standard form near β1.\nBy compactness, we may add additional charts ( Uj, hj),1≤j≤Nwith open images Ω j\nunder hjwhose union with those of ( Ui, hi) cover M. Then gcan be extended to all of M\nby setting g=gforxinU1andg=g0otherwise. We now proceed in iterations. Apply\n52\n--- Page 53 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n161116212631361\n6\n11\n16\n21\n26\n31\n36a Hebbian training\n161116212631361\n6\n11\n16\n21\n26\n31\n36Hebbian PGD\nbOriginal\n Corrupted\nHebbian training\n Hebbian PGD\nOriginal\n Corrupted\nHebbian training\n Hebbian PGD\n1\n01\n1\n01\n1\n01\n1\n01\n4\n 0 44\n04c=0\n1\n 0 11\n01=99\n1\n 0 11\n01=108\n1\n 0 11\n01=238\n1\n 0 11\n01=255\n4\n 0 44\n04=4347\n5\n 0 55\n05=0\n1\n 0 11\n01=147\n1\n 0 11\n01=156\n1\n 0 11\n01=286\n1\n 0 11\n01=305\n3\n 0 33\n03=4347\nTrajectory Energy Saddle Attractor / Memory\nFigure 10: Hebbian learning through projected gradient descent (Algorithm 1). (a)\nSynaptic connection matrix Wobtained by training a continuous-state Hopfield network with 36\nneurons to store six patterns in R36using the standard Hebbian rule (left) and Algorithm 1 (right)\n– the learning rate and convergence tolerance were set to 1 e−3and 1 e−12, while the norm constraint\nwas set as the norm of the weight matrix produced by the standard Hebbian rule. (b)Recall\nfrom two initial patterns corrupted with random Gaussian noise shows the concordance between the\ntwo approaches in a. Memory recall was performed by setting R−1= 0.125. (c)Hidden neuron\ntrajectories (grey) and critical points of a one-parameter family of gradients (left to right, indexed\nbyη) produced by training the network using Algorithm 1 and projecting on to two axes (top, axis\n5 and 11; bottom, axis 21 and 22). Trajectories and critical points are projections by fixing the\nstates of all other neurons to zero, and do not reflect the full dynamics. As the optimization index\nincreases from the initial state η0= 0 to the final state ηfinal= 4347, subcritical and supercritical\nsaddle-node bifurcations occur.\nthe same procedure above on a Morse chart ( U2, h2) by choosing suitable coordinate balls\nB(β2, ϵ)⊂B(β2, δ)⊂U2. Since U1andU2do not overlap, gis automatically in standard\nform near β1. After modifying it on U2with the bump function Λ, it is also in standard\nform near β2. Applying this procedure to all remaining Morse charts produces a metric in\nstandard form for all β1, ..., β n. So, gis compatible with the Morse charts of V.\nC.2 Hopfield networks\nThe following algorithm describes the projected gradient descent approach to training a\nHopfield network using the Hebbian learning rule, followed by an application of it to a\nhigher-dimensional system in Figure 10.\n53\n--- Page 54 ---\nHess and Morris\nAlgorithm 1: Projected Gradient Descent Hebbian Learning\nInput: {ξ1, . . . , ξM}: set of Mpatterns;\nη: learning rate;\nc: Frobenius norm bound for projection constraint ∥W∥F≤c;\nε: tolerance for stopping condition.\nResult: Synaptic weight matrix W.\nInitialization:\n1. Randomly initialize weight matrix W∈RN×N.\n2. Symmetrize W:W←W+WT\n2\n3. Project W:\nif∥W∥F> cthen\nW←W·c\n∥W∥F; // Project Wonto ball of radius c\nend\nwhile not converged do\nWprev←W; // Store weight matrix\nHebbian rule:\nforeach pattern ξm,m= 1, . . . , M do\nW←W+η·ξm(ξm)T; // Hebbian rule\nend\nProjection step:\nif∥W∥F> cthen\nW←W·c\n∥W∥F\nend\nStopping condition:\n∆W← ∥W−Wprev∥F\nif∆W < ε then\nbreak\nend\nend\nC.3 Denoising diffusion models\nThe following figure shows the training and generation dynamics of the probability flow\nODE of the denoising diffusion model from Figure 8 as a two-parameter family of gradients.\nThe model was trained using the score matching objective, and the score function was\nparameterized by a three-layer multilayer perceptron with the softplus activation function\nand hidden dimensionality of 128. The score was calculated using automatic differentiation.\n54\n--- Page 55 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\n1\n01=2\nGenerationOptimizationt=1.0\n t=0.49\n t=0.43\n t=0.384\n t=0.15\n1\n01=20\n1\n01=200\n1\n01=2000\n1\n 0 11\n01=16000\n1\n 0 1 1\n 0 1 1\n 0 1 1\n 0 1Trajectory Energy\nFigure 11: Example of diffusion model generation and learning as a two-parameter\nfamily of gradients. Trajectories (grey) of a two-parameter family of gradients derived from the\nprobability flow ODE of the variance-preserving diffusion model generating a data set with four\ncentroids in R2from §5.5. The generation dynamics are obtained by solving the probability flow\nODE backwards in time, with the energy of the time-varying potential depicted from left to right,\nindexed by time t, while the optimization dynamics are ordered from top to bottom by the gradient\ndescent index η. Critical points are not shown.\nReferences\nDavid H Ackley, Geoffrey E Hinton, and Terrence J Sejnowski. A learning algorithm for\nboltzmann machines. Cognitive science , 9(1):147–169, 1985.\n55\n--- Page 56 ---\nHess and Morris\nBrian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their\nApplications , 12(3):313–326, 1982.\nMichele Audin, Mihai Damian, and Reinie Ern´ e. Morse theory and Floer homology , vol-\nume 2. Springer, 2014.\nAugustin Banyaga, David Hurtubise, and Deborah Ajayi. Lectures on Morse homology ,\nvolume 29. Springer, 2004.\nAnton Bovier, Michael Eckhoff, V´ eronique Gayrard, and Markus Klein. Metastability in\nstochastic dynamics of disordered mean-field models. Probability Theory and Related\nFields , 119:99–161, 2001.\nAnton Bovier, Michael Eckhoff, V´ eronique Gayrard, and Markus Klein. Metastability in\nreversible diffusion processes. i. sharp asymptotics for capacities and exit times. J. Eur.\nMath. Soc.(JEMS) , 6(4):399–424, 2004.\nRufus Bowen and David Ruelle. The ergodic theory of Axiom A flows. Inventiones mathe-\nmaticae , 29:181–202, 1975.\nCletus J Burke and Murray Rosenblatt. A Markovian function of a Markov chain. The\nAnnals of Mathematical Statistics , 29(4):1112–1122, 1958.\nHanqun Cao, Cheng Tan, Zhangyang Gao, Yilun Xu, Guangyong Chen, Pheng-Ann Heng,\nand Stan Z Li. A survey on generative diffusion models. IEEE Transactions on Knowledge\nand Data Engineering , 2024.\nMichael A Cohen and Stephen Grossberg. Absolute stability of global pattern formation and\nparallel memory storage by competitive neural networks. IEEE transactions on systems,\nman, and cybernetics , (5):815–826, 1983.\nRalph L Cohen, Kevin Iga, and Paul Norbury. Topics in Morse theory: Lecture notes.\nhttps://math.stanford.edu/ ~ralph/morsecourse/biglectures.pdf , 2006.\nJordan Cotler and Semon Rezchikov. Renormalizing diffusion models. arXiv preprint\narXiv:2308.12355 , 2023.\nWilliam Cowieson and Lai-Sang Young. SRB measures as zero-noise limits. Ergodic Theory\nand dynamical systems , 25(4):1115–1138, 2005.\nGeorge Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics\nof control, signals and systems , 2(4):303–314, 1989.\nPeter Dayan and Laurence F Abbott. Theoretical neuroscience: computational and mathe-\nmatical modeling of neural systems . MIT press, 2005.\nMete Demircigil, Judith Heusel, Matthias L¨ owe, Sven Upgang, and Franck Vermet. On a\nmodel of associative memory with huge storage capacity. Journal of Statistical Physics ,\n168:288–299, 2017.\n56\n--- Page 57 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nMJ Dias Carneiro and Jacob Palis. Bifurcations and global stability of families of gradients.\nPublications Math´ ematiques de l’IH ´ES, 70:103–168, 1989.\nKen-Ichi Funahashi. On the approximate realization of continuous mappings by neural\nnetworks. Neural networks , 2(3):183–192, 1989.\nV´ eronique Gayrard. Mixed memories in hopfield networks. arXiv preprint\narXiv:2504.04879 , 2025.\nJohn Guckenheimer and Philip Holmes. Nonlinear oscillations, dynamical systems, and\nbifurcations of vector fields , volume 42. Springer Science & Business Media, 2013.\nGeoffrey E Hinton. Training products of experts by minimizing contrastive divergence.\nNeural computation , 14(8):1771–1800, 2002.\nMorris W Hirsch. Differential topology , volume 33. Springer Science & Business Media,\n2012.\nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Ad-\nvances in neural information processing systems , 33:6840–6851, 2020.\nBenjamin Hoover, Yuchen Liang, Bao Pham, Rameswar Panda, Hendrik Strobelt,\nDuen Horng Chau, Mohammed Zaki, and Dmitry Krotov. Energy transformer. Advances\nin neural information processing systems , 36:27532–27559, 2023a.\nBenjamin Hoover, Hendrik Strobelt, Dmitry Krotov, Judy Hoffman, Zsolt Kira, and\nDuen Horng Chau. Memory in plain sight: A survey of the uncanny resemblances between\ndiffusion models and associative memories. arXiv preprint arXiv:2309.16750 , 2023b.\nJohn J Hopfield. Neural networks and physical systems with emergent collective computa-\ntional abilities. Proceedings of the national academy of sciences , 79(8):2554–2558, 1982.\nJohn J Hopfield. Neurons with graded response have collective computational properties\nlike those of two-state neurons. Proceedings of the national academy of sciences , 81(10):\n3088–3092, 1984.\nMichael Hutchings. Lecture notes on Morse homology (with an eye towards Floer theory\nand pseudoholomorphic curves). 2002.\nChii-Ruey Hwang. Laplace’s method revisited: weak convergence of probability measures.\nThe Annals of Probability , pages 1177–1182, 1980.\nJohn Kent. Time-reversible diffusions. Advances in Applied Probability , 10(4):819–835,\n1978.\nDmitry Krotov. A new frontier for hopfield networks. Nature Reviews Physics , 5(7):366–367,\n2023.\nDmitry Krotov and John J Hopfield. Dense associative memory for pattern recognition.\nAdvances in neural information processing systems , 29, 2016.\n57\n--- Page 58 ---\nHess and Morris\nHiroshi Kunita and MK Ghosh. Lectures on stochastic flows and applications , volume 78.\nTata Institute of Fundamental Research Bombay, 1986.\nJohn M Lee. Riemannian manifolds: an introduction to curvature , volume 176. Springer\nScience & Business Media, 2006.\nJohn M Lee. Smooth manifolds. In Introduction to Smooth Manifolds . Springer, 2013.\nKenneth R Meyer. Energy functions for Morse Smale systems. American Journal of Math-\nematics , 90(4):1031–1040, 1968.\nJohn Milnor. Lectures on the h-cobordism theorem . Princeton university press, 1965.\nJohn Milnor. Morse Theory. (am-51), volume 51. In Morse Theory.(AM-51), Volume 51 .\nPrinceton university press, 2016.\nJohn Willard Milnor and James D Stasheff. Characteristic classes . Number 76. Princeton\nuniversity press, 1974.\nKevin P. Murphy. Probabilistic Machine Learning: Advanced Topics . MIT Press, 2023.\nURL http://probml.github.io/book2 .\nS Newhouse and J Palis. Bifurcations of Morse–Smale dynamical systems. In Dynamical\nsystems , pages 303–366. Elsevier, 1973.\nSheldon E Newhouse. Nondensity of Axiom A(a) on S2.Global analysis , 1:191, 1970.\nLiviu I Nicolaescu et al. An invitation to Morse theory . Springer, 2007.\nJ. Palis. On Morse-Smale dynamical systems. Topology , 8(4):385–404, 1969. ISSN\n0040-9383. doi: https://doi.org/10.1016/0040-9383(69)90024-X. URL https://www.\nsciencedirect.com/science/article/pii/004093836990024X .\nJ Jr Palis and Welington De Melo. Geometric theory of dynamical systems: an introduction .\nSpringer Science & Business Media, 2012.\nJacob Palis. A global view of dynamics and a conjecture on the denseness of finitude of\nattractors. Ast´ erisque , 261(xiiixiv):335–347, 2000.\nJacob Palis. A global perspective for non-conservative dynamics. In Annales de l’IHP\nAnalyse non lin´ eaire , volume 22, pages 485–507, 2005.\nJacob Palis and Floris Takens. Stability of parametrized families of gradient vector fields.\nAnnals of Mathematics , pages 383–421, 1983.\nGiorgio Parisi. Correlation functions and computer simulations. Nuclear Physics B , 180(3):\n378–384, 1981.\nKalyanapuram Rangachari Parthasarathy. Probability measures on metric spaces , volume\n352. American Mathematical Soc., 2005.\n58\n--- Page 59 ---\nAssociative Memory and Generative Diffusion in the Zero-noise Limit\nBao Pham, Gabriel Raya, Matteo Negri, Mohammed J Zaki, Luca Ambrogioni, and Dmitry\nKrotov. Memorization to generalization: Emergence of diffusion models from associative\nmemory. arXiv preprint arXiv:2505.21777 , 2025.\nArchishman Raju and Eric D Siggia. A geometrical model of cell fate specification in the\nmouse blastocyst. bioRxiv , pages 2023–10, 2023.\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical\ntext-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125 , 1\n(2):3, 2022.\nHubert Ramsauer, Bernhard Sch¨ afl, Johannes Lehner, Philipp Seidl, Michael Widrich,\nThomas Adler, Lukas Gruber, Markus Holzleitner, Milena Pavlovi´ c, Geir Kjetil Sandve,\net al. Hopfield networks is all you need. arXiv preprint arXiv:2008.02217 , 2020.\nDavid A Rand, Archishman Raju, Meritxell S´ aez, Francis Corson, and Eric D Siggia. Ge-\nometry of gene regulatory dynamics. Proceedings of the National Academy of Sciences ,\n118(38):e2109729118, 2021.\nFraydoun Rezakhanlou. Lectures on the large deviation principle. Lecture Notes, Math UC\nBerkeley , 2015.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj¨ orn Om-\nmer. High-resolution image synthesis with latent diffusion models. In Proceedings of the\nIEEE/CVF conference on computer vision and pattern recognition , pages 10684–10695,\n2022.\nM Schwarz. Morse homology, 1993.\nMichael Shub. Global stability of dynamical systems . Springer Science & Business Media,\n2013.\nYa G Sinai. Dynamical systems II: Ergodic theory with applications to dynamical systems\nand statistical mechanics . Springer, 1989.\nStephen Smale. Morse inequalities for a dynamical system. 1960.\nStephen Smale. On gradient dynamical systems. Annals of Mathematics , pages 199–206,\n1961.\nStephen Smale. Differentiable dynamical systems. Bulletin of the American mathematical\nSociety , 73(6):747–817, 1967.\nStephen Smale and Jacob Palis. Structural stability theorems. In Proceedings of Symposia\nin Pure Mathematics (Global Analysis) , volume XIV, pages 223–231. American Mathe-\nmatical Society (AMS), 1970.\nJascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep un-\nsupervised learning using nonequilibrium thermodynamics. In International conference\non machine learning , pages 2256–2265. pmlr, 2015.\n59\n--- Page 60 ---\nHess and Morris\nYang Song and Diederik P Kingma. How to train your energy-based models. arXiv preprint\narXiv:2101.03288 , 2021.\nYang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon,\nand Ben Poole. Score-based generative modeling through stochastic differential equations.\narXiv preprint arXiv:2011.13456 , 2020.\nFloris Takens. Moduli of stability for gradients. In North-Holland Mathematics Studies ,\nvolume 103, pages 69–79. Elsevier, 1985.\nRen´ e Thom. Topological models in biology. Topology , 8(3):313–335, 1969.\nRen´ e Thom. Stabilit´ e structurelle et morphog´ en` ese: essai d’une th´ eorie g´ en´ erale des\nmod` eles , volume 17. Addison Wesley Longman, 1972.\nHugo Touchette. The large deviation approach to statistical mechanics. Physics Reports ,\n478(1-3):1–69, 2009.\nWilderich Tuschmann and David J Wraith. Moduli spaces of Riemannian metrics . Springer,\n2015.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N\nGomez,  Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in\nneural information processing systems , 30, 2017.\nAlexander D Ventsel and Mark Iosifovich Freidlin. On small random perturbations of\ndynamical systems. Russian Mathematical Surveys , 25(1):R01, 1970.\nLai-Sang Young. What are SRB measures, and which dynamical systems have them? Jour-\nnal of statistical physics , 108:733–754, 2002.\nAlan L Yuille and Anand Rangarajan. The concave-convex procedure (cccp). Advances in\nneural information processing systems , 14, 2001.\nChristopher Zeeman. The classification of elementary catastrophes of codimension ≤5.\nInStructural Stability, the Theory of Catastrophes, and Applications in the Sciences:\nProceedings of the Conference Held at Battelle Seattle Research Center 1975 , pages 263–\n327. Springer, 2006.\n60",
  "text_length": 162489
}