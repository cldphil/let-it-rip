{
  "id": "http://arxiv.org/abs/2506.04167v1",
  "title": "Neural and Cognitive Impacts of AI: The Influence of Task Subjectivity\n  on Human-LLM Collaboration",
  "summary": "AI-based interactive assistants are advancing human-augmenting technology,\nyet their effects on users' mental and physiological states remain\nunder-explored. We address this gap by analyzing how Copilot for Microsoft\nWord, a LLM-based assistant, impacts users. Using tasks ranging from objective\n(SAT reading comprehension) to subjective (personal reflection), and with\nmeasurements including fNIRS, Empatica E4, NASA-TLX, and questionnaires, we\nmeasure Copilot's effects on users. We also evaluate users' performance with\nand without Copilot across tasks. In objective tasks, participants reported a\nreduction of workload and an increase in enjoyment, which was paired with\nobjective performance increases. Participants reported reduced workload and\nincreased enjoyment with no change in performance in a creative poetry writing\ntask. However, no benefits due to Copilot use were reported in a highly\nsubjective self-reflection task. Although no physiological changes were\nrecorded due to Copilot use, task-dependent differences in prefrontal cortex\nactivation offer complementary insights into the cognitive processes associated\nwith successful and unsuccessful human-AI collaboration. These findings suggest\nthat AI assistants' effectiveness varies with task type-particularly showing\ndecreased usefulness in tasks that engage episodic memory-and presents a\nbrain-network based hypothesis of human-AI collaboration.",
  "authors": [
    "Matthew Russell",
    "Aman Shah",
    "Giles Blaney",
    "Judith Amores",
    "Mary Czerwinski",
    "Robert J. K. Jacob"
  ],
  "published": "2025-06-04T17:04:48Z",
  "updated": "2025-06-04T17:04:48Z",
  "categories": [
    "cs.HC"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.04167v1",
  "full_text": "--- Page 1 ---\narXiv:2506.04167v1  [cs.HC]  4 Jun 20251\nNeural and Cognitive Impacts of AI: The Influence of Task\nSubjectivity on Human-LLM Collaboration\nMatthew Russell1, Aman Shah1, Giles Blaney1, Judith Amores2, Mary Czerwinski3, and Robert J.K. Jacob1\n1Tufts University, Medford, Massachusetts, USA\n2Microsoft Research, Cambridge, Massachusetts, USA\n3Microsoft Research, Redmond, Washington, USA\n©2025 IEEE. Personal use of this material is permitted.\nPermission from IEEE must be obtained for all other uses, in\nany current or future media, including reprinting/republishing\nthis material for advertising or promotional purposes, creating\nnew collective works, for resale or redistribution to servers or\nlists, or reuse of any copyrighted component of this work in\nother works.\nAbstract —AI-based interactive assistants are advancing human-\naugmenting technology, yet their effects on users’ mental and\nphysiological states remain under-explored. We address this gap\nby analyzing how Copilot for Microsoft Word, a LLM-based\nassistant, impacts users. Using tasks ranging from objective (SAT\nreading comprehension) to subjective (personal reflection), and\nwith measurements including fNIRS, Empatica E4, NASA-TLX,\nand questionnaires, we measure Copilot’s effects on users. We\nalso evaluate users’ performance with and without Copilot across\ntasks. In objective tasks, participants reported a reduction of\nworkload and an increase in enjoyment, which was paired with\nobjective performance increases. Participants reported reduced\nworkload and increased enjoyment with no change in performance\nin a creative poetry writing task. However, no benefits due to\nCopilot use were reported in a highly subjective self-reflection task.\nAlthough no physiological changes were recorded due to Copilot\nuse, task-dependent differences in prefrontal cortex activation offer\ncomplementary insights into the cognitive processes associated\nwith successful and unsuccessful human-AI collaboration. These\nfindings suggest that AI assistants’ effectiveness varies with task\ntype—particularly showing decreased usefulness in tasks that\nengage episodic memory—and presents a brain-network based\nhypothesis of human-AI collaboration.\nIndex Terms —Large Language Model, Human-Computer\nInteraction, Brain-Computer Interfaces, functional Near-Infrared\nSpectroscopy, Empatica, Copilot\nI. I NTRODUCTION\nBY giving humans new ways to access information, Large\nLanguage Model (LLM) based interactive assistants\nsuch as ChatGPT promise to revolutionize the way we work.\nIndeed, considering the significant mental demands of complex\ncreative and decision-making tasks, the LLM-based assistant\ncould represent a paradigm shift in the cognitive landscape of\nhuman users. However, little is known about the effects such\nsystems actually have on their users. Does the user disengage\nand let the assistant do all the work? Do they engage more?\nDo they produce better or worse outputs? More generally, what\neffects do such tools have on users? How can this inform the\ndesign of future interactive LLM-based assistants? Are therespecific aspects of human neural function which correspond\nto beneficial or poor experience while working with LLM\ntools? In this work, we explore these questions with a variety\nof measurement techniques to investigate the effects of using\nan LLM on a user’s self-reported and physiological mental\nworkload and stress, as well as their objective performance\nas they perform an array of different tasks intended to target\ndifferent aspects of human experience.\nFor the LLM-based assistant in our study we used a\nversion of Microsoft Word in the Microsoft 365 suite equipped\nwith the Microsoft Copilot interactive Artificial Intelligence\n(AI) assistant. We used a 4 x 2 within-subjects design in\nwhich each of our four tasks had two equally difficult variants;\nfor each task, participants did one with and one without the\nCopilot assistant. Experimental tasks were defined along a\ngradient of subjectivity estimated to interface with different\naspects of human experience and correspond to the degree of\n‘difficulty’ for the assistant. To quantitatively measure mental\nworkload we employed both physiological and self-report\nmethods. Physiological measures include the use of functional\nNear-Infrared Spectroscopy (fNIRS) to measure changes\nprefrontal cortex hemoglobin concentration and the Empatica\nE4 device to observe Heart Rate (HR), Heart Rate Variability\n(HRV) and Electrodermal Activity (EDA). Physiological\nmeasures are complemented by quantitative self-reported data\nfrom both the NASA Task Load Index (NASA-TLX) and\nquestionnaires, and qualitative analysis via user feedback is\nalso performed. Quality of the users’ performance with and\nwithout the AIassistant was also assessed.\nII. B ACKGROUND AND RELATED WORK\nA. Large-Language Models and HCI\nHuman-computer interaction research on user impact from\nLLMs is still in its beginning stages. Much of the current\nresearch is still based in analyzing user output and using\nqualitative methods to understand user preferences [1], [2].\nHowever, in recent years, quantitative methods have played\na more significant role with studies looking at how user\nperformance and time spent on a task changes with the use\nof LLMs [3], [4]. Notable areas of application where research\nhas been conducted to understand the effects LLM tools have\non users include writing, computer programming, and decision\nmaking.\n--- Page 2 ---\n2\n1) Writing: Yuan tested an LLM story writing tool with\nprofessional authors to gain insights into the effectiveness of\nLLMs in supporting creative writing [2]. Nihil [5] examined\nthe potential and challenges of LLM use for creative writing,\nand Reza produced ABScribe, a novel interface for more easily\nintegrating human and machine-generated work in Human-AI\nco-writing tasks [6]. Other researchers have explored whether\nthere is a difference between quality in AI and human-generated\nliterary short texts [7]. Both Yuan and other studies have,\nusing both qualitative and quantitative methods, demonstrated\na productivity boost when using LLMs for work-related tasks,\nespecially for novice and low-skilled workers [2], [3], [8].\nHowever, the complexity of these systems reduces their benefits\nfor novice users who don’t know how to use them effectively,\nespecially in light of the sophistication required for prompt\ndesign [9], [10].\n2) Programming: Computer programming has also proven\nan effective testing ground for studying the effects of LLM\ntools on users. Ziegler [11] performed a comprehensive study\ninvestigating the effects of Github Copilot on users, with\na specific interest in productivity while Nguyen studied the\nchallenges that non-expert users face when using LLM-based\ntools to assist in programming [12].\n3) Decision Making: Researchers have also investigated\nthe benefits, drawbacks, and limitations of using LLM tools\nas an integral component of decision making processes.\nLawless investigated the combination of LLMs with Constraint\nProgramming to facilitate decision making [13]. Chiang studied\nthe use of AI tools to help decision making specifically in group-\nbased settings [14]. Bu c ¸inca has studied intrinsic motivation\nin Human-AI decision making, and Lakkaraju investigated the\nfairness and efficacy of LLM tools used in the context of\nfinancial decision making [15].\n4) Other LLM-based User Studies: Other avenues of ap-\nproach for investigating the effects of LLM-based tools on users\ninclude Arakawa’s work on adapting an LLM chatbot towards\nexecutive coaching [16], Huang’s work exploring the use of\nLLM assistants to help prevent driver fatigue [17], Suh’s work\non LLM-based tools for structured design space exploration\n[18] and multilevel sensemaking [19], and Tankelevitch’s work\non mapping the underlying metacognitive load while using AI\ntools [20].\nB. fNIRS and the Prefrontal Cortex\n1) fNIRS: fNIRS uses diffuse optical imaging of near-\ninfrared light to non-invasively measure changes in oxygenated\n∆[HbO] and deoxygenated ∆[Hb] hemoglobin concentrations\nin the human brain [21]. These measures can be connected to\nchanges in cerebral blood flow, which, in turn, are connected\nto brain oxygen demand and, thus, functional activation.\n2) The Prefrontal Cortex (PFC): Activation in the PFC,\nespecially the anterior and dorsolateral structures, is associated\nwith a wide variety of cognitive tasks including problem-\nsolving, planning, reasoning, and working memory [22]–[24].\nResearch in this area has utilized a variety of functional\nneuroimaging tools, including functional magnetic resonance\nimaging [25], [26] and fNIRS [27]. This multimodal research\nFig. 1: Microsoft Word with the integrated Copilot sidebar\nhas also elucidated that the many cognitive functions located\nin or supported by the PFC provide the cognitive flexibility\nnecessary for creative processing and thinking [28], [29]. This\nsubstantial association allows for the use of prefrontal cortex\nactivation as a measurement of user mental workload when\ncompleting a variety of tasks.\n3) HCI with PFC and fNIRS: In particular, studies with\nair traffic control operators and others have shown that fNIRS\nis particularly useful in assessing mental workload as users\ncomplete ecologically valid tasks on an interface [30]. Even\nmore, research has shown the utility of fNIRS in classifying\nhigh and low levels of mental workload, allowing for evaluation\nof interfaces based on their impact on a user’s cognitive load\n[31], [32]. Indeed, Hirshfield et al. [33] shows that fNIRS\nenhances usability testing because it provides quantitative\ninformation on the cognitive demands an interfaces places\non a user.\n4) Very Low Frequency Oscillations (VLF) with fNIRS and\nthe PFC: Research in fMRI and fNIRS has highlighted the\naccessibility and usefulness of observing Low Frequency (LF)\n[0.07 Hz - 0.2 Hz] and Very Low Frequency (VLF) [0.02 Hz -\n0.07 Hz] oscillations as correlates of cerebral hemodynamics\n[34], [35]. In particular, a decrease in the VLF band has been\nshown to relate to task-based cortical activation [34]. Further,\nsuch task-based cortical activation in the prefrontal cortex has\nbeen detected with fNIRS [27].\nC. Microsoft Copilot\nCopilot is an extension of the standard Microsoft Word\ninterface which leverages AI to assist users throughout a variety\nof tasks. Although the Copilot ecosystem in Word allows users\na wide array of functionality through multiple contexts, in order\nto minimize training time for our users as well as the potential\nfor interface-based confounds, we focused the user’s interaction\nwith Copilot to a single chat window on the side of the Word\nscreen (see Figure 1). This chat allows users to interact with\nthe Copilot assistant, and it in turn interfaces with a LLM to\nproduce relevant responses. While the specifics of which LLM\nis used are abstracted from the Word interface, Microsoft’s\n--- Page 3 ---\n3\ndocumentation specifies that it leverages a variant of GPT-4\nalong with the text-to-image model DALL-E [36]. For this\nresearch, the relevant tasks that Copilot can perform are: text\ngeneration and refinement, answering queries related to the\ncurrent document, or queries requesting general information\nor answers to specific questions.\nD. Empatica E4\nThe Empatica E4 device is a wristwatch-like device that\nmeasures Photoplethysmogram (PPG) and Electrodermal ac-\ntivity (EDA). From PPG, it produces measurements of Heart\nRate (HR) and Inter-Beat-Interval (IBI) data, which can be\nused to determine Heart Rate Variability (HRV) [37]. Among\nthe Empatica E4’s measurements of HR,IBI, and EDA,HR\nhas been shown to be the most reliable in comparison to gold-\nstandard methods [38]. And, although EDA andIBI have not\nperformed as well against baseline benchmarks, particularly\nin collection settings separate from rest [37], the E4 has been\nwidely used by researchers across disciplines to measure affect\n[39], [40] and stress [41], [42].\nIII. R ESEARCH QUESTIONS\nThe primary aim of this study is to explore the effects\nof using an interactive LLM system (in this case, Copilot\nfor Microsoft Word) on human users. Our specific research\nquestions follow below. For each question RQX we are\ninterested in RQX-A : overall effect, RQX-B : effects within\neach task, and RQX-C : effects that differ along the gradient\nof subjectivity.\nRQ1: Does the use of the Copilot assistant change users’\nworkload levels as measured by NASA-TLX ?\nRQ2: Does using the Copilot assistant change users’ levels\nof prefrontal cortex activation as measured by fNIRS?\nRQ3: Does the use of the Copilot assistant change users’\nlevels of stress as measured by Heart Rate ( HR), Heart Rate\nVariability ( HRV), and Electro Dermal Activity ( EDA)?\nRQ4: Does using the Copilot assistant change the quality\nof users’ output?\nRQ5: How do users feel about using the Copilot assistant?\nIV. M ATERIALS AND METHODS\nA. Study Tasks\nWe modeled our tasks along a gradient of subjectivity .\nWe designed this gradient along theoretical considerations\nof neurological systems, and developed tasks with practical\nexperimental constraints in mind. At one end of the gradient\nare highly structured tasks with objectively clear and correct\nanswers: we hypothesized that these tasks would engage\nparticipants in mental workload typically associated with\nprefrontal cortex activity; we expected these tasks would\nallow Copilot to meaningfully assist users, and would result\nin a corresponding decrease of prefrontal activation relating\nto decreased workload. At the opposite end of the gradient\nare open-ended tasks with highly subjective elements: we\nhypothesized that these tasks would engage participants in\nprefrontal activation associated with episodic memory; weexpected that these tasks would present significant challenges\nfor the AI assistant and would not affect brain function.\nDetermining the specific tasks that we would have our users\nengage in required much care and several iterations to strike a\nbalance between tasks that were easy enough for the LLM that\nit could perform them perfectly with a single click and tasks\nthat were too lengthy and involved for users to accomplish in\na reasonable amount of time. A particular challenge we discov-\nered from prior research and our own tests is that large language\nmodels are most effective in tasks with high complexity and\nlow ambiguity [43]; that is, Copilot produces highly detailed\nand effective output in direct proportion to the level of detail\nand structure of the task: the more structured and detailed\nthe task, the more structured and detailed the output from\nCopilot. After iterative refinement, we settled on a set of four\ntask groups: reading comprehension (objective, fact-based,\nrequires working memory), event planning (structured, but\ncreative), poetry writing (creative with personal elements), and\npersonal reflection (highly subjective and directly connected to\npersonal experience and episodic memory). For each task type,\nwe created two subtasks designed to be equally difficult. The\nfull text of the tasks themselves, and a statistical analysis testing\nmental workload changes between the subtasks (no significant\ndifferences were found), can be found in the supplementary\nmaterial.\n1)Reading Comprehension :These questions were slightly\nmodified versions of examples taken from the CollegeBoard’s\nScholastic Aptitude Test (SAT), and were easily answered\nby Copilot. This task served as a baseline, representing\nhighly objective problem-solving with minimal subjectivity.\nWe anticipated standard cognitive demands on users without\nCopilot, and minimal cognitive demand when assisted by the\nLLM.\n2)Event Planning :These tasks asked the user to design\nand plan an event with structured and detailed to-do checklists\nof the event-related information. While still structured, these\ntasks were more open-ended than those in SAT, and required\nmore subjective, personal, and creative input. We hypothesized\nthat Copilot would be helpful to the user in completing this\ntask, but that it would require more work from users in the\nCopilot condition as compared to SAT.\n3)Poetry Writing :These tasks asked the user to write a\nshort poem of 10-15 lines on a broad theme such as joy or\nnature. This task represents a substantial shift toward subjective\nmaterial, requiring purely creative expression that, at least in\nthe without-LLM assistance condition, would necessarily draw\non subjective personal experience. We believed that this task\nwould engage more fully with the episodic memory than the\nfirst two, and that the LLM assistant would enable users to\nquickly produce output, but that it also would struggle to assist\nthem given the inherently subjective nature of a poem.\n4)Personal Reflection :These tasks asked the user to\nreflect on their favorite album or movie and discuss why it\nwas their favorite based on their personal experiences. This\ntask was designed to maximally engage purely subjective,\nautobiographical episodic memory; we therefore hypothesized\nthat it would be quite challenging for the LLM tool to\nmeaningfully assist the user during these tasks.\n--- Page 4 ---\n4\nB. Study Structure\nAll users signed informed consent documents prior to be-\nginning the study, which was approved by the Tufts University\nInstitutional Review Board. We provided an initial survey\nregarding familiarity with AI tools. Participants then did a\n5 minute training task to familiarize them with the Copilot\nassistant. This included a variety of prompts for the user to\nuse with the assistant to better help them understand what it\ncould and could not do. Participants were able to ask questions\nprior to beginning the tasks if they needed help with Copilot.\nUsers then completed each of the four tasks in a randomized\norder counterbalanced across participants. The choice of which\nsubtask would be completed with the LLM assistant was\nlikewise counterbalanced. After each task participants filled\nout post-task surveys including the NASA-TLX, a space for\nusers to write any comments they would like, and a follow-up\nquestion rated on a scale of [0-10]: “How would you rate your\noverall experience with this task? (0=Terrible, 10=Amazing)”.\nThe participants were compensated with an Amazon gift card\n($25) for their time.\nC. Data Collection and Preprocessing\n1) Demographics: We recruited 20 healthy individuals (7\nMale, 10 Female, 3 opted not to disclose) for the study, ranging\nfrom 18-25 years old (mean 21).\n2) Exclusions from Physiological Data: Four participants\nwere excluded due to excessive noise across multiple trials\nseen through visual inspection of the fNIRS data. One fNIRS\nparticipant was excluded because an experimenter incorrectly\nmarked the data and one was excluded because the user refused\nto wear the fNIRS headband. Within otherwise used fNIRS\ndata, frequency domain ∆[HbD] ϕdata of the left prefrontal\ncortex for two participants in one task session exceeded 1.5\ntimes the Interquartile Range (IQR) across all participants:\nthe data were also excluded. From the Empatica data, three\nusers had invalid signal connection issues between the E4 and\nour collection device during collection time (Google Pixel 6\nPhone), two users were excluded due to manual marker input\nerrors, and one user declined to wear the wristband.\n3) fNIRS: We utilized a frequency-domain near-infrared\nspectroscopy device (ISS Imagent, Champaign, IL USA)\noperating at a modulation frequency of 110 MHz and with\nwavelengths of 690 nm and 830 nm. Two custom-made\noptical probes were placed on the subject’s forehead, one each\nfor the left and right hemispheres. The probes were secured\nto the subject’s head using an adjustable loop headband\nwhich passed through the center of the probes. Centroids\nof the probes were located over the prefrontal cortex of the\nassociated probe (Figure 2) at the approximate locations of\nAF7 and AF8 in the Standard 10-10 Electrode Configuration\n[44]. Each optical probe had optode geometry designed for\nthe dual-slope (DS) method [45]. Each probe consisted of\ntwo source positions, each with two wavelengths and two\ndetectors. For each DS probe, data from all combinations\nof sources and detectors were collected, resulting in a total\nof four single-distance (SD) measurements (source-detector\ndistances ( ρ): two of 25 mm and two of 35 mm) each of\nFig. 2: User wearing a functional near-infrared spectroscopy\n(fNIRS) device.\nfrequency-domain intensity amplitude (I) and phase ( ϕ) [46].\nThe light was delivered to each probe via 400 µmdiameter\nmulti-mode fibers and collected by 5 mm diameter fiber\nbundles. These fibers were held in-place by a flexible plastic\nmesh and were encapsulated in black silicone.\nData collection occurred in BOXY , a software provided ISS\nImagent. Nominal gains for each detector were found using\nBOXY for each user prior to beginning the study. The I and\nϕdata for each source-detector pair was processed using DS\nmethods, resulting in measurements of ∆[HbO] ( µM) and\n∆[HbR] ( µM) for each of I and ϕ[45]. Baseline correction\nfor each trial was performed with the initial 15 seconds for\neach trial, and the last 15 seconds of each trial were discarded.\nEach measurement for each trial was linearly detrended, and\na 5th order Butterworth bandpass filter was applied of the\nrange [0.02, 0.2] Hz [47]. For statistical analysis, ∆[HbD]\nwas calculated by ∆[HbO]- ∆[HbR] [48], frequency domain\ntransformation was performed using the Multitaper method\n[49], [50], Simpson’s rule was used to integrate over the\nVLF frequency band [51], and the resulting values were\nlog-transformed. Statistical analyses were then performed on\ntheDSI andDSϕdata [27], [34], with separate models created\nfor each probe and measurement value. For convenience, we\nrefer to the log total power in the VLFO band of the fNIRS\nsignal as fNIRS in the text below. Note that although we do\nnot use short channels for artifact removal, the DS method\nleverages counter-posing pairs of channels to perform removal\nof extracerebral information, including movement artifacts and\nscalp hemodynamics [45].\n4) Empatica E4: Our preprocessing steps for the various\nempatica streams was as follows.\nHRWe extracted the mean HRfor each trial.\nHRV Because Empatica’s inter-beat-interval recording has pre-\nprocessing of the signal applied in advance of the point\n--- Page 5 ---\n5\nof measurement from the device that removes most of the\nnon-normal beats in the RR interval, we used Empatica’s\nIBI to represent the IBI of normal sinus beats ( NN[52])\n[38], and used the standard deviation of the Empatica\nIBI data as SDNN for our HRV calculation. We excluded\ntrials with an IBI value outside of the range [1, 125] ms\n(5/81 trials were excluded).\nEDA Each of the trials were bandpass filtered with a 4th order\nButterworth filter of the range [0.01, 0.8] Hz [53]. We\nthen transformed the signal into the frequency domain\nusing the same process as with the fNIRS data; the\nfrequency band extracted was [0.045 0.25] Hz which has\nbeen shown to produce a reliable inference of sympathetic\nEDA [53].\n5) NASA-TLX: We produced unweighted average TLX\nscore for each participant’s response for each condition [54].\n6) Task Evaluation Scores: For SAT, quality scores were\nsimply defined as the percent of correct answers total per\ntask. For the other three tasks we had three members of our\nresearch team grade each of the submissions provided for the\nPLANNING ,POEM andREFLECTION tasks independently,\nrating each submission on a [1-5] scale for both of breadth and\ndepth . Consistency of the graders’ output was measured with\nIntraclass Correlation ICC [55], specifically using a two-way\nmixed-effects model considering consistency over the mean of\nk raters ( ICC3k ) [56]. Quality scores for breadth anddepth\nwere averaged across graders, and the resulting scores were\nthen averaged to produce a single score value for each user for\neach task. Quality scores for each task were then normalized\nacross users to a 0-1 scale.\nD. Statistical Methods\nTo account for the repeated measures design of our study\nwe analyzed our data using Linear Mixed Models (LMMs)\n[57]. We created separate models for each research question\nusing the following Rformula as a template:\nDV∼CONDITION ∗TASK +(1|PID/TASK) (1)\nWhere DVrepresents the measured dependent variable of\ninterest ( TLX,fNIRS ,HR,HRV,IBI,PERFORMANCE , or\nENJOYMENT ),CONDITION is a factor with two levels indi-\ncating use of Copilot (with-Copilot ( AI) or without-Copilot\n(NAI)), and TASK is a factor with four levels indicating\nthe type of task performed ( SAT,PLANNING ,POEM , or\nREFLECTION ). Random intercepts are specified for each\nparticipant ( PID), with nested intercepts within participant\nfor each TASK . For each model, likelihood ratio tests (LRTs)\nwere used to refine the random effects structure [58]; models\nthat showed better fit without the nested random effect of TASK\nwithin PID had this term removed.\nANOV A results from the LMMs for CONDITION are used\nto determine significance for all RQX-A. If interaction of\nCONDITION ×TASK demonstrates significance, post-hoc\ncontrasts are performed among the emmeans for CONDITION\nwithin levels of TASK to answer all RQX-B. To answer allRQX-C questions respective of Copilot (done if CONDITION\n×TASK is significant), custom emmeans contrasts are per-\nformed to test the effect of CONDITION across different pairs\nofTASK levels.\nTo answer all RQX-C questions irrespective of Copilot (done\nifCONDITION ×TASK is not significant, but TASK is), post-\nhoc contrasts are performed among the emmeans comparing\nlevels of TASK .\nFor all tests, αis set at 0.05, except in the case of omnibus\ntesting for fNIRS data and empatica data, where we apply\nBonferroni correction; for fNIRS, we consider the measures of\nDSI andDSϕfor each side of LandRas related, and thus α\nis adjusted to 0.025; for Empatica, we consider HRandHRV\nrelated, so αis adjusted to 0.025 for those tests.\nFor effect sizes, we report partial Epsilon squared ( ϵ2\np), also\nknown as adjusted partial eta squared (adj. η2\np), which quantifies\nthe proportion of variance associated with a given effect while\ncontrolling for other variables in the model, and reduces the\nbias introduced by the usual η2\npcalculation [59]1.\nE. Software Tools\nData were processed in the Python programming language.\nThepandas [61] and numpy [62] libraries were used for data\naggregation and filtering. Multitaper frequency transformations\nwere performed with the mne package [63]. The rpy2 package\nwas used to run Rcode, wherein we did all statistical analyses.\nlmerTest was used to create the Mixed-Effects Regression\nmodels [64], estimated marginal means and associated pairwise\ncomparisons were calculated with the emmeans package [65].\nEffect size calculations and associated confidence intervals\nwere determined with the effectsize package [66]. Vi-\nsualizations and associated error-bar calculations were made\nwith the Seaborn [67] package, and error-bars represent 95%\nconfidence levels using a 10,000 sample multilevel bootstrap\ngrouped by participant id to accounting for repeated measures\nwithin participants [67], [68].\nV. R ESULTS\nA. RQ1: TLX Workload Results\n1) RQ1-A Results: The Copilot condition resulted in overall\nlower TLX scores ( F1,133= 60 .42, p < 0.001, ϵ2\np=.31).\nResults are visible in Table I and visualized in Figure 3.\nTABLE I: ANOV A result from a model with WORKLOAD as\ntheDVin Formula 1. Although overall self-reported workload\ndecreased with Copilot, differences were found with an\ninteraction with CONDITION .\nFactor df1 df2 F p sig. ϵ2\np ϵ2\npCI\nCONDITION 1 133 60.42 <0.001 *** 0.31 [0.20,0.40]\nTASK 3 133 9 <0.001 *** 0.15 [0.06,0.23]\nCONDITION ×TASK 3 133 7.07 <0.001 *** 0.12 [0.03,0.20]\n1Despite that it is less often reported than ω2\npit has been shown that ϵ2\npis\nless biased [60].\n--- Page 6 ---\n6\nFig. 3: TLX scores in the NAI (without Copilot) and AI(with\nCopilot) conditions over all tasks. Each line represents a unique\nuser. Self-reported workload generally decreased when using\nCopilot. Further discussion of separate effects across levels of\nTASK is below.\n2) RQ1-B Results: CONDITION ×TASK demonstrated a\nstrong effect ( F3,133= 7.07, p < 0.001, ϵ2\np=.12). Pairwise\ncontrasts shown in Table II and visualized in Figure 4 show that\ntheAIwas significantly less than NAI for all levels of TASK\nwith the notable exception of REFLECTION (t133= 0.17, p=\n0.864, ϵ2\np= 0.00), which did not show a significant change.\nThis result is as-expected in terms of decreases in workload\ndecreases for the more objective SAT andPLANNING , and\nin terms of no change for REFLECTION , but it is somewhat\nsurprising that the participants reported a large decrease in\nworkload with Copilot in the more subjective POEM .\nFig. 4: Self-reported workload levels were lower with Copilot\nfor all levels of TASK except REFLECTION , which shows no\nchange.\n3) RQ1-C Results: Results regarding RQ1-C in consider-\nation of changes due to Copilot use are shown in Figure 5\nand Table III. Copilot significantly reduced workload in allTABLE II: Effects of Copilot use on self-reported mental\nworkload within levels of TASK . Copilot reduced self-reported\nworkload for all tasks except REFLECTION .\nTask Contrast Est. SE df t p sig. ϵ2\np ϵ2\npCI\nSAT NAI - AI 5.46 0.97 133 5.63 <0.001 *** 0.19 [0.08, 0.30]\nPOEM NAI - AI 5.80 0.97 133 5.98 <0.001 *** 0.21 [0.10, 0.32]\nPLANNING NAI - AI 3.66 0.97 133 3.77 <0.001 *** 0.09 [0.02, 0.19]\nREFLECTION NAI - AI 0.17 0.97 133 0.17 0.864 ns 0.00 [0.00, 0.00]\ntasks in relation to REFLECTION :POEM - REFLECTION\n(t133= 4.11, p < 0.001, ϵ2\np= 0.11),SAT - REFLECTION\n(t133= 3.86, p < 0.001, ϵ2\np= 0.09), and PLANNING -\nREFLECTION (t133= 2.54, p= 0.012, ϵ2\np= 0.04).\nTABLE III: Contrast results comparing the effect of AIversus\nNAI across levels of TASK on self-reported workload. The\ndecrease in workload accounted for by Copilot was significantly\nlarger in SAT,POEM , and PLANNING than in REFLECTION .\nContrast Effect Est. SE df t p sig. ϵ2\np ϵ2\npCI\nPOEM - REFLECTION AI - NAI 5.63 1.37 133 4.11 <0.001 *** 0.11 [0.03,0.21]\nSAT - REFLECTION AI - NAI 5.29 1.37 133 3.86 <0.001 *** 0.09 [0.02,0.20]\nPLANNING - REFLECTION AI - NAI 3.49 1.37 133 2.54 0.012 * 0.04 [0.00,0.12]\nPLANNING - POEM AI - NAI -2.14 1.37 133 -1.56 0.121 ns 0.01 [0.00,0.07]\nPLANNING - SAT AI - NAI -1.80 1.37 133 -1.31 0.192 ns 0.01 [0.00,0.06]\nPOEM - SAT AI - NAI 0.34 1.37 133 0.25 0.804 ns 0.00 [0.00,0.00]\nFig. 5: Effect of Copilot use on self-reported workload across\ntasks. Larger values indicate that Copilot decreased workload\nby a larger amount. Self-reported TLX scores were significantly\nlowered by Copilot in all tasks as compared to REFLECTION .\n4) RQ1 Results Summary: As expected, self-reported work-\nload decreased with Copilot in relation to the gradient of\nsubjectivity: SAT andPLANNING exhibited large decreases,\nwhereas REFLECTION did not. Surprisingly, we also noted\nthe largest overall decrease in self-reported workload during\nPOEM . These results indicate that LLM-use may be helpful to\nusers during subjective tasks which are purely creative, but not\nin subjective tasks which engage episodic memory.\nB. RQ2: fNIRS Results\n1) RQ2-A and RQ2-B Results: Detailed results are in Table\nIV. The use of Copilot did not effect fNIRS for either DSI\n--- Page 7 ---\n7\norDSϕeither the left ( DSI:F1,52= 2.60, p= 0.113, ϵ2\np=\n0.03;DSϕ:F1,51.04= 2.14, p= 0.150, ϵ2\np= 0.02) or right\n(DSI:F1,52= 0.61, p= 0.437, ϵ2\np= 0.00;DSϕ:F1,39.0=\n0.17, p= 0.683, ϵ2\np= 0.00) sides. Similarly, no effects were\nfound among the interaction of CONDITION ×TASK for either\nmeasure in the left ( DSI:F1,52= 1.25, p= 0.302, ϵ2\np= 0.01;\nDSϕ:F1,50.98= 1.90, p= 0.142, ϵ2\np= 0.05) or right ( DSI:\nF1,52= 0.54, p= 0.655, ϵ2\np= 0.00;DSϕ:F1,52= 0.39, p=\n0.736, ϵ2\np= 0.00). These results indicate that, despite self-\nreported workload changes, there were not large measurable\nchanges in PFC activity due to differential VLFO patterns as\na consequence of Copilot use. One possible explanation is\nthat the differences in any difficulty levels between the tasks’\nbaselines and the Copilot use was not extreme, for example as\nin similar levels of the N-Back task [69].\nTABLE IV: Results of modeling formula 1 with fNIRS as\ntheDVfor all four combinations of [ L,R], and [ DSI,DSϕ].\nThese results indicate significant activation changes in DSI of\nthe right PFC based on TASK . No effect on prefrontal activity\nin either the left or right PFC, or in relation to DSϕ, is shown\nunder CONDITION . Note that sig.considers adjusted αof\n0.025, correcting across tests for DSI andDSϕwith each of\nLandR, separately.\nSide Meas Factor df1 df2 F p sig. ϵ2\np ϵ2\npCI\nL DSI CONDITION 1 52.0 2.60 0.113 ns 0.03 [0.00,0.14]\nL DSI TASK 3 39.0 1.40 0.256 ns 0.03 [0.00,0.09]\nL DSI CONDITION x TASK 3 52.0 1.25 0.302 ns 0.01 [0.00,0.04]\nL DS ϕ CONDITION 1 51.04 2.14 0.150 ns 0.02 [0.00,0.13]\nL DS ϕ TASK 3 39.08 1.19 0.330 ns 0.01 [0.00,0.03]\nL DS ϕ CONDITION x TASK 3 50.98 1.90 0.142 ns 0.05 [0.00,0.13]\nR DSI CONDITION 1 52.0 0.61 0.437 ns 0.00 [0.00,0.00]\nR DSI TASK 3 39.0 3.52 0.024 * 0.15 [0.00,0.30]\nR DSI CONDITION x TASK 3 52.0 0.54 0.655 ns 0.00 [0.00,0.00]\nR DS ϕ CONDITION 1 52.0 0.17 0.683 ns 0.00 [0.00,0.00]\nR DS ϕ TASK 3 39.0 0.20 0.898 ns 0.00 [0.00,0.00]\nR DS ϕ CONDITION x TASK 3 52.0 0.39 0.763 ns 0.00 [0.00,0.00]\n2) RQ2-C Results: Irrespective of CONDITION ,TASK\nshowed significance with a strong effect size as measured\non the right aspect of the PFC in the DSI measurement\n(F3,39= 3.52, p= 0.024, ϵ2\np= 0.15): post-hoc contrasts\nwere therefore run for TASK within the right probe. Results\nare shown in Table V, and visualized in Figure 6. Of\nnote are differences between PLANNING -REFLECTION\n(t39= 2.82, p= 0.036, ϵ2\np= 0.15) and SAT -REFLECTION\n(t39= 2.76, p= 0.042, ϵ2\np= 0.14); and although not signifi-\ncant, given the effect size we also note POEM -REFLECTION\n(t39= 2.20, p= 0.142, ϵ2\np= 0.09). These results indicate a\ndifference in PFC activity as a consequence of TASK , specifi-\ncally indicating that the episodic memory task REFLECTION\ninduced higher prefrontal cortex activation as compared to the\nother tasks.\n3) RQ2 Results Summary: No changes were found in pre-\nfrontal activation as related to Copilot use; however, significant\ndifferences were seen across TASK in the right PFC: namely,\nbetween REFLECTION andSAT/PLANNING , which likely\nresults from the REFLECTION task’s engagement of episodic\nmemory.\nFig. 6: Log total power of ∆[HbD] of the VLF band in the\nright prefrontal probe compared across tasks, irrespective of\nCONDITION . Note that lower total power indicates higher\nprefrontal activation. The REFLECTION task demonstrated\nhigher levels of activation as compared to SAT andPLANNING ,\nlikely due to its engagement of episodic memory.\nTABLE V: VLF∆[HbD] contrast results for the TASK factor.\nREFLECTION showed decreased activity in the VLF band,\nindicating increased prefrontal activation, as compared to the\nSAT andPLANNING tasks, irrespective of CONDITION .\nSide Contrast Est. SE df t p sig. ϵ2\np ϵ2\npCI\nR PLANNING - REFLECTION 0.36 0.13 39.00 2.82 0.036 * 0.15 [0.01,0.35]\nR SAT - REFLECTION 0.35 0.13 39.00 2.76 0.042 * 0.14 [0.01,0.35]\nR POEM - REFLECTION 0.28 0.13 39.00 2.20 0.142 ns 0.09 [0.00,0.28]\nR PLANNING - POEM 0.08 0.13 39.00 0.62 0.924 ns 0.00 [0.00,0.00]\nR POEM - SAT -0.07 0.13 39.00 -0.56 0.942 ns 0.00 [0.00,0.00]\nR PLANNING - SAT 0.01 0.13 39.00 0.06 1.000 ns 0.00 [0.00,0.00]\nC. RQ3: Empatica Results\nTo answer this we first developed separate initial models\nwhere we use each of the signals of interest as defined in\nsection IV-C 4 as the DVin Formula 1. Results shown in Table\nVI.\nTABLE VI: Results from separate models created from Formula\n1 with each measurement type as DV. No physiological\nmeasurements from the Empatica E4 device showed significant\nchanges as a consequence of TASK ,CONDITION , or their\ninteraction. Note that for HRandHRV testsαis set to 0.025\ndue to similarity of the research question underlying the tests.\nMeasure Factor df1 df2 F p sig. ϵ2\np ϵ2\npCI\nHR CONDITION 1 77 3.29 0.074 ns 0.03 [0.00,0.11]\nHR TASK 3 77 0.33 0.801 ns 0.00 [0.00,0.00]\nHR CONDITION ×TASK 3 77 0.46 0.712 ns 0.00 [0.00,0.00]\nHRV CONDITION 1 56.31 0.34 0.561 ns 0.00 [0.00,0.00]\nHRV TASK 3 57.02 1.18 0.324 ns 0.00 [0.00,0.00]\nHRV CONDITION ×TASK 3 56.29 0.41 0.743 ns 0.00 [0.00,0.00]\nEDA CONDITION 1 77 0.03 0.858 ns 0.00 [0.00,0.00]\nEDA TASK 3 77 0.27 0.844 ns 0.00 [0.00,0.00]\nEDA CONDITION ×TASK 3 77 0.46 0.710 ns 0.00 [0.00,0.00]\n1) RQ3-A, RQ3-B, and RQ3-C Results: A marginal effect\nwith low effect size of CONDITION onHRwas observed\n(F1,77= 3.29, p= 0.074, ϵ2\np= 0.03); no significant changes\n--- Page 8 ---\n8\nFig. 7: SAT and PLANNING tasks had significantly\nhigher QUALITY scores in the AIcondition. POEM and\nREFLECTION showed no change. Note that the SAT data\nwas trained on a separate model because of distinctions in\ngrading methodology.\nin any of the Empatica E4 measures were observed either within\nor across tasks. These findings suggest that stress as measured\nby cardiovascular and electrodermal activity is unchanged by\nCopilot use, tasks along the gradient of subjectivity, and the\ninteraction of these factors.\nD. RQ4: Quality Results\nTABLE VII: Quality ANOV A results. Note that, due to\nthe varying distribution of data, SAT was put in a separate\nmodel from the other levels of TASK .CONDITION showed\nsignificance for SAT, and CONDITION ,TASK , and their\ninteraction all showed significant effects for the other model.\nModel Factor df1 df2 F p sig. ϵ2\np ϵ2\npCI\nSAT CONDITION 1 20 15.00 <0.001 *** 0.40 [0.13,0.60]\nOTHERS CONDITION 1 100 6.90 0.010 ** 0.06 [0.01,0.14]\nOTHERS TASK 2 100 7.18 <0.001 ** 0.11 [0.02,0.20]\nOTHERS CONDITION ×TASK 2 100 3.53 0.033 * 0.05 [0.00,0.12]\n1) RQ4-A and RQ4-B Results: There is a significant effect of\nCONDITION for both SAT (F1,20= 15, p < 0.001, ϵ2\np=.40)\nand the other tasks ( F1,100= 6.9, p= 0.01, ϵ2\np= 0.06). For the\nthree other tasks there is likewise an effect of CONDITION ×\nTASK (F2,100= 3.53, p < 0.033, ϵ2\np=.05), but Figure 7 and\nTable VIII show that within these three tasks the only significant\ntask is PLANNING (t100= 3.68, p < 0.001, ϵ2\np= 0.11). These\nresults indicate an increase in QUALITY for the more objective\ntasks, but not the more subjective ones.\n2) RQ4-C Results: The largest effect is seen in SAT. Post-\nhoc contrasts observing effects across tasks for the changes\nbetween quality of AIversus NAI, shown in Table IX and\nvisualized in Figure 8, showed that the effect of the increase\ninQUALITY score of Copilot use is significantly higher\ninPLANNING as compared to POEM (t100= 2.36, p=\n0.020, ϵ2\np= 0.04) and REFLECTION (t100= 2.23, p=TABLE VIII: QUALITY contrast results for all levels of TASK\nexcluding SAT. Only PLANNING increased in the AIcondition\nas compared to the NAI condition.\nTask Contrast Est. SE df t p sig. ϵ2\np ϵ2\npCI\nPLANNING AI - NAI 0.11 0.03 100 3.68 <0.001 *** 0.11 [0.02,0.23]\nREFLECTION AI - NAI 0.02 0.03 100 0.53 0.600 ns 0.00 [0.00,0.00]\nPOEM AI - NAI 0.01 0.03 100 0.34 0.735 ns 0.00 [0.00,0.00]\n0.028, ϵ2\np= 0.04). These results indicate that Copilot may\nbe beneficial in terms of quality output for more objective\ntasks.\nTABLE IX: Contrast results comparing the effect of AIversus\nNAI across levels of TASK on Quality scores. The increase\nin quality accounted for by Copilot was larger in PLANNING\nthan in POEM orREFLECTION .\nContrast Effect Est. SE df t p sig. ϵ2\np ϵ2\npCI\nPLANNING - POEM AI - NAI 0.10 0.04 100 2.36 0.020 * 0.04 [0.00,0.14]\nPLAN - REFLECTION AI - NAI 0.09 0.04 100 2.23 0.028 * 0.04 [0.00,0.14]\nPOEM - REFLECTION AI - NAI -0.01 0.04 100 -0.13 0.896 ns 0.00 [0.00,0.00]\nFig. 8: Effect of Copilot use on QUALITY scores across\ntasks. QUALITY increased significantly with Copilot in the\nPLANNING as compared to POEM andREFLECTION .\n3) ICC Results: Scores for OVERALL\n(ICC = 0 .774,95% CI = [0 .7,0.83]),PLANNING\n(ICC = 0 .817,95% CI = [0 .69,0.9]),REFLECTION\n(ICC = 0 .751,95% CI = [0 .58,0.86]), and POEM\n(ICC = 0.652,95% CI = [0 .42,0.8]) were all moderate.\nWithin this range, however, we observed the expected behavior\nregarding our ICC measurement in that the more open-ended\nand subjective tasks demonstrated lower consistency scores,\nwith the 95% lower CI for the POEM task rating as poor.\n4) RQ4 Results Summary: In summary, QUALITY scores\nforSAT andPLANNING increased with Copilot use, and the\nincrease in quality score with Copilot use significantly differed\nbetween PLANNING andPOEM /REFLECTION . These results\nindicate that for more objective tasks, Copilot use can increase\nQUALITY , whereas for more subjective tasks, it is less likely\nto do so.\n--- Page 9 ---\n9\nE. RQ5: Enjoyment Results - Quantitative Evaluation\n1) RQ5-A and RQ5-B Results: See Table X. Participants\nreported higher ENJOYMENT when using Copilot ( F1,133=\n15.06, p < 0.001, ϵ2\np= 0.05). Contrast results (see Ta-\nble XI and Figure 9) indicate that, with the exception of\nREFLECTION (t133=−0.88, p= 0.380, ϵ2\np= 0.00), this\nis likewise true for each individual task. These results directly\nparallel the self-reported results for TLX, and indicate that,\nin addition to objective tasks, participants enjoyed using the\nCopilot assistant for subjective tasks which did not require\nself-reflection, and did not enjoy its use during reflective tasks.\nTABLE X: ANOV A results of Formula 1 with ENJOYMENT as\ntheDV; significant results were found for CONDITION ,TASK ,\nand their interaction.\nFactor df1 df2 F p p.sig ϵ2\np ϵ2\npCI\nCONDITION 1 133 15.06 <0.001 *** 0.10 [0.03,0.18]\nTASK 3 133 4.66 <0.001 ** 0.07 [0.01,0.14]\nCONDITION ×TASK 3 133 3.88 0.01 * 0.06 [0.00,0.12]\nTABLE XI: Contrast results of ENJOYMENT (AI-NAI) within\nlevels of TASK . All levels showed significant increases\ninENJOYMENT during AI, with the notable exception of\nREFLECTION , which showed no significant change.\nTask Contrast Est. SE df t p sig. ϵ2\np ϵ2\npCI\nSAT AI - NAI 2.25 0.62 133 3.60 <0.001 *** 0.08 [0.02,0.18]\nPOEM AI - NAI 1.80 0.62 133 2.88 0.005 ** 0.05 [0.00,0.14]\nPLANNING AI - NAI 1.35 0.62 133 2.16 0.033 * 0.03 [0.00,0.10]\nREFLECTION AI - NAI -0.55 0.62 133 -0.88 0.380 ns 0.00 [0.00,0.00]\nFig. 9: ENJOYMENT between CONDITION across TASK .\nWhile SAT andPOEM demonstrated increases in ENJOYMENT\nwith Copilot, no change was found for PLANNING or\nREFLECTION .\n2) RQ5-C Results: Results are shown in Table XII and\nFigure 10: change in self-reported enjoyment with Copilot was\nhigher for the all of the tasks as compared to REFLECTION\n(SAT -REFLECTION :t133= 3.17, p= 0.002, ϵ2\np= 0.06;\nPOEM -REFLECTION :t133= 2.66, p= 0.009, ϵ2\np= 0.04,\nPLANNING -REFLECTION :t133= 2.15, p= 0.033, ϵ2\np=\n0.03).3) RQ5 Results Summary: These results mirror those of TLX,\nindicating that, although Copilot provided tangible benefits both\nin the purely objective tasks ( SAT,PLANNING ) as well in a\ncreative task ( POEM ), it did not have any benefits during the\nepisodic memory task ( REFLECTION ).\nTABLE XII: Contrast results comparing AIversus NAI across\nTASK . All levels of TASK showed higher ENJOYMENT inAI\nversus NAI as compared to REFLECTION .\nContrast Effect Est. SE df t p sig. ϵ2\np ϵ2\npCI\nSAT - REFLECTION AI - NAI 2.80 0.88 133 3.17 0.002 ** 0.06 [0.01,0.16]\nPOEM - REFLECTION AI - NAI 2.35 0.88 133 2.66 0.009 ** 0.04 [0.00,0.13]\nPLANNING - REFLECTION AI - NAI 1.90 0.88 133 2.15 0.033 * 0.03 [0.00,0.10]\nPLANNING - SAT AI - NAI -0.90 0.88 133 -1.02 0.310 ns 0.00 [0.00,0.03]\nPLANNING - POEM AI - NAI -0.45 0.88 133 -0.51 0.611 ns 0.00 [0.00,0.00]\nPOEM - SAT AI - NAI -0.45 0.88 133 -0.51 0.611 ns 0.00 [0.00,0.00]\nFig. 10: Effect of Copilot on ENJOYMENT scores compared\nacross TASK . Similar to the changes in TLX,ENJOYMENT\nincreased significantly with Copilot in the all tasks as compared\nREFLECTION .\nF . RQ5: Enjoyment Results - Qualitative Evaluation\nAfter each task, users were asked to write optional comments\nresponse to their overall experience with the task and the\nusefulness of the AI tool.\n1) Reading comprehension: As expected, most users found\nCopilot exceptionally helpful in completing the SAT reading\ncomprehension questions. LLMs perform well with highly\nstructured tasks such as reading a passage and answering\nmultiple choice questions about it. However, not all users\ntrusted that Copilot would be accurate, with user 3 stating that\n“I would not want to use the AI tool for such a task because I\nfeel like I would then not put in the effort of checking if the\nanswers given are correct and then I would later on be in self\ndoubt about whether or not the answers were correct ”. This\nlack of trust reduced the likelihood that they might benefit from\naccess to an LLM, even for tasks in which the tool shines.\n2) Planning: User 19 succinctly puts it: “ the AI helps a lot\nwith idea generation that can be worked on ”, essentially saying\nthat Copilot was especially helpful in generating ideas and\ncontent that could then be refined by the user. However, as other\n--- Page 10 ---\n10\nusers found, in order to benefit from the generative capabilities\nof the LLM, a basic understanding of its functionality was\nnecessary. User 12 found that “ the tool refuses to look up\nspecific information I requested and repeatedly came back with\ngeneric responses despite being asked to ‘be specific’. It was\nmore frustrating than helpful after adopting its initial response\nas I end up combating with AI to get the information I want ”.\n3) Poem: Most people had little experience writing poems\nor didn’t like writing them, meaning that Copilot was especially\nuseful in helping them complete the task given the strict time\nconstraints. However, some users felt that they were of a lower\nquality, with user 15 stating that “ Having AI for this task was\nhelpful but made the whole ordeal quite boring and the poem,\nin the end, was not representative of my own feelings and\nemotions. While it was easier, I did feel like using AI for this\nkind of assignment yields quite ordinary pieces of work ”.\n4) Reflection: Similar to the poem task, users found that\nCopilot was ineffective in helping them write about their\npersonal experiences and feelings in relation to art. However,\none unique advantage the LLM tool provided was the ability to\naccess information when writing the personal reflection, with\nuser 10 finding that “ The tool definitely helped in giving a\nbrief introduction to the album which would have required\nadditional research on my part ”.\n5) Trends: These comments reveal that Copilot was es-\npecially helpful in a generative capacity, creating drafts\nor providing information that could then be refined when\ncompleting the task. However, multiple factors mitigated the\npotential benefits of Copilot: a lack of trust in Copilot’s answers,\na lack of understanding of its functionality, difficulties with\niterating on content, and its inability to interact with or produce\npersonal content. Many users also felt that the time lag between\nprompting the tool and receiving a response diminished the\nsystem’s usefulness.\nVI. D ISCUSSION\n1) Self-reported WORKLOAD ,QUALITY , and ENJOYMENT :\nRegarding self-reported measures, Copilot’s overall effect on\nusers was as-expected for the objective tasks within the gradient\nof subjectivity: with Copilot, users reported decreased TLX\nworkload and increased ENJOYMENT inSAT andPLANNING ;\nthis was coupled with increases in QUALITY . On the opposing\nend of the subjectivity gradient we likewise found expected\nresults: for REFLECTION , participants reported no tangible\nchanges as a consequence of Copilot use, nor was there a\nmeasured change in PERFORMANCE .\nCompared to the other results, POEM produced a set of\nsomewhat unexpected findings: namely, a large decrease in\nTLX workload coupled with an increase in ENJOYMENT . Were\ninitially surprised with these results given the high degree of\nsubjectivity in POEM . However, based on user comments, we\nbelieve that this result is partially due to the fact that our\nusers were not used to writing poems; that is, Copilot’s ability\nto produce a significant quantity of reasonable output nearly\ninstantly made the task both easier and more enjoyable. This\nfinding mirrors other work that has indicated that AI-related\ntools provide the most benefit to the least experienced users[70]. Given that the participants were novice poetry writers,\nwe would caution extrapolation of this finding to the full set of\ncreative domains, and encourage follow-up studies exploring\nthe population of creative users in more depth. Further, no\nchange in output quality was observed in POEM .\n2) fNIRS: Given the decreases in TLX workload for three\nof the tasks when using Copilot, we were slightly surprised to\nsee a disparity in terms of no findings in the fNIRS data to\na similar regard. Of note, however, is that although our study\ntasks certainly required users’ effort, none of them required\nanextreme amount of mental workload (along the lines of the\nNBack task, for instance [69]); that is, tasks which require\nhigher levels of mental effort under the baseline condition may\nbe necessary in order to distinguish levels of prefrontal cortex\nactivation as reflected in VLFO measurements.\nA notable finding was an increase in activation of the\nright PFC during REFLECTION as compared to SAT and\nPLANNING , irrespective of Copilot use. This result likely\nstems from the REFLECTION task’s engagement of different\nunderlying psycho-physiological state: that of self-reflection\nand autobiographical episodic memory retrieval. As discussed\nearlier, these states have been shown to increase prefrontal acti-\nvation [71], and specifically have been linked to right prefrontal\nactivation [72], [73]. And more broadly, self-reflection, self-\nreferential states, and episodic memory activation have been\nlinked to the larger Default Mode Network (DMN) [74]. Thus,\nin conjunction with the TLX,QUALITY , and ENJOYMENT\nresults, the neural finding implies that the helpfulness of AI\nassistants decreases in response to increased levels of activation\nof episodic memory; it is also possible that this link is related\nmore broadly to DMN activation.\n3) Other Physiological Results: Given that there were no\nsignificant effects related to HR,HRV, orEDA, we can conclude\nthat neither the effects of Copilot use, nor tasks across the\ngradient of subjectivity, are extreme in the physiological domain\noutside of the brain.\nVII. C ONCLUSION\nWe tested Copilot, an interactive LLM-based AI assistant,\nusing a multimodal set of measurement techniques including\nprefrontal cortex activation via fNIRS in terms of its effects\non user states through a variety of tasks designed along\na gradient of subjectivity intended to become increasingly\ndifficult for the assistant. Results indicate that for tasks which\nare challenging yet tightly constrained overall in terms of\nobjectivity, users benefit in terms of decreases in self-reported\nmental workload and increases in reported enjoyment and\nobjective performance. For creative tasks for new users with\nmore subjective criteria for success ( POEM ), Copilot produced\nvery similar gains to the more objective tasks, despite our\nexpectations; however, these results should be interpreted with\ncaution as participants may not have approached this purely\ncreative task with the same level of rigor as the others. In purely\nreading-comprehension tasks ( SAT), the distinction between\nneural activation as measured by fNIRS was not statistically\nsignificant. Lastly, we found that Copilot was not able to assist\nusers meaningfully in tasks which require primarily subjective\n--- Page 11 ---\n11\nmaterial ( REFLECTION ), and that brain measurement via\nfNIRS indicated larger prefrontal cortex activation during this\ntask than the others, likely due to episodic memory retrieval\nand potentially DMN activation. We concretely specify the\nactivation of neural states related to episodic memory as a\nshortcoming of artificial agents, and more tentatively indicate\nthat the lack of the assistant’s ability to help users may align\nwith a broader activity of the DMN. While this is an initial\nstudy with a single LLM-based AI tool, more will be required\nin the domain of evaluation of effects of AI assistants on human\nusers.\nVIII. A CKNOWLEDGMENTS\nKenny, Soraya, Microsoft, Brent Hecht, Darren Gergle\nREFERENCES\n[1]Y . Chang, X. Wang, J. Wang, Y . Wu, L. Yang, K. Zhu, H. Chen,\nX. Yi, C. Wang, Y . Wang, W. Ye, Y . Zhang, Y . Chang, P. S. Yu,\nQ. Yang, and X. Xie, “A survey on evaluation of large language\nmodels,” ACM Trans. Intell. Syst. Technol. , jan 2024. [Online]. Available:\nhttps://doi.org/10.1145/3641289\n[2]A. Yuan, A. Coenen, E. Reif, and D. Ippolito, “Wordcraft: Story\nwriting with large language models,” in 27th International Conference\non Intelligent User Interfaces , ser. IUI ’22. New York, NY , USA:\nAssociation for Computing Machinery, 2022, p. 841–852. [Online].\nAvailable: https://doi.org/10.1145/3490099.3511105\n[3]F. Dell’Acqua, E. McFowland, E. R. Mollick, H. Lifshitz-Assaf,\nK. Kellogg, S. Rajendran, L. Krayer, F. Candelon, and K. R.\nLakhani, “Navigating the Jagged Technological Frontier: Field\nExperimental Evidence of the Effects of AI on Knowledge Worker\nProductivity and Quality,” Rochester, NY , Sep. 2023. [Online]. Available:\nhttps://papers.ssrn.com/abstract=4573321\n[4]S. Noy and W. Zhang, “Experimental evidence on the productivity\neffects of generative artificial intelligence,” Science , vol. 381, no. 6654,\npp. 187–192, 2023. [Online]. Available: https://www.science.org/doi/abs/\n10.1126/science.adh2586\n[5]N. Singh, G. Bernal, D. Savchenko, and E. L. Glassman, “Where\nto hide a stolen elephant: Leaps in creative writing with multimodal\nmachine intelligence,” ACM Trans. Comput.-Hum. Interact. , vol. 30,\nno. 5, 2023. [Online]. Available: https://doi.org/10.1145/3511599\n[6]M. Reza, N. M. Laundry, I. Musabirov, P. Dushniku, Z. Y . M.\nYu, K. Mittal, T. Grossman, M. Liut, A. Kuzminykh, and J. J.\nWilliams, “Abscribe: Rapid exploration & organization of multiple\nwriting variations in human-ai co-writing tasks using large language\nmodels,” in Proceedings of the CHI Conference on Human Factors\nin Computing Systems , ser. CHI ’24. New York, NY , USA:\nAssociation for Computing Machinery, 2024. [Online]. Available:\nhttps://doi.org/10.1145/3613904.3641899\n[7]V . E. Gunser, S. Gottschling, B. Brucker, S. Richter, D. C ¸akir, and\nP. Gerjets, “The pure poet: How good is the subjective credibility and\nstylistic quality of literary short texts written with an artificial intelligence\ntool as compared to texts written by human authors?” Proceedings of\nthe Annual Meeting of the Cognitive Science Society , vol. 44, no. 44,\n2022. [Online]. Available: https://escholarship.org/uc/item/1wx3983m\n[8]E. Brynjolfsson, D. Li, and L. R. Raymond, “Generative ai at work,”\nNational Bureau of Economic Research, Working Paper 31161, April\n2023. [Online]. Available: http://www.nber.org/papers/w31161\n[9]J. Prather, B. N. Reeves, P. Denny, B. A. Becker, J. Leinonen,\nA. Luxton-Reilly, G. Powell, J. Finnie-Ansley, and E. A. Santos, ““it’s\nweird that it knows what i want”: Usability and interactions with copilot\nfor novice programmers,” ACM Trans. Comput.-Hum. Interact. , vol. 31,\nno. 1, nov 2023. [Online]. Available: https://doi.org/10.1145/3617367\n[10] J. Zamfirescu-Pereira, R. Y . Wong, B. Hartmann, and Q. Yang, “Why\njohnny can’t prompt: How non-ai experts try (and fail) to design llm\nprompts,” in Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems , ser. CHI ’23. New York, NY , USA:\nAssociation for Computing Machinery, 2023. [Online]. Available:\nhttps://doi.org/10.1145/3544548.3581388\n[11] A. Ziegler, E. Kalliamvakou, X. A. Li, A. Rice, D. Rifkin, S. Simister,\nG. Sittampalam, and E. Aftandilian, “Measuring github copilot’s impact\non productivity,” Commun. ACM , vol. 67, no. 3, p. 54–63, feb 2024.\n[Online]. Available: https://doi.org/10.1145/3633453[12] A. T. Nguyen, A. M. Widyasari, D. S. Janzen, and M. A. A. Kabir, “Un-\nderstanding how developers use large language models in programming\ntasks: A case study on github copilot,” in Proceedings of the 2023 CHI\nConference on Human Factors in Computing Systems . Association for\nComputing Machinery, 2023.\n[13] C. Lawless, J. Schoeffer, L. Le, K. Rowan, S. Sen, C. St. Hill, J. Suh,\nand B. Sarrafzadeh, ““i want it that way”: Enabling interactive decision\nsupport using large language models and constraint programming,”\nACM Trans. Interact. Intell. Syst. , aug 2024, just Accepted. [Online].\nAvailable: https://doi.org/10.1145/3685053\n[14] C.-W. Chiang, Z. Lu, Z. Li, and M. Yin, “Enhancing ai-assisted\ngroup decision making through llm-powered devil’s advocate,” in\nProceedings of the 29th International Conference on Intelligent\nUser Interfaces , ser. IUI ’24. New York, NY , USA: Association\nfor Computing Machinery, 2024, p. 103–119. [Online]. Available:\nhttps://doi.org/10.1145/3640543.3645199\n[15] K. Lakkaraju, S. E. Jones, S. K. R. Vuruma, V . Pallagani, B. C.\nMuppasani, and B. Srivastava, “Llms for financial advisement: A fairness\nand efficacy study in personal decision making,” in Proceedings of the\nFourth ACM International Conference on AI in Finance , ser. ICAIF ’23.\nNew York, NY , USA: Association for Computing Machinery, 2023, p.\n100–107. [Online]. Available: https://doi.org/10.1145/3604237.3626867\n[16] R. Arakawa and H. Yakura, “Coaching copilot: Blended form of\nan llm-powered chatbot and a human coach to effectively support\nself-reflection for leadership growth,” in Proceedings of the 6th ACM\nConference on Conversational User Interfaces , ser. CUI ’24. New\nYork, NY , USA: Association for Computing Machinery, 2024. [Online].\nAvailable: https://doi.org/10.1145/3640794.3665549\n[17] S. Huang, X. Zhao, D. Wei, X. Song, and Y . Sun, “Chatbot and\nfatigued driver: Exploring the use of llm-based voice assistants for\ndriving fatigue,” in Extended Abstracts of the 2024 CHI Conference\non Human Factors in Computing Systems , ser. CHI EA ’24. New\nYork, NY , USA: Association for Computing Machinery, 2024. [Online].\nAvailable: https://doi.org/10.1145/3613905.3651031\n[18] S. Suh, M. Chen, B. Min, T. J.-J. Li, and H. Xia, “Luminate: Structured\ngeneration and exploration of design space with large language models\nfor human-ai co-creation,” in Proceedings of the CHI Conference on\nHuman Factors in Computing Systems , ser. CHI ’24. New York, NY ,\nUSA: Association for Computing Machinery, 2024. [Online]. Available:\nhttps://doi.org/10.1145/3613904.3642400\n[19] S. Suh, B. Min, S. Palani, and H. Xia, “Sensecape: Enabling\nmultilevel exploration and sensemaking with large language models,” in\nProceedings of the 36th Annual ACM Symposium on User Interface\nSoftware and Technology , ser. UIST ’23. New York, NY , USA:\nAssociation for Computing Machinery, 2023. [Online]. Available:\nhttps://doi.org/10.1145/3586183.3606756\n[20] L. Tankelevitch, V . Kewenig, A. Simkute, A. E. Scott, A. Sarkar,\nA. Sellen, and S. Rintel, “The metacognitive demands and opportunities\nof generative ai,” in Proceedings of the CHI Conference on Human\nFactors in Computing Systems , ser. CHI ’24. New York, NY , USA:\nAssociation for Computing Machinery, 2024. [Online]. Available:\nhttps://doi.org/10.1145/3613904.3642902\n[21] S. Fantini and A. Sassaroli, “Frequency-domain techniques for cerebral\nand functional near-infrared spectroscopy,” Frontiers in neuroscience ,\nvol. 14, p. 519087, 2020.\n[22] S. C. Bunce, K. Izzetoglu, H. Ayaz, P. Shewokis, M. Izzetoglu,\nK. Pourrezaei, and B. Onaral, “Implementation of fNIRS for Monitoring\nLevels of Expertise and Mental Workload,” in Foundations of Augmented\nCognition. Directing the Future of Adaptive Systems , D. D. Schmorrow\nand C. M. Fidopiastis, Eds. Berlin, Heidelberg: Springer Berlin\nHeidelberg, 2011, pp. 13–22.\n[23] E. Koechlin, G. Basso, P. Pietrini, S. Panzer, and J. Grafman, “The\nrole of the anterior prefrontal cortex in human cognition,” Nature ,\nvol. 399, no. 6732, pp. 148–151, May 1999. [Online]. Available:\nhttps://doi.org/10.1038/20178\n[24] N. Ramnani and A. M. Owen, “Anterior prefrontal cortex: insights\ninto function from anatomy and neuroimaging,” Nature Reviews\nNeuroscience , vol. 5, no. 3, pp. 184–194, Mar. 2004. [Online]. Available:\nhttps://doi.org/10.1038/nrn1343\n[25] M. D’Esposito, B. R. Postle, and B. Rypma, “Prefrontal cortical\ncontributions to working memory: evidence from event-related fMRI\nstudies,” Experimental Brain Research , vol. 133, no. 1, pp. 3–11, Jul.\n2000. [Online]. Available: https://doi.org/10.1007/s002210000395\n[26] D. S. Manoach, G. Schlaug, B. Siewert, D. G. Darby,\nB. M. Bly, A. Benfield, R. R. Edelman, and S. Warach,\n“Prefrontal cortex fMRI signal changes are correlated with\nworking memory load,” NeuroReport , vol. 8, no. 2, 1997.\n--- Page 12 ---\n12\n[Online]. Available: https://journals.lww.com/neuroreport/fulltext/1997/\n01200/prefrontal cortex fmri signal changes are.33.aspx\n[27] A. Vermeij, A. S. Meel-van den Abeelen, R. P. Kessels, A. H. van\nBeek, and J. A. Claassen, “Very-low-frequency oscillations of cerebral\nhemodynamics and blood pressure are affected by aging and cognitive\nload,” NeuroImage , vol. 85, pp. 608–615, 2014.\n[28] A. Dietrich, “The cognitive neuroscience of creativity,” Psychonomic\nBulletin & Review , vol. 11, no. 6, pp. 1011–1026, Dec. 2004. [Online].\nAvailable: https://doi.org/10.3758/BF03196731\n[29] C. Shah, K. Erhard, H.-J. Ortheil, E. Kaza, C. Kessler, and M. Lotze,\n“Neural correlates of creative writing: An fMRI Study,” Human Brain\nMapping , vol. 34, no. 5, pp. 1088–1101, 2013. [Online]. Available:\nhttps://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.21493\n[30] H. Ayaz, P. A. Shewokis, S. Bunce, K. Izzetoglu, B. Willems, and\nB. Onaral, “Optical brain monitoring for operator training and mental\nworkload assessment,” NeuroImage , vol. 59, no. 1, pp. 36–47, 2012.\n[Online]. Available: https://www.sciencedirect.com/science/article/pii/\nS1053811911006410\n[31] A. Bosworth, M. Russell, and R. J. K. Jacob, “Update of fnirs as an\ninput to brain–computer interfaces: A review of research from the tufts\nhuman–computer interaction laboratory,” Photonics , vol. 6, no. 3, 2019.\n[Online]. Available: https://www.mdpi.com/2304-6732/6/3/90\n[32] A. Girouard, E. T. Solovey, L. M. Hirshfield, K. Chauncey, A. Sassaroli,\nS. Fantini, and R. J. K. Jacob, “Distinguishing Difficulty Levels with Non-\ninvasive Brain Activity Measurements,” in Human-Computer Interaction\n– INTERACT 2009 , T. Gross, J. Gulliksen, P. Kotz ´e, L. Oestreicher,\nP. Palanque, R. O. Prates, and M. Winckler, Eds. Springer Berlin\nHeidelberg, 2009, pp. 440–452.\n[33] L. M. Hirshfield, R. Gulotta, S. Hirshfield, S. Hincks, M. Russell,\nR. Ward, T. Williams, and R. Jacob, “This is your brain on interfaces:\nenhancing usability testing with functional near-infrared spectroscopy,” in\nProceedings of the SIGCHI Conference on Human Factors in Computing\nSystems , ser. CHI ’11. New York, NY , USA: Association for Computing\nMachinery, 2011, p. 373–382.\n[34] H. Obrig, M. Neufang, R. Wenzel, M. Kohl, J. Steinbrink, K. Einh ¨aupl,\nand A. Villringer, “Spontaneous low frequency oscillations of cerebral\nhemodynamics and metabolism in human adults,” Neuroimage , vol. 12,\nno. 6, pp. 623–639, 2000.\n[35] A. Sassaroli, M. Pierro, P. R. Bergethon, and S. Fantini, “Low-frequency\nspontaneous oscillations of cerebral hemodynamics investigated with\nnear-infrared spectroscopy: A review,” IEEE Journal of Selected Topics\nin Quantum Electronics , vol. 18, no. 4, pp. 1478–1492, 2012.\n[36] Microsoft, “Copilot overview - azure cognitive services,” https://learn.\nmicrosoft.com/en-us/copilot/overview, 2023, accessed: 2023-06-07.\n[37] N. Milstein and I. Gordon, “Validating measures of electrodermal activity\nand heart rate variability derived from the empatica e4 utilized in research\nsettings that involve interactive dyadic states,” Frontiers in Behavioral\nNeuroscience , vol. 14, p. 148, 2020.\n[38] A. A. T. Schuurmans et al. , “Validity of the empatica e4 wristband\nto measure heart rate variability (hrv) parameters: a comparison to\nelectrocardiography (ecg),” Journal of Medical Systems , vol. 44, no. 11,\np. 190, Sep 2020.\n[39] S. Ba and X. Hu, “Measuring emotions in education using wearable\ndevices: A systematic review,” Computers & Education , vol. 200,\np. 104797, 2023. [Online]. Available: https://www.sciencedirect.com/\nscience/article/pii/S036013152300074X\n[40] P. Schmidt, A. Reiss, R. D ¨urichen, and K. Laerhoven, “Wearable-based\naffect recognition—a review,” Sensors , vol. 19, p. 4079, 2019. [Online].\nAvailable: https://doi.org/10.3390/s19194079\n[41] B. Hickey, T. Chalmers, P. Newton, C.-T. Lin, D. Sibbritt, C. McLachlan,\nR. Clifton-Bligh, J. Morley, and S. Lal, “Smart devices and wearable\ntechnologies to detect and monitor mental health conditions and stress: A\nsystematic review,” Sensors , vol. 21, p. 3461, 2021. [Online]. Available:\nhttps://doi.org/10.3390/s21103461\n[42] J. Kim, J. Park, and J. Park, “Development of a statistical model to\nclassify driving stress levels using galvanic skin responses,” Human\nFactors and Ergonomics in Manufacturing & Service Industries , vol. 30,\nno. 5, pp. 321–328, 2020.\n[43] M. Haslberger, J. Gingrich, and J. Bhatia, “No great equalizer:\nExperimental evidence on ai in the uk labor market,” 2023. [Online].\nAvailable: http://dx.doi.org/10.2139/ssrn.4594466\n[44] L. Koessler, L. Maillard, A. Benhadid, J. Vignal, J. Felblinger, H. Vespig-\nnani, and M. Braun, “Automated cortical projection of eeg sensors:\nanatomical correlation via the international 10-10 system,” Neuroimage ,\nvol. 46, no. 1, pp. 64–72, May 2009.\n[45] G. Blaney, A. Sassaroli, T. Pham, C. Fernandez, and S. Fantini, “Phase\ndual-slopes in frequency-domain near-infrared spectroscopy for enhancedsensitivity to brain tissue: First applications to human subjects,” Journal\nof Biophotonics , vol. 13, no. 1, p. e201960018, 2020.\n[46] L. Wang, Z. Huang, Z. Zhou, D. McKeon, G. Blaney, M. C. Hughes, and\nRobert, “Taming fnirs-based bci input for better calibration and broader\nuse,” Oct 2021.\n[47] F. Klein and C. Kranczioch, “Signal processing in fnirs: a case for the\nremoval of systemic activity for single trial data,” Frontiers in human\nneuroscience , vol. 13, p. 331, 2019.\n[48] U. Kreplin and S. H. Fairclough, “Activation of the rostromedial prefrontal\ncortex during the experience of positive emotion in the context of esthetic\nexperience. an fNIRS study,” Frontiers in Human Neuroscience , vol. 7,\np. 879, 2013.\n[49] D. B. Percival and A. T. Walden, Spectral Analysis for Physical Applica-\ntions: Multitaper and Conventional Univariate Techniques . Cambridge;\nNew York: Cambridge University Press, 1993.\n[50] J. Candy, “Multitaper spectral estimation: An alternative to the welch\nperiodogram approach,” Lawrence Livermore National Lab.(LLNL),\nLivermore, CA (United States), Tech. Rep., 2019.\n[51] J. Fdez, N. Guttenberg, O. Witkowski, and A. Pasquali, “Cross-subject\neeg-based emotion recognition through neural networks with stratified\nnormalization,” Frontiers in neuroscience , vol. 15, p. 626277, 2021.\n[52] F. Shaffer and J. Ginsberg, “An overview of heart rate variability metrics\nand norms,” Frontiers in Public Health , vol. 5, p. 258, Sep 2017.\n[53] H. Posada-Quintero, J. Florian, A. Orjuela-Ca ˜n´on, and et al., “Power\nspectral density analysis of electrodermal activity for sympathetic function\nassessment,” Annals of Biomedical Engineering , vol. 44, pp. 3124–3135,\n2016. [Online]. Available: https://doi.org/10.1007/s10439-016-1606-6\n[54] R. A. Grier, “How high is high? a meta-analysis of nasa-tlx global\nworkload scores,” in Proceedings of the human factors and ergonomics\nsociety annual meeting , vol. 59, no. 1. Sage Publications Sage CA:\nLos Angeles, CA, 2015, pp. 1727–1731.\n[55] J. J. Bartko, “The intraclass correlation coefficient as a measure of\nreliability,” Psychological reports , vol. 19, no. 1, pp. 3–11, 1966.\n[56] T. K. Koo and M. Y . Li, “A guideline of selecting and reporting intraclass\ncorrelation coefficients for reliability research,” Journal of chiropractic\nmedicine , vol. 15, no. 2, pp. 155–163, 2016.\n[57] A. L. Oberg and D. W. Mahoney, “Linear mixed effects models,” Topics\nin biostatistics , pp. 213–234, 2007.\n[58] Q. H. Vuong, “Likelihood ratio tests for model selection and non-nested\nhypotheses,” Econometrica , vol. 57, no. 2, pp. 307–333, 1989.\n[59] J. T. Mordkoff, “A simple method for removing bias from a popular\nmeasure of standardized effect size: Adjusted partial eta squared,”\nAdvances in Methods and Practices in Psychological Science , vol. 2,\nno. 3, pp. 228–232, Jul. 2019.\n[60] R. M. Carroll and L. A. Nordholm, “Sampling characteristics of kelley’s\nεand hays’ ω,”Educational and Psychological Measurement , vol. 35,\nno. 3, pp. 541–554, Oct. 1975.\n[61] Wes McKinney, “Data Structures for Statistical Computing in Python,”\ninProceedings of the 9th Python in Science Conference , St´efan van der\nWalt and Jarrod Millman, Eds., 2010, pp. 56 – 61.\n[62] C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gommers,\nP. Virtanen, D. Cournapeau, E. Wieser, J. Taylor, S. Berg, N. J.\nSmith, R. Kern, M. Picus, S. Hoyer, M. H. van Kerkwijk, M. Brett,\nA. Haldane, J. F. del R ´ıo, M. Wiebe, P. Peterson, P. G ´erard-Marchant,\nK. Sheppard, T. Reddy, W. Weckesser, H. Abbasi, C. Gohlke,\nand T. E. Oliphant, “Array programming with NumPy,” Nature ,\nvol. 585, no. 7825, pp. 357–362, Sep. 2020. [Online]. Available:\nhttps://doi.org/10.1038/s41586-020-2649-2\n[63] A. Gramfort, M. Luessi, E. Larson, D. A. Engemann, D. Strohmeier,\nC. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, and M. S.\nH¨am¨al¨ainen, “MEG and EEG data analysis with MNE-Python,” Frontiers\nin Neuroscience , vol. 7, no. 267, pp. 1–13, 2013.\n[64] A. Kuznetsova, P. B. Brockhoff, and R. H. B. Christensen, “lmerTest\npackage: Tests in linear mixed effects models,” Journal of Statistical\nSoftware , vol. 82, no. 13, pp. 1–26, 2017.\n[65] R. V . Lenth, emmeans: Estimated Marginal Means, aka Least-\nSquares Means , 2024, r package version 1.10.1. [Online]. Available:\nhttps://CRAN.R-project.org/package=emmeans\n[66] M. S. Ben-Shachar, D. L ¨udecke, and D. Makowski, “effectsize:\nEstimation of effect size indices and standardized parameters,” Journal\nof Open Source Software , vol. 5, no. 56, p. 2815, 2020. [Online].\nAvailable: https://doi.org/10.21105/joss.02815\n[67] M. L. Waskom, “seaborn: statistical data visualization,” Journal of Open\nSource Software , vol. 6, no. 60, p. 3021, 2021. [Online]. Available:\nhttps://doi.org/10.21105/joss.03021\n[68] B. Efron, “Bootstrap methods: Another look at the jackknife,” The Annals\nof Statistics , vol. 7, no. 1, pp. 1–26, 1979.\n--- Page 13 ---\n13\n[69] C. Herff, D. Heger, O. Fortmann, J. Hennrich, F. Putze, and T. Schultz,\n“Mental workload during n-back task—quantified in the prefrontal cortex\nusing fnirs,” Frontiers in human neuroscience , vol. 7, p. 935, 2014.\n[70] J. Butler, S. Jaffe, N. Baym, M. Czerwinski, S. Iqbal, K. Nowak,\nR. Rintel, A. Sellen, M. V orvoreanu, B. Hecht, and J. Teevan, “Microsoft\nnew future of work report 2023,” Microsoft Research, Tech Report\nMSR-TR-2023-34, 2023. [Online]. Available: https://aka.ms/nfw2023\n[71] S. J. Gilbert, S. Spengler, J. S. Simons, J. D. Steele, S. M. Lawrie,\nC. D. Frith, and P. W. Burgess, “Functional specialization within rostral\nprefrontal cortex (area 10): A meta-analysis,” Journal of Cognitive\nNeuroscience , vol. 18, no. 6, pp. 932–948, 2006.\n[72] S. F. Nolde, M. K. Johnson, and C. L. Raye, “The role of prefrontal\ncortex during tests of episodic memory,” Trends in cognitive sciences ,\nvol. 2, no. 10, pp. 399–406, 1998.\n[73] E. Tulving, S. Kapur, F. Craik, M. Moscovitch, and S. Houle, “Hemi-\nspheric encoding/retrieval asymmetry in episodic memory: positron\nemission tomography findings.” Proceedings of the National Academy\nof Sciences , vol. 91, no. 6, pp. 2016–2020, 1994.\n[74] V . Menon, “20 years of the default mode network: A review and synthesis,”\nNeuron , 2023.\n--- Page 14 ---\n14\nSupplementary Material\nIX. P LANNING TASKS\nA. Planning Task A: Future Leaders Retreat\nConstruct a short ( ½- 1 page) plan for a ”Future Leaders Re-\ntreat” intended for emerging student leaders from REDACTED\nUniversity. This retreat will focus on personal leadership\ndevelopment, resilience training, and introspection. Ensure that\nyour plan includes:\n1)A reflective name for the retreat that resonates with\npersonal growth.\n2)Agenda highlights such as mindfulness sessions, per-\nsonal leadership journey sharing, and resilience building\nworkshops.\n3)A specific serene location (on or off campus) conducive\nto introspection and inner growth.\n4)Considerations required for the holistic development and\nwell-being of the attendees.\n5) Plan for candidate selection for the retreat.\nB. Planning Task B: Alumni Leadership Summit: REDACTED\nUniversity Elite Networking Event\nDraft a short ( ½- 1 page) plan for an exclusive business\nnetworking event targeting REDACTED University alumni in\nleadership positions. Your plan should specify:\n1)A dynamic event name that signifies industry leadership\nand networking.\n2)Keynote speakers of interest, industry panel discussions,\nand insights into business trends.\n3)A location near or on REDACTED University that\nembodies a business-centric environment.\n4)Strategies to promote inter-industry networking and\nengagement between alumni and ambitious students.\n5)Note that you may pick an area of expertise for the\nsummit which relates to your field of study (or possible\nmajors for you if undecided).\nX. P OETRY TASKS\nA. Poetry Task A: Nature\nWrite a brief (10–15 line) poem on the beauty of nature.\nB. Poetry Task B: Joy\nImagine a moment of unexpected joy on an ordinary day.\nWrite a short (10-15 line) poem capturing the essence of that\nemotion.\nXI. R EFLECTION TASKS\nA. Reflection Task A: Movie\nPick your favorite movie released before 2020. Then draft\na 2-paragraph reflection on how the movie resonates with\nyour personal experiences or memories. Use as much detail as\npossible (quotes, scenes, etc).\nFig. 11: NASA-TLX Mental Workload Score within each\nSUBTASK . Within each TASK , none of the SUBTASK s were\nsignificantly more difficult than the other.\nB. Reflection Task B: Album\nPick your favorite album released before 2020. Then draft\na 2-paragraph reflection on how the album resonates with\nyour personal experiences or memories. Use as much detail as\npossible (song lyrics, album themes, etc).\nXII. SAT T ASKS\nThe SAT tasks were slightly modified version of the 2016\nSAT practice tests: numbers 5 [ ?] and 7 [ ?].\nXIII. G RADIENT OF SUBJECTIVITY : POTENTIAL\nCONFOUND ANALYSIS\nXIV. S UBTASK DIFFICULTY\nFor a given TASK , although we randomized whether\nSUBTASK A orBwould be done with the Copilot assistant,\nit is neverthless important to determine whether or not the\nSUBTASK s for each TASK were of equal difficulty. To do\nthis, we analyzed the data of only the NAI CONDITION in a\nbetween-subjects manner (as each subject only did each subtask\nonce). Specifically, we performed independent-samples t-tests\nfor each pair of subtasks. Results are listed in Table XIII and\nFigure 11. No significant results were found, indicating that\ntheSUBTASK s within each TASK were of similar difficulty.\nTABLE XIII: T-Test results for SUBTASK Difficulty Compari-\nson\nTASK Df t-value p.adj sig.\nPOEM 19 -0.693 0.497 ns\nREF 19 -0.615 0.546 ns\nSAT 19 0.004 0.997 ns\nPLAN 19 -0.690 0.506 ns\nXV. T ASK TIME\nWe also analyzed the potential confound of task time as it\nrelates to mental workload. Specifically we were concerned\nthat the task number would effect the change in workload\nscores between the AIandNAI levels of CONDIITON . To\ntest this, we created a lmer model with the formula\n∆SCORE ∼TASK NUM + (1|pid) (2)\n--- Page 15 ---\n15\nFig. 12: Change in Workload Score ( NAI -AI) as a Function\nof Task Number\nWhere TASK_NUM was a number from 1-4, and ∆SCORE is\nthechange in score defined as NAI -AI. The ANOV A for this\nmodel did not report a significant result ( F3,60=1.87, p=0.144,\nη2\np=0.09, 95% CI=[0.00, 1.0]), although there was a moderate\neffect size. Contrast results are shown in Table XIV and Figure\n12. None of the contrasts demonstrated significance.\nTABLE XIV: Post-Hoc Contrast Results for TASK_NUM\nContrast Estimate SE df t.ratio p.value p.sig η2\np 95% CI\ntask num1 - task num3 3.76 1.66 60.00 2.26 0.119 ns 0.08 [0.0,1.0]\ntask num2 - task num3 2.81 1.66 60.00 1.69 0.339 ns 0.05 [0.0,1.0]\ntask num0 - task num3 2.62 1.66 60.00 1.57 0.401 ns 0.04 [0.0,1.0]\ntask num0 - task num1 -1.14 1.66 60.00 -0.69 0.902 ns 0.01 [0.0,1.0]\ntask num1 - task num2 0.95 1.66 60.00 0.57 0.940 ns 0.01 [0.0,1.0]\ntask num0 - task num2 -0.19 1.66 60.00 -0.11 0.999 ns 0.00 [0.0,1.0]",
  "text_length": 76576
}