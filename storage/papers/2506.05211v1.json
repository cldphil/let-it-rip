{
  "id": "http://arxiv.org/abs/2506.05211v1",
  "title": "Intentionally Unintentional: GenAI Exceptionalism and the First\n  Amendment",
  "summary": "This paper challenges the assumption that courts should grant First Amendment\nprotections to outputs from large generative AI models, such as GPT-4 and\nGemini. We argue that because these models lack intentionality, their outputs\ndo not constitute speech as understood in the context of established legal\nprecedent, so there can be no speech to protect. Furthermore, if the model\noutputs are not speech, users cannot claim a First Amendment speech right to\nreceive the outputs. We also argue that extending First Amendment rights to AI\nmodels would not serve the fundamental purposes of free speech, such as\npromoting a marketplace of ideas, facilitating self-governance, or fostering\nself-expression. In fact, granting First Amendment protections to AI models\nwould be detrimental to society because it would hinder the government's\nability to regulate these powerful technologies effectively, potentially\nleading to the unchecked spread of misinformation and other harms.",
  "authors": [
    "David Atkinson",
    "Jena D. Hwang",
    "Jacob Morrison"
  ],
  "published": "2025-06-05T16:26:32Z",
  "updated": "2025-06-05T16:26:32Z",
  "categories": [
    "cs.CY",
    "cs.AI"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.05211v1",
  "full_text": "--- Page 1 ---\nIntentionally Unintentional: GenAI Exceptionalism and the First \nAmendment  \nDavid Atkinson ,1 Jena D. Hwang ,2 and Jacob Morrison3 \nABSTRACT  \nThis paper challenges the assumption that  courts should grant  First Amendment protections \nto outputs from large generative AI models, such as GPT -4 and Gemini . We  argue that \nbecause these models lack intentionality, their outputs do not constitute speech as understood \nin the context of established legal precedent, so there can be no speech to protect. \nFurthermore, if the model outputs are not speech, users cannot claim a First Amendment  \nspeech  right to receive the outputs. We also argue that extending First Amendment rights to \nAI models would not serve the fundamental purposes of free speech, such as promoting a \nmarketplace of ideas, facilitating self -governance, or fostering self -expression. I n fact, \ngranting First Amendment protections to AI models would be detrimental to society because \nit would hinder the government’s ability to regulate these powerful technologies effectively, \npotentially leading to the unchecked spread of misinformation an d other harms.  \nI. INTRODUCTION  \nSince ChatGPT first burst into society’s collective consciousness toward the end of 2022 , scholars have \npondered its implications . While discussions of copyright receive the lion’s share of attention,4 and privacy \nrights consume most of the remaining spotlight,5 the debate  of whether generative AI (GenAI) models should \n \n1 Assistant Professor of Instruction,  Business, Government and Society Department  at McCombs School of \nBusiness, University of Texas, Austin . \n2 Research Scientist at the Allen Institute for Artificial Intelligence.  \n3 Predoctoral Researcher at the Allen Institute for Artificial Intelligence.  \n4 Katherine Lee, A. Feder Cooper, & James Grimmelmann , Talkin ’ ‘Bout AI Generation: Copyright and the \nGenerative -AI Supply Chain , CS&L AW ’24: PROC. OF THE SYMP. ON COMPUT . SCI. AND L. (2024 ). \n5 See, e.g. , Chen Ruizhe et al. , Learnable Privacy Neurons Localization in Language Models  (May 16, 2024)  \n(unpublished manuscript ) (https://arxiv.org/abs/2405.10989 ); Zhipeng  Wang  et al. , Information Leakage \nfrom Embedding in Large Language Models  (May 22, 2024) (unpublished manuscript) \n(https ://arxiv.org/abs/2405.11916 ).  \n--- Page 2 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 2  \n receive First Amendment protections is growing.6 \nIt bears emphasizing that whether First Amendment protections apply to GenAI outputs  is an unsettled \nlegal question. The importance of this analysis can’t be overstated given the convergence of several factors: \n(1) the number of GenAI models like GPT -4 and Gemini is proliferating, (2) the use of GenAI in everyday \nlife is becoming more com mon, and (3) people tend to anthropomorphize things that seem to have human \ncharacteristics.7  \nAdditionally, the legal implications of assigning First Amendment protection to GenAI, in effect, would \nnecessarily deem its outputs as speech. The repercussions of doing so would be non -trivial , as legal scholars \nKarl Manheim and Jeffrey Atik explain:  \n[If GenAI output is speech, it] would likely prohibit treating AI as a product or attaching \nliability to harmful outputs. It could also give AI companies free rein to collect and use \npersonal information as data inputs for their algorithmic (constitutional ly protected) outputs.8 \nIt is not just privacy rights that would vanish under such a regime, but many forms of \nconsumer protection and other regulatory objectives.9  \nThe potential consequences of assigning protections to GenAI outputs rest on the premise that GenAI  \nmodel s are constitutionally recognizable speakers,  and their outputs are, therefore, speech. Works criticizing \n \n6 See, e.g. , Cass R. Sunstein , Artificial Intelligence and the First Amendment  (April 28, 2023) (unpublished \nmanuscript) ( https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4431251 ); Eugene Volokh , Mark A. \nLemley, & Peter Henderson, Freedom of Speech and AI Output , 3 J. FREE SPEECH L. 651 (2023).  \n7 The way we talk about chatbots warps our understanding. We “chat” with it and have “conversations .” It \n“responds” based on what it “knows .” Since we, as humans evolved over millennia to socialize with others, \ntend to interpret the outputs of the model in that social context, we also naturally extend the metaphor to \nbelieving the model is providing meaningful outputs as expected from another h uman being.  \n8 See NetChoice v. Bonta , 692 F.Supp.3d 924 , 936 –37 (N.D. Cal. 2023 ) (issuing a preliminary injunction \nagainst the California Age -Appropriate Design Code Act on the ground that regulating the collection and use \nof children’s personal information infringed the free speech rights of online tech companies).  \n9 Karl Manheim  & Jeffery Atik, AI Outputs and the Limited Reach of the First Amendment , 63 WASHBURN \nL. J. 159, 161  (2023).  \n \n--- Page 3 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 3  \n this premise have pointed out GenAI’s tendencies to produce nonsense or asemic language.10 Others have \ncontended that GenAI cannot be a speaker as it does not participate in communication.11  \nWe draw from and build on these works to argue that there are no constitutionally recognized speakers \nin GenAI because, unlike human beings, models lack communicative intent, akin to stochastic parrots.12 \nThis, in turn, means there is no speech that the First Amendment can protect. Moreover, if there is no speech, \nthere can be no constitutionally recognized listeners  of speech , meaning users of the models generally have \neither weak or no First Amendment right to receive any model outputs. Consequently, if the First \nAmendment does not apply, the government can more freely regulate GenAI. We further argue that GenAI \noutputs are not speech; therefore, no court should take the extraordinary step of extending the highest First \nAmendment protections  and scrutiny  to non -speech by non -humans.  \nOur primary contribution s to this discussion include  clarif ying the legal stakes  (such as the \nunprecedented expansion of free speech rights to a non -human entity ) and the most common arguments \ninvolved in First Amendment discussions regarding GenAI outputs  (like whether the developer, model, or \nrecipients have speech rights that would likely trigger strict scrutiny ) by unifying multiple concepts within \nlegal theories , including asemic language, intentionality, human involvement, generation versus use, \nstochasticity, and substantive constitutional arguments. This research also provides an informed technical \ndescription by including  AI researchers as co -authors. Finally, the brevity of this paper compared to \ncomparable papers facilitates a concise discussion using accessible  prose to make concepts more broadly \nunderstandable beyond legal scholars.  \n \nA. Scope  \n \n10 E.g., Dan L. Burk , Asemic Defamation, or, the Death of the AI Speaker , 22 FIRST AMEND . L. REV. 189 \n(2024).  \n11 E.g., Manheim & Atik, supra note 9.  \n12 Emily M. Bender et al., On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? , PROC. \nOF THE 2021  ACM  CONF. ON FAIRNESS , ACCOUNTABILITY , AND TRANSPARENCY 616 (2021).  \n \n--- Page 4 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 4  \n There are some important limitations of the following argument : (1) The argument only considers \nfoundation models like GPT -4, Claude, Gemini, and Llama, not all GenAI models,  and (2) relatedly, the \nargument asserts  that not all model outputs are protected by the First Amendment, not that no outputs could \never be protected by the First Amendment.13 Generally, the more directed the model is, the more likely that \nsome protections may attach.14 Our default argument for all foundation models is that virtually none of their \noutputs are protected speech.  \nB. How GenAI Works  \nBefore going any further, it is helpful to understand how GenAI functions. In a few words, GenAI models \nare mathematical functions for predicting what words follow  a given input. Models do this by inputting \ntokens (subcomponents of words) from the prompt into a model , taking its output as the token most likely \nto follow the input, and repeating this process until the desired output length is achieved.  \nTokens are created by a “tokenizer ,” which is a model that takes in data and separates it into tokens, \nwhich are then fed into a model. A token is a series of weights that define the subcomponent of a word, and \nthe weights within the token help define the statistical relationship between different tokens learned during \ntraining.15 On the other hand, the weights within a model  are tuned during training to take in tokens and \n“learn ” relationships between them to predict likely outputs. Its primary function, in other words, is to \nrespond to user prompts with plausible -sounding outputs based on what the model was trained to \n“understand” as likely related tokens. The models can generali ze to some extent ,16 and even without referring \n \n13 It seems at least theoretically possible that one day AI could become self -aware, and if so, it could make \nexpressions with intention. But that is not the case today, and there is no reason to believe it will be the case \nin the near future. Regardless, th e First Amendment only applies to humans, another requirement for  \nprotected speech.  \n14 Outputs may only be speech when the developer directs the model  to produce a particular or distinct \noutput. Merely applying an insignificant filter does not automatically turn non -speech into speech, as that \nwould make it trivially easy to make all outputs protected speech, subverting the purpose of the First \nAmendmen t.  \n15 Similar to John Rupert Firth’s “You shall know a word by the company it keeps.”  J.R. Firth, A Synopsis of \nLinguistic Theory, 1930 –1955 , in STUDIES IN LINGUISTIC ANALYSIS  11 (Oxford 1962). \n16 Some argue it’s not true generalization but  is instead something like “approximate retrieval”. See, e.g. , \n--- Page 5 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 5  \n to an external database they can sometimes memorize and output images and text that is a verbatim or near -\nverbatim version of the material it was trained on, perhaps indicating the models themselves are a kind of \ndatabase.  \nC. The First Amendment  \nAnd for the last introductory matter , it is helpful to understand the nature of speech protected by the First  \nAmendment. The Amendment reads:  \nCongress shall make no law respecting an establishment of religion, or prohibiting the free \nexercise thereof; or abridging the freedom of speech, or of the press; or the right of the people \npeaceably to assemble, and to petition the Government for a redress of grievances.17  \nWe bring attention to the following portion that focuses on speech: “Congress shall make no law  . . . \nabridging the freedom of speech, or of the press [.]”  \nThe Supreme Court has interpreted the  First Amendment’s freedom of speech clause in  a long series of  \ncases. This paper will explore a few relevant quotes later, but for now, it is sufficient to think of it as \nprotecting the “marketplace of ideas,” self -governance, and self -expression. The protections extend not only \nto speakers (the people producing the speech) but also to listeners (the people receiving the speech), because \nit wou ld undermine the purposes of the First Amendment to allow anyone to say anything but bar others \nfrom receiving the communication.  \nFinally —and this is worth stating clearly —there is no binding case law in the United States that grants \nFirst Amendment speech protections to anything that was created absent a human’s significant, intentional \n \nZhaofeng Wu et al., Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models \nThrough Counterfactual Tasks , CONF. OF THE N. AM. CHAPTER OF THE ASS’N FOR COMP. LINGUISTICS 1819 –\n62 (2024) . \n \n17 U.S. CONST . amend. I .   \n--- Page 6 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 6  \n involvement.18  \nII. THE CODE IS SPEECH, SO MODELS ARE SPEECH  ARGUMENT19 \nThe first argument many will make is that GenAI functions like code, and code is protected speech; therefore, \nGenAI outputs are protected speech. This notion is misguided, but it is worth walking through the argument \nto better understand why the argument is misplaced.  \nThere are at least three cases in multiple circuits where the courts determined that code is speech \nprotected by the First Amendment. The courts decided e ach case around the turn of the century as software \nbecame an unavoidable legal topic with the widespread use of the internet. In two of the three cases ( Junger  \nv. Daley20 and Bernstein  v. United States Department of Justice21), the issue was government -export  control \nrestrictions that attempted to prevent researchers from sharing cryptographic code.  \nFor example, in Junger v. Daley , the Sixth Circuit found that “Because computer source code is an \nexpressive means for the exchange of information and ideas about computer programming, we hold that it \nis protected by the First Amendment.”22  \nLikewise, in Bernstein , the Ninth Circuit  held that :  \n[C]ryptographers use source code to express their scientific ideas in much the same way that \n \n18 See, e.g. , Miles v. City Council , 710 F.2d 1542 , 1544 n.5  (11th Cir. 1983) (“This Court will not hear a \nclaim that Blackie’s [the cat’s] right to free speech has been infringed. First, although Blackie arguably \npossesses a very unusual ability, he cannot be considered a “person” and is therefore not protected by the \nBill of Rights . Second, even if Blackie had such a right, we see no need for appellants to assert his right jus \ntertii . Blackie can clearly speak for himself. ” (emphasis added) ). \n19 The structure of this section of the paper was informed by  comments from the Center for Democracy & \nTechnology. Center for Democracy & Technology, Re: NTIA’s Request for Comment Regarding Dual -Use \nFoundation Artificial Intelligence Models with Widely Available Model Weights as per Section 4.6 of the \nExecutive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence , \nCDT. ORG  (Mar. 27, 2024),  https://cdt.org/wp -content/uploads/2024/03/CDT -to-NTIA -comments -on-open -\nfoundation -models -03272023.pdf . \n20 Junge r v. Daley 209 F.3d 481  (6th Cir. 2000).  \n21 Bernstein v. Dep’t of Just., 176 F.3d 1132, 1141 (9th Cir. 1999), reh’g granted, withdrawn , 192 F.3d 1308 \n(9th Cir. 1999) . \n22 Junger , 209 F.3d at 485.   \n--- Page 7 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 7  \n mathematicians use equations or economists use graphs  . . .  . [M]athematicians and \neconomists have adopted these modes of expression in order to facilitate the precise and \nrigorous expression of complex scientific ideas. Similarly, the undisputed record here makes \nit clear that cryptographers utilize source code in t he same fashion. In light of these \nconsiderations, we conclude that encryption software, in its source code form and as \nemployed by those in the field of cryptography, must be viewed as expressive for First \nAmendment purposes, and thus is entitled to the protections of the prior restraint doctrine. If \nthe government requir ed that mathematicians obtain a prepublication license prior to \npublishing material that included mathematical equations, there is  no doubt that such a regime \nwould be subject to scrutiny as a prior restraint .23  \n  \nA. Prior Restraint and Functionality  \nImportantly, the courts applied different standards to the cases. Bernstein applied the prior restraint doctrine, \nwhich arises when a government action prohibits speech or other expression  before the speech happens.24 \nOvercoming the scrutiny of  a prior restraint is a tall order . The  Supreme Court has noted that “ [a]ny system \nof prior restraints of expression comes to this Court bearing a heavy presumption against its constitutional \nvalidity.”25 The government must overcome strict scrutiny by show ing that ( 1) there is a compelling interest \nin the law, and ( 2) that the law is either narrowly tailored or is the least speech -restrictive means available \nto the government. In short, this means the government “carries a heavy burden of showing justification for \nthe imposition of such a restraint.”26 There have been very few exceptions to the bar o n prior restraint s; only \n \n23 Bernst ein,176 F.3d at 1141 . This case was later  withdrawn because the U .S. government  modified its \nencryption reg ulations  before the appellate court could hear the case, making the issue moot.  \n24 Bantam Books v. Sullivan , 372 U.S. 58, 70 (1963) . \n25 Id. \n26 N.Y.  Times Co. v. United States, 403 U.S. 713, 714 (1971) (citing Org. for a Better Austin v. Keefe, 402 \nU.S. 415, 419 (1971)).  \n--- Page 8 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 8  \n things like  obscene speech, incitement to violence, and national security  concerns have justified them .27  \nInstead of the prior restraint standard, t he Junger court applied intermediate scrutiny because the law \nfocused on the code's functionality, not its expressiveness .28 Intermediate scrutiny consists of a two -part test: \nthe challenged law must ( 1) further an important government interest (which is a lower burden than the \ncompelling state interest required by  the strict scrutiny test),29 and ( 2) must do so by means that are \nsubstantially related to that interest.  \nCourts have applied intermediate scrutiny in other First Amendment cases and determined that for the \nfirst prong (important government interest) , the government “must demonstrate that the recited harms are \nreal, not merely conjectural, and that the regulation will in fact alleviate these harms in a direct and material \nway.”30 For the second prong ( substantially related means ), the regulation must leave “ample alternative \nchannels of communication.”31  \nMore recently, in a case challenging provisions of the Digital Millennium Copyright Act (DMCA) , a \nstatute  meant to prevent the circumvention of protections of access to digital content, the D.C. Circuit noted \nthat the government “conceded that ‘if you write code so somebody can read it,’ it is ‘expressive’ speech. \nAll of our sister circuits to have addressed the issue agree.”32 The court went on to conclude th at the  DMCA \napplied to the function of the code rather than its expression, applied intermediate scrutiny, and ruled in  \nfavor of the government.   \n \n27 Near v. Minnesota  ex rel. Olson , 283 U.S. 697 , 716  (1931) .   \n28 Junger , 209 F.3d at 485.  Had the regulation instead focused on the content of the code ––its \nexpressiveness ––strict scrutiny would have likely applied  which would require that the law be narrowly \ntailored to serve a compelling government interest. See Am. Libr . Ass’n v. Reno, 33 F.3d 78 (D.C. Cir. \n1994) . \n29 The Supreme Court has found important government interests. See, e.g., Michael M. v. Superior Ct., 450 \nU.S. 464 (1981) (prevention of teenage pregnancy); Craig v. Boren, 429 U.S. 190 (1976), (public health); \nRostker v. Goldberg, 453 U.S. 57 (1981) (nationa l defense); Dothard v. Rawlinson, 433 U.S. 321 (1977) \n(physical safety of women); Califano v. Goldfarb, 430 U.S. 199 (1977) (remediation of past societal \ndiscrimination).   \n30 Turner Broad. Sys. Inc. v. F CC, 512 U.S. 622, 664 (1994).   \n31 Ward v. Rock Against Racism, 491 U.S. 781, 802 (1989).  \n32 Green v. U.S. Dep’t of Justice , 54 F.4th 738, 745 (D.C. Cir. 2022)  (citation omitted) . \n--- Page 9 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 9  \n Given the cases discussed above,  it seems clear that code is speech.33 This means any content -neutral \nregulation of code, and perhaps GenAI models, would be subject to intermediate scrutiny, and an expression -\nbased regulation would invite strict scrutiny.  \nIII. IMPLICATIONS  \nAcademics, politicians, and market participants have floated various proposals to regulate large language \nmodels. This section will examine the implications of assuming the First Amendment protects GenAI \nmodels.  \nA. Regulations That May Be Prior Restraint s \nOne often -raised  proposal is to implement a licensure system whereby a regulator must certify or license a \nmodel before the developer can release or deploy it to a wide audience.34 Other examples would be if the \ngovernment prevented models from telling users how to build a bomb, make drugs, promote conspiracy \ntheories, create malware, or access pirated movies. Such regulations may trigger the prior restraint doctrine \nby preventing the model from communicating . As noted above, this is a high bar, and only with the most \npersuasive  justifications may a prior restraint pass constitutional muster.  \nB. Other Regulations That May Trigger Intermediate or Strict Scrutiny  \nAnother common proposal is to require certain transparency thresholds for models. At the extreme, \ntransparency requirements could include revealing the model weights and training data, but they could also \ninclude reporting impact assessments or the following kinds of information,  as suggested by AI researchers \nat Princeton University.  \n \n33 Not to stray too far from the topic of speech, but another important fact is that models are not code and are \nnot made up of code .  \n34 We acknowledge that the data collectors, data curators, model trainers, and model deployers may all be \ndifferent entities. For simplicity, we treat them as a single group,  and it does not affect the free speech \nanalysis.  \n--- Page 10 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 10  \n [F]or each category of harmful output, transparency reports must:  \n1. Explain how it is defined and how harmful content is detected.  \n2. Report how often it was encountered in the reporting period.  \n3. If it is the result of a Terms of Service violation, describe the enforcement mechanism and provide \nan analysis of its effectiveness.  \n4. Describe the mitigations implemented to avoid it (e.g., safety filters), and provide an analysis of \ntheir effectiveness.35  \nThe issue is that courts may construe such reports as compelled speech, and compelled speech invit es \nstrict scrutiny. Most compelled  speech case law arises when the government requires an entity to convey or \nallow a particular message or to allow space for a viewpoint the entity may disagree with.36 That criterion \ndoes not neatly apply to models where the transparency reports do not require the model developers to carry \na particular message or allow others to transmit messages through the model. Moreover, the courts take a \nmore relaxed stance on transparency reporti ng when disclosure is purely factual and in a commercial \ncontext.37  \nOverall, an analysis of how the First Amendment may apply to transparency reports will require a more \nnuanced assessment, including examining which models the regulation would apply to ( All of them? Only \nthose of a certain size? Only those that used a certain threshold of compute? Only those that are available \nfor certain uses or certain audiences?), whether the regulation might affect the speech rights of the model \ndevelopers, and how burdensome the regulation would  be to comply with. The  broader the regulation, the \n \n35 Arvind  Narayanan  & Sayash Kapoor, Generative AI Companies Must Publish Transparency Reports , AI \nSNAKE OIL (June 26, 2023), https://www.aisnakeoil.com/p/generative -ai-companies -must -publish . \n36 See, e.g. , Miami Herald Pub . Co. v. Tornillo , 418 U.S. 241  (1974); Pac. Gas & Elec . Co. v. Pub . Util. \nComm’n , 475 U.S. 1 (1986); Hurley v. Irish -Am. Gay Group , 515 U.S. 557 (1995); Nat’l Inst. of Fam . and \nLife Advoc . v. Becerra , 585 U.S. 755 (2018).   \n37 See e.g. , Zauderer v. Off . of Disciplinary Couns . of Sup . Ct. of Ohio , 471 U.S. 626  (1985).  \n--- Page 11 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 11  \n more likely it is to invite strict, rather than intermediate, scrutiny.38  \nC. Takeaways  \nAs discussed above, if models, like code, receive First Amendment protections, it could stifle or prohibit \nmeaningful regulation of what many have claimed is a technology as powerful as fire,39 electricity,40 the \nsteam engine,41 the printing press,42 and more.43 Notably, none of those technologies has First Amendment \nprotections, so none receive  the same  insulation  from regulation . This could grant the developers of GenAI \nbroader freedoms to experiment, innovate, and disseminate models without the fear of substantial \ngovernment influence. It could also grant the developers greater influence and far more protection  against \ngovernment intervention than prior technologies  may have enjoyed .  \nIV. LET’S MENTION INTENTIONS  \nMany legal scholars  have assumed that all GenAI outputs are speech for the sake of legal analysis .44 If their \n \n38 See Netchoice, LLC v. Paxton, 49 F.4th 439 (5th Cir. 2022) (requiring disclosure of acceptable use policy \nlikely not a violation of the First Amendment); N etChoice, LLC v. Att ’y Gen., Florida, 34 F.4th 1196 (11th \nCir. 2022),  vacated and remanded sub nom.  Moody v. NetChoice, LLC, 603 U.S. 707  (2024)  (requiring \nplatforms to inform users of changes to platform rules likely not a violation of the First Amendment).  \n39 Prarthana  Prakash , Alphabet CEO Sundar Pichai Says That A.I. Could Be ‘More Profound ’ Than Both \nFire and Electricity —but He’s Been Saying The Same Thing for Years , FORTUNE  (Apr. 17, 2023), \nhttps://fortune.com/2023/04/17/sundar -pichai -a-i-more -profound -than-fire-electricity .  \n40 Shana  Lynch , Andrew Ng: Why AI Is the New Electricity , STANFORD GRADUATE SCH. OF BUS. (Mar. 11, \n2017), https://www.gsb.stanford.edu/insights/andrew -ng-why-ai-new-electricity .    \n41 Hannah  Levitt  & Bloomberg, JP Morgan CEO Jamie Dimon Compares AI’s Potential Impact to \nElectricity and the Steam Engine and Says the Tech Could ‘Augment Virtually Every Job ’, FORTUNE  (Apr. 8, \n2024) , https://fortune.com/2024/04/08/jpmorgan -ceo-jamie -dimon -compares -ai-electricity -steam -engine -\ntech-augment -every -job/. \n42 Lauren  Sforza , Microsoft President Compares AI to Invention of Printing Press , THE HILL (May 28, \n2023 ), https://thehill.com/policy/technology/4024394 -microsoft -president -compares -ai-to-invention -of-\nprinting -press/ .  \n43 Bill Gates , The Age of AI has Begun , GATESNOTES  (Mar. 21, 2023) , https://www.gatesnotes.com/the -age-\nof-ai-has-begun . And these claims are not limited to for -profit organizations. Wired reports that the CEO of \nthe nonprofit Allen Institute for Artificial Intelligence, Ali Farhadi, says he’s “100 percent convinced that \nthe hype is justified” Steven Levy, Don’t Let Mistrust of Tech Companies Blind You to the Power of AI , \nWIRED (June 7, 2024), https://www.wired.com/story/dont -let-mistrust -of-tech-companies -blind -you-power -\nof-ai/. \n44 See, e.g. , Sunstein , supra note 6; Volokh , Lemley, & Henderson , supra note 6.   \n--- Page 12 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 12  \n assumptions were correct, their analyses would likely be correct, but we believe they  are misplaced.  \nIn cases where courts have found that code is protected speech, they have relied on several analogies: \nmathematical formulas, foreign languages, player piano paper, and music more generally.45  \nUpon first glance , it appears First Amendment protections could reasonably extend to model weights \nfor a number of reasons  if they can apply to mathematical equations, including that the model is essentially \na compressed copy of its training data , and the training data is mostly expressive content . The model converts \nthe expressive nature of the training data into numbers and merely transforming the format of speech does \nnot remove its protections (e.g., making a photo a JPEG  file, making a document a DOCX  file, or making a \nsong an MP3  file does not affect speech protections ), or that the model is able to produce outputs that are \ncoherent to humans.  \nBut perhaps such an analysis gets ahead of itself by overlooking the assumption inherent in all the \nanalogies and case law thus far: that someone intended to create the protected speech.46 The First \nAmendment does not apply to random strips of black cloth (or any color, for that matter). If it did, garment \nfactories might be in massive violation of the law every day when they discard scraps left over from sewing \nshirts, pants, dresses, and s o on. Similarly, if the random cloth was protected, government regulations that \nrequire discarding the scraps for environmental or safety reasons might also implicate the First Amendment.  \nAs another example, if you accidentally knock over a can of paint on the sidewalk that spills onto a piece of \npaper, a police officer can throw the paper away and clean up the mess, ask you to clean it up, or fine you \nfor not cleaning it up, all without i mplicating the First Amendment.  \nThe reason the First Amendment can protect some pieces of cloth and some paint on paper is  that they \nare imbued with intent by a human.47 Intentionality, in turn, requires both sentience  (the ability to feel, \n \n45 See, e.g. , Bernstein v. U .S. Dep’t. of State , 922 F.  Supp. 1426 , 1435  (N.D. Cal. 1996) .  \n46 Consider  another famous case  where First Amendment protections extended to wearing a black armband \nto protest the Vietnam War . Tinker v. Des Moines Indep. Cmty. Sch. Dist., 393 U.S. 503 , 506  (1969).  \n47 Mackenzie Austin and Max Levy,  Speech Certainty: Algorithmic Speech and the Limits of the First \nAmendment , 77 STAN. L. REV. 1, (2025 ) (making a powerful argument that the First Amendment  \nrequires “speech certainty,” which is that the speaker knows what they are saying when they say it.  \nThis paper agrees with that criterion but believes requiring intentionality, including sentience and  \n--- Page 13 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 13  \n perceive, or experience subjectivity) and self-awareness (the ability to  recognize oneself as an individual).48 \nWearing a black armband was protected speech in Tinker because the wearer inten ed the cloth  to convey a \nparticular message. Likewise, if you paint a portrait on a canvas while sitting at an easel on a sidewalk, that \npainting is protected speech because a person intends to convey something, not merely because some paint \nis applied to some surface .49  \nTo make the claim clearer, we can extend it to the other analogies. Music is protected because someone \nintended specific sounds. A player piano roll is protected because someone intended the roll to create certain \nsounds. Source code and object code are pr otected because someone intended to cause a computer to perform \ncertain actions and communicate the  intended  actions to fellow coders. The same logic applies to video \ngames and board games. In every case , a person intended for the protected speech to result in some particular \nmessage.50 And because there is intended speech or expression, other humans have a protected right to \nreceive the expressions.  \nFinally, while intention is a reasonable  boundary for the sake of legal analysis --because we are willing \nto concede that perhaps one day machines will have true intent, and therefore their outputs could be \nprotected -- we could also rely on a simpler human -directly -involved/no human -directly -involved dichotomy \nfor the foreseeable future . The First Amendment has only ever recognized the speech of humans. While \nother  creatures have appeared to make intentional communications , perhaps understanding what they  are \n \nself-awareness, and humanity is also necessary to ensure the definition of what could be speech is  \nproperly constrained) . \n48 Even gorillas that are sentient, self -aware, and can intentionally communicate ideas that they  \nknow they are communicating when the ideas are communicated do not receive free speech  \nprotections, and people have no First Amendment right to receive gorilla communications.  \n49 This does not mean the painter would win a lawsuit about being asked to move. It could be that content -\nneutral  regulation s prohibit people from painting on the sidewalk for any number of good reasons. See, e.g ., \nCity of Austin v. Reagan Nat’l Advert . of Austin, LLC , 596 U.S.  61, 69  (2022) (finding that content -neutral  \nregulations regarding billboards were not unconstitutional).  \n50 Cass Sunstein mentions that the First Amendment would likely extend to Magic Eight  Balls, so a \ngovernment cannot  say the ball must reply “Yes” when asked if a particular viewpoint is correct . Sunstein, \nsupra note 6, at 11 –12. How this would ever be enforced or how a company could possibly rig a Magic \nEight  Ball in such a way is beyond us. It seems as nonsensical as trying to restrain the speech of newborns. \nAnd this, in a way, helps make our point: we are doing too much by trying to hyperextend the First \nAmendment to cover more and more without a strong just ification and by relying on strained analogies.  \n--- Page 14 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 14  \n communicating when they communicate it -such as dogs whimpering for food, parrots  requesting crackers, \ngorillas using sign language, and cats allegedly speaking English -U.S. courts , as Manheim and Atik put it  \n“emphasize [s] the human element, the First Amendment does not protect speech as such, but only ‘the \nfreedom of speech.’ Freedom is a quality that only humans enjoy. What would it mean for AI to be “free”? \nFree to speak? Free to believe in religion? Freedom from captivit y?”51  \nGenAI lacks intentionality, sentience, self -awareness, and humanness. Therefore,  unlike code and other \nforms of communication, nothing GenAI generates can be considered protectable speech under any \nreasonable reading of  the Constitution or any binding case law.  \nV. MODELS, UNLIKE CODE, ARE NOT SPEECH  \nWhile the lack of intention is itself dispositive of whether free speech protections should attach, we can also \nsummarily dismiss the notion that there is a speaker by considering the only two possible speakers: the \nmodel developers and the model itself.  \nA. Developers Are Not Speakers  \nIn contrast to the examples in the preceding section regarding music and code, developers do not intend for \nfoundation models to convey any particular message. In fact, large models –the kinds the government is \nmost likely to regulate because they are generally more capable of producing outputs the government \nwould be interested in regulating —are often intentionally trained not to produce a particular output \nbecause that would be less  interesting and limit their  usefulness to a broader audience. That is  not to say \nthe model developers have no control over the general types of outputs a model may produce, but developers \ndo not control specific outputs.  \nThe developer s of large models also have no way of knowing how the model will associate any given \n \n51 Mainheim  & Atik , supra  note 9, at 1 69.  \n \n--- Page 15 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 15  \n tokens or how it will reply to any given input.52 While developers may make opinionated decisions about \nwhat data to include or exclude, or what types of queries to respond to or refuse, or what kinds  of outputs to \nfilter, the model itself is merely a representation or abstraction of these choices , and it has no agency of its \nown. You also cannot  easily “hard-code ” any particular responses. As Joshua Batson, a researcher at the AI \nfirm Anthropic, noted in a New York Times podcast,  \n[t]hese models are grown more than they are programmed. So you kind of take the data, and \nthat forms like the soil, and you construct an architecture and it’s like a trellis, and you shine \nthe light, and  that’s the training. And then the model sort of grows up here, and at the end, \nit’s beautiful. It ’s all these little like curls, and it’s holding on. But  you didn’t, like, tell it \nwhat to do.53 \n \n Instead, the outputs are merely statistically plausible tokens formed into words and sentences \nresponding to the statistical association of the tokens created from the words and sentences of the user \nprompt.54 GenAI model developers cannot know or  understand when, where, or why any particular output \nwill include any particular token.  \nMore generally, the mere fact that a person created something does not mean that everything that entity \nsays or does is potentially acting on behalf of the creator. Imagine if all parents were responsible for \neverything their teenagers said or did. Or supp ose Ford was responsible for everything the eventual buyers \ndid with the vehicles. Society has had the good sense to recognize that mere creation of something does not  \nmean the creator always retains all rights and responsibilities associated with the thing they created.  \nIf companies claim a restriction on output is unconstitutional, they must argue that the output is speech. \n \n52 Set aside, for the purposes of this article, the uncommon scenario of a malevolent developer who curates \ndata to make the model more inclined to do harmful things, or who uses supervised fine -tuning or other \ntechniques specifically to make harmful actions more likely.  \n53 Kevin Roose  & Casey Newton , Google Eats Rocks, a Win for A.I. Interpretability and Safety  Vibe Check , \nN.Y.  TIMES (May 31, 2024), https://www.nytimes.com/2024/05/31/podcasts/hardfork -google -overviews -\nanthropic -interpretability.html . \n54 Prompts, though they may be intricate and very creative to achieve a particular outcome, are not \ndeterministically shaping the actual generated content. Prompt engineering optimizes the model’s likelihood \nto generate what the user wants. However, whether  the model actually generates what the user desires  is \ndependent on a number of factors beyond the user’s control such as the effectiveness of the model’s training, \nthe efficacy of the instruction tuning the model received, and the alignment of the model’s learned human \npreference. Thus, the link between t he prompt and generation is tenuous. Generation from an AI is \nintrinsically separate from user intent.  \n--- Page 16 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 16  \n And because GenAI itself cannot  create speech as it has been recognized in the U .S. legal system, the speech \nmust be that of the company. This means all GenAI outputs would be the company ’s speech.  \nNotably, no large GenAI entity has claimed that any models represent the company’s speech. If \nanything, they expressly disclaim  this, noting that the models are experimental and that the models do  not \nrepresent their views.55 Additionally, AI developers and most users do not want to claim legal liability for \nanything harmful the model may output  for the simple reason that they have no idea what it might output  in \nresponse to any given prompt. It is also not clear whether 47 U.S.C. §  230, more commonly known as \nSection 230, the law that immunizes platforms from most content users post,  would protect GenAI \ndevelopers in the same way it shields large social media platforms, so the hesitancy is logical.56  \nB. Models Are Not Speakers  \nThe model has no intention or even understanding of what it is doing. This is largely why problems like \nhallucinations and shortfalls in common sense persist.57 As discussed above, models are merely making \nprobable guesses of which token should go next , given the prior tokens. When an AI model states a falsehood \nas if it is fact, it is called hallucinating. But everything  models output  is a hallucinat ion; it just so happens  \nthat often  their output s align with reality. They have no awareness of what they are outputting , and they do \nnot know if it is accurate or rational. GenAI cannot  express itself because it has no self to express. And \nunlike corporations, discussed below, GenAI is not made up of humans.  \nA model can generate speech the way a parrot can generate speech by mimicking humans. A parrot may \nproduce coherent outputs , but it does not have the capability to fully understand the full extent of what it is \n \n55 See, e.g., Gemini for Google Workspace Cheat Sheet , SUPPORT .GOOGLE  (2024), \nhttps://support.google.com/a/users/answer/14143478?hl=en  (specifies that “ Gemini feature suggestions \ndon’t represent Google’s views, and should not be attributed to Google ”).   \n56 See PETER J. BENSON & VALERIE C. BRANNON , CONG. RSCH. SERV., LSB11097, SECTION 230  IMMUNITY \nAND GENERATIVE ARTIFICIAL INTELLIGENCE  2–4 (2023) . \n57 See Bender  et al. , supra  note 12, at 610–23; Emily M. Bender &  Alexander Koller, Climbing Towards \nNLU: On Meaning, Form, and Understanding in the Age of Data , PROC. OF THE 58TH ANN. MEETING OF THE \nASS’N FOR COMP. LINGUISTICS  5185 –98 (2020); Zachary  Kenton et al.,  Alignment of Language Agents  \n(Mar. 26, 2021) (unpublished manuscript) (https://arxiv.org/abs/2103.14659 ). \n--- Page 17 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 17  \n producing. A model, like a parrot, generates coherent outputs , but researchers have shown that models do \nnot understand what they generate,  no matter how sophisticated the output may appear .58 In fact, it could be \nsaid that a parrot has even more intention than a model because it is producing output on its own initiative \nand can do so without prompting. Yet, nobody has claimed it would violate a person’s First Amendment  \nrights to not be allowed to listen to a parrot. Even if we assume parrots are sentient and self -aware and can \nspeak  with intentionality and speech certainty (knowing what it said when it said it), they lack the other  \nfundamental and unavoidable characteristic of protectable speech: human origin.  \nIn fact, the same logic applies to other entities that can communicate a message that is clearly understood \nby humans, but that would not be protected by the First Amendment, including doorbells, thermostats, \nschool bells , smoke detectors, and house alarms.  \nThe reason is that the First Amendment protects speech, not the mere transmission of information. The \nfact that someone can ascribe meaning to something does not mean First Amendment protections \nautomatically apply —regardless of how profound the self -imposed meaning may be. I may find the shape \nof a large rock in a nearby park to convey something profound about the meaning of life, but if the city \ndecides to obscure or destroy the rock, they have not assaulted the Fi rst Amendment. I have no First \nAmendment right to receive the rock’s expression, such that it is.59  \nThe limitation on the extent of First Amendment protections is necessary. If the mere communication \nof information were  constitutionally protected speech, then virtually nothing could be meaningfully \nregulated, or at the very least , it would trigger waves of incessant litigation where the government would be \nrequired to satisfy, at a minimum, intermediate scrutiny each time.  \n \n58 See Nouha Dziri et al., Faith and Fate: Limits of Transformers on Compositionality , ACM  DIGIT. LIBR. \n(2024),  https://dl.acm.org/doi/10.5555/3666122.3669203; see also Peter West et al., The Generative AI \nParadox: What It Can Create, It May Not Understand , ARXIV (2023), https://arxiv.org/abs/2311.00059 . \n59 Note that we are not arguing that analyses and discussion about the rock or cults or religions that spring  \nfrom worshiping the rock would not receive First Amendment protections. We are  only concerned with the \nreceiver/listener’s supposed protections to read/view and interpret the rock, because any “insights” would \nderive entirely from their self -reflection. The resulting self -reflections may result in protected speech from \nthe receiver,  but no protections go from the rock to the receiver.  \n--- Page 18 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 18  \n C. Humans Are Not Stochastic Parrots  \nGenAI models are undeniably impressive as far as producing coherent outputs based on probable tokens. \nHowever, they are still only tools. They exhibit intelligence similar to the way a calculator exhibits \nintelligence: input by user, output by tool.60 Yet some people still insist that human communication is merely \nstochastic outputs , meaning that speech is only probabilistic,  and that our communication is not \nmeaningfully different from how GenAI creates outputs . Therefore,  GenAI and brains should not be treated \ndifferently under the law.61 This is wrong.  \nCognitive linguistics has long argued that speakers retain the ability to selectively compose their \nutterances to coincide with their communicative intent, their attitude, and the intended message.62 Humans \nplay an active role in organizing and personalizing what we say and how we say things. Similarly, listeners \nengage in an active process of construing or interpreting the received message , taking into account various \ncontextual cues , such as shared information between the speaker and the listener as well as the intent of the \nspeaker.  \nIt is beyond the scope of this paper to detail all the ways human thinking, creativity, and communication \nare distinguishable from GenAI outputs . Still, several brief examples are worth mentioning  so anyone who \nwishes to explore the topic further can have ideas to build on. We acknowledge that GenAI can sometimes \nperform some of the tasks associated with the following examples. But this reminds us of the old saying \nabout broken clocks being correct twice a day. What follows are some of the ways in which GenAI functions \nis unlike how human minds work.  \n \n60 And so far, calculators are better at solving math problems when told what to do with numbers. \nThankfully their outputs aren’t just based on the probability of, say, 2+2 equals 3 or 4 or 5.  \n61 For example,  Sam Altman, CEO of OpenAI, famously tweeted “I’m a stochastic parrot, and so r u [.]” Sam \nAltman (@sama), X (Dec. 4, 2022, 1:32 PM), \nhttps://x.com/sama/status/1599471830255177728?lang=en&mx=2 . \n62 See Ronald W. Langacker , FOUNDATIONS OF COGNITIVE GRAMMAR : VOLUME I: THEORETICAL \nPREREQUISITES (Stan. Univ. Press  1987);  Leonard Talmy, Figure and Ground in Complex Sentences , BLS \n(1975),  https://journals.linguisticsociety.org/proceedings/index.php/BLS/article/view/2322/2092.  \n \n \n--- Page 19 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 19  \n 1. GenAI has no intentionality nor agency.63 It does not provide any output deliberately, purposefully, \nor with thoughts, desires, or beliefs because it does not contain the capacity for such conditions. It \nmerely responds to user inputs.  \n2. GenAI has no theory of mind.64 It does not have any idea what you may be thinking, desiring, or \nbelieving, and it does not spend any time thinking about what you may be thinking versus what it is \n“thinking .”  \n3. GenAI lacks a notion of truth or belief in what is true versus false, showing tendencies to generate \nfalse information and hallucinations.65 It is trained to associate tokens with other tokens, not to \nidentify truthful information from false information. It does not possess the ability to scrutinize its \ntraining data to determine whether what it was trained on is true or not, unlike how a huma n can \nquestion whether the information provided to us is likely true or not.  \n4. Language requires both form and meaning. An LLM is only trained on form (predicting the most \nlikely next token), so it has no ability to learn or understand meaning.66 This is why it cannot  tell if \nsomething is true or false. It does not  know what content is trustworthy or not.67 Coherence does not \n \n63 See Bender et al. , supra  note 12, at 610 -23; See also  Reto Gubelmann,  Large Language Models, Agency, \nand Why Speech Acts are Beyond Them (For Now) –a Kantian -Cum -Pragmatist Case , 37 SPRINGER NATURE  \n32 (2024) . \n64 See Hyunwoo Kim et al., FANToM: A Benchmark for Stress -testing Machine Theory of Mind in \nInteractions,  ASS’N COMPT . LINGUISTICS 14397  (2023) , https://arxiv.org/abs/2310.15421 ; see also Mudit \nVerma et al., Theory of Mind Abilities of Large Language Models in Human -Robot Interaction: An \nIllusion? , HRI  ‘24:  COMPANION 2024  ACM/IEEE  INT’L CONF. HUM.-ROBOT INTERACTION 36 (2024) , \nhttps://arxiv.org/abs/2401.05302 ;Gu, Yuling et al., SimpleToM: Exposing the Gap between  Explicit ToM \nInference and Implicit ToM Application in LLMs (unpublished arXiv Oct. 17, 2024),  \nhttps://arxiv.org/abs/2410.13648.  \n65 See Saurav Kadavath et al., Language Models (Mostly) Know What They Know , (July 11, 2022) \n(unpublished manuscript) (https://arxiv.org/abs/2207.05221 ); Stephanie  Lin et al.,  TruthfulQA: Measuring \nHow Models Mimic Human Falsehoods , PROC. OF THE 60TH ANN. MEETING ASS’N COMP. LINGUISTICS \n3214 –52 (2022) , https://arxiv.org/abs/2109.07958.  \n66 See Bender  & Koller, supra note 53, at 5185 –98; West et al., supra  note 54.  \n67 See Reece Rogers,  Google Admits Its AI Overviews Search Features Screwed Up , WIRED  (May 30, 2024 ), \nhttps://www.wired.com/story/google -ai-overview -search -issues/ .   \n--- Page 20 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 20  \n equal understanding. Past performance (a model being right about something) does not  guarantee \nfuture results (that the model will continue to be correct about that topic or any other topic).  \n5. GenAI cannot make significant innovations.68 In contrast, humans can create and innovate, which \ngoes beyond mere repetition of patterns. We can compose new genres of music, invent useful \ntechnologies that have never existed before, and develop entirely new fields of study (calculus, \nphysics, evolution, cosmology, etc.).  \n6. GenAI is not self -aware.69 While humans possess self -awareness and consciousness, which allow us \nto reflect on our thoughts, experiences, and existence, stochastic models like GenAI entirely lack this \nlevel of meta -cognition.70  \n7. GenAI is not great at prediction and adaptation. Unlike GenAI, human learning is not just about \nmimicking patterns; it is about understanding principles and applying them in novel situations. We \ncan learn from a few examples and generalize to new contexts, a trait that stochastic models struggle \nwith because their knowledge is limited to the information they were trained on.  This is why, for \nexample, researchers found that GPT -4 did excellent on coding problems available before GPT -4’s \ndata collection cutoff date, but it performed poorly on coding problems available just after the data \ncollection cutoff.71 It is also why the models must be exposed to several orders of magnitude more \ncontent than humans to provide outputs that humans sometimes find useful.  \n \n68 See Giorgio Franceschelli & Mirco Musolesi, On the Creativity of Large Language Models  (Mar. 27, \n2023) (unpublished manuscript)  (https://arxiv.org/abs/2304.00008) . \n69 See David J.  Chalmers , Could a Large Language Model Be Conscious?  (Mar. 4, 2023) (unpublished \nmanuscript) (https://arxiv.org/abs/2303.07103 ) (presented at NeurIPS Conference in 2022 as an invited talk ). \n70 When we asked Microsoft Copilot, powered by GPT -4, about humans being stochastic parrots it \nrepeatedly referred to itself as being  a human. So much for self -awareness .  \n71 See Arvind Narayanan & Sayash Kapoor , GPT -4 and Professional Benchmarks: The Wrong Answer to \nthe Wrong Question , AI SNAKE OIL (Mar. 20, 2023), https://www.aisnakeoil.com/p/gpt -4-and-professional -\nbenchmarks;  see also Ben Turner, GPT -4 Didn’t Ace The Bar Exam After All, MIT Research Suggests —It \nDidn’t Even Break The 70th Percentile , LIVE SCIENCE  (May 31, 2024), \nhttps://www.livescience.com/technology/artificial -intelligence/gpt -4-didnt -ace-the-bar-exam -after-all-mit-\nresearch -suggests -it-barely -passed  (showing OpenAI’s claims about the bar exam are similarly under \nscrutiny).  \n--- Page 21 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 21  \n 8. Humans are deeply embedded in social and cultural contexts that implicitly shape how we understand \nthe world. Our language and actions are influenced by these contexts in ways that are not merely \nstochastic. GenAI, in contrast, generally only knows how and when to adapt to a different culture if \ntold to do so explicitly.  \nD. GenAI Models Are Not Like Corporations  \nSome claim that GenAI should receive speech rights because other non -human entities , like corporations,  \nreceive such rights. But corporations have speech rights they are made up of humans , and all actions \ncorporations take are  on behalf of humans. This is because the language of the First Amendment is based \non actions that require intention and agency. The fictional entity of “Ford” does not create advertisements ; \nthe sales and marketing teams, consisting of humans,  do. Ford would not  exist without humans. There is no \nprotected corporate speech in the absence of humans.  \nThe distinction between corporations and GenAI becomes more obvious when considering the \nadditional rights corporations possess. For example, corporations can enter into legally binding contracts, \nbut GenAI, like ChatGPT,  cannot. Similarly, corporations can own property, but GenAI cannot.72 It seems \nodd to think that GenAI cannot  own something as trivial as a cup, but some people are eager to grant it \npowerful First Amendment rights.73  \nE. Listeners Are Not Protected  \nThe above  sections  focus on the purported speakers. But what about listeners of the alleged speech? We \nbelieve that users of models do not have a First Amendment speech right to receive model outputs. If there \n \n72 This may be a useful frame for thinking about when the First Amendment should apply to something. If it \ncannot have property rights, then it should not have speech rights .  \n73 But even corporations do not  have full First Amendment protections. They can be compelled to speak, for \nexample, by SEC rules and regulations about disclosures (S -1s, 10 -Ks, 8 -Ks, etc.).  See e.g., Form S -1, SEC, \nhttps://www.sec.gov/files/forms -1.pdf.   The government cannot similarly compel humans to reveal all the \npotential risks, of, say, marrying them.  \n--- Page 22 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 22  \n is no speech from the model developers and the model itself is not a speaker, then there is no speech to \n“listen” to or receive. If there is no speech, then there are no speech rights. However, what users of GenAI \ndo with the outputs would be protected because the user would be making an intentional communication. \nWe must separate the generation of outputs from the use of those outputs for proper legal analyses, just as \nthe court in  Tinker v. Des Moines Independent Community School District74 implicitly recognized that the \nproduction of some black cloth is separate from the use of that cloth  to protest a war . Use is protected speech.  \nThere is a related argument that people use GenAI outputs to improve their writing  or to conduct \nresearch, so they should have free speech rights to what the model generates.75 But this is misguided. Nobody \nis entitled to the very best of anything, including the best or easiest way to create speech. We are not entitled \nto a laptop with word processing software that makes composing documents and conducting research easier, \nand la ptops do not  receive First Amendment protections for merely existing or because they are more useful \nthan a stone and chisel. GenAI is a tool, no different from pens, paper, and word processors, and using tools, \nby itself, does not bestow First Amendment protections o n the tools themselves or give people a First \nAmendment right to access the tools in the condition that is most beneficial to the people. It may be that a \nmachine gun would make a  more impressive sculpture when fired on a chunk of marble than a hammer and \na chisel , but we do not have an unrestricted free speech right to access and use a machine gun  just because \nit can be used to produce what may be protected speech .  \nAnother argument about listeners is that because people can record things and such actions are protected \nby the First Amendment, using a tool like GenAI also gives users First Amendment protection . But the \nrecording rights hinge on humans intentionally creating the recording, knowing that the cameras will record \nwhat they are aimed at. Not to beat a dead horse, but there is no similar 1:1 knowledge with the input and \noutput of GenAI. Nobody expecte d Google to tell people to put glue in their pizza, for example, but it \n \n74 393 U.S. 503 (1969) . \n75 See Volokh , Lemley, & Henderson , supra note 6.  \n--- Page 23 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 23  \n happened  when a user asked how to make cheese stick to the pizza .76  \nMoreover, nobody disputes that the government can regulate cameras, recorders, and other tools even \nthough the users of those tools may have First Amendment rights from their use. All other tools that courts \nhave granted some protection to have involved hu mans trying to communicate a message to other humans: \nthe Internet, film, cable television, etc. No copper wire has been granted First Amendment protections just \nbecause it may be used to communicate something by transmitting signals. It  is the actual use or attempted \nuse that matters, not the existence of the potential use of a tool.  \nA more helpful framework would be to consider whether the information received is speech. That is, \nwas it intentional and by a human ? If it was, traditional free speech protections apply. If it was not, there are \nno listener rights and no first -party speech protections. Instead, it is fully non -expressive conduct.  \nFor non -expressive conduct, the proper analysis is whether the government is attempting to forbid the \nrecorder or listener from recording or listening, and if so, does the law improperly target  and stifle some \nkind of downstream speech or speaker.  \nThis is where the analysis, as applied to GenAI, becomes interesting. It cannot be the case that any \neffect on downstream speech or a speaker triggers a First Amendment analysis. If it did, anyone claiming \nany government action disrupted the person’s speech in any manner could file a non -frivolous lawsuit. The \nkey question becomes: at what point does some thing have a predictable connection to a person’s potential \nexpression?  \nAssuming that GenAI outputs likely impact a person’s future expression, what level of judicial scrutiny \nshould apply when the government tries to curtail GenAI outputs? We think that the rational basis  test, which \nrequires only a  rational relationship  to a legitimate government purpose , would be too low a hurdle for the \ngovernment to meet  because a law or action is generally upheld if there's any conceivable, legitimate reason \n \n76 See Kylie Robison,  Google Promised a Better Search Experienc e—Now It’s Telling Us to Put Glue on \nOur Pizza , THE VERGE  (May 23, 2024), https://www.theverge.com/2024/5/23/24162896/google -ai-\noverview -hallucinations -glue-in-pizza . (“Add some glue,” Google answers. “Mix about 1/8 cup of Elmer’s \nglue in with the sauce. Non -toxic glue will work.” ) \n--- Page 24 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 24  \n for it . The challenger (the person or entity challenging the law) must prove that the government has no \nlegitimate interest or that there's no rational connection between the law and that interest , and it seems \ntrivially easy to make up a reason to curtail some model outputs .  \nWe also believe strict scrutiny is too high a standard. Instead, strict scrutiny should be reserved for \nprotected speech, which GenAI cannot, by definition, produce. Therefore, the standard that makes the most \nsense is some form of heightened scrutiny akin  to a weak version of  intermediate scrutiny.   \nF. When Would Rights Attach?  \nEven if one were inclined to give models some  speech  protections, it is unclear  when those rights would \nattach. A model produces nonsense even after a few hundred training steps.77 Nobody knows when, exactly, \na foundation model becomes coherent. Is the gibberish output from the beginning of training protected \nspeech?78 If not, when do we decide to attach protections? When  the output  has a few understandable words? \nMostly understandable words? Perfect grammar?  \n \nG. Summary  \nWhen trying to identify the speaker, perhaps legal scholar Dan L. Burk described it best:  \nCertainly, the machine is not a speaker for tort, First Amendment, or related purposes; as a \nmachine, it has no awareness, cognition, or intent. Neither is the user a speaker; although the \nuser’s prompts elicit the textual output, the nature and language o f the outputs are largely \nunanticipated and are generated by unknown (possibly unknowable) statistical mechanics. \nNeither is the designer, creator, or deployer of the LLM likely to be a speaker. In the case of \nChatGPT, OpenAI is not aware of the details of  any particular machine response, even if they \nmay be informed of a general trend or likelihood of damaging machine responses.  . . . [T]he \nprompter is a cause, but not a creator of the text, and the same may be said of the LLM \nproprietor. Consequently, LLM texts appear to entail a kind of reader response theory on \nsteroids: essentially all the meaning in the text must be supplied by the reader, as there is no \n \n77 Aatish Bhatia,  Watch an A.I. Learn to Write by Reading Nothing but Jane Austen,  N.Y.  TIMES  (Apr. 27, \n2023), https://www.nytimes.com/interactive/2023/04/26/upshot/gpt -from -scratch.html .   \n78 For a helpful explainer and visualization of this process, see \nhttps://www.nytimes.com/interactive/2023/04/26/upshot/gpt -from -scratch.html .  \n--- Page 25 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 25  \n meaning supplied by an author.79  \nIn sum, there are several reasons one should conclude that GenAI outputs are typically not speech. First, \nthe analogy often drawn from human communicative acts to describe how GenAI models work is a \nfundamentally misguided basis for claiming speaker -hood , as GenAI is incapable of intentions, agency, or \nthought. Moreover, GenAI outputs have little , if anything,  in common with corporate speech, so any analogy \nbetween the two fails to accomplish much.  \nEven if one wanted to assign speakership to GenAI outputs, who that speaker is remains  unclear. This \nis especially murky when the developers of GenAI are eager to disclaim the outputs of their models as the ir \nown views. Finally, it is not entirely clear when any speech rights would attach to GenAI as models display \na wide variety of levels of generative capabilities depending on factors such as the model’s size and training \ncycles. Thus, any claim of when speech r ights begin would be entirely arbitrary.  \nFor all these reasons, there is no speech. Because there is no speech, there is no need for any First \nAmendment  speech  analysis. At most, models produce non -expressive conduct, but that conduct is only \nprotectable  if a law or regulation  improperly targets or stifles some  probable  downstream speech or \nspeaker.  \nVI. SUBSTANTIVE ARGUMENT  \nThere may be some who read this paper and agree with the analysis that GenAI outputs are not speech under \ncurrent law but  still believe that courts should make the extraordinary extension of human -based free speech \nprotections to GenAI. We believe this would be a bad idea.  \n \nA. The Purpose of Free Speech  \nFirst, we must consider why the Constitution protects the freedom of speech. We could look at what the \n \n79 Burk, supra note 10 , at 216 –17, 222 . \n--- Page 26 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 26  \n founders were thinking when they passed the First Amendment, but, of course, the founders could not have \npossibly anticipated GenAI like they could commercial speech, corporations, political speech, and the media. \nWhat we do know is that i n the founding era, protected speech consisted  solely of speech where the speaker \nwas a human who spoke with intentionality, understanding  what they were saying when they said it.80 A \nmore fruitful source for deciphering the purposes of free speech has been language provided by the Supreme \nCourt.  \nOne of the most cited justifications for the freedom of speech is the “marketplace of ideas,” which grew \nin part from Justice Holmes’s dissent in Abrams v. United States .81 He wrote that “the ultimate good desired \nis better reached by free trade of ideas —that the best test of truth is the power of the thought to get itself \naccepted in the competition of the market.”82 \nJustice Brandeis, who concurred with the Abrams  dissent, built on that idea  in Whitney v. California83 \nby championing freedom of speech as a necessary ingredient for self -governance as well. He noted that \n“[f]reedom to think as you will and to speak as you think are means indispensable to the discovery and \nspread of political truth.”84  \nNearly fifty years later, Justice Marshall made an argument geared more toward  the rights associated \nwith self -fulfillment, stating , \"The First Amendment serves not only the needs of the polity, but also those \n \n80 For an even more fundamental analysis, others have ably explored the text from the founding -era \ndefinitions of “speech” and the history and the original meaning of “speech,” reaching conclusions that align  \nwith this paper. See, e.g., Austin and Levy, supra note 47 (“…, a comprehensive survey of  \nFounding -era dictionaries reveals remarkably consistent definitions of speech. These definitions  \ndraw sharp distinctions between thoughts and speech, defining speech as the external  \nmanifestation of something that previously existed only in the speaker’s mind. That external  \nmanifestation, by its very nature, will always be capable of certain identification by its speaker...in  \nthe Founding era “there were essentially three methods of communication: oral, unamplified  \nspeech; handwritten correspondence; and printed materials created using a printing press.”  \nEach of these modes of communication are inherently and unavoidably characterized by speech  \ncertainty. By their very nature, they require that the speaker be able to identify with certainty what  \nhe said at the moment he said it. The act of speaking orally demands that something has been  \nsaid aloud; writing demands something be written; printing that something be printed.”)  \n81 Abrams v. U.S. , 250 U.S. 616, 624 (1919) (Holmes, J., dissenting).  \n82 Id. at 630.  \n83 Whitney v. California,  274 U.S. 357 (1927).  \n84 Id. at 375.  \n--- Page 27 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 27  \n of the human spirit —a spirit that demands self -expression. Such expression is an integral part of the \ndevelopment of ideas and a sense of identity. To suppress expression is to reject the basic human desire for \nrecognition and affront the individual’s worth and dignity.”85  \nThese are not the only statements about why freedom of speech is important or perhaps even paramount \nto a functioning democracy, but they provide a reasonable overview of the key arguments. How, then, does \nGenAI fit in?  \nAs discussed in the paper, GenAI can neither  think nor offer new ideas beyond those learned in training. \nIt is not self -aware and therefore cannot think or participate in self-expression . Thus, it is entirely unclear \nhow granting speech protections to GenAI outputs would enhance a marketplace of ideas, how it would lead \nto “discovery and the spread of political truth” (GenAI has no agency and cannot investigate, interrogate, \nexplore, or d iscover), or how it would lend itself to self -fulfillment (GenAI has no desires and therefore \ncannot wish to express itself in any particular way).  \nMoreover, a “marketplace of ideas” argument only works if one legal person is trying to convince \nanother legal person that their position is correct. Humans think, form ideas, and make choices in our \nexpressions based on various factors , including the audience and one’s own stance on the topic. Therefore, \nwe have the ability to make a case for our beliefs and convince others of them . GenAI systems, however, \nhave none of that. They do not have an internal belief system —moral, political , or otherwise. They do not \nhave the capacity to persuade anyone of anything, as they lack  the capability of thought and self-awareness . \nIn fact, the communications of animals like whales or house pets are closer to the speech we currently protect \nas they are voluntary expressions that carry meaning. Even so, we do not claim animal communications are \nprotected speech. Even if humans are able to lend meaning to the particular meowing of their cat, th at does \nnot mean the cat’s meowing becomes protected speech. If anyone is persuaded by an output by GenAI, it is \nbecause the user is affixing meaning to the output, and not because persuasion was intended by the model.  \nAdditionally, any argument that more speech is always the cure for bad speech, and therefore we should \n \n85 Procunier v. Martinez,  416 U.S. 396, 427 (1974) (Marshall, J., concurring).  \n--- Page 28 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 28  \n seek to expand what speech is protected, overlooks the possibility (or the reality, really) of how GenAI can \ncreate bad speech more quickly than any human possibly could.86 The more -speech  argument came about \nwhen GenAI was unforeseeable and when humans had to craft all the speech.87 The claim also overlooks \nthat a tsunami of information does not enhance or facilitate any discussion ––especially when it \noverwhelmingly springs from a single source. It  is not at all clear to us how GenAI that can hallucinate a \nfalse output or be coaxed to produce outputs for the express purpose of undermining democracy at scale \nthrough various means (e.g., misinformation, disinformation, manipulation, undermining society’s trust in \ncontent it encounters generally and from high -quality news sources specifically, etc.) improves our nation \nin a way that overwhelmingly offsets the potential and potentially irreversible harms.  \nWith GenAI, there is incredible potential to be beneficial. But the benefits w ill not  happen without \nhuman intervention. The laws of entropy teach us as much: there are more ways for things to turn out useless, \nto have no impact, or to be harmful than there are to be beneficial. The resting state of GenAI is not  inherently \nbeneficial. The benefits must be willed into existence and then sustained by thoughtful, concerted efforts \nfrom everyone who touches on the lifecycle, including regulators.  \nIt is also difficult to see why a model that is incapable of safely and effectively providing medical care, \nhiring, or legal advice should be protected on the basis that its outputs are vital to democracy itself. It is even \nmore difficult to understand why the First Amendment should be read to disable the government’s —and \ntherefore democracy’s —ability to protect itself from non -human speech.  \nB. GenAI Governance  \nBefore handicapping  the government’s ability to regulate GenAI, we must also ask who else should regulate \nit. If not the elected government, through a democratic process with input from the elected officials or \n \n86 It also overlooks that GenAI models, unlike humans, cannot be dissuaded from bad speech, like  \ndefamation or “fighting words” because GenAI does not understand what it is generating.  \n87 See Whitney , 274 U.S. at 377 (“If there be time to expose through discussion, the falsehoods  and fallacies, \nto avert the evil by the processes of education, the remedy to be applied is more speech, not enforced \nsilence.”) . \n--- Page 29 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 29  \n referendums of a pluralistic society, then we are choosing to cede control to a handful of unelected \ntechnologists.  \nAllowing a small group of people, such as officers and directors of a handful of powerful corporations, \nto determine what speech is and is not acceptable for tools intended for use in nearly every profession seems \nanathema to the nation's pluralistic principles .88 Unsurprisingly, the GenAI entities also lack the incentives \nand varied demographic and socioeconomic characteristics of the people whose democracy they are \nsupposedly aiding. If GenAI truly is as consequential as electricity and fire, then perhaps it should be \nregulated as such, meaning oversigh t by elected officials and sometimes constrained by strict liability.  \nAn exception to our general stance would be if U .S. citizens approve an amendment to the Constitution  \nto grant GenAI full free speech protections . This would mean that society affirmatively chooses to expand \nthe power of GenAI companies and constrain the power of the U.S. government to influence it . We do not \nthink such an action  would be wise, but at least it would be a democratic decision.  \nC. Remaining Protections  \nSuppose the argument is that if GenAI received no First Amendment protections , it would invite abuse by \ngovernments who may, for example, want to silence certain ideas. This overlooks the fact that having no \nspeech protections is not the same as having no protections at all. It is a defining principle in the United \nStates  that viewpoint discrimination is frowned upon regardless of the First Amendment , and GenAI \ndevelopers could make any number of arguments against it: due process, violation of liberty, arbitrariness, \nbill of attainder, and so on. It is not as if the First Amendment is the single constitutional  reed protecting \n \n88 The news source with the highest subscriber count, the New York Times, has 11.4 million subscribers. \nhttps://www.nytimes.com/2025/02/05/business/media/new -york-times -q4-2024 -\nearnings.html#:~:text=The%20New%20York%20Times%20Company%20added%20350%2C000%20digita\nl%2Donly%20subscribers,percent%20from%20a%20year%20earlier . The GenAI system with the most \nsubscribers, GPT -4, has 15.5 million. https://www.theinformation.com/articles/chatgpt -subscribers -nearly -\ntripled -to-15-5-million -in-2024 . A key difference is that news sources create a limited number of articles a \nday. A year ago, OpenAI claimed its models were used to output 100 billion words per day. https://www.the -\nindependent.com/tech/chatgpt -openai -words -sam-altman -b2494900.html . \n--- Page 30 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 30  \n everyone from an overreaching  government.  \nAs Lawrence Lessig put it when describing what he called “replicants ,” which are “processes that have \ndeveloped a capacity to make semantic and intentional choices, the particulars of which are not plausibly \nascribed to any human or team of humans in advance of those choices ,” he said that :  \nNone of this is to say that such speech is entitled to no protection at all. This is the insight in \nJustice Scalia’s opinion in R.A.V. v. City of St. Paul (1992).89 We could well conclude that \nreplicant speech is entitled to no protection but  also conclude that the government is not free \nto discriminate among replicant speech. From this perspective, the replicant targeting the ads \nin Facebook’s algorithm would have no presumptive constitutional protection. But the \ngovernment couldn’t decide to  ban Republican targeting but  not targeting for Democrats. As \nin R.A.V., that is not because the underlying speech is protected. It is because a second value \nwithin the contours of the First Amendment is the value of government neutrality.90  \n \nVII. HUMANS MUST BE TREATED DIFFERENTLY FROM GENAI  \nWhile there are close calls regarding the First Amendment and when protections attach, this is not one of \nthem. And, because models are not protected by the First Amendment, we need not consider whether \nregulating them may stifle someone’s ability to speak  or to receive speech any more than a regulation on \npaper or pencils or computers, all of which, like models, are mere tools and none of which, like models, are \nspeech.  \nWe should not go out of our way to give precious protections to entities that neither want nor need them. \nThe fact that some listeners can ascribe meaning to model outputs is not sufficient to claim the output is \nspeech. With models, there is no speaker an d there is no intended message, so there can be no speech as it \nis understood in constitutional law.  \nFurthermore, models are not code,  and, for First Amendment purposes, they are not like code. Blurring \nthe lines for models invites a restraint on democratic governance as the government will be limited in how \nit can effectively control what many technology luminaries believe is one of the  most consequential \n \n89 R.A.V. v. City of St. Paul , 505 U.S. 377, 387–96 (1992).  \n90 Lawrence Lessig, The First Amendment Does Not Protect Replicants , in SOCIAL MEDIA , FREEDOM OF \nSPEECH , AND THE FUTURE OF OUR DEMOCRACY  13 (Lee C. Bollinger & Geoffrey R. Stone, eds., 2022).  \n--- Page 31 ---\n   \nIntentionally Unintentional: GenAI Exceptionalism and  the First Amendment  \n 31  \n innovations in human history. Allowing a handful of companies to improperly rely on the powerful shield \nof the First Amendment when wielding such an indisputably powerful technology with far -reaching \nimplications for democracy and the economy is unwise.  A better approach is to require greater democratic \nparticipation and accountability.  Whatever people may think of the developers of large language models, \nthey probably do not think those developers have too little power.  \nFinally, if any court should feel tempted to extend free speech rights to GenAI , it must first reckon with \nthe purpose of the First Amendment and whether protecting GenAI does more harm than good for society. \nRelying on strained analogies to expand legal rights is not the best way to analyze the law. However , one \nmay define GenAI , it is clearly not a human, not an entity comprised of humans, and it is certainly not a \ncitizen of the United States. Therefore, it makes little sense to grant it any speech rights to partake in our \ndemocratic processes.  \nWhen it comes to GenAI, which CEOs of trillion -dollar companies have compared to the most \nconsequential technological advances in human history, the risks from too little regulation by granting \nvirtually all GenAI outputs full free speech protections, where laws and regulations must satisfy strict \nscrutiny , likely dwarf the risks of too much regulation. Courts long ago recognized that having no regulations \non fire or electricity would be bad for society. GenAI is no different.",
  "text_length": 79876
}