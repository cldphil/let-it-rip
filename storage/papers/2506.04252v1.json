{
  "id": "http://arxiv.org/abs/2506.04252v1",
  "title": "A Graph-Retrieval-Augmented Generation Framework Enhances\n  Decision-Making in the Circular Economy",
  "summary": "Large language models (LLMs) hold promise for sustainable manufacturing, but\noften hallucinate industrial codes and emission factors, undermining regulatory\nand investment decisions. We introduce CircuGraphRAG, a retrieval-augmented\ngeneration (RAG) framework that grounds LLMs outputs in a domain-specific\nknowledge graph for the circular economy. This graph connects 117,380\nindustrial and waste entities with classification codes and GWP100 emission\ndata, enabling structured multi-hop reasoning. Natural language queries are\ntranslated into SPARQL and verified subgraphs are retrieved to ensure accuracy\nand traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG\nachieves superior performance in single-hop and multi-hop question answering,\nwith ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also\nimproves efficiency, halving the response time and reducing token usage by 16%\nin representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready\nsupport for circular economy planning, advancing reliable, low-carbon resource\ndecision making.",
  "authors": [
    "Yang Zhao",
    "Chengxiao Dai",
    "Dusit Niyato",
    "Chuan Fu Tan",
    "Keyi Xiang",
    "Yueyang Wang",
    "Zhiquan Yeo",
    "Daren Tan Zong Loong",
    "Jonathan Low Zhaozhi",
    "Eugene H. Z. HO"
  ],
  "published": "2025-06-01T07:49:47Z",
  "updated": "2025-06-01T07:49:47Z",
  "categories": [
    "cs.AI",
    "cs.CL",
    "cs.LG"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.04252v1",
  "full_text": "--- Page 1 ---\narXiv:2506.04252v1  [cs.AI]  1 Jun 2025A Graph-Retrieval-Augmented Generation\nFramework Enhances Decision-Making in the\nCircular Economy\nYang Zhao1, Chengxiao Dai2, Dusit Niyato3, Chuan Fu Tan1,\nKeyi Xiang3, Yueyang Wang4, Zhiquan Yeo1,\nDaren Tan Zong Loong1, Jonathan Low Zhaozhi1,\nEugene H.Z. HO1\n1Singapore Institute of Manufacturing Technology (SIMTech), Agency for\nScience, Technology and Research (A*STAR), 2 Fusionopolis Way,\nInnovis#08-04, 138634, Republic of Singapore.\n2School of Computer Science, Faculty of Engineering, The University of\nSydney, Building J12, 1 Cleveland Street, Darlington, NSW, 2008,\nAustralia.\n3College of Computing and Data Science, Nanyang Technological\nUniversity, 50 Nanyang Ave, 639798, Republic of Singapore.\n4Faculty of Science, National University of Singapore, 6 Science Drive 2,\n117546, Republic of Singapore.\nContributing authors: Zhao_Yang@simtech.a-star.edu.sg;\ndaicxx1226@gmail.com; DNIYATO@ntu.edu.sg;\nTan_Chuan_Fu@simtech.a-star.edu.sg; KEYI003@e.ntu.edu.sg;\ne0726339@u.nus.edu; zqyeo@simtech.a-star.edu.sg;\ntanzld@simtech.a-star.edu.sg; Jonathan_Low@simtech.a-star.edu.sg;\neugene_ho@simtech.a-star.edu.sg;\nAbstract\nLarge language models (LLMs) hold promise for sustainable manufacturing, but\noften hallucinate industrial codes and emission factors, undermining regulatory\nand investment decisions. We introduce CircuGraphRAG, a retrieval-augmented\ngeneration (RAG) framework that grounds LLMs outputs in a domain-specific\nknowledge graph for the circular economy. This graph connects 117,380 indus-\ntrial and waste entities with classification codes and GWP100 emission data,\n1\n--- Page 2 ---\nenabling structured multi-hop reasoning. Natural language queries are translated\ninto SPARQL and verified subgraphs are retrieved to ensure accuracy and trace-\nability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG\nachieves superior performance in single-hop and multi-hop question answering,\nwith ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also\nimproves efficiency, halving the response time and reducing token usage by 16%\nin representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready\nsupport for circular economy planning, advancing reliable, low-carbon resource\ndecision making.\nKeywords: Circular Economy, Large Language Model, RAG, GraphRAG.\n1 Introduction\nThe global transition to a circular economy promises substantial improvements in\nresourceefficiencyandwastereduction,wherebytheby-productsofoneindustrialpro-\ncess can serve as input to another, thus reducing waste and conserving resources [1, 2].\nDespite its considerable potential, many organizations face persistent barriers, includ-\ning fragmentation of data, limited trust, and stringent regulatory requirements, which\nhinder their ability to align resource availability with sustainability objectives [3–5].\nIn addition, material flow, energy use, and emission data are frequently located in\nisolated systems, undermining collective efforts to minimize waste [6, 7]. Even when\npotential opportunities arise, the lack of standardized terminology, divergent measure-\nment protocols, and intellectual property concerns often restrict open data sharing,\nthus impeding the widespread adoption of circular practices [8, 9].\nCurrently,environmental,social,andgovernance(ESG)reportingframeworks[10],\nsuchastheGlobalReportingInitiative(GRI)[11],theSustainabilityAccountingStan-\ndards Board (SASB) [12], and the Climate-related Financial Disclosure Task Force\n(TCFD) [13], have gained prominence in guiding corporate transparency and invest-\nment decisions. These frameworks require auditable disclosures on waste streams,\nresource utilization, and environmental impacts, aligning closely with the objectives\nof a circular economy. However, bridging data fragmentation, establishing trust across\norganizations, and meeting compliance demands remain non-trivial tasks.\nStandardized databases and systematic monitoring frameworks have emerged to\naddress these data-related challenges [14, 15]. Classification systems such as the\nEuropean Waste Catalog (EWC) [16] and the Nomenclature of Economic Activities\n(NACE) [17] provide universal taxonomies for categorizing resources and waste, thus\nreducing intersectoral misalignment. These foundational structures are suitable for\nthe construction of knowledge graphs [18], where entities such as waste streams, pro-\nduction facilities are represented as nodes, and their relationships, including “can be\nprocessed by,” and “located in” are encoded as semantic links. Typically, these links\nare implemented using the Resource Description Framework (RDF) [19, 20], ensuring\nstructured and machine-readable data across multiple domains.\n2\n--- Page 3 ---\nRecent advances in large language models (LLMs) offer expert-level insight and\ndecision support in various fields, including healthcare and environmental manage-\nment [21]. However, LLMs can produce inaccurate or fabricated content due to\nhallucination [22–24], reinforcing the need for robust and vetted databases. Retrieval-\naugmented generation (RAG) [25, 26] partially addresses this challenge by integrating\nexternal knowledge into the inference process. An advanced variant, GraphRAG [27],\nexploits the interconnected nature of knowledge graphs to perform multi-hop reason-\ning, producing more reliable outputs than traditional RAG pipelines based solely on\nvector similarity [28, 29]. By systematically linking nodes through explicit relation-\nships, GraphRAG retrieves contextually relevant knowledge, thus improving precision\nand mitigating tangential data [30]. In addition, this graph-based structure clarifies\nthe chain of reasoning, allowing users to trace how each data point contributes to the\nfinal output, mitigating hallucinations, and increasing user trust.\nTo align with climate mitigation targets, it is also critical to integrate emission\nfactor data. The 100-year Global Warming Potential (GWP100) indicator provides a\nstandardized benchmark to assess the climate impacts of industrial processes [31, 32].\nReflecting GWP100 in transactions, stakeholders can rank or filter synergy opportu-\nnities based on greenhouse gas footprints, thus making decisions that comply with\nESG standards and advance sustainability goals.\nTogether, these frameworks and technologies create the foundation for a\nrobust, data-driven platform that can effectively enable circular economy synergies.\nDespite these promising developments, direct applications of knowledge graphs and\nGraphRAG within the circular economy remain limited. Existing standards and\nframeworks provide a foundation for modeling waste and resource data but lack inte-\ngration into a cohesive platform capable of supporting large-scale synergy discovery\nand continuous sustainability assessments [33, 34].\nIn this paper, we detail how CircuGraphRAG synergistically integrates knowl-\nedge graph technology, RAG, and ESG metrics to advance data-driven circular\neconomy practices. Specifically, we build a harmonized industrial-waste knowledge\ngraph that links industries, waste classifications, materials, and environmental fac-\ntors (GWP100) across multiple standards (ISIC, NACE, EWC), enabling structural\nand semantic exploration. We then present a knowledge graph enabled RAG archi-\ntecture that incorporates ontology-aligned industrial knowledge and environmental\nmetrics,supportingstructuredretrievalandmulti-hopreasoningforlow-carbonindus-\ntrial symbiosis. Our approach further employs a light-weight library of 18 SPARQL\nquery templates, automatically selected and parameterized by the LLMs, to facilitate\nboth single-hop lookups and multi-hop synergy discovery without handwritten rules.\nIn addition, a hybrid ranking mechanism uses GWP100 to order query results, guid-\ning practitioners toward low-carbon waste-to-resource pathways. We also contribute\na reproducible graph reasoning benchmark for code alignment, numeric accuracy, and\nindustrial symbiosis scenarios. Finally, we demonstrate model-agnostic empirical gains\nacross various LLMs, showing that CircuGraphRAG consistently reduces hallucina-\ntions and accelerates inference compared to Naive RAG, without diminishing answer\ncompleteness.\nThe abbreviations used in the paper are summarized in the Appendix 6.9.\n3\n--- Page 4 ---\n2 Results\nDeveloping robust waste-to-resource strategies is crucial to minimize environmen-\ntal impacts and advance circular economy goals. This section presents an extensive\nevaluation of CircuGraphRAG across realistic waste-to-resource management queries,\nillustrating how knowledge-graph-driven retrieval substantially enhances the discov-\nery of reuse pathways. We compare our CircuGraphRAG against several baselines on\nthree primary tasks: structured data extraction (single-hop queries) and multi-hop\nreasoning including synergy identification. Quantitative metrics are complemented by\nan analysis of computational overhead and template matching ablation study, as well\nas an assessment of the multi-round consistency of LLMs reasoning.\n2.1 Quantitative Results for Single-Hop Queries\nSingle-hop queries consist of directly retrieving a single fact or entity from the knowl-\nedge graph. A representative query is “Which resource corresponds to EWC code\n080121 and HS code 810330?\" in Appendix 6.1. Then, Appendix 6.2 summarizes the\nresults on three distinct single-hop queries (Cases 1–3).\n2.1.1 Overall Performance\nCircuGraphRAG consistently outperforms both Standalone LLM and Naive RAG\nacrossallexaminedLLMs(Llama,Qwen,DeepSeek)intermsof ROUGE-L F1scores.\nThese improvements are visualized in Figure 1a, which illustrates the performance\ndifferencesacrossmodelsandtestcasesinthreedimensions.Detailednumericalresults\ncan be found in Appendix 6.2, highlighting the significant gains enabled by domain-\nconstrained retrieval.\n2.1.2 Precision and Recall Gains\nIn Case 1, CircuGraphRAG with Qwen and with DeepSeek both achieve a perfect\nROUGE-L recall (1.0). In contrast, Standalone LLM approaches frequently produce\nincomplete or inaccurate responses, suggesting hallucinations or a lack of contextual\ngrounding. However, CircuGraphRAG anchors the query to specific domain edges,\nsuch as iskg:hasHSCode andiskg:hasEwcCode , to reliably match the correct entity.\nIn Case 2, CircuGraphRAG improves ROUGE-L precision and recall over base-\nlines. For example, CircuGraphRAG with Qwen achieves a ROUGE-L precision of\n0.4286, a substantial gain over Naive RAG with Qwen (0.0150). These improvements\nindicate that forcing query resolution through valid code and entity relationships (e.g.,\niskg:hasNaceCode ) filters out spurious completions. From a regulatory point of view,\nan incorrect assignment of provider or resource codes (for example, NACE 3821 vs.\n3822) could lead to non-compliance.\n2.1.3 Numeric Retrieval\nNumerical accuracy is critical for compliance driven domains, particularly for\nGWP100. In Case 3, CircuGraphRAG with both Qwen and Llama correctly retrieves\nthe minimal GWP100 value ( 0.008930631 ), achieving an ROUGE-L F1 score of\n4\n--- Page 5 ---\n1.0. All baseline approaches either return a spurious figure or no result, under-\nscoring the difficulty of numeric retrieval within unconstrained LLMs. Since small\ndeviations in emission metrics can misrepresent environmental impact assessments,\nCircuGraphRAG’s exact retrieval of numeric data is vital for reliable industrial\ndecision-making.\nllama\nqwen\ndeepseekModelCase 1Case 2Case 3\nCase0.00.20.40.60.81.0\nF1 Score\n(a)F1 Score\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama\nqwen\ndeepseekModelCase 1Case 2Case 3\nCase0.00.20.40.60.81.0\nPrecision\n(b)Precision\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama\nqwen\ndeepseekModelCase 1Case 2Case 3\nCase0.00.20.40.60.81.0\nRecall\n(c)Recall\nStandalone LLM\nNaive RAG\nCircuGraphRAG\n(a) Single-hop QA: ROUGE-L F1, precision, and recall across Cases 1–3.\nllama\nqwen\ndeepseekModelCase 4Case 5Case 6\nCase0.00.20.40.60.81.0\nF1 Score\n(a)F1 Score\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama\nqwen\ndeepseekModelCase 4Case 5Case 6\nCase0.00.20.40.60.81.0\nPrecision\n(b)Precision\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama\nqwen\ndeepseekModelCase 4Case 5Case 6\nCase0.00.20.40.60.81.0\nRecall\n(c)Recall\nStandalone LLM\nNaive RAG\nCircuGraphRAG\n(b) Multi-hop QA: ROUGE-L F1, precision, and recall across Cases 4–6.\nFig. 1: 3D performance comparison of different LLMs and retrieval methods on\nsingle-hop QA tasks.\n5\n--- Page 6 ---\n2.2 Quantitative Results for Multi-Hop Reasoning and\nSynergy Identification\nMulti-hop queries assess a model’s capacity to traverse multiple linked relationships,\nan essential capability for identifying synergies in industrial symbiosis. For instance,\nverifying that a receiver of one resource can act as a provider of another often requires\nnavigation through various classification codes (e.g., EWC, HS, NACE, CPA) and\nproperties (e.g., iskg:hasGwp100 ). As shown in Figure 1b, CircuGraphRAG consis-\ntently outperforms both Standalone LLM and Naive RAG in Cases 4–6, achieving\nnotably higher ROUGE-L F1 scores.\nIn Case 4, the query determines which CPA code and category apply to the\nresources generated under a specific NACE code. Both Standalone LLM and Naive\nRAG yield a ROUGE-L F1 of 0.0 across all language models. CircuGraphRAG with\nLlama or DeepSeek also returns 0.0, yet CircuGraphRAG with Qwen achieves 1.0,\nindicating that a sufficiently capable model can take advantage of the constraints\nbased on the knowledge graph.\nMoreover, Case 5 extends this concept by examining whether receivers under a\nCPA code can later serve as providers of a second resource (e.g. “waste polystyrene”).\nCircuGraphRAG with Llama or Qwen achieves a perfect ROUGE-L F1 of 1.0,\nwhereas Naive RAG and Standalone LLM each fall below 0.08 in most configu-\nrations, underscoring that purely generative reasoning is prone to errors without\nexplicit domain guidance. CircuGraphRAG with DeepSeek performs moderately\nwell ( ROUGE-L F1=0.4615), though not matching the near-ideal scores of Circu-\nGraphRAG with Qwen or Llama.\nIn Case 6, the query identifies providers of a resource coded EWC 070213 that\ncan also receive “aluminum scrap.” CircuGraphRAG with Qwen again achieves a\nROUGE-L F1 of 1.0, while CircuGraphRAG with Llama and DeepSeek remain at\n0.0, and the baseline approaches exhibit limited precision below 0.035. These results\ndemonstratethatCircuGraphRAGsignificantlyoutperformsbaselinemethodsincom-\nplex multi-hop queries, particularly when structural constraints are applied. However,\nperformance differences across LLMs remain, and some models still require strat-\negy calibration or further fine-tuning to fully leverage knowledge graph-enhanced\nreasoning.\nFrom a circular economy perspective, this level of multi-hop precision is crucial\nfor industrial symbiosis, in which by-products from one facility become feedstock for\nanother. By encoding explicit relationships in a knowledge graph, CircuGraphRAG\nreduces reliance on heuristic inference, thus mitigating misclassification risks and\nfacilitating data-driven synergy discovery. Overall, these results confirm that Circu-\nGraphRAG enhances multi-hop reasoning, particularly when deployed with capable\nLLMs, thus improving the identification of multi-step resource flows and advancing\ncircular economy’s objectives. Supporting metrics for this evaluation are presented in\nAppendix 6.3.\n6\n--- Page 7 ---\n2.3 Computation Cost and Token Usage\nWe further evaluated CircuGraphRAG in terms of token consumption and infer-\nence time across various LLM back-ends and task types. Although the framework\nincorporates additional retrieval components including template matching (TM),\nquery merging (QM), and querying with recovered context (QRC), which might\nincrease computational overhead, our results indicate that CircuGraphRAG consis-\ntently reduces both total token usage and inference latency. These gains are attributed\nto the construction of more compact, domain-specific input contexts that constrain\nthe language model’s generative scope and streamline the reasoning process.\nIn single-hop queries (Figure 2a), CircuGraphRAG with Qwen processes fewer\ntokens more quickly than Naive RAG with Qwen or Standalone Qwen, as evidenced in\nCase 1 (2,009 tokens vs. 2,381 tokens and over 10,000 tokens) while doubling inference\nspeed.Theapproachmayincurhighertokenusageinmorecomplextasks(Case2)due\nto broader subgraph lookups, but yields more reliable answers by leveraging domain-\nspecific evidence. In contrast, Standalone Qwen tends to generate excessively long\noutputs with correspondingly higher latency.\nllama qwen deepseek\nLLM Model0510152025Inference Time (s)\nCase 1\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama qwen deepseek\nLLM Model\nCase 2\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama qwen deepseek\nLLM Model\nCase 3\nStandalone LLM\nNaive RAG\nCircuGraphRAG\n(a) Single-hop cases (Cases 1–3).\nllama qwen deepseek\nLLM Model05101520Inference Time (s)\nCase 4\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama qwen deepseek\nLLM Model\nCase 5\nStandalone LLM\nNaive RAG\nCircuGraphRAG\nllama qwen deepseek\nLLM Model\nCase 6\nStandalone LLM\nNaive RAG\nCircuGraphRAG\n(b) Multi-hop cases (Cases 4–6).\nFig. 2: Inference time comparison across different models and methods for (a)\nsingle-hop and (b) multi-hop QA tasks.\nMulti-hop queries often exacerbate off-topic content unless retrieval is carefully\nguided. In Case 5 (Figure 2b), Standalone Qwen outputs 8,677 tokens in 21.35s,\n7\n--- Page 8 ---\nwhile CircuGraphRAG with Qwen trims responses to 2,733 tokens only in 3.11s.\nAlthough certain queries (e.g., Case 4) require more extensive retrieval (6,041 tokens\nover 11.50s), CircuGraphRAG is the only method that achieves an F1 score of 1.0\nfor this scenario. Across all LLMs, CircuGraphRAG constrains generative pathways\nby embedding domain relationships, balancing overhead with enhanced multi-hop\naccuracy.\nOverall, these observations show that CircuGraphRAG effectively reduces super-\nfluous text generation while sustaining high factual fidelity. When additional tokens\nare needed, the resulting improvements in answer quality and reliability offset the\nhigher computational cost, demonstrating the potential of a domain-targeted retrieval\nstructure for large-scale industrial knowledge queries.A detailed comparison of token\nusage and inference latency across models and methods supporting these findings is\npresented in Appendix 6.4 and Appendix 6.5.\n2.4 Template Matching Ablation Study\nSince structural templates play a central role in shaping how the model identifies and\ncomposesquery paths,we conductan ablation studyto investigate howdifferent levels\nof template guidance affect the reasoning process in CircuGraphRAG. Specifically, our\nobjective is to evaluate whether removing or weakening the use of templates impacts\nthe accuracy of downstream SPARQL query generation and final answers.\nWe consider three template configurations: (1) with template , where the sys-\ntem utilizes explicitly defined query structures to guide the reasoning process; (2) no\ntemplate , where the LLM must generate the SPARQL query path without structural\nguidance; and (3) fuzzy template , where only partial structural hints (e.g. entity\ntypes or field names) are provided without complete logical templates. For each set-\nting, we evaluate the accuracy of the answer in three LLMs under the same task input.\nTo isolate the influence of template guidance, we conducted this study in a represen-\ntative single-hop QA case where the expected output depends on precise entity-code\nmapping.\nTable 1: Accuracy Comparison under\nDifferent Template Matching Conditions. (A\n✓indicates a correct answer; a ✗indicates\nan incorrect one.)\nTemplate Type llama qwen deepseek\nWith Template ✓ ✓ ✓\nNo Template ✗ ✗ ✗\nFuzzy Template ✓ ✓ ✗\nAs shown in Table 1, the performance of different models varies significantly across\ntemplate configurations, further validating the critical role of predefined templates in\nthe CircuGraphRAG system. Under the with template condition, all three models\n8\n--- Page 9 ---\nachieve 100% query matching accuracy. This demonstrates that explicitly injected\ntemplates not only provide structural guidance, but also normalize the reasoning\npath and entity operation process, directly determining the quality and stability of\nSPARQL query generation.\nIn contrast, when the templates are completely removed ( no template ), none of\nthe models can generate correct SPARQL queries, and the accuracy drops to 0. This\nresult clearly demonstrates that even in single-hop question answering scenarios, large\nlanguage models struggle to reconstruct the necessary triple patterns and query logic\nwithout explicit structural templates. The absence of templates leads to significant\nerrors in entity selection, property targeting, and predicate direction, often resulting\nin failed path construction or invalid answers.\nUnder the fuzzy template condition, the system provides only partial struc-\ntural cues. Llama and Qwen still maintain relatively high accuracy, whereas DeepSeek\nshows a notable performance drop. This suggests that while fuzzy template hints can\nassist in constructing basic reasoning structures. However, without complete template\nlogic, query path generation becomes unstable and the final answers less reliable,\nparticularly for models with limited structural understanding.\n2.5 Multi-Round Consistency of LLMs Reasoning\nTo evaluate the robustness of the structured reasoning framework against the inher-\nent uncertainty in LLM output, we designed a set of experiments to examine whether\nvariability during the reasoning phase of LLM affects the overall performance of Cir-\ncuGraphRAG. Although the system leverages template matching and SPARQL query\nconstructiontoenablestructuredquestionansweringsupportedbyaknowledgegraph,\nthe generation of these structures is still fundamentally dependent on the reasoning\ncapability of the LLM. We hypothesize that if the LLM exhibits instability in tem-\nplate recognition or query path merging, it may lead to downstream retrieval failures\nor incorrect paths, ultimately degrading the answer accuracy.\nWe designed two sub-experiments, and to ensure experimental controllability, we\nconducted the evaluation on a representative single-hop question answering case. The\nfirst part evaluates the structural output consistency of the LLM in two key stages:\ntemplate matching andquery merging . Specifically, we compute three metrics over five\nrepeated runs: (1) ROUGE-L for lexical similarity, (2) BERTScore for semantic\nsimilarity, and (3) Exact Match Rate to measure whether the generated structures\nremain identical across runs. The second part examines whether structural gener-\nation differences affect the final answer quality. We record the answer accuracy of\nCircuGraphRAG, Naive RAG, and Standalone LLM over five runs for each input and\ncompare their accuracy levels.\nAccording to Figure 3, the results confirm that LLMs exhibit significant instability\nin two critical stages of structured generation, template matching and query merging.\nAlthough DeepSeek maintains complete consistency across multiple reasoning rounds,\nboth Llama and Qwen achieve only 60%exact match rates in both stages, indicating\nsubstantial variability in symbolic output structures (as reflected in lower ROUGE-L\nscores). Although the semantic content remains largely consistent (as shown by high\n9\n--- Page 10 ---\n/uni0000004f/uni0000004f/uni00000044/uni00000050/uni00000044 /uni00000054/uni0000005a/uni00000048/uni00000051 /uni00000047/uni00000048/uni00000048/uni00000053/uni00000056/uni00000048/uni00000048/uni0000004e/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000014/uni00000036/uni00000046/uni00000052/uni00000055/uni00000048\n/uni00000013/uni00000011/uni00000018/uni00000015\n/uni00000013/uni00000011/uni00000017/uni0000001a/uni00000014/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000016\n/uni00000013/uni00000011/uni00000018/uni00000013/uni00000014/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni0000001c/uni0000001c\n/uni00000013/uni00000011/uni0000001c/uni00000016/uni00000014/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni0000001c/uni00000018/uni00000013/uni00000011/uni0000001c/uni0000001a/uni00000014/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni00000019/uni00000013 /uni00000013/uni00000011/uni00000019/uni00000013/uni00000014/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni00000019/uni00000013 /uni00000013/uni00000011/uni00000019/uni00000013/uni00000014/uni00000011/uni00000013/uni00000013/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000010/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047/uni00000003/uni00000032/uni00000058/uni00000057/uni00000053/uni00000058/uni00000057/uni00000003/uni00000036/uni0000004c/uni00000050/uni0000004c/uni0000004f/uni00000044/uni00000055/uni0000004c/uni00000057/uni0000005c\n/uni00000035/uni00000032/uni00000038/uni0000002a/uni00000028/uni00000010/uni0000002f/uni00000003/uni00000010/uni00000003/uni00000037/uni00000048/uni00000050/uni00000053/uni0000004f/uni00000044/uni00000057/uni00000048\n/uni00000035/uni00000032/uni00000038/uni0000002a/uni00000028/uni00000010/uni0000002f/uni00000003/uni00000010/uni00000003/uni00000030/uni00000048/uni00000055/uni0000004a/uni0000004c/uni00000051/uni0000004a/uni00000025/uni00000028/uni00000035/uni00000037/uni00000036/uni00000046/uni00000052/uni00000055/uni00000048/uni00000003/uni00000010/uni00000003/uni00000037/uni00000048/uni00000050/uni00000053/uni0000004f/uni00000044/uni00000057/uni00000048\n/uni00000025/uni00000028/uni00000035/uni00000037/uni00000036/uni00000046/uni00000052/uni00000055/uni00000048/uni00000003/uni00000010/uni00000003/uni00000030/uni00000048/uni00000055/uni0000004a/uni0000004c/uni00000051/uni0000004a/uni00000028/uni0000005b/uni00000044/uni00000046/uni00000057/uni00000003/uni00000030/uni00000044/uni00000057/uni00000046/uni0000004b/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000003/uni00000010/uni00000003/uni00000037/uni00000048/uni00000050/uni00000053/uni0000004f/uni00000044/uni00000057/uni00000048\n/uni00000028/uni0000005b/uni00000044/uni00000046/uni00000057/uni00000003/uni00000030/uni00000044/uni00000057/uni00000046/uni0000004b/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000003/uni00000010/uni00000003/uni00000030/uni00000048/uni00000055/uni0000004a/uni0000004c/uni00000051/uni0000004a(a) Multi-round output similarity across LLMs and stages.\n/uni00000035/uni00000014 /uni00000035/uni00000015 /uni00000035/uni00000016 /uni00000035/uni00000017 /uni00000035/uni00000018\n/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047/uni00000056/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000014/uni00000011/uni00000013/uni00000013 /uni00000014/uni00000011/uni00000013/uni00000013 /uni00000014/uni00000011/uni00000013/uni00000013 /uni00000014/uni00000011/uni00000013/uni00000013 /uni00000014/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni00000016/uni00000016 /uni00000013/uni00000011/uni00000016/uni00000016/uni00000013/uni00000011/uni00000019/uni0000001a /uni00000013/uni00000011/uni00000019/uni0000001a /uni00000013/uni00000011/uni00000019/uni0000001a\n/uni0000000b/uni0000002c/uni0000000c/uni00000024/uni00000059/uni00000048/uni00000055/uni00000044/uni0000004a/uni00000048/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000033/uni00000048/uni00000055/uni00000010/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047\n/uni00000031/uni00000044/uni0000004c/uni00000059/uni00000048/uni00000003/uni00000035/uni00000024/uni0000002a\n/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000035/uni00000024/uni0000002a/uni00000003/uni0000000b/uni00000024/uni00000059/uni0000004a/uni0000000c\n/uni00000035/uni00000014 /uni00000035/uni00000015 /uni00000035/uni00000016 /uni00000035/uni00000017 /uni00000035/uni00000018\n/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047/uni00000056/uni00000031/uni00000044/uni0000004c/uni00000059/uni00000048/uni00000003/uni00000035/uni00000024/uni0000002a/uni00000027/uni00000048/uni00000048/uni00000053/uni00000036/uni00000048/uni00000048/uni0000004e/uni00000003/uni0000000b/uni00000026/uni0000004c/uni00000055/uni00000046/uni00000058/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000035/uni00000024/uni0000002a/uni0000000c/uni00000034/uni0000005a/uni00000048/uni00000051/uni00000003/uni0000000b/uni00000026/uni0000004c/uni00000055/uni00000046/uni00000058/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000035/uni00000024/uni0000002a/uni0000000c/uni0000002f/uni0000002f/uni00000044/uni00000030/uni00000024/uni00000003/uni0000000b/uni00000026/uni0000004c/uni00000055/uni00000046/uni00000058/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000035/uni00000024/uni0000002a/uni0000000c\n/uni0000000b/uni0000002c/uni0000002c/uni0000000c/uni00000033/uni00000048/uni00000055/uni00000010/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047/uni00000003/uni00000033/uni00000055/uni00000048/uni00000047/uni0000004c/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000035/uni00000048/uni00000056/uni00000058/uni0000004f/uni00000057/uni00000056\n(b) I. Average accuracy of CircuGraphRAG vs. Naive RAG over 5 rounds. II. Per-round\ncorrectness indicators for each model.\nFig. 3: Multi-round consistency and accuracy evaluation of CircuGraphRAG.\nBERTScores), such structural fluctuations can still lead to erroneous retrieval paths,\nultimately compromising the accuracy of the final answers.\nIn contrast, non-structured RAG methods such as Naive RAG and Standalone\nLLM demonstrate greater tolerance to reasoning variance, as they are not bound by\nrigid structural dependencies. This highlights a key trade-off: while structured QA\nframeworks enhance interpretability and control, they also amplify the adverse impact\nof LLM reasoning instability.\n10\n--- Page 11 ---\n2.6 Error Analysis and Qualitative Observations\nWhile CircuGraphRAG substantially reduces hallucinations and numeric errors, two\nprimary limitations remain:\n•Knowledge Gaps: Some specialized or newly introduced waste streams may be\nmissing in the knowledge graph. In such cases, CircuGraphRAG returns partial or\nincomplete results.\n•Vague User Prompts: Overly broad queries can mismatch the available tem-\nplates, producing off-target or partial retrieval. By contrast, standalone LLMs and\nnaive RAG often produce confident but incorrect code assignments or invented\nnumerical values.\nThese limitations underscore the importance of regularly updating the ontology and\nrefining domain-specific query templates to ensure coverage of emerging regulations\nand precise user intent.\n2.7 Summary of Findings\nOur experiments demonstrate that aligning an LLM with a structured knowledge\ngraph offers significant accuracy and efficiency gains for waste-to-resource manage-\nment. CircuGraphRAG consistently delivers higher ROUGE-L scores in single and\nmultihop tasks, reduces hallucinations and numeric inaccuracies, and in many queries\nlowerstheoveralltokenfootprintby15–16%comparedtonaiveretrievalenhancement.\nIts strong synergistic detection performance and precise code alignments highlight\nthe potential of the system to navigate complex industrial ecology regulations and\naccelerate the real-world adoption of circular economy practices.\n3 Discussion\nOur findings illustrate that linking an LLM to a structured knowledge graph\nsignificantly improves accuracy, numeric consistency, and code alignment in waste-\nto-resource management. The examples presented in Appendix 6.7 and Appendix 6.8\nhighlight how CircuGraphRAG outperforms both standalone LLMs and naive\nretrieval-augmented systems in representative queries, ranging from simple lookups\nfrom “identifying the correct category for polyurethane waste” to multi-hop reasoning\nsuch as “matching NACE code 3821 to CPA code 382150”.\n3.1 Key Advances\n3.1.1 Reduced Hallucinations in Single-Hop Queries\nWe selected the classification of “waste polyurethane” as a representative single-hop\nquery to evaluate the reasoning performance of CircuGraphRAG. While the ground\ntruth specifies “construction and demolition wastes,” Standalone LLMs frequently\nproduced overgeneralized or inconsistent categories, such as “municipal solid waste.”\nIn contrast, CircuGraphRAG accurately identified the correct classification through\n11\n--- Page 12 ---\nits graph-based retrieval mechanism, which links “waste polyurethane” to its cor-\nresponding relationship (e.g., hasCategory ) in the knowledge graph. In real-world\napplications, classification codes are often governed by regulatory standards for safe\ndisposal or recycling, making the reduction of such hallucinations essential. Detailed\nresults for this case are presented in Appendix 6.7.\n3.1.2 Enhanced Multi-Hop Reasoning for the Identification of\nSynergies\nMulti-hop queries often involve combining multiple relationships, such as mapping a\nprovider’s NACE code (e.g., 3821) to the CPA code corresponding to its generated\nresources (e.g., 382150). CircuGraphRAG achieves exact matches in such scenarios,\nwhere both Standalone LLMs and naive retrieval methods typically fail, underscor-\ning the system’s capacity to verify each step against structured ontology links. This\ncapability to handle multi-hop reasoning is essential for identifying opportunities for\nindustrial symbiosis, such as matching metal slags from steelmaking with cement\nproduction, thereby supporting circular-economy initiatives. Illustrative multi-hop\nexamples can be found in Appendix 6.8.\n3.1.3 Traceable Explanations and Regulatory Relevance\nBeyondnumericmetrics,CircuGraphRAGensuresthateachretrievalstepistranspar-\nent, as illustrated in the “Query Merging” blocks in Appendix 6.7 and Appendix 6.8.\nDomain experts and regulators can audit exactly how the system arrived at a particu-\nlar classification code or emission factor. Given the potential legal and environmental\nramifications of an incorrect or fabricated classification (e.g., labeling a hazardous\nwaste as non-hazardous), this built-in transparency meets a critical need in regulated\nindustries.\n3.2 Practical Implications\nThe improved accuracy and explainability of the system address key challenges in\nindustrial ecology.\n3.2.1 Faster and More Reliable Synergy Discovery\nAppendix 6.7 and Appendix 6.8 feature typical queries in which organizations seek to\nidentify compatible receivers for by-products. CircuGraphRAG reduces the manual\noverheadofcross-referencingwastecodesandemissionthresholds,thussurfacingreuse\npathways that a purely text-based approach might overlook.\n3.2.2 Minimizing Incorrect Classifications\nEven minor classification errors (e.g., mislabeling polyurethane as municipal waste)\ncan lead to non-compliance or suboptimal resource routing. The examples show that\nCircuGraphRAG’s graph-anchored retrieval routinely supplies the correct code align-\nment, enabling more rigorous decision-making for facility-level or regional-scale waste\nmanagement.\n12\n--- Page 13 ---\nBy systematically linking classification codes, GWP100, and facility attributes,\nCircuGraphRAG accelerates large-scale circular initiatives. Its subgraph retrieval\nalso provides an auditable trail that reassures regulators and other stakeholders,\nwho can confirm that each proposal meets legal or emissions requirements before\nimplementation.\n4 Methods\nWe propose CircuGraphRAG, a retrieval-augmented LLM framework that integrates\nmultiple industrial classification systems, environmental impact factors, and textual\nembeddings into a unified knowledge graph. By automating single-hop and multi-hop\nqueries, CircuGraphRAG identifies feasible “waste-to-resource” routes across indus-\ntries, highlighting those with low GWP100 emissions. Our approach tackles two core\nchallenges of sustainable industrial ecology:\n•the diversity and complexity of classification schemes for waste and industrial\nprocesses, and\n•the need to ground LLM responses in reliable, structured data to avoid hallucina-\ntions.\nThe following sections describe each methodological step, from dataset construction\nto the final synergy recommendations ranked by GWP100.\n4.1 Dataset Overview\nOur experiments make use of 3,896 entries from the “Waste Treatment and Recy-\ncling” sector of the Ecoinvent dataset [35], each mapped to International Standard\nIndustrial Classification of All Economic Activities (ISIC), Central Product Classifica-\ntion (CPC), Nomenclature statistique des activités économiques dans la Communauté\neuropéenne (NACE), Wirtschaftszweige (WZ), Classification of Products by Activity\n(CPA), European Waste Catalogue (EWC), Harmonized System (HS), and Singapore\nStandardIndustrialClassification(SSIC)codes,aswellastherespectiveimpactfactor\nGWP100. We merge domain-specific information such as facility locations, emissions\ndata, provider and receiver identities, and regulatory constraints into a unified knowl-\nedge graph. This preserves the original code mappings and introduces semantic links\nacross datasets. In practice, we harmonize codes from multiple classification systems\nto ensure cross-regional compatibility. The resulting knowledge graph includes the\nfollowing:\n•117,380 nodes , each representing a discrete resource entity (e.g., waste streams,\nby-products, industrial facilities, emission flows and regulatory guidelines).\n•753,145 edges , capturing relationships such as hasGwp100 (mapping a resource to\nitsGWP100 ),hasProvider ,hasReceiver (linking facilities that generate or accept\na given waste stream), and hasResource (connecting a by-product to relevant\nindustrial processes).\n•Anintegrated ontology that consolidates EWC, NACE, ISIC, and SSIC coding,\nnormalizing terminology that would otherwise vary across geographies or regulatory\nbodies.\n13\n--- Page 14 ---\n4.2 Dataset Construction\nWe draw on the Ecoinvent database [35], a comprehensive repository of industrial\nprocesses, resource flows, and emissions data as shown in Figure 4. Each record is\nenriched with standard classification codes, such as ISIC, NACE, SSIC, WZ, EWC,\nHS, and CPA, thus enabling both industry-oriented andwaste-oriented analyses:\n•Industry-orientedqueries: Identifysynergiesbetweenindustriesbasedonshared\nor compatible classification codes, as shown in Figure 4a.\n•Waste-oriented queries: Pinpoint potential receivers for a given waste stream\naligned with regulatory codes and environmental metrics, as shown in Figure 4b.\nWhere direct crosswalks are incomplete, we apply sentence-embedding techniques\n(multi-qa-mpnet-base-cos-v1 ) to infer plausible mappings from textual descrip-\ntions. Newly inferred codes are flagged for domain experts to validate. This harmo-\nnized dataset provides a robust basis for constructing our knowledge graph, ensuring\nconsistent references for industrial activities and waste categories across multiple\nsectors and jurisdictions.\n4.3 Ground Truth Dataset Construction\nTo rigorously measure the accuracy of the response, we developed a set of canonical\nqueries and the corresponding reference ground truth . Table 2 illustrates the variety of\nsingle-hopandmulti-hopqueriesusedtoevaluatethesystems.Eachquery–answerpair\nunderwent a multi-hop curation process to ensure industrial relevance and technical\ncorrectness:\n1.Query Selection: We identified representative questions reflecting real-world\nneeds in waste-to-resource management, including code alignment (EWC, HS,\nNACE,CPA)andkeyattributes(GWP100).Thesequeriesspansingle-hoplookups\n(e.g., retrieving a code-specific entity) and multi-hop reasoning (e.g., applying\nregulatory constraints across multiple entities).\n2.Domain Annotation: We cross-referenced official coding guidelines and our\nexpanded knowledge graph to establish gold-standard answers. Verification was\ncentered on correct waste code matching, valid provider–receiver relationships, and\nconsistent metadata.\n3.Cross-Checking: Each annotated answer was tested against our knowledge graph\nto confirm that the declared relationships were unambiguously retrievable. Any\ninconsistenciesresultedinfurtherrefinementstotheknowledgegraphortheground\ntruth.\nSubsequently, we evaluated the performance of our proposed CircuGraphRAG\napproach on two primary tasks: answering single-hop andmulti-hop queries. These\ntasks range from straightforward fact retrieval, such as obtaining a GWP100 value,\nto multi-hop reasoning that involves identifying by-products and matching them with\nsuitable receivers under specific regulatory constraints. We compare CircuGraphRAG\nwith two baselines:\n14\n--- Page 15 ---\n1.Standalone LLM: An LLM in isolation (Llama, Qwen, DeepSeek) without\nexplicit retrieval.\n2.Naive RAG: A RAG approach that lacks fine-grained graph constraints.\nIndustry-Oriented Queries\nNACE: 0111-Growing of cereals (except rice), leguminous crops, and oil seeds\nProviders Receivers Resources\nCrop Residue Producers\nCrop Rotation Farmers\nPesticide and Fungi-\ncide Producers\nRenewable\nEnergy Producers\nWater Manage-\nment Providers\nCrop Monitoring\nTechnology ProvidersLivestock Feed Producers\nSoil Fertility\nInput Producers\nCrop Protection Services\nBiofuel Producers\nIrrigation Sys-\ntem Producers\nAgricultural Tech-\nnology ProvidersCrop residue (straw,\nstems, leaves)\nCrop rotation\nPesticides and fungicides\nVegetable oils\nIrrigation systems\nCrop monitor-\ning technology\n(a) Industry-Oriented Queries (NACE:\n0111).Waste-Oriented Queries\nMill Scale\nEWC Code\n100210Providers Receivers\nIron & Steel Production\nMetal Surface Treatment\nManufacture\nof Metal Parts\nManufacture of\nBasic Iron & Steel\nManufacture of\nTubes & Pipes\nManufacture of Fabri-\ncated Metal ProductsConstruction\nSteel Production\nSoil Remediation\nPigment Production\nFuel Source\nFertilizer\nNLP NLP\n(b) Waste-Oriented Queries (EWC:\n100210).\niskg:Provider\niskg:Receiveriskg:Resourceiskg:Provider_SSICiskg:Receiver_SSICiskg:EW\nC_Codeiskg:Provider_W\nZiskg:Receiver_W\nZiskg:HS_Codeiskg:Provider_ISIC\n Import\n Explore\n SPARQL\n Monitor\n Setup\n HelpGraphs overview\nClass hierarchy\nClass relationships\nVisual graph\nSimilarity\n\n\n\n\n(c) Class Relationship.\nVisual gr aph \nhasGwp100hasReceiverhasResource\ntypehasCPACodehasEW\nCCodehasHSCode\ntype\nhasISICCodehasNACECodehasSSICCode hasWZCode\ntype\ntype4e9357cd-66da-439b-\n9927-4bf3ff c05297\n4e9357cd-66da-439b-\n9927-4bf3ff c05297_E…4e9357cd-66da-439b-\n9927-4bf3ff c05297_R…4e9357cd-66da-439b-\n9927-4bf3ff c05297_R…\nActivity382150101112848050\nResour ce\n38213821382003821\nReceiv er\nEmission      \nmouse and keyboard actions\n Import\n Explore\n SPARQL\n Monitor\n Setup\n HelpGraphs o verview\nClass hier archy\nClass r elationships\nVisual gr aph\nSimilarity\n\n\n\n WASTE  en (d) Visual Graph of Waste:\n4e9357cd-66da-439b-9927-4bf3ffc05297.\nFig. 4: An overview of the structure of our knowledge graph database.\n4.4 Knowledge Graph Construction\n1.Providers: Entitiesorprocessesthatgeneratesecondarymaterialsorby-products.\n2.Receivers: Facilities that reuse or recycle these materials.\n3.Resources: The actual material flows, annotated with attributes such as GWP100\nor hazardous status.\n15\n--- Page 16 ---\nProperties (e.g., iskg:hasEWCCode ,iskg:hasGwp100 ) link these classes as shown\nin Figure 4c, enabling SPARQL queries for fine-grained investigations of waste-\nto-resource pathways. Using canonical URIs for classification codes, we maintain\nsemantic clarity even when bridging multiple standards (ISIC, NACE, EWC, etc.) as\nshown in Figure 4d.\n4.5 The CircuGraphRAG Framework\nCircuGraphRAG unifies knowledge graph queries with large language models in a\nretrieval-augmented generation pipeline (see Figure 5). Its main components include :\n4.5.1 Text-Based Query\nUsers submit queries in free text form, often specifying a particular industrial code or\nwaste type (e.g. “Find the provider with NACE code 3821 producing waste cement\").\nAn LLM then parses this prompt to extract key concepts (e.g., “NACE 3821,” “waste\ncement”).\n4.5.2 Entity Classification & Vector Indexing\nEach user query is parsed to determine whether it targets a provider or a\nreceiver. Potential entities are encoded into 384-dimensional embeddings using\nall-MiniLM-L6-v2 and stored in two Facebook AI Similarity Search (FAISS) indexes\n(one for providers, one for receivers). For each query embedding q∈Rd, we retrieve\nthe top-kmost similar entity vectors {e1,...,ek}by maximizing the inner product\nscore (q,ei) =⟨q,ei⟩=d/summationdisplay\nj=1qj·ei,j.\nThis is implemented efficiently using faiss.IndexFlatIP , which ranks all entity vec-\ntors in descending order of similarity. Top- kcandidates are retrieved for downstream\nreasoning and reranking.\n4.5.3 Knowledge Graph-based Retrieval and Reasoning\nBased on Algorithm 1, the knowledge graph-based retrieval process uses an LLM-\ndriven template matcher to interpret user queries and produce appropriate SPARQL\nstatements. We maintain a TemplateLibrary of 18 distinct SPARQL templates, each\ndesigned to address common query intentions (for example, “Find all receivers for a\nspecific waste stream,” “Locate facilities by classification code,” etc.). In Step 1, the\nLLM identifies relevant entities (for example, a facility code or the name of a resource)\nand selects all templates that match the semantic intent of the user’s question. These\nmatching templates, often more than one, have placeholders (such as ?providerCode\nor?resourceName ) that are filled with information extracted from the query.\nIn Step 2, if multiple templates are selected, the LLM determines how to merge\nthem according to the query requirements. Depending on whether the user needs\n16\n--- Page 17 ---\nLLM based  \nEntity  \nExtraction\n“Find out the provider that is \ncoded with NACE code 3821 \nand produces waste cement.”Text-based Query \nPrompt: Knowledge Graph -\nbased Retrieval \nand Reasoning\nContext  GenerationAnswer:\n“Municipal incineration \nof waste polyethylene ”provider  list\n receiver  list\nFormal \nQuery\nFormal Query\nKnowledge  Graph  Database\nSPARQL Query Construction via \nTemplate Matching & Query MergingRanking by GWP100Knowledge Graph -based Retrieval and Reasoning12\n3 45 6\n7\n7.1 7.2 7.3 7.4\nSPARQL Query Template Library\n…\nLLMs\nLLMs\n8\nLLM  R easoning\n7.5\nQuery Merging\nLLM Assisted\n1. Input Prompt\n2. Retrieve Candidates\n3. Generate Context\n4. Feed Context5. Extract Entities\n6. Build Query\n7. Query KG / KG Reasoning\n8. Generate Answer\nKnowledge \nGraph\nMatch Template \nInput PromptQuery Graph Output Result \n& RankFig. 5: The CircuGraphRAG Pipeline.\nintersecting results, chained filtering, or broader coverage, the templates are com-\nbined using operations, including intersection, chaining, or union. This automated\nmerging ensures that all relevant aspects of the user’s request are handled in a single\nFinalQuery.\nSubsequently, in Step 3, we execute the FinalQuery against the knowledge graph\nand retrieve a structured result set that contains facts such as the matching of facil-\nity names, classification codes, and values GWP100. We then rank the results by\nascending GWP100, ensuring that the most environmentally favorable reuse pathways\nappear at the top. Typically, we return the top-5 results by default, but the user can\nspecify any subset size or additional filters as needed.\n4.5.4 LLM Response Composition\nFinally, a concise LLM generated response is displayed to the user. Because LLM\noutput is tightly grounded in knowledge graph data (rather than raw text frag-\nments), hallucination is greatly reduced. Each recommendation can be traced back\nto its matching entities, classification codes, and GWP100 values on the RDF graph,\npromoting transparency and reproducibility.\nIf the knowledge graph contains no relevant entries or mappings for the user’s\nquery, the system returns a brief message indicating that no matches were found in the\ndatabase. However, the pipeline then relies on the broader knowledge of the LLM to\nprovide any contextual information available, acknowledging that these details are not\ndrawn from the verified graph. This fallback approach ensures that the user receives\nat least a partial or approximate answer, while clearly distinguishing graph-based\nfacts from the LLM’s more general training data. Users can refine the query or add\n17\n--- Page 18 ---\nAlgorithm 1 Knowledge Graph-based Retrieval and Reasoning Algorithm\nRequire: A natural language question Q\nEnsure: A concise answer to Q\n1:Step 1: Template Matching (LLM-Reasoning)\n2:Use an LLM to parse Qand identify relevant entities (e.g., codes, resource or\nprovider names), along with the intended search objective.\n3:MatchedTemplates ←{}\n4:for all SPARQL template TinTemplateLibrary do\n5:ifLLM semantic matching confirmsTfitsQ’s intentthen\n6:MatchedTemplates ←MatchedTemplates ∪ {(templateID =\nT,inputFields from Q,expectedOutput )}\n7:end if\n8:end for\n9:\n10:Step 2: Query Merging (LLM-Reasoning)\n11:If multiple templates are selected, use an LLM to determine the optimal merging\nmethods (e.g., intersection, chaining, union) based on Q’s requirements.\n12:Combine all templates in MatchedTemplates into a single SPARQL query\nFinalQuery (e.g.,A∩B,A→B, orA∪B).\n13:\n14:Step 3: Execute and Retrieve Answer\n15:ExecuteFinalQuery against the knowledge graph to obtain the result set R.\n16:Parse Rto extract the entities or values requested by Q.\n17:returna concise answer derived from R.\nadditional details to improve the precision of future lookups and guide the continuous\nexpansion of the knowledge graph coverage.\n4.6 Experimental Setup\n4.6.1 Hardware and Environment\nAllexperimentsareconductedonaLinuxserverequippedwithanNVIDIA4090GPU,\ndual Intel Xeon processors, and 256GB of RAM. We host the knowledge graph using\nGraphDB, and handle SPARQL queries through SPARQLWrapper . Vector embeddings\nare managed by FAISS, while LLM inference is provided via the Groq API. To enable\nflexible deployments across different environments, we use Python’s dotenvto store\nendpoint URLs and credentials.\n4.6.2 Models Evaluated\nWe benchmark the following models:\n•Llama3 (70B) [36]: A 70B-parameter transformer model with a 4,096-token\ncontext window.\n•Qwen-qwq (32B) [37]: A 32B-parameter variant tailored for domain-oriented\ntasks.\n18\n--- Page 19 ---\n•DeepSeek-R1-Distill-Llama(70B) [38]:A70B-parameterLlamaderivativefine-\ntuned on specialized corpora.\nAll three models share identical inference hyperparameters ( temperature = 0.7,\ntop-p= 0.9, max_tokens = 4096) unless otherwise specified.\n4.6.3 Baselines and Proposed Method\nWe compare our proposed CircuGraphRAG system to two baselines:\n1.Standalone LLM : The user query is directly passed to the model without any\nexternal retrieval step.\n2.Naive RAG : Unstructured text segments are retrieved, rather than relying on\nSPARQL queries and a structured knowledge graph.\nIn contrast, CircuGraphRAG combines structured SPARQL-based retrieval with\na knowledge graph to improve both factual precision and sustainability-focused\nrelevance.\n4.7 Evaluation Metrics\n4.7.1 Query Types\n1. Single-Hop Queries\nExamines whether the system can accurately retrieve a single fact from the graph.\n2. Multi-Hop Queries\nDetermines the capacity of the system to chain multiple codes, constraints, and\nindustrial relationships for valid reuse pathways.\n4.7.2 Accuracy\nWe report two types of accuracy to evaluate the consistency of multi-round outputs\nand the correctness of responses under different template matching settings.\n1. Round-level Precision\nMeasures the average accuracy of the model output over a sequence of evaluation\nrounds (Figure 3b). It is defined as\nAccuracyround =1\nTT/summationdisplay\nt=1⊮[youtput\nt =ytrue\nt], (1)\nwhereTis the total number of rounds.\n2. Template Matching Accuracy\nAssesses whether the system generates correct outputs under different template\nmatching settings (Table 1).\n19\n--- Page 20 ---\n4.7.3 ROUGE-L Precision, Recall, and F1\nWe use ROUGE-L, a recall-oriented metric based on the Longest Common Subse-\nquence (LCS), to evaluate the lexical overlap between the generated and reference\nanswers.\n1. ROUGE-L Precision\nMeasures how much of the generated answer matches the reference, relative to the\ngenerated length:\nPrecision ROUGE-L =LCS (C,R)\n|C|. (2)\n2. ROUGE-L Recall\nMeasures how much of the reference answer is captured in the generated answer:\nRecallROUGE-L =LCS (C,R)\n|R|. (3)\n3. ROUGE-L F1 Score\nIs the harmonic mean of ROUGE-L precision and recall:\nF1ROUGE-L =(1 +β2)·Precision ROUGE-L·RecallROUGE-L\nPrecision ROUGE-L +β2·RecallROUGE-L. (4)\nwhereβ= 1by default. Here, LCS (C,R)denotes the length of the longest common\nsubsequence between the candidate answer Cand the reference answer R.\n4.7.4 BERTScore\nBERTScore evaluates the semantic similarity between a generated answer C=\n{c1,...,c m}and a reference answer R={r1,...,r n}by computing pairwise cosine\nsimilarities between their contextual embeddings. The final score is\nBERTScore (C,R) =1\n2/parenleftigg\n1\n|C|/summationdisplay\nci∈Cmax\nrj∈Rcos(⃗ ci,⃗ rj) +1\n|R|/summationdisplay\nrj∈Rmax\nci∈Ccos(⃗ rj,⃗ ci)/parenrightigg\n,(5)\nwhere cos(⃗ ci,⃗ rj)denotes the cosine similarity between the contextual embeddings of\nthe tokensciandrj.\n4.7.5 Exact Match Rate\nEM measures the strictest form of matching, evaluating whether the predicted answer\nexactly matches the reference answer after normalization (lowercasing, removing\n20\n--- Page 21 ---\narticles and punctuation, etc.).\nEM=1\nNN/summationdisplay\ni=1⊮[ˆyi=yi], (6)\nwhere ˆyiis the predicted answer, yiis the reference answer, ⊮[·]is the indicator\nfunction and Nis the total number of evaluation instances.\nBy presenting the query process in a knowledge graph and ranking synergies by\nGWP100, CircuGraphRAG improves both the factual precision and environmen-\ntal relevance of “waste-to-resource” recommendations, thus advancing data-driven\nsustainability in industrial ecosystems.\n5 Conclusion\nWe introduced CircuGraphRAG, a knowledge graph based RAG framework that\nunites knowledge graph reasoning with LLMs to address waste-to-resource challenges\nin the circular economy. By mapping diverse industrial codes (EWC, NACE, ISIC,\nSSIC) and embedding regulatory metadata into a unified graph, CircuGraphRAG\nconsistently surpassed baseline methods on single- and multi-hop queries, reducing\nhallucinations and boosting synergy discovery among potential waste producers and\nreusers.\nOur experiments showed clear gains in factual accuracy, improved multi-hop rea-\nsoning, and lowered token usage when retrieving only relevant subgraphs. However,\nthe effectiveness of CircuGraphRAG relies on continuously updated ontologies and\naccess to real-time data, both of which remain open challenges. Future work will\nexplore expanding domain coverage, incorporating dynamic sensor data, and collabo-\nrating with policymakers to encourage standardized data reporting. By systematically\nconnecting industrial by-products to potential receivers, CircuGraphRAG marks a\npromising step toward more sustainable, circular production systems.\nDeclarations\n•Conflict of interest/Competing interests: The authors declare that they have\nno conflict of interest.\n•Ethics approval and consent to participate: Not applicable.\n•Consent for publication: Not applicable.\n•Data availability: Part of the data used in this study is obtained from the Ecoin-\nvent dataset [35]. In compliance with data licensing terms, no actual numerical\nvalues from Ecoinvent are disclosed in this paper. The remaining datasets will be\npublicly released upon publication.\n•Materials availability: Not applicable.\n•Code availability: The relevant code for this study will be made publicly available\nafter publication\n21\n--- Page 22 ---\nReferences\n[1] Chertow, M.R.: Industrial symbiosis: literature and taxonomy. Annual review of\nenergy and the environment 25(1), 313–337 (2000)\n[2] Lombardi, D.R., Laybourn, P.: Redefining industrial symbiosis: Crossing\nacademic–practitioner boundaries. Journal of industrial ecology 16(1), 28–37\n(2012)\n[3] Püchel, L., Wang, C., Buhmann, K., Brandt, T., Schweinitz, F., Edinger-Schons,\nL.M., Brocke, J., Legner, C., Teracino, E., Mardahl, T.D.: On the pivotal\nrole of data in sustainability transformations. Business & Information Systems\nEngineering 66(6), 831–848 (2024) https://doi.org/10.1007/s12599-024-00904-4\n[4] Solaimani, S.: From compliance to capability: On the role of data and technology\nin environment, social, and governance. Sustainability 16(14) (2024) https://doi.\norg/10.3390/su16146061\n[5] Nookala, G., Gade, K.R., Dulam, N., Thumburu, S.K.R., et al.: Governance for\ndata ecosystems: Managing compliance, privacy, and interoperability (2024)\n[6] Kullmann, F., Markewitz, P., Stolten, D., Robinius, M.: Combining the worlds of\nenergy systems and material flow analysis: a review. Energy, Sustainability and\nSociety11(1), 13 (2021) https://doi.org/10.1186/s13705-021-00289-2\n[7] Moriguchi, Y., Hashimoto, S.: Material Flow Analysis and Waste Management,\npp. 247–262 (2016). https://doi.org/10.1007/978-3-319-20571-7_12\n[8] Moraga, G., Huysveld, S., Mathieux, F., Blengini, G.A., Alaerts, L., Van Acker,\nK., de Meester, S., Dewulf, J.: Circular economy indicators: What do they\nmeasure? Resources, Conservation and Recycling 146, 452–461 (2019) https:\n//doi.org/10.1016/j.resconrec.2019.03.045\n[9] Roy, T., Garza-Reyes, J.A., Kumar, V., Kumar, A., Agrawal, R.: Redesign-\ning traditional linear supply chains into circular supply chains–a study into\nits challenges. Sustainable Production and Consumption 31, 113–126 (2022)\nhttps://doi.org/10.1016/j.spc.2022.02.004\n[10] Tsang, A., Frost, T., Cao, H.: Environmental, social, and governance (esg)\ndisclosure: A literature review. The British Accounting Review 55(1), 101149\n(2023)\n[11] Hedberg, C.-J., Von Malmborg, F.: The global reporting initiative and corporate\nsustainabilityreportinginswedishcompanies.Corporatesocialresponsibilityand\nenvironmental management 10(3), 153–164 (2003)\n[12] Hales, J.: Sustainability accounting standards board (sasb). In: World Scientific\nEncyclopedia of Climate Change: Case Studies of Climate Risk, Action, and\n22\n--- Page 23 ---\nOpportunity Volume 3, pp. 37–41. World Scientific, Singapore (2021)\n[13] Board, F.S.: Task force on climate-related financial disclosures. Final Report:\nRecommendations of the Task Force on Climate-Related Financial Disclosures\n(2017)\n[14] Fraccascia, L., Yazan, D.M.: The role of online information-sharing platforms on\nthe performance of industrial symbiosis networks. Resources, conservation and\nrecycling136, 473–485 (2018)\n[15] Fraccascia, L., Giannoccaro, I.: What, where, and how measuring industrial sym-\nbiosis: A reasoned taxonomy of relevant indicators. Resources, conservation and\nrecycling157, 104799 (2020)\n[16] Capelleveen,G.,Amrit,C.,Zijm,H.,Yazan,D.M.,Abdi,A.:Towardbuildingrec-\nommender systems for the circular economy: Exploring the perils of the european\nwaste catalogue. Journal of environmental management 277, 111430 (2021)\n[17] Vidali, A., Jean, N., Pera, G.L.: Unlocking nace classification embeddings with\nopenai for enhanced analysis and processing. arXiv preprint arXiv:2409.11524\n(2024)\n[18] Hogan, A., Blomqvist, E., Cochez, M., d’Amato, C., Melo, G.D., Gutierrez, C.,\nKirrane, S., Gayo, J.E.L., Navigli, R., Neumaier, S., et al.: Knowledge graphs.\nACM Computing Surveys (Csur) 54(4), 1–37 (2021)\n[19] Powers, S.: Practical RDF: Solving Problems with the Resource Description\nFramework. \" O’Reilly Media, Inc.\", Sebastopol, CA (2003)\n[20] Lassila, O.: Resource description framework (rdf) model and syntax (1997)\n[21] Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al.: Improving\nlanguage understanding by generative pre-training (2018)\n[22] Rillig, M.C., Ågerstrand, M., Bi, M., Gould, K.A., Sauerland, U.: Risks and\nbenefits of large language models for the environment. Environmental Science &\nTechnology 57(9), 3464–3466 (2023)\n[23] Zhu, J.-J., Jiang, J., Yang, M., Ren, Z.J.: Chatgpt and environmental research.\nEnvironmental Science & Technology 57(46), 17667–17670 (2023)\n[24] Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y.J., Madotto,\nA., Fung, P.: Survey of hallucination in natural language generation. ACM\ncomputing surveys 55(12), 1–38 (2023)\n[25] Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler,\nH., Lewis, M., Yih, W.-t., Rocktäschel, T., et al.: Retrieval-augmented generation\nfor knowledge-intensive nlp tasks. Advances in Neural Information Processing\n23\n--- Page 24 ---\nSystems33, 9459–9474 (2020)\n[26] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang,\nH.: Retrieval-augmented generation for large language models: A survey. arXiv\npreprint arXiv:2312.10997 (2023)\n[27] Hu, Y., Lei, Z., Zhang, Z., Pan, B., Ling, C., Zhao, L.: Grag: Graph retrieval-\naugmented generation. arXiv preprint arXiv:2405.16506 (2024)\n[28] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang,\nM., Wang, H.: Retrieval-Augmented Generation for Large Language Models: A\nSurvey (2024). https://arxiv.org/abs/2312.10997\n[29] Lewis,P.,Perez,E.,Piktus,A.,Petroni,F.,Karpukhin,V.,Goyal,N.,Küttler,H.,\nLewis,M.,Yih,W.-t.,Rocktäschel,T.,Riedel,S.,Kiela,D.:Retrieval-Augmented\nGeneration for Knowledge-Intensive NLP Tasks (2021). https://arxiv.org/abs/\n2005.11401\n[30] Kang, M., Kwak, J.M., Baek, J., Hwang, S.J.: Knowledge Graph-Augmented\nLanguage Models for Knowledge-Grounded Dialogue Generation (2023). https:\n//arxiv.org/abs/2305.18846\n[31] Godal, O., Fuglestvedt, J.: Testing 100-year global warming potentials: impacts\non compliance costs and abatement profile. Climatic Change 52(1), 93–127\n(2002)\n[32] United States Environmental Protection Agency: Understanding Global Warm-\ning Potentials | US EPA. Accessed: 2025-05-18 (2023). https://www.epa.gov/\nghgemissions/understanding-global-warming-potentials\n[33] Han, H., Wang, Y., Shomer, H., Guo, K., Ding, J., Lei, Y., Halappanavar, M.,\nRossi, R.A., Mukherjee, S., Tang, X., He, Q., Hua, Z., Long, B., Zhao, T., Shah,\nN., Javari, A., Xia, Y., Tang, J.: Retrieval-Augmented Generation with Graphs\n(GraphRAG) (2025). https://arxiv.org/abs/2501.00309\n[34] Peng, B., Zhu, Y., Liu, Y., Bo, X., Shi, H., Hong, C., Zhang, Y., Tang, S.: Graph\nRetrieval-Augmented Generation: A Survey (2024). https://arxiv.org/abs/2408.\n08921\n[35] Frischknecht, R., Rebitzer, G.: The ecoinvent database system: a comprehensive\nweb-based lca database. Journal of Cleaner Production 13(13), 1337–1343 (2005)\nhttps://doi.org/10.1016/j.jclepro.2005.05.002 . Life Cycle Assessment\n[36] Meta AI: Introducing Meta Llama 3: The most capable openly available LLM.\nhttps://ai.meta.com/blog/meta-llama-3/. Accessed: 2025-05-18 (2024)\n[37] Qwen Team: QwQ-32B: Embracing the Power of Reinforcement Learning. https:\n24\n--- Page 25 ---\n//qwenlm.github.io/blog/qwq-32b/. Accessed: 2025-05-18 (2024)\n[38] DeepSeek AI: DeepSeek-R1-Distill-Llama-70B. https://huggingface.co/\ndeepseek-ai/DeepSeek-R1-Distill-Llama-70B. Accessed: 2025-05-18 (2025)\n25\n--- Page 26 ---\n6 Appendix\n6.1 Query–Answer Pairs from the Ground Truth.\nTable 2: Query–Answer Pairs from the Ground Truth.\nCase Type Query Answer\n1 Single-Hop Q: Find out the resource that is coded with\nEWC code 080121 and HS code 810330.A: Waste paint\n2 Single-Hop Q: Find out the provider that is coded with\nNACE code 3821 and produces waste cement.A: Municipal incineration of\nwaste polyethylene\n3 Single-Hop Q: Find out the least value of GWP100 among\nthe receivers coded with NACE code 3822.A: 0.008826959\n4 Multi-Hop Q: The resources generated by the providers\nunder the NACE code 3821 are all categorized\nunder what CPA code and category?A: 382150; “Pellets of munici-\npal waste”\n5 Multi-Hop Q: Among the receivers of resources coded\nwith CPA code 382150, which can be matched\nagain with the receiver “market for waste\npolystyrene” as a provider?A: “treatment of waste\npolystyrene terephthalate,\nmunicipal incineration”\n6 Multi-Hop Q: Among the providers of resources coded\nwith EWC code 070213, which can also be a\nreceiver of the “aluminium scrap”?A: “treatment of wastewa-\nter from PV cell production,\nwastewater treatment”\n26\n--- Page 27 ---\n6.2 Single-hop QA performance for different LLMs and\nretrieval methods across 3 test cases.\nTable 3: Single-hop QA performance for different LLMs\nand retrieval methods across 3 test cases.\nCase Method LLMROUGE-L\nPrecision Recall F1\n1Standalone LLMllama 0.0161 0.5 0.0313\nqwen 0.0045 0.5 0.0090\ndeepseek 0.0086 0.5 0.0169\nNaive RAGllama 0 0 0\nqwen 0 0 0\ndeepseek 0 0 0\nCircuGraphRAGllama 0 0 0\nqwen 1 1 1\ndeepseek 1 1 1\n2Standalone LLMllama 0.0165 0.4 0.0317\nqwen 0.0064 0.4 0.0127\ndeepseek 0.0213 0.4 0.0404\nNaive RAGllama 0.0099 0.4 0.0192\nqwen 0.0150 0.4 0.0290\ndeepseek 0.0230 0.4 0.0435\nCircuGraphRAGllama 0.4286 0.6 0.5\nqwen 0.4286 0.6 0.5\ndeepseek 0.0909 0.2 0.125\n3Standalone LLMllama 0 0 0\nqwen 0.0025 0.5 0.0050\ndeepseek 0 0 0\nNaive RAG llama 0 0 0\nqwen 0 0 0\ndeepseek 0 0 0\nCircuGraphRAG llama 1 1 1\nqwen 1 1 1\ndeepseek 0 0 0\n27\n--- Page 28 ---\n6.3 Multi-hop QA performance for different LLMs and\nretrieval methods across 3 test cases.\nTable 4: Multi-hop QA performance for different LLMs and\nretrieval methods across 3 test cases.\nCase Method LLMROUGE-L\nPrecision Recall F1\n4Standalone LLMllama 0 0 0\nqwen 0 0 0\ndeepseek 0 0 0\nNaive RAGllama 0 0 0\nqwen 0 0 0\ndeepseek 0 0 0\nCircuGraphRAGllama 0 0 0\nqwen 1 1 1\ndeepseek 0 0 0\n5Standalone LLMllama 0.0273 0.4286 0.0513\nqwen 0.0385 0.2857 0.0678\ndeepseek 0.0303 0.4286 0.0566\nNaive RAGllama 0.0160 0.2857 0.0303\nqwen 0.0207 0.4286 0.0395\ndeepseek 0.0417 0.4286 0.0759\nCircuGraphRAGllama 1 1 1\nqwen 1 1 1\ndeepseek 0.3158 0.8517 0.4615\n6Standalone LLMllama 0.0165 0.2222 0.0308\nqwen 0.0069 0.3333 0.0135\ndeepseek 0.0179 0.2222 0.0331\nNaive RAGllama 0.0095 0.1111 0.0175\nqwen 0.0085 0.1111 0.0157\ndeepseek 0.0357 0.2222 0.0615\nCircuGraphRAGllama 0 0 0\nqwen 1 1 1\ndeepseek 0 0 0\n28\n--- Page 29 ---\n6.4 Single-Hop Timing and Token Usage.\nTable 5: Single-Hop Timing and Token Usage.\nCase Method LLM Input Tokens Output Tokens Inference Time (s)\n1Standalone LLM llama 30 106 0.39\nStandalone LLM qwen 38 10572 25.82\nStandalone LLM deepseek 23 707 3.37\nNaive RAG llama 396 178 0.66\nNaive RAG qwen 555 1826 4.23\nNaive RAG deepseek 389 699 3.35\nCircuGraphRAG llama 1140 66 0.27\nCircuGraphRAG qwen 1220 789 1.97\nCircuGraphRAG deepseek 1100 1570 5.80\n2Standalone LLM llama 28 159 0.46\nStandalone LLM qwen 30 3569 8.77\nStandalone LLM deepseek 21 995 5.34\nNaive RAG llama 314 258 0.89\nNaive RAG qwen 420 646 1.48\nNaive RAG deepseek 307 681 3.03\nCircuGraphRAG llama 1508 71 0.30\nCircuGraphRAG qwen 1206 1787 4.45\nCircuGraphRAG deepseek 1192 2450 9.01\n3Standalone LLM llama 30 304 0.98\nStandalone LLM qwen 34 4075 10.01\nStandalone LLM deepseek 23 1187 4.75\nNaive RAG llama 319 94 0.31\nNaive RAG qwen 426 1434 4.27\nNaive RAG deepseek 312 1515 5.54\nCircuGraphRAG llama 1297 82 0.36\nCircuGraphRAG qwen 1408 1355 3.44\nCircuGraphRAG deepseek 1377 1692 6.24\nCircuGraphRAG input, output, and inference time are aggregated across three sequential stages:\nTemplate Matching (TM), Query Merging (QM), and Querying with Retrieved Context (QRC). For\nexample, for Case 1–llama: 314 (TM) + 410 (QM) + 416 (QRC) = 1140 input tokens.\n29\n--- Page 30 ---\n6.5 Multi-Hop Timing and Token Usage.\nTable 6: Multi-Hop Timing and Token Usage.\nCase Method LLM Input Tokens Output Tokens Inference Time (s)\n4Standalone LLM llama 32 135 0.45\nStandalone LLM qwen 34 3764 8.58\nStandalone LLM deepseek 25 968 4.35\nNaive RAG llama 398 213 0.92\nNaive RAG qwen 547 1149 2.89\nNaive RAG deepseek 391 1251 5.19\nCircuGraphRAG llama 1240 76 0.36\nCircuGraphRAG qwen 1322 4719 11.50\nCircuGraphRAG deepseek 1153 2434 8.92\n5Standalone LLM llama 44 156 0.63\nStandalone LLM qwen 48 8677 21.35\nStandalone LLM deepseek 37 969 4.27\nNaive RAG llama 344 160 0.63\nNaive RAG qwen 449 1487 3.65\nNaive RAG deepseek 337 1043 4.43\nCircuGraphRAG llama 1356 79 0.29\nCircuGraphRAG qwen 1506 1227 3.11\nCircuGraphRAG deepseek 1409 1230 4.62\n6Standalone LLM llama 37 168 0.55\nStandalone LLM qwen 41 2172 5.30\nStandalone LLM deepseek 30 944 4.20\nNaive RAG llama 350 141 0.51\nNaive RAG qwen 441 1000 2.30\nNaive RAG deepseek 343 2230 8.13\nCircuGraphRAG llama 1365 90 0.35\nCircuGraphRAG qwen 1390 1373 3.47\nCircuGraphRAG deepseek 1321 1646 6.34\nCircuGraphRAG input, output, and inference time are aggregated across three sequential stages:\nTemplate Matching (TM), Query Merging (QM), and Querying with Retrieved Context (QRC). For\nexample, for Case 4–llama: 374 (TM) + 468 (QM) + 398 (QRC) = 1240 input tokens.\n30\n--- Page 31 ---\n6.6 Comparative Analysis of Token Usage and Inference Time\nAcross the Three Stages of CircuGraphRAG (Cases 1–6)\nTable 7: Comparative Analysis of Token Usage and Inference Time Across the\nThree Stages of CircuGraphRAG (Cases 1–6)\nCase LLM StageInput\nTokensOutput\nTokensInference\nTime (s)\n1llamaTemplate Matching 314 56 0.17\nQuery Merging 410 6 0.05\nQuerying with Context 416 4 0.05\nqwenTemplate Matching 334 481 1.13\nQuery Merging 432 165 0.46\nQuerying with Context 454 143 0.38\ndeepseekTemplate Matching 307 795 2.92\nQuery Merging 384 475 1.75\nQuerying with Context 409 300 1.13\n2llamaTemplate Matching 312 48 0.15\nQuery Merging 755 6 0.08\nQuerying with Context 441 17 0.07\nqwenTemplate Matching 326 1120 2.77\nQuery Merging 412 213 0.51\nQuerying with Context 468 454 1.17\ndeepseekTemplate Matching 305 1635 5.98\nQuery Merging 372 214 0.80\nQuerying with Context 515 601 2.23\n3llamaTemplate Matching 338 69 0.22\nQuery Merging 423 7 0.08\nQuerying with Context 536 6 0.06\nqwenTemplate Matching 360 597 1.51\nQuery Merging 442 516 1.33\nQuerying with Context 606 242 0.60\ndeepseekTemplate Matching 331 885 3.24\nQuery Merging 392 479 1.76\nQuerying with Context 654 328 1.24\n4llamaTemplate Matching 374 56 0.19\nQuery Merging 468 5 0.06\nQuerying with Context 398 15 0.11\nqwenTemplate Matching 397 3691 9.05\nQuery Merging 488 745 1.74\nQuerying with Context 437 283 0.71\ndeepseekTemplate Matching 355 1275 4.66\nQuery Merging 419 741 2.72\nContinued on next page\n31\n--- Page 32 ---\nTable 7 (continued)\nCase LLM StageInput\nTokensOutput\nTokensInference\nTime (s)\nQuerying with Context 379 418 1.54\n5llamaTemplate Matching 386 56 0.17\nQuery Merging 480 6 0.05\nQuerying with Context 490 17 0.07\nqwenTemplate Matching 411 437 1.02\nQuery Merging 500 360 0.97\nQuerying with Context 595 430 1.12\ndeepseekTemplate Matching 379 483 1.79\nQuery Merging 473 385 1.42\nQuerying with Context 557 362 1.41\n6llamaTemplate Matching 380 75 0.23\nQuery Merging 493 13 0.07\nQuerying with Context 492 2 0.05\nqwenTemplate Matching 405 764 1.92\nQuery Merging 476 232 0.56\nQuerying with Context 509 377 0.99\ndeepseekTemplate Matching 373 491 1.83\nQuery Merging 489 561 2.10\nQuerying with Context 459 594 2.41\n32\n--- Page 33 ---\n6.7 Response Comparison for General Knowledge Question.\nTable 8: Response Comparison for General Knowledge Question.\nQuestion: What category of solid waste does waste polyurethane belong to?\nGround Truth: Construction and demolition wastes\nMethod LLM Response\nStandalone\nLLMLlama Waste polyurethane (PU) is a type of synthetic polymer\nwaste, and it belongs to the category of non-hazardous\nsolid waste. Specifically, it falls under the category of\n“Municipal Solid Waste” (MSW) or “Residual\nWaste.” ✗\nIn the European Union, waste polyurethane is classi-\nfied under the European Waste Catalogue (EWC) code\n17 04 07*, “Polyurethane waste.” This code is part of\nthe “Construction and Demolition Waste” (C&D waste)\nsector.\nIn the United States, the Environmental Protection\nAgency (EPA) classifies waste polyurethane as a non-\nhazardous waste, and it is typically managed through\nmunicipal solid waste landfills or recycling facilities.\nIt’s worth noting that some polyurethane waste may be\nconsidered hazardous if it contains additives or contami-\nnants—suchasheavymetals,flameretardants,orvolatile\norganic compounds (VOCs)—that render it hazardous.\nIn such cases, the waste must be managed as hazardous\nwaste under the applicable regulations and protocols.\n(continued on next page)\n33\n--- Page 34 ---\nMethod LLM Response (continued)\nQwen <think> ...</think>\nWaste polyurethane is typically categorized within solid\nwaste management systems based on its source and\ncomposition. Here’s a structured breakdown:\n•Municipal Solid Waste (MSW): When\nderived from residential or commercial sources\n(e.g., discarded furniture, packaging, or consumer\ngoods), polyurethane is generally classified as\nmunicipal solid waste . It falls under the \"plas-\ntics\" or \"textiles/furniture\" subcategory in MSW\nsystems, depending on its form (e.g., foam, coat-\nings, or rigid parts).\n•Industrial Waste: If generated during manu-\nfacturing processes (e.g., production scraps or\noffcuts), it may be categorized as industrial\nwaste, subject to regulations governing industrial\nbyproducts.\n•Construction & Demolition (C&D) Debris:\nWhen part of construction materials like insula-\ntion, roofing, or building components, it is clas-\nsified asC&D debris , a distinct category from\nhousehold waste.\n•Hazardous Waste: If the polyurethane contains\nhazardous additives (e.g., certain flame retar-\ndants, isocyanates, or other chemicals that make\nit toxic, reactive, or flammable), it may qualify\nashazardous waste under regulations like the\nU.S. EPA’s RCRA or the EU’s Waste Framework\nDirective. This requires specialized handling.\n•Recyclable/Recoverable Waste: If being\ndiverted for recycling (e.g., into new materials or\nenergy recovery), it may be categorized separately\nasrecyclable or recoverable waste , depending\non local recycling infrastructure and policies.\nSummary:\nPrimary Category: Municipal solid waste (non-\nhazardous) ✗when from households or businesses.\nExceptions:Hazardous waste ✗if contaminated with\ntoxic additives; industrial or C&D debris depending on\norigin.\nThis classification ensures proper disposal, recycling, or\nregulation ....\n(continued on next page)\n34\n--- Page 35 ---\nMethod LLM Response (continued)\nDeepseek <think> ...</think>\nWaste polyurethane is typically categorized as either\nmunicipal solid waste orindustrial solid waste ,\ndepending on its source.\n•Municipal Solid Waste : This applies when\npolyurethane waste comes from consumer prod-\nucts, such as discarded furniture foam or house-\nhold items. These items are often sent to landfills\nas part of general municipal waste.\n•Industrial Solid Waste : This applies when the\nwaste is generated from manufacturing processes,\nsuch as production scraps or leftover materials\nfrom industrial applications.\nIn cases where polyurethane is contaminated with haz-\nardous substances, it may be classified as hazardous\nwaste ✗. However, polyurethane itself is generally non-\nhazardous. Disposal methods often involve landfilling,\nthough recycling is not always feasible due to the mate-\nrial’s properties.\nNaive RAG Llama Retrieved Triplets:\nTop results:\n1: 3228870b-72a1...-Resource, hasInformation,\n’waste polyurethane’ is a solid waste under the category\nof construction and demolition wastes..... (Distance:\n0.4850251078605652)\n(Note: All LLMs use the same retrieved context informa-\ntion.)\nBased on the retrieved contexts, the answer to the ques-\ntion is that waste polyurethane belongs to the\ncategory of construction and demolition wastes\n✓. It can also belong to the following waste categories:\nindustrial .\nQwen <think> Okay, let’s see. The user is asking which cate-\ngoryofsolidwastewastepolyurethanebelongsto....The\nanswer is that it’s under construction and demolition\nwastes, and can also be industrial. </think>\nThe waste polyurethane is categorized as a solid waste\nunder the category of construction and demoli-\ntion wastes ✓. Additionally, depending on its source,\nit may also fall under the industrial waste category .\nThis classification is based on its generation during pro-\nductionandconstructionactivitiesacrossvarioussectors,\nas stated consistently across all retrieved contexts.\n(continued on next page)\n35\n--- Page 36 ---\nMethod LLM Response (continued)\nDeepseek <think> Okay, I need to figure out what category of\nsolid waste waste polyurethane belongs to. ...It’s non-\nhazardous and has specific disposal methods like landfills\nand incineration. The contexts are consistent across all\nfive, so I can confidently state the category based on this\ninformation. </think>\nWaste polyurethane belongs to the category of con-\nstruction and demolition wastes ✓and can also\nbe classified under industrial waste categories. It is\nconsidered non-hazardous and is typically disposed of\nthrough methods such as landfill deposition or municipal\nincineration.\nCircuGraphRAG Llama 1. Template Matching:\n[{\"query\": 17, \"input\": \"waste polyurethane\", \"output\":\n\"category of solid waste\"}, {\"query\": 6, \"input\": \"waste\npolyurethane\", \"output\": \"resource code\"}]\n2. Query Merging:\n17\n3. Querying with Retrieved Context:\nconstruction and demolition wastes, industrial ✓\nQwen 1. Template Matching:\n<think> ...</think>\n- Possible Solutions: [{\"query\": 17, \"input\": \"waste\npolyurethane\", \"output\": \"category information\"}]\n2. Query Merging:\n<think> ...</think>\n17\n3. Querying with Retrieved Context:\n<think> ...</think>\nconstruction and demolition wastes ✓\n(continued on next page)\n36\n--- Page 37 ---\nMethod LLM Response (continued)\nDeepseek 1. Template Matching:\n<think> ...</think>\n[{\"query\": 17, \"input\": \"waste polyurethane\", \"output\":\n\"category of solid waste\"}]\n2. Query Merging:\n<think> ...</think>\nSince the question directly asks for the category of solid\nwaste for \"waste polyurethane,\" and query 17 is specif-\nically designed to retrieve information based on the\nentity’s name, the solution is to execute query 17 with\nthe input \"waste polyurethane.\"\nMerging method : 17(\"waste polyurethane\")\n3. Querying with Retrieved Context:\n<think> ...</think>\nThe category of solid waste that waste polyurethane\nbelongs to is construction and demolition wastes ✓,\nand it can also be classified as industrial waste.\nNote: For brevity, the <think> sections are partially omitted in this table.\n37\n--- Page 38 ---\n6.8 Response Comparison for Multi-hop Question.\nTable 9: Response Comparison for Multi-hop Question.\nQuestion: The resources generated by the providers under the NACE code 3821 are\nall categorized under what CPA code?\nGround Truth: 382150\nMethod LLM Response\nStandalone LLM Llama AccordingtotheEuropeanCommission’swebsite,\ntheNACEcode3821correspondsto “Rentingof\nair transport equipment” and is categorized\nunder CPA (Common Procurement Vocabulary)\ncode63500000 ✗, which covers “Air transport\nservices” .\nBreakdown:\n•NACE code 3821: Renting of air trans-\nport equipment\n•CPA code 63500000: Air transport ser-\nvices\nQwen <think> Okay, let me try to figure out\nthe answer to this question. ...Therefore, the\nresources (products) from NACE 3821 would be\nunder CPA code 3111. </think>\nThe resources generated by providers under the\nNACE code 38.21(\"Manufacture of semiconduc-\ntors and discrete components\") are categorized\nunderCPA code 3111 in the Classification of\nProducts by Activity (CPA).\nBreakdown:\n-NACE 38.21 →Production of semiconductors\nand discrete electronic components.\n-CPA 31 →\"Manufacture of computer, elec-\ntronic and optical products\".\n-CPA 3111 →\"Semiconductors and discrete\ncomponents\".\nThus, the CPA code for these resources is\n3111✗.Thisensuresconsistencybetweentheeco-\nnomic activity and its product classification.\nNote:Always verify with the latest CPA version,\nas codes may be updated.\n(continued on next page)\n38\n--- Page 39 ---\nMethod LLM Response (continued)\nDeepseek <think> Okay, so I need to figure out the CPA\ncode that categorizes the resources generated by\nproviders under the NACE code 3821. I’m not\nentirely sure what NACE and CPA codes are, but\nI think they’re some kind of classification systems\nused in the EU. ...Yes, I think that’s correct. So,\nthe resources (services) from NACE 3821 are cat-\negorized under CPA code 37.10.00. </think>\nThe resources generated by providers under\nthe NACE code 3821, which pertains to waste\ncollection (including both hazardous and non-\nhazardous waste), are categorized under the CPA\ncode 37.10.00. This CPA code specifically covers\nwaste collection services.\nAnswer: CPA code 37.10.00 ✗\nNaive RAG Llama Retrieved Triplets:\n1: 37f20209-b2a3-4950-ac0d-88c830c73c\n2c, hasResource,\n37f20209-b2a3-4950-ac0d-88c830c73c2c\n_Resource (Distance: 1.03)\n...\n(Note: All LLMs use the same retrieved context\ninformation.)\nResponse:\nBased on the provided context, there is no direct\ninformation about NACE codes or CPA codes.\nThe context only mentions NLP derived EWC,\nTranslated CPA, and NLP derived HScode, but it\ndoes not provide any specific values or mappings\nbetween them. Therefore, I’ll have to rely on my\nown knowledge.\nNACE(NomenclatureofEconomicActivities)isa\nEuropean classification system for industries and\neconomic activities. CPA (Classification of Prod-\nucts by Activity) is a classification system for\nproducts. Unfortunately, without more spe-\ncific information, it’s not possible to deter-\nmine the exact CPA code corresponding to\nNACE code 3821 ✗. NACE code 3821 corre-\nsponds to \"Manufacture of bicycles and invalid\ncarriages\",buttheCPAcodesforproductsrelated\nto this industry can vary depending on the spe-\ncific product.\nIf you have more information or context about the\nresources generated by the providers, I might be\nable to help you with the CPA code categoriza-\ntion.\n(continued on next page)\n39\n--- Page 40 ---\nMethod LLM Response (continued)\nQwen <think> Okay,let’ssee.Theuserisaskingabout\nthe CPA code that categorizes resources from\nproviders with the NACE code 3821. ...Since the\nuser is expecting an answer, maybe the intended\nanswer is CPA 24. I’ll go with that, but note\nthat the given contexts don’t explicitly state it.\n</think>\nThe resources retrieved do not explicitly men-\ntion NACE code 3821 or any CPA code in their\ntriplet structures. However, based on standard\nclassification mappings between NACE and CPA\ncodes,NACE code 38.21 (\"Manufacture of\noffice, accounting, and computing machin-\nery\")typically corresponds to CPA code 24.11\n(\"Computing machinery and software\").\nIf forced to infer from the closest context (the first\ntriplet, with the shortest distance of 1.0286), the\nanswer might align with common categorizations,\nbut this is speculative. The provided contexts lack\nexplicitlinksbetweenNACE3821andCPAcodes,\nso the answer is best approximated using external\nknowledge of standard classifications.\nAnswer: The resources under NACE code 3821\nare generally categorized under CPA code 24.11\n✗. However, this requires confirmation from the\nactual resource data linked in the graph database.\nDeepseek <think> Okay, I’m trying to figure out the\nanswer to the question: \"The resources generated\nby the providers under the NACE code 3821 are\nall categorized under what CPA code?\". Let me\nbreak this down step by step. First, I know that\nNACE codes are used for classifying businesses\nin the European Union. Specifically, NACE code\n3821 refers to \"Waste treatment and disposal\".\nSo, the question is asking about resources gener-\nated by providers in this waste treatment sector.\n...However, without specific CPA code numbers\nfrom the context, I can’t provide an exact code.\nThe context only mentions that CPA codes are\ntranslated from NLP outputs, but doesn’t specify\nwhich ones. Therefore, based on my own knowl-\nedge, I can infer that the CPA codes for resources\nunder NACE 3821 would be within the waste\ntreatment and disposal category, possibly starting\nwith 38. But I can’t provide the exact code with-\nout more specific information. </think>\nResponse:\nThe resources generated by providers under the\nNACE code 3821, which pertains to waste treat-\nment and disposal, are categorized under CPA\ncodes related to waste management. Specifically,\nthese resources fall under CPA code 38.00.00\n✗, which covers \"Waste treatment and disposal.\"\n(continued on next page)\n40\n--- Page 41 ---\nMethod LLM Response (continued)\nCircuGraphRAGLlama 1. Template Matching:\n[{\"query\": 10, \"input\": \"NACE code 3821\", \"out-\nput\": \"resource name\"}, {\"query\": 5, \"input\":\n\"resource name\", \"output\": \"CPA code\"}]\n2. Query Merging:\nMerging method: Query 10 ⇒Query 5\n3. Querying with Retrieved Context:\nThe SPARQL query returned no results.\nThe providers under NACE code 3821 are likely\nrelated to waste treatment, so the resources gen-\nerated might be categorized under CPA code 38\n(Waste collection, treatment and disposal\nactivities; materials recovery) ✗.\nQwen 1. Template Matching:\n<think> ...</think>\n•Query 1: Input = NACE 3821 →Output =\nProviders under that code\n•Query 7: Input = Provider names →Output\n= Resources generated by providers\n•Query 6: Input = Resource names →Output\n= CPA codes (resource codes)\n2. Query Merging:\n<think> ...</think>\nMerging Strategy: Chaining\nExecution Flow: Query 1 ⇒Query 7 ⇒Query\n6\n3. Querying with Retrieved Context:\n<think> ...</think>\nThe SPARQL query returned the code cpa:\n382150, hence the CPA code that categorizes the\nresources generated by providers under NACE\n3821 is382150 ✓.\n(continued on next page)\n41\n--- Page 42 ---\nMethod LLM Response (continued)\nDeepseek 1. Template Matching:\n<think> ...</think>\n- Possible Solutions: [{\"query\": 18, \"input\":\n\"NACE code 3821\", \"output\": \"provider informa-\ntion (including resources)\"}, {\"query\": 5, \"input\":\n\"resource code(s) from provider\", \"output\": \"CPA\ncode\"}]\n2. Query Merging:\n<think> ...</think>\nThe merging method is chaining because the\noutput of query 18 (resource codes) is used as the\ninput for query 5 to get the CPA codes.\nMerging method: Query 18 ⇒Query 5\n3. Querying with Retrieved Context:\n<think> ...</think>\nThe SPARQL query returned no results. Based on\ngeneral knowledge, resources under NACE code\n3821 (waste collection, treatment, and disposal\nactivities) are typically categorized under CPA\ncode 37.20 (Waste collection, treatment, and dis-\nposal activities).\nAnswer:CPA code 37.20 ✗.\nNote: For brevity, the <think> sections are partially omitted in this table.\n42\n--- Page 43 ---\n6.9 List of Abbreviations.\nTable 10 : List of Abbreviations.\nAbbreviation Full Name Explanation\nLLM Large Language Model AI model trained on large corpora\nfor text generation.\nLCS Longest Common Subsequence The longest ordered subsequence\nshared by two sequences, allowing\ngaps but preserving order.\nRAG Retrieval-Augmented\nGenerationCombines an LLM with external\ndata or knowledge bases to reduce\nhallucinations.\nCircuGraphRAG Circular Graph-based RAG Proposed system anchoring the\nLLM in a waste-to-resource knowl-\nedge graph.\nGraphRAG Graph-based RAG RAG that uses knowledge graphs\nfor multi-hop queries.\nESG Environmental, Social, and\nGovernanceCriteria for evaluating organiza-\ntions’ sustainability and societal\nimpact.\nEWC European Waste Catalogue EU classification system for listing\nand categorizing waste.\nNACE Nomenclature of Economic\nActivitiesEU classification of economic activ-\nities.\nCPA Classification of Products by\nActivityConnects products to the economic\nactivity that produces them.\nHS Harmonized System Globally standardized codes for\nclassifying traded goods.\nISIC International Standard Indus-\ntrial ClassificationUNclassificationofglobaleconomic\nactivities.\nWZ Wirtschaftszweige German classification of economic\nactivities.\nSSIC Singapore Standard Industrial\nClassificationSingapore’s national standard for\neconomic activities.\nTCFD Task Force on Climate-related\nFinancial DisclosuresFramework for climate-related\nfinancial transparency.\nGRI Global Reporting Initiative Guidelines for sustainability and\nsocial responsibility reporting.\nSASB Sustainability Accounting Stan-\ndards BoardIndustry-specific sustainability dis-\nclosure standards.\nRDF Resource Description Frame-\nworkW3C standard for implementing\nknowledge graphs.\n(continued on next page)\n43\n--- Page 44 ---\nAbbreviation Full Name Explanation\nGWP100 100-year Global Warming\nPotentialA gas’s heat-trapping impact over\n100 years vs. CO 2.\nPU Polyurethane Synthetic polymer used in foams\nand coatings.\nC&D Construction and Demolition Waste generated by\nconstruction/demolition activities.\nEPA Environmental Protection\nAgencyU.S. environmental regulatory\nauthority.\nVOC Volatile Organic Compound Quickly evaporating organic pollu-\ntants.\nRCRA Resource Conservation and\nRecovery ActU.S. law on solid and hazardous\nwaste disposal.\nSPARQL SPARQL Protocol and RDF\nQuery LanguageQuery language for RDF-based\nknowledge graphs.\nNLP Natural Language Processing AI for analyzing and generating\nhuman language.\nEcoinvent Ecoinvent Database Industrial life cycle database with\nresource and emissions data.\nFAISS Facebook AI Similarity Search Library for vector similarity search\nand clustering.\nRDFlib RDF Library Python library for RDF graph han-\ndling.\nSPARQLWrapper SPARQLWrapper Library Python tool for sending SPARQL\nqueries to endpoints.\nGroq (API) Groq API High-performance runtime for LLM\ninference.\nMPNet Masked and Permuted Pre-\ntrainingTransformer model for sentence\nembeddings.\n44",
  "text_length": 89517
}