{
  "id": "http://arxiv.org/abs/2506.00856v1",
  "title": "Can AI Master Econometrics? Evidence from Econometrics AI Agent on\n  Expert-Level Tasks",
  "summary": "Can AI effectively perform complex econometric analysis traditionally\nrequiring human expertise? This paper evaluates an agentic AI's capability to\nmaster econometrics, focusing on empirical analysis performance. We develop an\n``Econometrics AI Agent'' built on the open-source MetaGPT framework. This\nagent exhibits outstanding performance in: (1) planning econometric tasks\nstrategically, (2) generating and executing code, (3) employing error-based\nreflection for improved robustness, and (4) allowing iterative refinement\nthrough multi-round conversations. We construct two datasets from academic\ncoursework materials and published research papers to evaluate performance\nagainst real-world challenges. Comparative testing shows our domain-specialized\nagent significantly outperforms both benchmark large language models (LLMs) and\ngeneral-purpose AI agents. This work establishes a testbed for exploring AI's\nimpact on social science research and enables cost-effective integration of\ndomain expertise, making advanced econometric methods accessible to users with\nminimal coding expertise. Furthermore, our agent enhances research\nreproducibility and offers promising pedagogical applications for econometrics\nteaching.",
  "authors": [
    "Qiang Chen",
    "Tianyang Han",
    "Jin Li",
    "Ye Luo",
    "Yuxiao Wu",
    "Xiaowei Zhang",
    "Tuo Zhou"
  ],
  "published": "2025-06-01T06:34:42Z",
  "updated": "2025-06-01T06:34:42Z",
  "categories": [
    "econ.EM",
    "cs.AI"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00856v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00856v1  [econ.EM]  1 Jun 2025Can AI Master Econometrics? Evidence from Econometrics AI\nAgent on Expert-Level Tasks\nQiang Chen∗a, Tianyang Han†b, Jin Li‡b, Ye Luo§b, Yuxiao Wu¶b, Xiaowei Zhang‖c,\nand Tuo Zhou∗∗b\naSchool of Economics, Shandong University\nbHKU Business School, University of Hong Kong\ncDepartment of Industrial Engineering and Decision Analytics, Hong Kong University of\nScience and Technology\nABSTRACT\nCan AI effectively perform complex econometric analysis traditionally requiring human expertise?\nThis paper evaluates an agentic AI’s capability to master econometrics, focusing on empirical anal-\nysis performance. We develop an “Econometrics AI Agent” built on the open-source MetaGPT\nframework. This agent exhibits outstanding performance in: (1) planning econometric tasks strate-\ngically, (2) generating and executing code, (3) employing error-based reflection for improved ro-\nbustness, and (4) allowing iterative refinement through multi-round conversations. We construct\ntwo datasets from academic coursework materials and published research papers to evaluate per-\nformance against real-world challenges. Comparative testing shows our domain-specialized agent\nsignificantly outperforms both benchmark large language models (LLMs) and general-purpose AI\nagents. This work establishes a testbed for exploring AI’s impact on social science research and\nenables cost-effective integration of domain expertise, making advanced econometric methods ac-\ncessible to users with minimal coding expertise. Furthermore, our agent enhances research repro-\nducibility and offers promising pedagogical applications for econometrics teaching.\nKeywords : Econometrics, Empirical Replication, AI Adoption, Agentic AI\nJEL classification: A20, B41, C49, C87\n∗email: qiang2chen2@126.com\n†email: tyhan@connect.hku.hk\n‡email: jli1@hku.hk\n§email: kurtluo@hku.hk\n¶email: wyx2000@connect.hku.hk\n‖email: xiaoweiz@ust.hk\n∗∗email: zhoutuo@connect.hku.hk\n--- Page 2 ---\nI. Introduction\nAs AI becomes a major topic in mainstream media since ChatGPT’s launch (OpenAI, 2023),\npublic expectations have soared regarding generative AI’s potential to enhance productivity and\nefficiency. This excitement has quickly spread throughout academia, particularly in economics,\nbusiness, and social sciences. Recent studies demonstrate promising applications: Li et al., 2024\nshowed that Large Language Models (LLMs) could effectively substitute for human participants\nin marketing research, particularly in perceptual analysis, while Chakraborty et al., 2025 proved\nthe effectiveness of AI and AI-human hybrid models in salesforce hiring, achieving high prediction\naccuracy through conversational video interviews with minimal professional involvement.\nHowever, despite these advances, LLMs face significant limitations in practical applications.\nCurrent studies primarily restrict LLMs to generating brief textual content or utilizing basic ca-\npabilities within general knowledge domains (Korinek, 2023). More challenging tasks reveal fun-\ndamental constraints: LLMs struggle with complex analytical tasks (Xu et al., 2024) and require\ncostly specialized training for knowledge-dense domains (Ling et al., 2024).\nAs AI’s underlying models rapidly evolve, a new paradigm called AI Agent has emerged\n(https://aws.amazon.com/what-is/ai-agents/). An AI agent is a software program that can in-\nteract with its environment, collect data, and independently perform self-determined tasks to meet\npredetermined goals. This evolution represents a significant advancement beyond traditional LLMs,\nas AI agents promise to handle complex, professional-level tasks with greater autonomy.\nThe practical applications are already evident, such as Amazon’s Alexa+ which manages house-\nhold appliances through personalized conversational interfaces. The development of numerous\nhigh-profile open-source frameworks further validates this trend. For instance, Microsoft’s Au-\ntoGen (https://github.com/microsoft/autogen) provides a comprehensive framework for creating\nmulti-agent AI applications that can act autonomously or work alongside humans. Both academia\nand industry acknowledge AI agents’ promising future, as reflected in notable statements:\n“I expect that the set of tasks AI could do will expand dramatically this year because of\nagentic workflows.” — Andrew Ng (Stanford University) at AI Ascent 2024 Conference.\n“Nvidia will one day have 50,000 employees and over 100 million AI assistants” — Jensen\nHuang (NVidia) at Gartner IT Symposium/Xpo 2024.\nWhile AI agent applications are rapidly advancing in industry, their adoption in academic\nresearch remains limited. Our paper addresses this gap by developing AI agent applications specif-\nically for business, economics, and social sciences research.\nWe propose and implement a zero-shot learning framework, called Econometrics AI Agent , that\nenables AI agents to acquire domain knowledge without costly LLM fine-tuning. The framework’s\ncore component is an econometrics “tool library” implementing popular econometric methods,\nincluding IV-2SLS, DID, and RDD. These methods typically challenge leading benchmark LLMs\nlike OpenAI GPT-4o, which struggle to understand and implement them correctly (for detailed\nevidence, see Section V).\n2\n--- Page 3 ---\nTo bridge this capability gap, we augment each econometric tool with detailed “prompts”—\ncomprehensive method descriptions that specify inputs, hyperparameters, and outputs. These\nprompts are provided alongside corresponding Python implementations, creating a standardized\ninterface between the econometric methods and the AI agent. This design allows the LLM to\nleverage both its general econometric knowledge and the specifically crafted prompts and tools,\nenabling it to conduct complex econometric analyses through multi-round interactions with users.\nThe resulting framework empowers Econometrics AI Agent to independently handle applied\neconometric tasks, delivering comprehensive results that include parameter estimation, inference,\nand analytical discussions. Compared to prevalent approaches like model fine-tuning or pure prompt\nengineering, our design offers a more efficient solution for domain knowledge-intensive problems,\nachieving high accuracy at lower cost.\nTo validate Econometrics AI Agent’s professionalism, efficiency, and autonomy, we conduct\ncomprehensive empirical tests using real-world applications. Our test dataset comprises applied\neconometrics tasks from published academic papers and Ph.D.-level coursework assignments. We\nstandardize these econometric questions into structured prompts that can be processed by both\nEconometrics AI Agent and benchmark LLMs. We evaluate Econometrics AI Agent’s performance\nagainst three control groups: (i) direct LLM generation in Python code, (ii) direct LLM generation\nin Stata code, and (iii) baseline general-purpose AI agents without specialized econometric tools\nand domain knowledge.\nThe experimental results demonstrate Econometrics AI Agent’s superior performance. While\nLLMs’ direct code generation successfully completes less than 50% of complex tasks, our domain-\nknowledge-enhanced AI agent achieves nearly perfect completion rates. Furthermore, Econometrics\nAI Agent achieves significantly higher replication accuracy, with rates above 66% for course assign-\nments (relatively easier tasks) and above 40% for published paper tasks (more complex tasks). In\ncontrast, control groups achieve only 33% and 30% replication rates for easier and complex tasks,\nrespectively.\nThe Econometrics AI Agent framework offers significant implications for the global adoption\nof AI technology. Our structural design provides a cost-effective approach to integrating domain\nexpertise, transforming AI agents into genuine productivity enhancers. In empirical research across\nbusiness, economics, and social sciences, this framework reduces educational barriers by enabling\nstudents and practitioners to utilize sophisticated econometric tools without extensive specialized\ntraining. Beyond econometrics, our design’s modular architecture allows for seamless integration\nof domain knowledge into AI agent “knowledge libraries” across various fields. This extensibil-\nity makes our framework a valuable template for developing domain-specific AI agents in other\ndisciplines.\nOur work contributes to business, economics, and social sciences research in three crucial ways.\nFirst, the Econometrics AI Agent’s robust capabilities in applied econometrics can significantly\naccelerate both adoption of new econometric methods and empirical research processes. Second, it\nenhances research reproducibility by providing standardized implementation of econometric meth-\n3\n--- Page 4 ---\nods. Third, it provides researchers a concrete case study to investigate AI’s impact not merely\nas a content generation tool, but as an autonomous productivity enhancer. This shift in perspec-\ntive enables more nuanced investigations into AI’s broader implications for economic and societal\ndevelopment.\nThe remainder of this paper is organized as follows. Section II reviews emerging literature\non LLM applications, highlighting our contributions. Section III introduces the Econometrics AI\nAgent’s design, focusing on its domain knowledge integration and applied econometrics capabilities.\nSection IV details our evaluation methodology, including dataset construction from coursework\nassignments and published papers, assessment criteria, and performance comparisons with other\nLLM-based tools. Section V presents two in-depth case studies demonstrating the Econometrics AI\nAgent’s task-solving procedure and its advantages over existing LLM-based solutions. Section VI\ndiscusses potential applications and concludes. The Econometrics AI Agent package is available at\nhttps://github.com/FromCSUZhou/Econometrics-Agent.\nII. Literature Review\nOur paper relates to the growing literature on LLM applications in business, economics, and so-\ncial sciences, where LLMs primarily serve as tools for analyzing unstructured textual data, replacing\ntraditional natural language processing techniques. Research has demonstrated LLMs’ fundamen-\ntal content creation capabilities in various settings. Stroube and Waguespack, 2024 used GPT-4 to\ngenerate synthetic gender-neutral movie pitches to control for gender influence in quality evaluation.\nYoganarasimhan and Iakovetskaia, 2024 applied GPT-3.5 Turbo to calculate polarization scores for\narticles and topics in social media analysis. Abraham et al., 2024 utilized ChatGPT to generate\nESG scores from PE firms’ websites, improving upon dictionary-based measurements. Armstrong\net al., 2024 applied the GPT-3.5 Turbo to quantify the firm exposure in Securities Exchange Com-\nmission agencies but received insignificant enhancement. Niu et al., 2025 verified the consistency of\n“bag-of-words” technique by GPT-4 when measuring the effect of manufacturers’ service offerings\non demand variability. Noailly et al., 2024 utilized EnvP-BERT fine-tuned with environmental\npolicies to capture climate-related indexes, which obtained resembling accuracy. Apart from gen-\nerating numeric data by analyzing the implication of the context, LLMs are additionally exerted\nin detecting the similarity by tokenizing context as vectors and afterward calculating the distances\nin different norms (Bursztyn et al., 2022; Graeber et al., 2024; Ahrens et al., 2025; Gorodnichenko\net al., 2025; Curti and Kazinnik, 2023; Balsmeier et al., 2024).\nMost existing research focuses on direct applications of LLMs’ language capabilities, primarily\nusing simple prompts to extract information from textual data. Due to LLMs’ limited capabilities in\nspecific domains like econometrics, their application in these areas remains restricted. Our paper\nadvances this literature by endowing LLMs with domain knowledge through the Econometrics\nAI Agent framework. This enables social science researchers to efficiently implement advanced\neconometric methodologies, expanding LLMs’ utility beyond basic content generation.\n4\n--- Page 5 ---\nOur second contribution relates to the literature exploring AI’s economic impact and human-AI\ninteraction. Previous research has extensively studied productivity effects. Hui et al., 2024 found\nthat ChatGPT usage among freelancers reduces skill-based gaps in highly affected occupations,\nimpacting both earnings and employment. Brynjolfsson et al., 2025 demonstrated heterogeneous\nproductivity gains among customer service workers using LLM-based conversational guidance sys-\ntems. Similar productivity effects were found by Noy and Zhang, 2023 in professional writing\nand Dell’Acqua et al., 2023 in consulting, where AI augmentation improved performance within\nAI-capable tasks but showed limitations beyond the AI’s capability frontier.\nThese productivity shifts have broader implications, as Meltzer, 2024 discussed in analyzing po-\ntential job market changes across manufacturing and international trade, emphasizing the need for\nregulatory frameworks. Beyond productivity, Generative AI influences other economic behaviors.\nLeib et al., 2023 found that AI-generated dishonesty-promoting suggestions affect human honesty\nsimilarly to human advice, while Doshi and Hauser, 2024 revealed that LLMs enhance individual\ncreative writing but may reduce global novelty by channeling creativity in similar directions.\nResearch has also examined LLMs’ decision-making patterns compared to humans. Goli and\nSingh, 2024 found LLMs prefer lower discount rates and earlier rewards in intertemporal choices,\nwith effects moderated by language features. Chen et al., 2025 identified varying risk and certainty\npreferences across different LLM models in operations management decisions. Regarding occupa-\ntional assessment, Gmyrek et al., 2024 found GPT-4 generally aligns with human judgments, except\nfor overestimating digital economy roles and underestimating non-conventional occupations.\nWhile these studies explore LLMs’ economic impact across various dimensions, their research\ndesigns focus on LLMs’ current capabilities and limitations. None examines the impact of domain-\nspecific AI agents, which represent a more advanced application of LLMs with enhanced robust-\nness and task-solving capabilities. Our paper addresses this gap. Through our agent design, we\ndemonstrate how LLMs can transcend basic content generation to become effective task solvers\nand productivity enhancers. By studying how professionally-equipped AI agents impact practical\nusers, we expand the scope of social science research into advanced AI applications.\nLastly, our paper makes a technical contribution, addressing the challenge of enhancing LLMs’\ndomain knowledge performance through a cost-effective solution. Current approaches primarily rely\non expensive and time-consuming methods. These include fine-tuning models with curated domain-\nspecific data, such as BloombergGPT (Wu et al., 2023) for finance and Med-PaLM 2 (Singhal et al.,\n2025) for medicine, or using lightweight fine-tuned LLMs to guide other LLMs (Yao et al., 2023).\nAlternative approaches focus on complex prompt engineering to generate domain knowledge content\n(Liu et al., 2025). However, without proper workflow and self-reflection mechanisms, these direct\nLLM applications remain vulnerable to hallucination issues that can significantly impact output\nquality.\nThe Econometrics AI Agent’s structural design implements a zero-shot learning framework that\nensures high task-solving performance at minimal cost. Our approach minimizes hallucinations\nthrough two key mechanisms. First, domain knowledge toolkit integration prevents hallucinations\n5\n--- Page 6 ---\nin code generation and execution, limiting potential errors to tool selection and calling procedures.\nSecond, self-reflection processes further reduce hallucinations by validating execution outputs and\nimplementing error corrections. This design framework can be extended to other domains, particu-\nlarly those with limited textual training samples or frequent knowledge updates, enabling efficient\ndevelopment of customized AI agents with domain-specific tools.\nIII. Methodology\nCurrent LLM tools face two primary limitations: they struggle to deliver complete workflows\nand perform poorly in knowledge-dense domains. The Econometrics AI Agent addresses both\nchallenges through a customized AI Agent system and a zero-shot learning framework, enabling\naccurate and executable workflows without the substantial costs of LLM retraining.\nA. Overview of Econometrics AI Agent Structure\nLLM-based AI agents are autonomous systems that perceive instructions, reason about complex\ntasks, and execute actions to achieve specified goals through code execution and tool usage. While\ngeneric LLM agents can handle open-ended queries, they struggle in expert domains such as econo-\nmetrics, where problem-solving requires adherence to established analytical steps and specialized\nmethods. Recent AI agent frameworks demonstrate that incorporating structured domain knowl-\nedge significantly enhances performance. MetaGPT (Hong, Zhuge, et al., 2024) encodes procedural\nknowledge as Standardized Operating Procedures within prompt sequences, using specialized sub-\nagents to verify intermediate results and decompose complex tasks. The Data Interpreter agent\n(Hong, Lin, et al., 2024) uses a hierarchical task graph and iterative refinement modules for end-\nto-end data-science workflows.\nBuilding on these advances, the Econometrics AI Agent features a customized architecture\nspecifically designed to embed econometric domain expertise into its core operations. This spe-\ncialization moves beyond the capabilities of general-purpose agents or direct LLM interactions by\nincorporating specific structural enhancements tailored for econometric analysis.\nA cornerstone of this specialized structure lies in enhanced task decomposition. When pre-\nsented with an econometric problem ( User Input in Figure 1), the agent’s Plan Generation module\nfollows predefined templates reflecting standard econometric research paths—such as causal infer-\nence strategies and time-series analysis workflows—rather than relying solely on generic planning.\nThis approach decomposes complex requests into logically sequenced, econometrically meaningful\nsub-tasks. These sub-tasks are categorized using specific econometric actions like “instrumental\nvariable selection” and “difference-in-differences pre-trend check,” enabling more precise execution\nthan generic labels.\nCrucially, executing these specialized sub-tasks requires more than the LLM’s reasoning capa-\nbilities. Thus, another key structural enhancement is the integration of a unique Econometrics Tool\nLibrary. During the Tool Selection andProgram Execution phases (Figure1), the agent accesses a\n6\n--- Page 7 ---\nFigure 1. Workflow of Econometrics AI Agent\nbespoke set of Python functions implementing various econometric methods (e.g., OLS, PanelOLS,\nIV-2SLS, DID, RDD, propensity score methods), including options for robust standard errors and\nfixed effects. As detailed in Section III.B, these tools are described with internal prompts that\nenable the LLM core to understand their functionality and application context. This structured\napproach, where the agent selects and invokes validated tools, minimizes LLM hallucination risk\nfor complex algorithms and ensures adherence to econometric practices—a distinct advantage over\ngeneral agents lacking such domain-specific implements.\nFurthermore, recognizing empirical analysis as an iterative process, the Econometrics AI Agent\nincorporates sophisticated multi-round conversational capabilities with intent recognition and mem-\nory. When users provide subsequent instructions ( multi dialogue loop in Figure 1), an Intent Recog-\nnition mechanism assesses whether the new input relates to the ongoing analysis or initiates a new\ntask. For continuing analyses, the agent retrieves context from its Memory—including current data\nstate, generated code, existing plan, and environment variables within its sandboxed execution en-\nvironment. It then updates the Plan Generation phase, modifying or adding sub-tasks as needed,\n7\n--- Page 8 ---\nand resumes execution from the appropriate point. For new tasks, it initializes a fresh environ-\nment. This mechanism enables users to iteratively refine analyses, correct misunderstandings, or\nexplore alternative specifications conversationally, ensuring outputs align with evolving research\nrequirements.\nThese core structural enhancements—particularly the domain-tailored task decomposition and\nthe unique econometrics toolkit—work in concert to ensure the Econometrics AI Agent’s effective-\nness. The agent’s step-by-step reasoning is grounded in econometric best practices, while code\nexecution relies on robust, pre-defined functions, leading to more reliable and accurate outcomes.\nThis built-in domain expertise substantially reduces logical errors and methodological misapplica-\ntions compared to general agents.\nA key advantage of this design is its extensibility through a zero-shot prompting framework\nwith tool use, allowing the agent to incorporate new econometric methods without LLM retraining.\nUnlike the costly and often infeasible process of fine-tuning an LLM to keep pace with rapid\nacademic advances in developing new techniques, our agent can be updated simply by adding\nnew tool functions and descriptions to the prompt library. This modularity allows the agent’s\nknowledge base to expand alongside the field’s developments, making the integration of recently\npublished procedures as straightforward as adding new modules. Such capability ensures the agent’s\nstate-of-the-art performance while potentially enabling the transfer of this structured approach to\nother specialized domains.\nIn short, by combining LLM-driven reasoning with domain-specific planning structures and\na dedicated toolkit, the Econometrics AI Agent achieves performance, robustness, accuracy, and\nadaptability beyond the capabilities of generic AI agents. The architecture executes complete\neconometric analyses end-to-end, delivering rigorous results while dynamically incorporating user\nfeedback through its interactive workflow.\nB. Customization Towards Econometrics Tasks\nLLMs are generative pre-trained transformers that learn from massive amounts of textual data\nacross various knowledge domains, enabling strong performance in general topics (Wang et al.,\n2019). However, achieving professional-level capability in specialized domains remains challenging,\nparticularly in econometrics where two major limitations affect LLM fine-tuning.\nFirst, econometric methods and algorithms rapidly evolve through academic journals, creating\nan expanding frontier of new knowledge. LLMs struggle to keep pace with these developments:\nfrequent fine-tuning or retraining incurs prohibitive time and financial costs (Xia et al., 2024),\nwhile limited availability of training data—both textual explanations and code—for new methods\nconstrains learning capabilities. Second, novel econometric methodologies often face slow adoption\nand knowledge diffusion among empirical researchers and practitioners, resulting in insufficient\ntraining samples for LLM learning and performance.\nThe Econometrics AI Agent framework achieves proper understanding and accurate appli-\ncation of econometric knowledge through a zero-shot learning approach. This is accomplished\n8\n--- Page 9 ---\nvia an econometrics algorithm tool package designed specifically for LLM use rather than hu-\nman users. Unlike traditional packages familiar to econometricians in Stata and R, our Python-\nscripted package incorporates system prompts engineered for LLM comprehension. The cur-\nrent tool package supports popular empirical econometric applications including general linear\nmodels, propensity score methods, IV-2SLS regression, static/staggered difference-in-differences,\nand sharp/fuzzy RDD. All econometric models and methodologies use function calling format\n(https://platform.openai.com/docs/guides/function-calling), supporting flexible natural language\ninputs for econometric tasks.\nMore importantly, each function in the tool library includes a carefully designed internal prompt\nthat introduces the background knowledge of the relevant econometric method and provides im-\nplementation guidance. These prompts define and explain hyper-parameters that enable flexible\ntool usage based on user requirements—for example, choosing between regular and robust standard\nerrors in OLS. These system prompts enhance the LLM’s understanding of different econometric\ntools’ functionality, allowing accurate tool selection through reasoning when addressing user tasks.\nAn example of tool functions and internal prompts is provided in Figure A.1 in Appendix A.\nThese tool packages are written in Python format to match the Econometrics AI Agent’s code\nexecution environment. As previously introduced, an LLM serves as the agent’s core, understanding\navailable tools, selecting appropriate ones for given tasks, and carefully extracting inputs from user\ncommands, including datasets, econometric methodologies, and related hyper-parameters. Each\ntool features carefully designed functional arguments that meet researchers’ needs while maintaining\nsufficient flexibility to handle diverse, customized econometric tasks.\nThe tool packages’ functionality builds upon established Python packages for simpler econo-\nmetric algorithms (like OLS and logistic regression), while complex algorithms lacking available\npackages (such as staggered DID event study and fuzzy RDD) are developed on our own following\nstandard Python package formats. Each tool package includes a detailed description prompt—\neffectively a “manual for LLMs”—that instructs the core LLM about the package’s use. This\ndesign implements zero-shot learning (Lampert et al., 2014; Larochelle et al., 2008), allowing the\nLLM to learn directly from its environment and access relevant knowledge without training or\nfine-tuning costs.\nAn example of the complete tool-selection-and-implementation workflow is provided in Fig-\nure A.2 in Appendix A. During initialization, the LLM processes each registered tool’s internal\nprompt, summarizing four key aspects: target scenario, input requirements, output structure, and\nspecial requirements (if any). The Econometrics AI Agent ranks available tools based on their\ntarget scenarios, selecting the highest-scoring tool for the current task. The LLM then generates\ncode to ensure inputs meet tool package requirements while outputs fulfill user needs.\nOne might question whether LLM code generation capabilities could replace tools specifically\ndesigned for LLM use, suggesting that direct code generation might suffice given that Python\nand Stata package documentation is publicly available and likely included in LLM training data.\nHowever, limited training samples for specific econometric methods prevent LLMs from master-\n9\n--- Page 10 ---\ning domain knowledge and ensuring reliable performance. The test results in Sections IV and V\ndemonstrate the critical importance of our tool package zero-shot learning framework.\nOur design has several key advantages. First, it requires no econometrics-specific LLM tuning.\nGeneral-domain LLMs (such as GPT-4o and LLaMA 3) perform effectively within the Econometrics\nAI Agent framework, as demonstrated in our empirical tests using unmodified GPT-4o. Second,\nsince all tool methods are fixed functions—although accepting flexible inputs—hallucination within\neconometric algorithms is eliminated. The LLM’s role is limited to understanding tool application\nscenarios and selecting/calling appropriate tools, with any remaining errors readily caught by the\ncode compiler. Last but not least, the zero-shot learning framework enables simple integration of\nnew algorithms and methodologies in Python function format, allowing continuous expansion of\nthe econometric “ecosystem” and enhancement of the Econometrics AI Agent’s capabilities.\nIV. Empirical Tests\nA. Data Source and Summary Statistics\nWe evaluate the Econometrics AI Agent through two sets of inquiries. The first comprises 18\nexercises from the coursework assignments of a doctoral-level course titled “Applied Economet-\nrics” at the University of Hong Kong, with Python-generated standard solutions. These exercises\ncover OLS & PanelOLS regression, propensity score matching, IV-2SLS regression, Difference-in-\nDifferences (DID) analysis, and Regression Discontinuity Design. The second set consists of test\ndatasets from randomly selected seminal articles in reputable journals, primarily accompanied by\nStata-based replication packages.\nAssignments Published Papers\nNumber of Samples (Percentage)\nOLS & Panel OLS 8 (44.4%) 23 (51.1%)\nPropensity Score 2 (11.1%) 6 (13.3%)\nInstrument Variable (IV) 2 (11.1%) 8 (17.8%)\nDifference-in-Differences (DID) 2 (11.1%) 3 (6.7%)\nRegression Discontinuity Design (RDD) 4 (22.2%) 5 (11.1%)\nData Processing 13 (72.2%) 23 (51.1%)\nCovariance Adjustment 14 (77.8%) 29 (64.4%)\nFixed Effects 4 (22.2%) 24 (53.3%)\nTotal 18 45\nTable I . Testset Summary Statistics\nTable I and Figure 2 show the distribution of econometric algorithms across both test datasets.\nOLS and PanelOLS emerge as the predominant methodologies in empirical research in business,\neconomics, and social sciences, while advanced causal analysis techniques like IV and DID also\nmake significant contributions. The Econometrics AI Agent supports these algorithms, enabling\n10\n--- Page 11 ---\nautomated research workflows with minimal development time and cost. All test datasets are\navailable in the study’s online appendix.\nFigure 2. Task Distribution (Econometric Methods)\nB. Test Design\nOur empirical test adopts a structural prompt template to construct detailed questions. To\ndemonstrate the Econometrics AI Agent’s capabilities, we present results against control groups\nusing standardized evaluation metrics.\nB.1. Prompt Structure\nWhile LLMs can process prompts of varying lengths, tones, attitudes, languages, and formats,\ntheir performance may be affected by potential latent factors in these prompts (He et al., 2024). To\nensure consistent performance evaluation, we standardized the prompt format across all test ques-\ntions. Each prompt must specify the data source, proposed econometric methodology, treatment\nvariable, dependent variable, control variables, and customized requirements (such as data process-\ning, fixed effects, robust standard errors, or methodology-specific settings). These components are\nintegrated into a fixed prompt structure. For illustration, consider this example from Anderson,\n2008 using staggered DID event study to estimate safety belt legislation effects on traffic fatalities:\nPlease use the Staggered DID Event Study method to compute the effect of “pri-\nmary” on“logfatality rate”.There is no control variable .\nBesides, you need to consider the following requirements: divide states into two\ngroups by the median value of population in 1982 and choose the high-\npopulation group. For the event study setting, set the see-back length as\n4 and see-forward length as 3. Need to construct logfatality rate as the\ndependent variable, by taking the direct logarithm of fatality rate. Add\nstate fixed effect, year fixed effect and cluster standard error by state. Out-\nput the result of coefficient towards “LagD1”term.\n11\n--- Page 12 ---\nYou could load the corresponding data from /home/data/DID sample data.dta .\nAt the end of the program, please print the coefficient, standard error and p-value of\nthe effect in a json format like {“coefficient ”: 1,“standard error ”: 2,“p-value ”: 0.5},\nand output the json string as a .json file.\nIn this prompt template, boldface elements vary across questions to accommodate different\neconometric tasks, while the remaining structure stays fixed. For researchers familiar with econo-\nmetric analysis, the workflow typically involves data exploration and cleaning, programming lan-\nguage selection, code implementation, and debugging. However, those without sufficient economet-\nric experience face a more challenging process, often requiring extensive trial-and-error iterations.\nB.2. Test Procedure and Evaluation Metrics\nThe generated prompts are fed directly to the Econometrics AI Agent, which automatically\nexecutes Python code in a Jupyter kernel and iteratively updates based on error messages. As\ndetailed in Section III, the program terminates upon completion, storing results in JSON format.\nAll scripts and outcomes are preserved for review, allowing users to interact with the AI agent\nthrough multi-round conversations for result revision and additional tasks.\nPerformance evaluation compares the generated coefficient, standard error, and p-value against\nstandard solutions from coursework materials or original papers. We assess coefficient direction and\nL1-norm distance (coefficients and standard errors in percentage, p-values in absolute distance).\nTwo replication standards are defined: perfect replication requires all three errors to be below 1%,\nwhile partial replication requires coefficient and standard error gaps below 5%.\nTo demonstrate the Econometrics AI Agent’s capabilities, we establish three control groups:1\n1. Direct GPT-4o Python code generation: We test the single-round code generation ability of\nGPT-4o by feeding it our structured prompts prefixed with “use Python language to compute\nthe following task” and manually executing the generated code. This serves as a baseline for\ncomparison.\n2. Direct GPT-4o Stata code generation: Similar to the first control, but testing LLM code\ngeneration in Stata, the most popular software in empirical research. Results are recorded in\n“.smcl” log files.\n3. General-purpose Data Interpreter agent (Hong, Lin, et al., 2024): We test a standard AI\nagent for data analysis without econometric tool packages. This comparison highlights the\nadvantages of our zero-shot learning framework and specialized tool package.\nC. Test Result Summary\nTable II summarizes the performance of the four groups on the coursework assignment problems.\nThe Econometrics AI Agent demonstrates superior performance with a 95% directional replication\n1To ensure clear performance differentiation across all the four groups, we consistently use GPT-4o as the base\nmodel for both direct response generation and agent empowerment. For the Stata-based tests, we manually collect\nmetrics from summary tables, bypassing JSON file generation due to Stata’s language constraints.\n12\n--- Page 13 ---\nrate and average coefficient value errors below 3%. In contrast, both GPT-generated Python and\nStata control groups show incorrect directions in over half of test cases. While the general AI Agent\nachieves a 78% directional replication rate, its coefficient values frequently deviate significantly from\ntrue values.\nIn addition, the Econometrics AI Agent perfectly replicates over 60% of cases, compared to ap-\nproximately 20% for control groups. Its robust econometric toolkit and systematic internal prompts\nyield higher replication rates for advanced algorithms and complex procedures. Furthermore, both\nAI agents—Econometrics AI Agent and general-purpose AI agent (Data Interpreter)—achieve per-\nfect compilation rates through error-feedback mechanisms, while direct LLM generation groups\ncompile successfully less than 50% of the time.\nGPT(Py) GPT(Stata) General AI Agent Econometric AI Agent\nOverall Performance\nCompilation Success 35.56% 23.33% 98.89% 98.15%\nPerfect Replication 12.22% 10% 28.89% 51.85%\nPartial Replication 16.67% 11.11% 33.33% 59.26%\nCoefficient\nCorrect Direction 35.56% 21.11% 74.44% 92.59%\nCoefficient Median Error 0.99% 0.04% 5.15% 0.01%\nCoefficient Error <1% 17.78% 11.11% 32.22% 62.96%\nCoefficient Error <10% 30% 15.56% 43.33% 70.37%\nStandard Error\nStandard Error Median Error 2.14% 2.12% 2.14% 0.34%\nStandard Error Error <1% 13.75% 8.75% 28.75% 50%\nStandard Error Error <10% 32.5% 17.5% 51.25% 75%\nP-value & Significant Level\nP-value Average abs Error .0197 .0306 .0691 .0357\nP-value Median abs Error 0 .0004 0 0\nP-value abs Error <1% 37.5% 15% 62.5% 83.33%\nP-value abs Error <10% 37.5% 16.25% 66.25% 85.42%\nSignificant Level Correctness 37.5% 17.5% 66.25% 85.42%\nSignificant Level Error == 1 0 0 2.5% 4.17%\nSignificant Level Error == 2 1.25% 0 1.25% 0\nSignificant Level Error == 3 0 1.25% 8.75% 4.17%\nPartial Replication based on Task Type\nOLS, Panel OLS 32.5% 7.5% 47.5% 50%\nPropensity Score Regression 0 0 0 33.33%\nInstrument Variable (IV) 20% 60% 80% 100%\nDifferences in Differences (DID) 0 0 30% 33.33%\nRegression Discontinuity Designs (RDD) 0 5% 0 83.33%\nData Processing 16.92% 15.38% 38.46% 69.23%\nCovariance Adjustment 14.29% 14.29% 32.86% 57.17%\nFixed Effects 30% 0 55% 33.33%\nNumber of Tasks 90 90 90 54\nTable II . Assignment Testset Performance\nTable III presents results from the paper replication dataset. Given Stata’s dominance in empir-\nical research across business, economics, and social sciences, the Stata code generation group holds a\nnatural advantage over Python-based approaches. Indeed, GPT-generated Stata code outperforms\nGPT-generated Python code across most evaluation metrics. Nevertheless, the Econometrics AI\nAgent achieves superior performance even in this Stata-favorable context, with a 93% directional\n13\n--- Page 14 ---\nreplication rate—40% higher than the Stata control group.\nAcademic paper tasks present greater complexity than coursework, requiring detailed specifica-\ntions, customized model structures, and various covariance adjustment methods. Nevertheless, the\nEconometrics AI Agent consistently outperforms all control groups across key metrics: coefficient\nestimation error, standard error estimation error, p-value estimation error, and partial replication\nrates for different econometric algorithms and procedures. These results demonstrate the Agent’s\ncapability to handle complex econometric tasks autonomously while delivering reliable results.\nGPT(Py) GPT(Stata) General AI Agent Econometric AI Agent\nOverall Performance\nCompilation Success 28.89% 38.89% 92.59% 93.33%\nPerfect Replication 8.44% 17.78% 14.81% 27.41%\nPartial Replication 13.78% 22.22% 35.56% 37.78%\nCoefficient\nCorrect Direction 24.44% 36.11% 80.74% 87.41%\nCoefficient Median Error 0.86% 0.00% 3.24% 0.40%\nCoefficient Error <1% 12.44% 18.89% 29.63% 46.67%\nCoefficient Error <10% 13.33% 24.44% 48.15% 57.04%\nStandard Error\nStandard Error Median Error 1.84% 0.00% 9.71% 8.82%\nStandard Error Error <1% 11.58% 22.37% 16.67% 24.56%\nStandard Error Error <10% 20.53% 28.95% 38.60% 43.86%\nP-value & Significant Level\nP-value Average Error .0385 .0160 .1371 .0521\nP-value Median abs Error .0001 0 .0026 .0026\nP-value Error <1% 15.79% 27.63% 43.86% 50%\nP-value Error <10% 24.21% 35.53% 66.67% 77.19%\nSignificant Level Correctness 25.26% 31.58% 58.77% 70.18%\nSignificant Level Error == 1 2.11% 3.95% 8.77% 9.65%\nSignificant Level Error == 2 0.53% 0 3.51% 2.63%\nSignificant Level Error == 3 1.05% 0.66% 7.02% 1.75%\nPartial Replication based on Task Type\nOLS, Panel OLS 24.35% 23.91% 42.03% 42.03%\nPropensity Score Regression 3.33% 16.67% 72.22% 77.78%\nInstrument Variable (IV) 0 25% 20.83% 12.5%\nDifferences in Differences (DID) 0 25% 11.11% 33.33%\nRegression Discontinuity Designs (RDD) 8% 15% 0 13.33%\nData Processing 20% 25% 49.28% 47.83%\nCovariance Adjustment 19.31% 25% 37.93% 37.93%\nFixed Effects 12.5% 16% 27.78% 27.78%\nNumber of Tasks 225 180 135 135\nTable III . Paper Testset Performance\nDespite substantially outperforming control groups, the Econometrics AI Agent does show room\nfor improvement. For example, its performance declines for complex econometric methods like DID\nand RDD compared to simpler approaches such as OLS and IV-2SLS. Similarly, results slightly dete-\nriorate when moving from straightforward coursework problems to more sophisticated paper replica-\ntion tasks. However, these limitations can be addressed through the AI agent’s domain knowledge\narchitecture—specifically by developing customized tools and enhancing prompt instructions to\nbetter support complex algorithms and detailed requirements.\n14\n--- Page 15 ---\nV. Case Study\nFollowing the empirical results presented in Section IV, we demonstrate the Econometrics AI\nAgent’s problem-solving approach through a comprehensive case study, comparing its procedures\nwith the three control groups. The study combines questions from both coursework and paper\nreplication datasets.\nThe first component examines a propensity score-based regression adjustment method analyzing\nthe effect of maternal smoking during pregnancy on infant weights, drawn from Almond et al., 2005\nand included in doctoral-level econometrics coursework. The question prompt is as follows:\nPlease use the propensity score regression method to compute the effect of\ntobacco ondbrwt . You also need to control the following control variables: rec-\ntype, csex, dmar, pldel3, pre4000, preterm, alcohol, dmage, demduc, dlivord,\nmonpre, nprevist, dplural, birattnd, cntocpop, ormoth, mrace3, adequacy,\ndelmeth5 .\nBesides, you need to consider the following requirements: birattnd, cntocpop,\normoth, mrace3, adequacy, delmeth5 are multi-class categorical variables.\nTrim the samples with the highest 10% score and the lowest 10% score\nYou could load the corresponding data from /home/data/ps 124Scleaned.dta .\nAt the end of the program, please print the coefficient, standard error and p-value of\nthe effect in a json format like {“coefficient ”: 1,“standard error ”: 2,“p-value ”: 0.5},\nand output the json string as a .json file.\nThe empirical research process begins with data pre-processing and matching, including data file\nmerging, variable selection (dependent, independent, and control variables), and handling missing\nvalues. The analysis requires:\n1. Constructing propensity scores using logistic or probit models (given the binary treatment\nvariable tobacco ).\n2. Trimming samples to exclude extreme propensity scores (e.g., below 0 .1 or above 0 .9) to\nensure sufficient overlap between treatment and control groups.\n3. Running OLS regression with dbrwt as the dependent variable and both tobacco and the\npropensity score as independent variables.\nUsing the provided dataset, the standard solution yields an ATE of −207.7272 with standard error\n5.508. One may also add the covariates into the second-stage OLS regression, which would produce\nan alternative ATE of −212.9892 with standard error 5 .071.\nIn the following, we compare the Econometrics AI Agent with the three control groups in terms\nof problem-solving procedures, highlighting common LLM tool limitations and demonstrating how\nthe Econometrics AI Agent addresses them. All code generation and execution records are available\nonline and can be accessed via https://github.com/FromCSUZhou/Econometrics-Agent.\n15\n--- Page 16 ---\nA. Python Code Generation: LLM and AI Agents\nDirect code generation by LLMs appears to be a straightforward solution given the clear re-\nquirements and simple knowledge base. However, LLM hallucinations frequently disrupt code gen-\neration, where even minor errors can cause program termination without any meaningful results.\nThe GPT-generated Python script demonstrates this vulnerability. As propensity score regression\nadjustment lacks built-in Python implementation, LLMs must generate complete data processing\nand regression procedures. Without self-correction capabilities, hallucinations occur in two areas,\ncausing coding errors and execution failure:\n•Syntax Error: After the “pd.get dummies” operation, all variables affected are transformed\ninto new columns with new labels (Figure B.1 in Appendix B). LLMs fail to detect this label\nchange, during code generation, causing execution termination.\n•Logic Error: During categorical variable preparation, GPT incorrectly applies dummy variable\ntransformation to all covariates, including continuous variables, rather than only categorical\npredictors (Figure B.2 in Appendix B). This deviation violates problem requirements, creating\nan oversized right-hand-side dataset (exceeding 112313 ×112313) and triggering errors.\nUnlike direct LLM code generation, the general-purpose AI agent avoids coding errors through\nits reflection capabilities. However, Figure B.3 in Appendix B reveals a behavioral bias of the\nagent. Since logistic regression, the first step of this analysis, is common in machine learning, the\nagent machine learning conventions by splitting data into training and test sets. This approach\nconflicts with standard econometric practice, which emphasizes empirical explanation rather than\nprediction, making such splitting unnecessary. The resulting estimates deviate significantly from\nthe correct answer, yielding an ATE of −103.7577 with standard error 15 .8834.\nFar from coincidental, this behavioral bias reflects a systemic issue stemming from the substan-\ntially greater accessibility of machine learning materials compared to econometric code resources.\nThe Econometrics AI Agent addresses this bias through two mechanisms: detailed internal prompts\nthat enforce econometric standards, and a specialized tool library that ensures adherence to econo-\nmetric conventions.\nB. Stata Code Generated by LLM\nSince Stata provides numerous built-in data pre-processing methods and econometric algo-\nrithms, LLMs generate Stata code more effectively than Python code for econometric analysis.\nMoreover, Stata’s specialized focus on econometrics, rather than machine learning, means its scripts\nin training samples naturally guide LLMs toward standard econometric approaches. However,\nStata’s function library lacks a built-in function specifically for propensity score regression adjust-\nment. After obtaining propensity scores, the optimal approach is to directly apply OLS for final\nestimation. Instead, as Figure B.4 in Appendix B shows, the hallucination issue arises, leading\nthe LLM to mistakenly select propensity score matching for the second-step estimation. Although\n16\n--- Page 17 ---\nthe results closely match the standard answer (ATE: −218.9029, standard error: 7 .5627), this\nmethodological deviation render these estimates unreliable.\nTheknowledge mismatch error is another aspect of the hallucination issue that requires careful\nattention. For tasks related to propensity score, although OLS regression adjustment is simpler,\nLLMs tend to select the more popular and well-documented propensity score matching method,\nfollowing their tendency to generate the most probable tokens.\nIn contrast, the Econometrics AI Agent has two advantages that prevent this error: First, its\ntool library supports user-customized functions tailored to specific needs, including less common\nmethods. For this task specifically, the Agent is equipped with both propensity score regression\nadjustment functionality and various other propensity score-based econometric methods. Second,\nthe selection of econometric algorithms (and their corresponding tool functions) does not rely on\nLLM generation capabilities. Instead, the tool recommendation procedure introduced in Section III\nfirst identifies the tool that best matches the task requirements. Only after that does LLM generate\ncorresponding codes to correctly apply the tool and finish the task.\nC. Econometrics AI Agent Operation Record\nThe Econometrics AI Agent decomposes this task into three steps. The first two steps—“Load\nand preprocess the dataset from a specified file path” and “Perform exploratory data analysis on\nthe dataset”—follow standard empirical econometric paradigms under internal prompt instructions.\nThese steps complete essential data preparation, including categorical variable one-hot encoding\nand data cleaning. Furthermore, as Figure B.5 in Appendix B shows, the Econometrics AI’s precise\nworkflow requirements prevent the coding errors observed in control groups.\nFor the final step, “Apply propensity score regression, controlling for specified variables and\ntrimming samples,” the Econometrics AI Agent utilizes built-in tool functions to construct propen-\nsity scores and conduct regression adjustment analysis, as shown in Figure B.6 in Appendix B.\nAfter tool selection, the LLM focuses solely on preparing correct inputs to meet task requirements.\nThis approach significantly reduces both the knowledge mismatch error from LLM hallucination\nand the behavioral bias through standardized tool functions. The final estimates (ATE: −207.8559,\nstandard error: 5 .4845) closely match the standard answer, validating the results.\nD. More Illustration Towards Knowledge Hallucination Issue\nBeyond the discussions in Almond et al., 2005, subsequent studies have further explored propen-\nsity score methods for treatment effect identification. Take Cattaneo, 2010 as an example. Based\non their analytical frameworks, we formulate another propensity score matching task with the\nfollowing instruction prompt:\nPlease use the propensity score matching method to compute the ATE of to-\nbacco ondbrwt . You also need to control the following control variables: mmarried,\nmage, mage2, fbaby, medu .\n17\n--- Page 18 ---\nBesides, you need to consider the following requirements: need to constuct mage2\nby taking the squared value of mage; use one-to-one matching; mbsmoke,\nmmarried, fbaby are dummy variables, and other variables are numerical\nvariables\nYou could load the corresponding data from /home/data/cattaneo.dta .\nAt the end of the program, please print the estimated ATE in a json format like\n{“ATE ”: 0.2}, and output the json string as a .json file.\nThe manual solution procedure follows similar initial steps as the propensity score regression\nadjustment method. For ATE estimation, a nearest-neighborhood matching method is applied to\nboth treatment and control groups using estimated propensity scores. The final estimate is derived\nfrom the mean difference between groups across all included entities. Under the specified settings,\nthis procedure yields an ATE estimate of −210.9683.\nSince propensity score matching is a built-in Stata function, GPT-generated Stata code provides\nsuccinct solutions. However, for Python implementations, where no popular packages exist for\nthis method, the generated code must implement the method step-by-step. Here, the knowledge\nhallucination issue emerges consistently in our tests: as Figure B.7 in Appendix B shows, GPT\nmodels claim to calculate ATE while actually producing ATET (Average Treatment Effect on the\nTreated) estimates. This error stems from LLMs’ domain knowledge limitations. While general-\npurpose AI agents can use internal prompts to guide LLM behavior, such guidance is not sufficient\nand cannot ensure comprehensive knowledge of every domain-specific detail.\nThis example therefore provides direct evidence for the advantage of the Econometrics AI\nAgent’s tool library design. Figure B.8 in Appendix B demonstrates how the core LLM, supported\nby a well-established knowledge and tool library, avoids knowledge hallucination under the Econo-\nmetrics AI Agent framework. Rather than solely relying on LLMs’ content generation ability to\nperform domain knowledge-driven tasks—which are often complicated, in-depth, and sometimes\nuncommon and ambiguous—the tool library greatly simplifies LLMs’ generation and decision pro-\ncesses while guaranteeing domain knowledge capability. Beyond this straightforward case example\nand simple methodology, the tool library’s robustness, flexibility, and extensibility ensure the elim-\nination of knowledge hallucination across more complex tasks and algorithms.\nVI. Conclusions\nThe AI era has brought significant productivity gains across various domains, yet challenges\npersist in fields requiring deep domain expertise. We introduce the Econometrics AI Agent, a LLM-\ndriven specialized system that automates econometric analysis. Through a carefully customized\nagent structure, it executes complete econometric analyses while dynamically adapting to user\nfeedback. The agent incorporates a simple yet robust zero-shot learning framework that enables\ncontinuous functionality expansion, both within econometrics and across other knowledge domains.\nWe demonstrate the agent’s superior performance through empirical testing on coursework assign-\n18\n--- Page 19 ---\nments and economics papers, complemented by in-depth case study comparisons against standard\nLLMs and general-purpose AI agents.\nThe Econometrics AI Agent’s excellent performance demonstrates its significant potential for\nfuture applications. Beyond reducing learning barriers for econometrics students, it provides aca-\ndemic researchers and industry practitioners with efficient tools for research tasks. As leading\nacademic journals increasingly require original data and replicable procedures, manual paper proof-\nreading has become time-consuming and challenging. the Econometrics AI Agent can serve as an\nAI-driven digital referee for empirical research papers, significantly boosting proofreading efficiency\n(Mueller-Langer et al., 2019) while ensuring content quality and validity.\nOur work’s extensibility manifests in two key dimensions. First, the Econometrics AI Agent’s\ncapabilities can be expanded by incorporating additional tool packages. For instance, addressing\ngrowing concerns about p-hacking in empirical research in business, economics, and social sciences,\nwe developed a tool package using inverse optimization to analyze potential decision procedures\nregarding empirical test settings within given optimization spaces and datasets. This cost-effective\naddition helps detect potential p-hacking risks in empirical research, offering an efficient alternative\nto manual review.\nSecond, our zero-shot learning framework can extend to other knowledge-intensive domains.\nThrough targeted instruction prompt refinement and domain-specific tool package development,\nthis one-off setup enables new AI agents to deliver consistent, high-quality performance in their\nrespective domains. This extensibility opens possibilities for future applications in areas such as\nquantitative investing and macroeconomics.\nReferences\nAbraham, J., Olbert, M., & Vasvari, F. (2024). Esg disclosures in the private equity industry.\nJournal of Accounting Research ,62(5), 1611–1660.\nAhrens, M., Erdemlioglu, D., McMahon, M., Neely, C. J., & Yang, X. (2025). Mind your language:\nMarket responses to central bank speeches. Journal of Econometrics ,249, 105921.\nAlmond, D., Chay, K., & Lee, D. (2005). The costs of low birth weight. The Quarterly Journal of\nEconomics ,120(3), 1031–1083.\nAnderson, M. (2008). Safety for whom? The effects of light trucks on traffic fatalities. Journal of\nHealth Economics ,27(4), 973–989.\nArmstrong, D. M., Glaeser, S., & Hoopes, J. L. (2024). Measuring firm exposure to government\nagencies. Journal of Accounting and Economics , 101703.\nBalsmeier, B., Fleming, L., Stiebale, J., & Veihl, M. (2024). The unintended impact of R&D tax\ncredits on innovative search. The Review of Economics and Statistics , forthcoming.\nBrynjolfsson, E., Li, D., & Raymond, L. (2025). Generative AI at work. The Quarterly Journal of\nEconomics ,140(2), 889–942.\n19\n--- Page 20 ---\nBursztyn, L., Rao, A., Roth, C., & Yanagizawa-Drott, D. (2022). Opinions as facts. The Review of\nEconomic Studies ,90, 1832–1864.\nCattaneo, M. (2010). Efficient semiparametric estimation of multi-valued treatment effects under\nignorability. Journal of Econometrics ,155(2), 138–154.\nChakraborty, I., Chiong, K., Dover, H., & Sudhir, K. (2025). Can AI and AI-hybrids detect per-\nsuasion skills? Salesforce hiring with conversational video interviews. Marketing Science ,\n44(1), 30–53.\nChen, Y., Kirshner, S. N., Ovchinnikov, A., Andiappan, M., & Jenkin, T. (2025). A manager and\nan AI walk into a bar: Does ChatGPT make biased decisions like we do? Manufacturing &\nService Operations Management ,27(2), 354–368.\nCurti, F., & Kazinnik, S. (2023). Let’s face it: Quantifying the impact of nonverbal communication\nin fomc press conferences. Journal of Monetary Economics ,139, 110–126.\nDell’Acqua, F., McFowland III, E., Mollick, E. R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S.,\nKrayer, L., Candelon, F., & Lakhani, K. R. (2023). Navigating the jagged technological\nfrontier: Field experimental evidence of the effects of AI on knowledge worker productivity\nand quality. https://ssrn.com/abstract=4573321\nDoshi, A. R., & Hauser, O. P. (2024). Generative AI enhances individual creativity but reduces the\ncollective diversity of novel content. Science Advances ,10(28), eadn5290.\nGmyrek, P., Lutz, C., & Newlands, G. (2024). A technological construction of society: Comparing\nGPT-4 and human respondents for occupational evaluation in the UK. British Journal of\nIndustrial Relations ,63, 180–208.\nGoli, A., & Singh, A. (2024). Frontiers: Can large language models capture human preferences?\nMarketing Science ,43(4), 709–722.\nGorodnichenko, Y., Pham, T., & Talavera, O. (2025). Central bank communication on social media:\nWhat, to whom, and how? Journal of Econometrics ,249, 105869.\nGraeber, T., Roth, C., & Zimmermann, F. (2024). Stories, statistics, and memory. The Quarterly\nJournal of Economics ,139(4), 2181–2225.\nHe, J., Rungta, M., Koleczek, D., Sekhon, A., Wang, F. X., & Hasan, S. (2024). Does prompt\nformatting have any impact on LLM performance? https://arxiv.org/abs/2411.10541\nHong, S., Lin, Y., Liu, B., Liu, B., Wu, B., Zhang, C., et al. (2024). Data interpreter: An LLM\nagent for data science. https://arxiv.org/abs/2402.18679\nHong, S., Zhuge, M., Chen, J., Zheng, X., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K. S.,\nLin, Z., Zhou, L., Ran, C., Xiao, L., Wu, C., & Schmidhuber, J. (2024). MetaGPT: Meta\nprogramming for a multi-agent collaborative framework. The Twelfth International Confer-\nence on Learning Representations . https://openreview.net/forum?id=VtmBAGCN7o\n20",
  "text_length": 57907
}