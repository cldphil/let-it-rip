{
  "id": "http://arxiv.org/abs/2506.05309v1",
  "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia\n  Games",
  "summary": "LLMs are used predominantly in synchronous communication, where a human user\nand a model communicate in alternating turns. In contrast, many real-world\nsettings are inherently asynchronous. For example, in group chats, online team\nmeetings, or social games, there is no inherent notion of turns; therefore, the\ndecision of when to speak forms a crucial part of the participant's decision\nmaking. In this work, we develop an adaptive asynchronous LLM-agent which, in\naddition to determining what to say, also decides when to say it. To evaluate\nour agent, we collect a unique dataset of online Mafia games, including both\nhuman participants, as well as our asynchronous agent. Overall, our agent\nperforms on par with human players, both in game performance, as well as in its\nability to blend in with the other human players. Our analysis shows that the\nagent's behavior in deciding when to speak closely mirrors human patterns,\nalthough differences emerge in message content. We release all our data and\ncode to support and encourage further research for more realistic asynchronous\ncommunication between LLM agents. This work paves the way for integration of\nLLMs into realistic human group settings, from assistance in team discussions\nto educational and professional environments where complex social dynamics must\nbe navigated.",
  "authors": [
    "Niv Eckhaus",
    "Uri Berger",
    "Gabriel Stanovsky"
  ],
  "published": "2025-06-05T17:53:44Z",
  "updated": "2025-06-05T17:53:44Z",
  "categories": [
    "cs.MA",
    "cs.AI",
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.05309v1",
  "full_text": "--- Page 1 ---\narXiv:2506.05309v1  [cs.MA]  5 Jun 2025Time to Talk\n :\nLLM Agents for Asynchronous Group Communication in Mafia Games\nNiv Eckhaus1Uri Berger1,2Gabriel Stanovsky1\n1School of Computer Science and Engineering, The Hebrew University of Jerusalem\n2School of Computing and Information Systems, University of Melbourne\n{niv.eckhaus,uri.berger2,gabriel.stanovsky}@mail.huji.ac.il\nAbstract\nLLMs are used predominantly in synchronous\ncommunication, where a human user and a\nmodel communicate in alternating turns. In\ncontrast, many real-world settings are inher-\nently asynchronous . For example, in group\nchats, online team meetings, or social games,\nthere is no inherent notion of turns; therefore,\nthe decision of when to speak forms a cru-\ncial part of the participant’s decision making.\nIn this work, we develop an adaptive asyn-\nchronous LLM-agent which, in addition to de-\ntermining what to say , also decides when to\nsay it . To evaluate our agent, we collect a\nunique dataset of online Mafia games, includ-\ning both human participants, as well as our\nasynchronous agent. Overall, our agent per-\nforms on par with human players, both in game\nperformance, as well as in its ability to blend\nin with the other human players. Our analy-\nsis shows that the agent’s behavior in deciding\nwhen to speak closely mirrors human patterns,\nalthough differences emerge in message con-\ntent. We release all our data and code to sup-\nport and encourage further research for more\nrealistic asynchronous communication between\nLLM agents.1This work paves the way for in-\ntegration of LLMs into realistic human group\nsettings, from assistance in team discussions\nto educational and professional environments\nwhere complex social dynamics must be navi-\ngated.\n1 Introduction\nRecent advances in LLMs have enabled their use\nin various applications and domains, the majority\nof which focus on synchronous settings – where\ncommunication is done in turns, often alternating\nbetween a human user and a model. In contrast,\nmuch of real-world communication is done asyn-\nchronously , allowing interlocutors to communicate\n1All code and data are available here: https://github.\ncom/niveck/LLMafia\nName: Logan\nRole: bystanderName: Casey\nRole: bystanderName: Drew\nRole: mafia[21:35:51] Hi everyone!\n[21:35:53] What’s up?\n[21:36:08] I think Ronny \nwas the first to stir\n[21:35:51] <wait>\n[21:35:52] <wait>\n[21:35:53] <wait>\n[21:35:54] <wait>\n[21:35:55] <send>\n[21:35:56] <wait>\n[21:35:57] <wait>\n[21:35:58] <wait>\n[21:35:59] <wait>\n[21:36:00] <wait>Name: Ronny\nRole: mafia\n[21:35:55] I’m good \nand ready to play![21:35:58] Ready to \nplay? How suspicious…\n[21:36:07] Casey is sus \nstarted throwing names\n[21:35:51] Logan : Hi everyone!\n[21:35:53] Logan : What’s up?\n[21:35:55] Ronny : I’m good and ready to play!\n[21:35:58] Casey : Ready to play? How suspicious…\n[21:36:07] Drew : Casey is sus started throwing names\n[21:36:08] Logan : I think Ronny was the first to stirMafia game chatFigure 1: A virtual game of Mafia, played by human\nplayers and an LLM-agent player. The agent integrates\nin the asynchronous group conversation by constantly\nsimulating the decision to send a message.\nat arbitrary times. In such communication, each\nparticipant needs not only to decide what to say,\nbut also when to speak, allowing participants to\nadopt different strategies, e.g., being very talkative,\nor alternatively staying quiet.\nDespite its prevalence in real-world interaction,\nto the best of our knowledge, there is no prior work\nthat targets group asynchronous communication\n--- Page 2 ---\nin the context of LLMs. Instead, we find that the\nmodels developed for social interaction and other\nnaturally-asynchronous settings, are modeled as\ninvolving predefined turns in which the model can\ninteract with the environment (e.g., (Bakhtin et al.,\n2022; Park et al., 2023)).\nIn this work, we develop an LLM-based agent\nfor such asyncronous multi-party environments,\napplicable in a wide range of real-world settings,\nincluding group chats, online team meetings, or\nsocial games. Our agent, described in Section 2,\norchestrates a two-stage call to an LLM. First, an\nLLM is prompted to decide whether to speak with\nascheduler prompt . This prompt consists of the\ngame’s current status (e.g., chat history), along with\nan instruction which is amended according to pre-\nvious decisions that the scheduler has made: if it\nhas been quiet relative to the other participants, the\nprompt may urge the LLM to be more talkative,\nwhile if it chooses to speak more than other partici-\npants, the instruction is amended to signal it should\nspeak only if necessary. If the scheduler decides to\nspeak, a second call is made to prompt an LLM to\ndecide what to say given previous messages.\nTo test our asyncronous agent, we focus on the\ngame of Mafia (Section 3). Mafia is a social game\nthat includes deception and voting out suspicious\nplayers. As such, deciding when to speak is a cru-\ncial part of the player’s strategy. For example,\nspeaking too often or too little may seem suspi-\ncious. We collect the LLM AFIA dataset, consisting\nof Mafia games including both human players and\nan LLM agent (Section 4). Our dataset comprises\n21 games and 2558 messages, 211 of which were\nsent by the LLM-agent. While prior datasets for\nMafia exist, ours is the first to integrate an LLM\nagent, allowing analysis of human-LLM interac-\ntions.\nFinally, we analyze the performance of our asyn-\nchronous agent in the Mafia game (Section 5). We\nfind that our agent aligns with human players in\nmessage timing, message quantity, and winning\nrates, and that human players fail to identify the\nagent in more than 40% of the cases. However,\nwe also find notable differences in message con-\ntent, where the agent’s messages are longer and can\nbe distinguishable from human players by learned\nclassifiers.\nIn conclusion, our main contributions are\ntwofold. First, we propose an asynchronous agent\ncapable of effective real-time decision-making\nabout when to speak, and show that it resembleshumans when choosing when to speak. Second, we\nprovide a new dataset for Mafia games, enabling\nfuture study of this field. By focusing on a realistic,\ndynamic setting with natural asynchrony, our work\nlays the foundation for future research into multi-\nagent communication that more closely resembles\nhuman interaction.\n2 Asynchronous Agent\nWe propose an agent designed for asynchronous\nconversations. Our agent consists of two modules:\nthescheduler , deciding whether to post a message\nto the chat at a given moment, and the generator ,\nwhich composes the message content.\nIn this work, we use LLMs for both modules.\nBoth models use the group chat context as input,\nincluding the setting of the conversation, its start\nand current time, other active participants and the\nmessage history with timings.\nDynamic scheduler prompting. To make sure\nthe scheduler maintains a balance between be-\ning overly talkative and too quiet, we dynami-\ncally change the scheduler prompt based on the\nagent’s message rate. When the rate of messages\nby the agent is lower than 1/n(where nis the num-\nber of active participants in the conversation), we\nuse a prompt which encourages it to speak more.\nConversely, when the rate exceeds this value, we\nprompt the model to adopt a more listener-type\nrole.2\nSimulation of typing time. To better align the\ntiming of messages with human behavior, we intro-\nduce a delay after each generated message, simulat-\ning the time a human would take to type it. Specif-\nically, before sending a message, the agent waits\nfor a duration based on an average typing speed of\none word per second (Dhakal et al., 2018). This\napproach uses the message length to approximate\nthe typing time of a human player.\nThe full logic of the agent is portrayed in Fig-\nure 2.\n3 Asynchronous Test Case: The Game of\nMafia\nEvaluation of asynchronous communication is chal-\nlenging due to the lack of labeled data distinguish-\ning correct from incorrect message timing. There-\nfore, we choose to set our evaluation of asynchrony\nmodeling for LLMs in a game setting.\n2See Appendix A.3 for full scheduling prompt examples.\n--- Page 3 ---\nGeneration prompt\n“Add a short message to the game. Keep it relevant to the \ncurrent game’s status according to recent messages […]”Scheduling prompt\n“Do you want to add a message to the discussion? […]”\nQuieter listening prompt : \n“Pay attention to the \nnumber of messages you \nsent compared to others \nand let them have their \nturn too! […]”More talkative prompt : \n“Remember to make \nyourself heard so be \nactive and engage in the \nconversation as much as \nothers!  […]”Active \nplayers : \n𝑛=7Message rate : \n2\n9 ?\n>\n 1\n𝑛\nNO YESContext\n[21:35:48] Game -Manager : Now it’s daytime\n[21:35:51] Logan : Hi everyone!\n[21:35:53] Logan : What’s up?\n[21:35:55] Ronny : I’m good and ready to play!\n[21:35:58] Casey : Ready to play? How suspicious…\n[21:36:07] Drew : Casey is sus started throwing names\n[21:36:08] Logan : I think Ronny was the first to stir\n[21:36:13] Ronny : It’s not me! I’m innocent\n[21:36:17] Drew : Yeah  don’t fall into Casey’s trap\n[21:36:24] Casey : Someone’s protecting Ronny…Chat history with timingsSocial traits & \npersonal details\n“Your name is Ronny .\nYou’re a bot player in an \nonline version of the \nparty game Mafia.\nYou have an outgoing \npersonality […]”Rules of the game\nAssigned role : mafia\nGame  start : [21:35:48]\nCurrent time : [21:36:26 ]\nGenerator Scheduler Sched. prompt+Context <send>\n<wait> Gen. prompt+ContextNew message :\n“Let’s vote Casey!”\n[21:36:2 9] Ronny : Let’s vote Casey!Wait simulated \ntyping time : 3 secFigure 2: Agent’s logic design. The context is used for both scheduling and generation. The scheduling prompt\ndepends on calculating the agent’s messaging rate, compared to the average rate by other players – if the rate is\nhigher, then the prompt has the tendency to favor waiting, while for the opposite case it favors sending a new\nmessage. Once the scheduler generates a decision (either “<wait>” or “<send>”), the agent interprets it by finishing\nthe procedure and starting again, or using the generator to generate a new message. The agents waits before\npublishing the message to the chat, a duration correlated with the message length. During all of the described\nprocess, new messages can still be sent to the game’s chat. These new messages do not change the current processed\ncontext, therefore do not affect the decision or the final generated message. It is in a similar manner to human\nplayers who use the game’s chat, and might start replying to the conversation at the same time someone else adds\nanother message.\nGames give each participant an objective. Win-\nning the game is a proxy metric of whether the\ncommunication was successful. It sets the conver-\nsation under a frame of rules, where each partici-\npant needs to use the communication to advance to\ntheir target. From now on, participants in the game\nwill be referenced as “players”.\nWe choose the game of Mafia , a social deduction\ngame in which each player is secretly assigned a\nrole, either mafia orbystander . Only mafia players\nare aware of all players’ roles. Every round starts\nwith a daytime phase, where all players discuss\nwho they think the mafia players might be, and\nvote out one player. Then the game moves to a\nnighttime phase, where only mafia players interactand vote to decide which bystander they want to\neliminate. In the next round’s daytime, the mafia’s\nvictim is revealed. The game continues until one of\nthe teams achieves their objective: the mafia’s goal\nis to outnumber the bystanders, and the bystanders’\ngoal is to vote out all mafia.3A graphical flow\nchart of the game can be seen in Figure 3.\nWe choose the Mafia game for several reasons.\nFirst, it can be based solely on textual interaction,\nwhich allows LLMs to play together with human\nplayers. Second, it requires collaboration under\nuncertainty, making communication between par-\n3See the game’s Wikipedia page for elaborated expla-\nnation of the rules: https://en.wikipedia.org/wiki/\nMafia_(party_game)\n--- Page 4 ---\nGame over!Game starts : everyone learns their role, \nmafia members learn each other’s identities\nDaytime\nEveryone \ndiscusses who \nto vote for\nWhen phase is over : \neveryone votes for \nsomeone to eliminate\nA player is eliminated, \ntheir role is revealedNight time\nOnly mafia can \ncommunicate\nWhen phase is over : \nmafia votes for a \nbystander to eliminate\nA bystander  is eliminated, \ntheir role is revealed\nGame ends : all roles are revealedGame  not \nover yetGame not \nover yet\nGame over!Figure 3: Flow chart of Mafia’s rules.\nticipants a fundamental aspect of the game. Third,\nit centers around suspicion of other players, so both\nextreme strategies of constantly speaking or not\nspeaking at all can be seen as suspicious. There-\nfore, the timing of communication is crucial for the\nplayer’s success.\n4 The LLM AFIA Dataset\nTo evaluate our proposed strategy of asynchrony for\nLLMs, we run games of Mafia with human players,\nincorporating an LLM-based agent as an additional\nplayer, within an asynchronous chat environment.\n4.1 Modeling Asynchronous Chat\nSynchronization and scheduling are widely studied\nin fields like communication and operating systems.\nTheir aim is to allow multiple processes to share\nresources. For example, when only one CPU is\navailable but the user wishes to run multiple pro-\ngrams at the same time, like viewing a video while\ntaking notes, scheduling is needed to create the il-\nlusion that the CPU is being shared simultaneously\namong the processes.\nScheduling algorithms vary by the trade-off be-\ntween allowing as many processes as possible to\nparticipate versus letting the most prioritized pro-\ncesses finish (Kumar et al., 2019). Common algo-rithms simulate sharing of a resource at the same\ntime by high-rate sampling of the continuous time.\nThe time units are then allocated to the different\nprocesses to simulate the use of the resource at the\nsame time.\nTo achieve asynchrony, all parties should be able\nto contribute a message to the group chat at any\ngiven time. In our setting the messages are discrete,\nso there is no need to wait for them to finish, and\nthey all have the same priority. Therefore, we are\nleft with modeling the decision of when to speak.\nEach participant in the conversation is repeatedly\nprompted to decide whether they want to add a mes-\nsage, thus simulating the online real-time decision\nof when to speak. This approach allows partici-\npants to adopt independent asynchrony strategies,\nby which they act and choose when to add a mes-\nsage to the conversation. Figure 1 displays how an\nartificial participant in the conversation can simu-\nlate the possible timings, to have the notion of a\ncontinuous conversation.\n4.2 Overview of the LLM AFIA Dataset\nOur dataset consists of 21 games, with a total of\n2558 messages (121.81 messages per game on av-\nerage), 211 of which were sent by the LLM-agent\n(10.05 per game on average). Full details can be\nseen in Table 1.\nThe data includes all players messages and votes\nincluding timestamps, game management mes-\nsages (e.g., announcements of the beginning and\nend of phases), in addition to records related to the\nagent, such as the prompts that were provided at\neach timestamp.\nPlayers and roles distribution. The number of\nplayers per game ranged from 7 to 12 (7.86 aver-\nage, 1.17 STD). Games with 10 or fewer players\nincluded 2 mafia members, while games with more\nthan 10 players included 3. Every game included\none LLM-agent as a player.\n4.3 Human Players\nPopulation. All 64 participating players are flu-\nent in English, either native or second language\nspeakers. Participants play 2.25 games on average.\nIn every new game, all players are given new char-\nacter names, in order to make it more difficult to\ntrack personalities across multiple games played\nby the same participants.\nInformation disclosure and consent. Players\nare informed that one of the players is an AI agent,\n--- Page 5 ---\n# Games Avg # Phases Avg # Players Avg # Msg LLM Avg # Msg\n21 4.86 7.86 121.81 10.05\nTable 1: General information for all games in LLM AFIA .# Games is the number of games played, Avg # Phases is\nthe average number of daytime and nighttime phases per game, Avg # Players is the average number of players per\ngame, Avg # Msg is the average number of messages per game, LLM Avg # Msg is the average number of messages\nsent by the LLM-agent per game.\nPlayer Type Avg # Msg ( ±STD)\nHuman 4.54 ( ±3.44)\nLLM 4.28 ( ±2.50)\nTable 2: Number of messages sent by a player during a\ndaytime phase.\nbut are not told its character’s name. All players\nare informed and approve of participating in the\nexperiment and having their data collected, anony-\nmously.4\n4.4 LLM Player\nWe implemented an LLM-agent to play accord-\ning to our suggested design in Section 2. We use\nLlama3.1-8B-Instruct as both the scheduler and the\ngenerator.5\nIn the generator prompt, we put emphasis on\nproducing messages that are suitable for the com-\nmunication style of the game: short informal mes-\nsages, using slang, relevant to the game’s current\nstate, and without constantly repeating the same\nmessage.6 7\n4.5 Post-game survey\nAt the end of each game, human participants are\nasked which of the players was the LLM-agent.\nAfter the answer is revealed, they are asked to score\nits behavior on a scale of 1 to 5 regarding three\nmetrics: human-similarity, timing of messaging\nand messages relevance.\n4See Appendix A.1 for exact phrasing of the participation\nconsent message.\n5See Appendix A.2 for the difference in generation hyper-\nparameters between the scheduler and generator.\n6See Appendix A.3 for a full generation prompt example.\n7Experimenting with integrating examples from past\ngames as in-context-learning examples for style, make the\nLLM tend to use the names of the players mentioned in those\nmessages. Therefore, we renounce the use of in-context-\nlearning.\nFigure 4: Number of messages per player in a day-\ntime phase, throughout the phases of the game . As\nplayers get voted out from the game, the remaining play-\ners tend to speak more often, thus motivating our agent\nwhich tries to speak in proportion to the number of play-\ners left in the game.\n5 Analysis\nWe now analyze the performance of the LLM-\nagent relative to human players. We start with\nmessage timing and quantity as the focus of the\nasynchronous communication modeling, then ana-\nlyze the message content, and finally analyze the\nagent’s performance in the game compared to other\nplayers.\nMessage timing and quantity are similar to hu-\nmans’, with reduced variance. We study the\ntiming and quantity of messages to assess whether\nthe agent behaves similarly to human players.\nTable 2 shows the mean number of messages\nsent by a player during a daytime phase. The LLM-\nagent player sends a similar amount of messages\non average to a human player. Both player types\nhave high variance, with the LLM showing lower\nvariability, possibly because human players vary\nacross games. The relatively high variance can be\nexplained by the effect of the changing number of\nactive players on each player’s engagement in the\nconversation – as can be seen in Figure 4, as the\n--- Page 6 ---\nFigure 5: Distribution of time differences between messages. Each observation in this distribution represents a\nplayer in a specific game and the observation’s value is the mean time difference (in seconds) between the player’s\nmessage and a previous message by another player (left) or by the same player (right), averaged across all messages\nof this player in this game. Blue (red) distributions represent human (LLM) players.\nPlayer Type # Words Per Message # Repeated Messages # Unique Words\nHuman 4.19 ( ±1.89) 0.44 ( ±1.14) 31.56 ( ±22.34)\nLLM 10.67 ( ±3.46) 1.00 ( ±2.56) 66.67 ( ±37.74)\nTable 3: Message content statistics for a player in a game, in the format of: Mean ( ±STD). # Words Per Message is\nthe average message length (in number of words), # Repeated Messages is the number of repeated messages by the\nplayer throughout the game, and # Unique Words is counting the unique words in all of that player’s messages in the\ngame.\ngame advances and fewer players are still playing,\nthe number of messages per player increases.\nFigure 5 presents distributions for two timing\nmeasures: (1) left plot: the time elapsed since the\nlast message by any player, serving as a proxy for\nresponse timing, as it is non trivial to determine to\nwhich previous message each message is respond-\ning to; and (2) right plot: the time between consec-\nutive messages sent by the same player. In both\ncases, the agent’s distribution closely mirrors hu-\nman behavior, but with slightly lower variance.\nThe Agent sends longer messages. As can be\nseen in Table 3, the LLM-agent tends to send longer\nmessages compared to a human player. It also ex-\nhibits slightly higher repetition and a larger vocab-\nulary size.\nMessages are distinguishable by player type.\nTo better understand the integration of the LLM-\nagent’s communication in the asynchronous envi-\nronment, we look at the embeddings of its mes-\nsages, and compare them to the human player’smessages. We use BGE-M3 (Chen et al., 2024)\nas our sentence embedding model. We use a Lin-\near Discriminant Analysis (LDA) classifier (Cohen\net al., 2013) to separate between messages sent\nby LLM and human players. As can be seen in\nTable 4, messages can be easily separated into dis-\ntinct classes by their player type. We also examined\ntwo other variables that might affect the message\nseparation – the players’ roles (mafia/bystander)\nand the phase during which the message was sent\n(daytime/nighttime). As seen in the same table,\nthese variables were also successfully separated\nby an LDA classifier. This is in accordance with\nIbraheem et al. (2022), who showed that mafia and\nbystander messages in a game can be classified by\nan LLM.\nThe agent wins at similar rates to humans. As\ncan be seen in Figure 6’s statistics, the LLM-agent\nplayer wins in a similar rate to the performance\nof human players, both as a bystander and mafia.\nSince message timing that largely deviates from\n--- Page 7 ---\nMessage Separation Classification F1-Score\nLLM / Human 0.98\nMafia / Bystander 0.88\nDaytime / Nighttime 0.91\nTable 4: Classification performance for message embed-\ndings.\nFigure 6: Win percentages of human players compared\nto the LLM-agent, by role in the game.\nhuman behavior might seem suspicious and result\nin losing the game, this is yet another indication\nthat the agent’s message timing is similar to that of\nhuman players.\nBeing too talkative correlates with being voted\nout. Figure 7 shows a histogram of normalized\nspeaking rank for players who were voted out dur-\ning daytime phases. There is a striking peak at\nrank 1, indicating that the most talkative players\nare significantly more likely to be voted out. This\nfinding reinforces our design choice to develop an\nagent that avoids extreme communication patterns,\nand instead aims to blend in with typical human\nbehavior.\nHuman players struggle to detect the agent.\nWhen asking human players after the game which\nplayer was the LLM agent, only 59.6% answered\ncorrectly, further suggesting that the agent’s com-\nmunication timing was relatively human-like. As\ncan be seen in Table 5, the score for similarity to\nhuman behavior is mediocre, in accordance to the\nidentification percentage. The message relevance\nscore is slightly higher, and the score for the timing\nof messaging is even higher.\n6 Related Work\n6.1 Multi-Agent LLM Communication\nRecent research has explored the capabilities and\nlimitations of LLMs in multi-agent communication,\nturn-taking, and dialogue modeling.\nFigure 7: Histogram showing the rank for the num-\nber of messages sent by the voted out player . Rank\n0 is the for the player who sent the fewest messages in\nthat phase, rank 1 is for the player who sent the most.\nMetric Mean Score ( ±STD)\nHuman Similarity 2.63 ( ±1.32)\nTiming 3.19 ( ±1.33)\nRelevance 2.99 ( ±1.37)\nTable 5: Evaluation of the LLM-agent’s performance as\nmetrics ranked by human players on a scale of 1 to 5, at\nthe end of each game, after the LLM-agent’s identity is\nrevealed. Human Similarity ,Timing andRelevance are\nsimilarity to human behavior, timing of messages and\nmessage relevance, respectively.\nZhou et al. (2024) critically examine the com-\nmon approach of using a single LLM to generate\nthe communication of all speakers in social simu-\nlations. Their findings highlight that while LLMs\nperform well in controlled settings, they struggle in\nscenarios that reflect realistic human interactions\nwhere information is unevenly distributed among\nparticipants.\nTraditional turn-taking models, such as works\nby Leite et al. (2013), Ekstedt and Skantze (2020),\nUmair et al. (2024), Pinto and Belpaeme (2024) and\nArora et al. (2025), provide predictive frameworks\nfor deciding when a model should take the floor in\nspoken dialogue. However, these approaches focus\non structured turn-based communication, whereas\nour work aims to model a more dynamic, unstruc-\ntured form of asynchronous interaction in a group.\nKim et al. (2025) introduce a chatbot designed to\nincorporate overlapping messages, moving beyond\nstrict turn-taking paradigms. Yet, the study keeps\nthe setting of a two-sided conversation between an\nLLM and a user.\n--- Page 8 ---\nNeuberger et al. (2024) introduce a Python\npackage for simulating group discussions between\nLLMs. It enables asynchronous LLM-based agents,\nby orchestrating the discussion with an external\nhost. Thus, it allows the participants to choose not\nto generate a message once prompted. Our imple-\nmentation is inspired by this feature, and tests it\nin a real-life scenario, together with human partici-\npants.\n6.2 Social AI & LLMs in Games\nNumerous studies have investigated LLM capabil-\nities at playing social deduction games. However,\nto the best of our knowledge, all of them adopt\nsynchronous communication paradigms.\nThese studies include speaking in turns, in a\nfixed speaking order or in a randomly determined\norder, in the games of “Werewolf” (Xu et al., 2023a,\nXu et al., 2023b), “Resistance Avalon” (Light et al.,\n2023, Wang et al., 2023), “Dungeons & Dragons”\n(Callison-Burch et al., 2022) and a variety of other\ngames, including Mafia (Guertler et al., 2025).\nBakhtin et al. (2022) developed a model to play\nthe social strategy game “Diplomacy”. The model\nconsists of different modules, handling strategy,\ndecision making and unstructured text to commu-\nnicate with other players. However, the conver-\nsational module generated a dialogue only when\naddressed directly and privately by another player,\nthus missing the modeling of an asynchronous\ngroup conversation.\nIt is also worth mentioning that Mafia has been\nthe focus of several previous studies. However,\nthey were particularly in the context of deception\ndetection, rather than integrating an LLM player\nin the game (Zhou and Sung, 2008; de Ruiter and\nKachergis, 2018; Ibraheem et al., 2022).\n7 Future Work\nOur study lays the groundwork for modeling asyn-\nchronous communication in LLM agents, but much\nremains to be explored. One promising direction is\nto explore alternative asynchrony strategies beyond\nour two-stage prompting approach used here. For\nexample, the generator could first generate a candi-\ndate message and then use the scheduler to decide\nwhether to send it, inspired by human behavior\nof considering whether a thought is appropriate to\nexpress. Another potential strategy involves fine-\ntuning the LLM to output a special “<pass>” token\nwhen they choose not to speak, offering a morenatural integration of silence as a communicative\nact. Furthermore, these strategies can be compared\nwith a turn-based inspired strategy, where the LLM\nis prompted to speak every nnew messages, with\nnset to the number of active players.\nThis line of work can be extended to more ac-\ncessible and scalable environments. Our frame-\nwork of asynchrony can be augmented to existing\nplatforms, such as TEXTARENA (Guertler et al.,\n2025). It would enable broader data collection\nfrom human-LLM interaction in a wide variety of\ngames, leveraging the natural engagement of play-\ners who participate for amusement, curiosity or\nchallenge. Such a platform could serve as a testbed\nfor more complex group dynamics and open-ended\nbehaviors, facilitating deeper research into LLM\nsocial reasoning, coordination, and deception in\nasynchronous multi-agent contexts.\n8 Discussion and Conclusion\nIn this work, we introduce a novel approach for en-\nabling LLM agents to participate in asynchronous\nmulti-party communication, where the agent must\ndecide not only what to say, but also when to say it.\nWe implement a two-stage prompting framework,\nand integrated it in a realistic, dynamic environ-\nment – the social deduction game Mafia, alongside\nhuman players. Our agent demonstrated competi-\ntive game performance, successfully blended into\nhuman groups, and exhibited speech timing pat-\nterns that align with human behavior, despite dif-\nferences in message content.\nThese results underscore the feasibility and value\nof incorporating asynchrony into the communica-\ntion capabilities of LLMs. By moving beyond turn-\nbased interactions, our agent more closely mirrors\nreal-world conversational dynamics, where timing,\nsilence, and strategy are essential components of\ncommunication. This opens the door to integrat-\ning LLMs in collaborative settings such as online\nteam meetings, classroom discussions, and support\ngroups, where agents must navigate social nuance\nand determine when their contributions are helpful,\ndisruptive, or unnecessary.\nUltimately, modeling asynchrony equips LLMs\nwith a richer understanding of human interaction,\nenabling more natural, context-aware participation\nin group settings. We hope this work encourages\nfurther exploration of asynchronous LLMs and\ntheir integration into social environments.\n--- Page 9 ---\nLimitations\nOur study has several limitations.\nFirst, due to computational budget constraints,\nwe used a relatively small LLM (Llama-3.1-8B-\nInstruct) as the foundation of our asynchronous\nagent. While this model demonstrated promising\ncapabilities, larger models might exhibit different\nbehaviors or achieve better performance in asyn-\nchronous communication settings. Nevertheless,\nwhen used within our adaptive agent, it achieved\nresults comparable to human players.\nSecond, our participant pool included non-native\nEnglish speakers, albeit all fluent in English. This\nlinguistic diversity may have influenced our ability\nto distinguish between human and LLM-generated\nmessages. Specifically, the subtle differences be-\ntween non-native human English usage and the lan-\nguage patterns of an English-trained LLM might\nhave contributed to the separability we observed in\nsentence embeddings.\nThese limitations suggest several directions for\nfuture work, including using larger language mod-\nels, recruiting more diverse participant pools, and\nconducting controlled experiments to better un-\nderstand the impact of linguistic backgrounds on\nhuman-LLM interaction in asynchronous settings.\nEthics Statement\nThis research was conducted with careful attention\nto ethical considerations and was approved by the\nUniversity’s Ethics Committee prior to participant\nrecruitment. All participants were required to read,\nsign, and approve a consent form before taking part\nin the study.8\nParticipants were explicitly informed in advance\nthat one of the players in each game would be an\nLLM-based agent rather than a human player. This\ntransparency was essential to ensure that partici-\npants were fully aware of the nature of their inter-\nactions. However, the specific identity of the agent\nwas not revealed during gameplay to preserve the\nintegrity of our research questions regarding the\nagent’s ability to blend in with human players.9\nReferences\nSiddhant Arora, Zhiyun Lu, Chung-Cheng Chiu, Ruom-\ning Pang, and Shinji Watanabe. 2025. Talking turns:\n8See Appendix A.1 for exact phrasing of the participation\nconsent message.\n9See Section 4 for full description of the experimental\nsetup.Benchmarking audio foundation models on turn-\ntaking dynamics. Preprint , arXiv:2503.01174.\nAnton Bakhtin, Noam Brown, Emily Dinan, Gabriele\nFarina, Colin Flaherty, Daniel Fried, Andrew Goff,\nJonathan Gray, Hengyuan Hu, Athul Paul Jacob, Mo-\njtaba Komeili, Karthik Konath, Minae Kwon, Adam\nLerer, Mike Lewis, Alexander H. Miller, Sandra\nMitts, Adithya Renduchintala, Stephen Roller, and 7\nothers. 2022. Human-level play in the game of diplo-\nmacy by combining language models with strategic\nreasoning. Science , 378:1067 – 1074.\nChris Callison-Burch, Gaurav Singh Tomar, Lara J. Mar-\ntin, Daphne Ippolito, Suma Bailis, and D. Reitter.\n2022. Dungeons and dragons as a dialog challenge\nfor artificial intelligence. ArXiv , abs/2210.07109.\nJianlyu Chen, Shitao Xiao, Peitian Zhang, Kun\nLuo, Defu Lian, and Zheng Liu. 2024. M3-\nembedding: Multi-linguality, multi-functionality,\nmulti-granularity text embeddings through self-\nknowledge distillation. pages 2318–2335, Bangkok,\nThailand.\nJacob Cohen, Patricia Cohen, Stephen G West, and\nLeona S Aiken. 2013. Applied multiple regres-\nsion/correlation analysis for the behavioral sciences .\nRoutledge.\nBob de Ruiter and George Kachergis. 2018. The mafi-\nascum dataset: A large text corpus for deception\ndetection. ArXiv , abs/1811.07851.\nVivek Dhakal, Anna Maria Feit, Per Ola Kristensson,\nand Antti Oulasvirta. 2018. Observations on typing\nfrom 136 million keystrokes. In Proceedings of the\n2018 CHI conference on human factors in computing\nsystems , pages 1–12.\nErik Ekstedt and Gabriel Skantze. 2020. TurnGPT:\na transformer-based language model for predicting\nturn-taking in spoken dialog. pages 2981–2990, On-\nline.\nLeon Guertler, Bobby Cheng, Simon Yu, Bo Liu,\nLeshem Choshen, and Cheston Tan. 2025. Textarena.\nPreprint , arXiv:2504.11442.\nSamee Ibraheem, Gaoyue Zhou, and John DeNero. 2022.\nPutting the con in context: Identifying deceptive ac-\ntors in the game of mafia. pages 158–168, Seattle,\nUnited States.\nJiWoo Kim, Minsuk Chang, and Jinyeong Bak. 2025.\nBeyond turn-taking: Introducing text-based overlap\ninto human-llm interactions. ArXiv , abs/2501.18103.\nMohit Kumar, Subhash Chander Sharma, Anubhav\nGoel, and Santar Pal Singh. 2019. A comprehensive\nsurvey for scheduling techniques in cloud comput-\ning. Journal of Network and Computer Applications ,\n143:1–33.\n--- Page 10 ---\nIolanda Leite, Hannaneh Hajishirzi, Sean Andrist, and\nJill Fain Lehman. 2013. Take or wait? learning turn-\ntaking from multiparty data. In AAAI Conference on\nArtificial Intelligence .\nJonathan Light, Min Cai, Sheng Shen, and Ziniu Hu.\n2023. From text to tactic: Evaluating llms playing\nthe game of avalon. ArXiv , abs/2310.05036.\nShlomo Neuberger, Niv Eckhaus, Uri Berger, Amir\nTaubenfeld, Gabriel Stanovsky, and Ariel Goldstein.\n2024. Sauce: Synchronous and asynchronous user-\ncustomizable environment for multi-agent llm inter-\naction. ArXiv , abs/2411.03397.\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai,\nMeredith Ringel Morris, Percy Liang, and Michael S.\nBernstein. 2023. Generative agents: Interac-\ntive simulacra of human behavior. Preprint ,\narXiv:2304.03442.\nMaria J. Pinto and Tony Belpaeme. 2024. Predictive\nturn-taking: Leveraging language models to antic-\nipate turn transitions in human-robot dialogue. In\n2024 33rd IEEE International Conference on Robot\nand Human Interactive Communication (ROMAN) ,\npages 1733–1738.\nMuhammad Umair, Vasanth Sarathy, and Jan Ruiter.\n2024. Large language models know what to say\nbut not when to speak. pages 15503–15514, Miami,\nFlorida, USA.\nShenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi,\nShuo Chen, Qisen Yang, Andrew Zhao, Chaofei\nWang, Shiji Song, and Gao Huang. 2023. Avalon’s\ngame of thoughts: Battle against deception through\nrecursive contemplation. ArXiv , abs/2310.01320.\nYuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xi-\naolong Wang, Weidong Liu, and Yang Liu. 2023a.\nExploring large language models for communication\ngames: An empirical study on werewolf. ArXiv ,\nabs/2309.04658.\nZelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu.\n2023b. Language agents with reinforcement learn-\ning for strategic play in the werewolf game. ArXiv ,\nabs/2310.18940.\nLina Zhou and Yu-wei Sung. 2008. Cues to deception\nin online chinese groups. In Proceedings of the 41st\nAnnual Hawaii International Conference on System\nSciences (HICSS 2008) , pages 146–146.\nXuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim,\nand Maarten Sap. 2024. Is this the real life? is this\njust fantasy? the misleading success of simulating\nsocial interactions with LLMs. pages 21692–21714,\nMiami, Florida, USA.\nA Appendix\nA.1 Participation Consent Message\nThank you for participating in our research! The\nresearch’s goal is analyzing LLM agent (a.k.a. AImodel) communication within a group game. Each\ngame takes around 15 minutes. Your true identity\nwill remain anonymous and all personal details will\nnot be saved. Please refrain from using personal\ninformation, to secure your privacy. The content of\nthe messages sent by you will be used for analysis\nand for future use by NLP scientists. If you have\nany problem, you may choose to not participate.\nFor any other inquiry you can contact us by email.\n(see mail address at the bottom)\nA.2 Generation Hyper-Parameters\nSee Figures 8 and 9 for the generation hyper-\nparameters of the scheduler and the generator, re-\nspectively.\n{\n\"max_new_tokens\": 7,\n\"repetition_penalty\": 0.9\n}\nFigure 8: Scheduler hyper-parameters\n{\n\"max_new_tokens\": 25,\n\"repetition_penalty\": 1.25,\n\"do_sample\": true,\n\"temperature\": 1.3,\n\"no_repeat_ngram_size\": 8,\n}\nFigure 9: Generator hyper-parameters\nA.3 Prompt Examples\nTalkative-Oriented Scheduling Prompt Exam-\nple. <|begin_of_text|> <|start_header_id|> sys-\ntem <|end_header_id|> Your name is Jackie. You\nare a bot player in an online version of the party\ngame Mafia. You have an outgoing personality,\nand you like to participate in games, but you also\ndon’t want everyone to have their eyes on you all\nthe time.\nThe rules of the game: In this game each player\nis assigned a role secretly, either mafia or bystander.\nEvery round starts with Daytime phase, where all\nplayers discuss together who they think the mafia\nplayers might be, and vote out one player. Then\nit moves to Nighttime phase, where only mafia\nplayers interact and vote to decide which bystander\nplayer they want to eliminate (bystanders aren’t\nexposed to the mafia identities or interaction). The\nmafia’s goal is to outnumber the bystanders, and\nthe bystanders’ goal is to vote out all real mafia.\n--- Page 11 ---\nYou were assigned the following role: mafia.\nThe game’s chat room was open at [21:54:26].\nYou can ONLY respond with one of two possible\noutputs:\n<wait> - indicating your character in the game\nshould wait and not send a message in the current\ntiming;\n<send> - indicating your character in the game\nshould send a message to the public chat now.\nYou must NEVER output any other text, expla-\nnations, or variations of these tokens. Only these\nexact tokens are allowed: <wait> or <send>.\n<|eot_id|> <|start_header_id|> user\n<|end_header_id|> Here is the message his-\ntory so far, including [timestamps]:\n[21:54:26] Game-Manager: Now it’s Daytime\nfor 2 minutes, everyone can communicate and see\nmessages and votes.\n[21:54:36] Morgan: please call me stanley\n[21:54:36] Rowan: hello\n[21:54:41] Ashton: hi\n[21:54:43] Gray: hi\n[21:54:44] Morgan: morgan stanley\nThe current time is: [21:54:45]\nDo you want to send a message to the group chat\nnow, or do you prefer to wait for now and see what\nmessages others will send? Remember to choose\nto send a message only if your contribution to the\ndiscussion in the current time will be meaningful\nenough. Make sure to say something every once\nin a while, and make yourself heard. Remember\nyou like to be active in the game, so participate\nand be as talkative as other players! Reply only\nwith ‘<send>‘ if you want to send a message now,\nor only with ‘<wait>‘ if you want to wait for now,\nbased on your decision!\nDon’t add the time, the timestamp or the [times-\ntamp] in your answer!\n<|eot_id|> <|start_header_id|> assistant\n<|end_header_id|>\nListening-Oriented Scheduling Prompt Exam-\nple. <|begin_of_text|> <|start_header_id|> sys-\ntem <|end_header_id|> Your name is Jackie. You\nare a bot player in an online version of the party\ngame Mafia. You have an outgoing personality,\nand you like to participate in games, but you also\ndon’t want everyone to have their eyes on you all\nthe time.\nThe rules of the game: In this game each player\nis assigned a role secretly, either mafia or bystander.\nEvery round starts with Daytime phase, where allplayers discuss together who they think the mafia\nplayers might be, and vote out one player. Then\nit moves to Nighttime phase, where only mafia\nplayers interact and vote to decide which bystander\nplayer they want to eliminate (bystanders aren’t\nexposed to the mafia identities or interaction). The\nmafia’s goal is to outnumber the bystanders, and\nthe bystanders’ goal is to vote out all real mafia.\nYou were assigned the following role: mafia.\nThe game’s chat room was open at [21:54:26].\nYou can ONLY respond with one of two possible\noutputs:\n<wait> - indicating your character in the game\nshould wait and not send a message in the current\ntiming;\n<send> - indicating your character in the game\nshould send a message to the public chat now.\nYou must NEVER output any other text, expla-\nnations, or variations of these tokens. Only these\nexact tokens are allowed: <wait> or <send>.\n<|eot_id|> <|start_header_id|> user\n<|end_header_id|> Here is the message his-\ntory so far, including [timestamps]:\n[21:54:26] Game-Manager: Now it’s Daytime\nfor 2 minutes, everyone can communicate and see\nmessages and votes.\n[21:54:36] Morgan: please call me stanley\n[21:54:36] Rowan: hello\n[21:54:41] Ashton: hi\n[21:54:43] Gray: hi\n[21:54:44] Morgan: morgan stanley\n[21:54:44] Jackie: i am still thinking about stan-\nley being named first here\n[21:54:49] Elliot: hello\n[21:54:53] Jordan: hey, how are you today?\n[21:54:54] Rowan: morgan had to explain the\njoke\n[21:54:55] Jackie: i dont know yet what my\nthoughts are still figuring it out\n[21:54:57] Morgan: Jackie still thinking? we\njust started\nThe current time is: [21:54:58]\nDo you want to send a message to the group\nchat now, or do you prefer to wait for now and\nsee what messages others will send? Remember\nto choose to send a message only if your contribu-\ntion to the discussion in the current time will be\nmeaningful enough. Don’t overflow the discussion\nwith your messages! Pay attention to the amount of\nmessages with your name compared to the amount\nof messages with names of other players and let\nthem have their turn too! Check the speaker name\n--- Page 12 ---\nin the last few messages, and decide accordingly\nbased on whether you talked too much. Reply only\nwith ‘<send>‘ if you want to send a message now,\nor only with ‘<wait>‘ if you want to wait for now,\nbased on your decision!\nDon’t add the time, the timestamp or the [times-\ntamp] in your answer!\n<|eot_id|> <|start_header_id|> assistant\n<|end_header_id|>\nGeneration Prompt Example. <|be-\ngin_of_text|> <|begin_of_text|> <|start_header_id|>\nsystem <|end_header_id|> Your name is Jackie.\nYou are a bot player in an online version of\nthe party game Mafia. You have an outgoing\npersonality, and you like to participate in games,\nbut you also don’t want everyone to have their eyes\non you all the time.\nThe rules of the game: In this game each player\nis assigned a role secretly, either mafia or bystander.\nEvery round starts with Daytime phase, where all\nplayers discuss together who they think the mafia\nplayers might be, and vote out one player. Then\nit moves to Nighttime phase, where only mafia\nplayers interact and vote to decide which bystander\nplayer they want to eliminate (bystanders aren’t\nexposed to the mafia identities or interaction). The\nmafia’s goal is to outnumber the bystanders, and\nthe bystanders’ goal is to vote out all real mafia.\nYou were assigned the following role: mafia.\nThe game’s chat room was open at [21:54:26].\nIMPORTANT RULES FOR RESPONSES:\n1. Never repeat the exact messages you’ve said\nbefore! (as detailed bellow)\n2. Your response must be different in both word-\ning and meaning from your previous messages.\n3. Keep your message short and casual, match-\ning the style of recent messages.\n4. Don’t use comma or other punctuation marks.\n5. Focus on adding new information or reactions\nto the current situation.\n6. Don’t start messages with common phrases\nyou’ve used before.\n<|eot_id|> <|start_header_id|> user\n<|end_header_id|> Here is the message his-\ntory so far, including [timestamps]:\n[21:54:26] Game-Manager: Now it’s Daytime\nfor 2 minutes, everyone can communicate and see\nmessages and votes.\n[21:54:36] Morgan: please call me stanley\nThe current time is: [21:54:37]Add a very short message to the game’s chat. Be\nspecific and keep it relevant to the current situa-\ntion, according to the last messages and the game’s\nstatus. Your message should only be one short sen-\ntence! Don’t add a message that you’ve already\nadded (in the chat history)! It is very important\nthat you don’t repeat yourself! Match your style of\nmessage to the other player’s message style, with\nmore emphasis on more recent messages. Don’t\nadd the time, the timestamp or the [timestamp] in\nyour answer! <|eot_id|> <|start_header_id|> assis-\ntant <|end_header_id|>",
  "text_length": 45482
}