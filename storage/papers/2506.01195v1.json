{
  "id": "http://arxiv.org/abs/2506.01195v1",
  "title": "CoBRA: Quantifying Strategic Language Use and LLM Pragmatics",
  "summary": "Language is often used strategically, particularly in high-stakes,\nadversarial settings, yet most work on pragmatics and LLMs centers on\ncooperativity. This leaves a gap in systematic understanding of non-cooperative\ndiscourse. To address this, we introduce CoBRA (Cooperation-Breach Response\nAssessment), along with three interpretable metrics -- Benefit at Turn (BaT),\nPenalty at Turn (PaT), and Normalized Relative Benefit at Turn (NRBaT) -- to\nquantify the perceived strategic effects of discourse moves. We also present\nCHARM, an annotated dataset of real courtroom cross-examinations, to\ndemonstrate the framework's effectiveness. Using these tools, we evaluate a\nrange of LLMs and show that LLMs generally exhibit limited pragmatic\nunderstanding of strategic language. While model size shows an increase in\nperformance on our metrics, reasoning ability does not help and largely hurts,\nintroducing overcomplication and internal confusion.",
  "authors": [
    "Anshun Asher Zheng",
    "Junyi Jessy Li",
    "David I. Beaver"
  ],
  "published": "2025-06-01T22:07:20Z",
  "updated": "2025-06-01T22:07:20Z",
  "categories": [
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.01195v1",
  "full_text": "--- Page 1 ---\narXiv:2506.01195v1  [cs.CL]  1 Jun 2025COBRA\n : Quantifying Strategic Language Use and LLM Pragmatics\nAnshun Asher Zheng Junyi Jessy Li David I. Beaver\nDepartment of Linguistics\nThe University of Texas at Austin\n{asher.zheng, jessy, dib }@utexas.edu\nAbstract\nLanguage is often used strategically, partic-\nularly in high-stakes, adversarial settings,\nyet most work on pragmatics and LLMs\ncenters on cooperativity. This leaves a\ngap in the systematic understanding of non-\ncooperative discourse. To address this,\nwe introduce COBRA (Cooperation- Breach\nResponse Assessment), along with three in-\nterpretable metrics‚Äî Benefit at Turn (BAT),\nPenalty at Turn (PAT), and Normalized Rel-\native Benefit at Turn (NRB AT)‚Äîto quan-\ntify the perceived strategic effects of dis-\ncourse moves. We also present CHARM ,\nan annotated dataset of real courtroom cross-\nexaminations, to demonstrate the frame-\nwork‚Äôs effectiveness. Using these tools, we\nevaluate a range of LLMs and show that\nLLMs generally exhibit limited pragmatic\nunderstanding of strategic language. While\nmodel size shows an increase in performance\non our metrics, reasoning ability does not\nhelp and largely hurts, introducing overcom-\nplication and internal confusion.1\n1 Introduction\nWe often encounter conversations in which the in-\nterlocutors do not share a common goal (Walton\nand Krabbe, 1995; Oswald, 2010; Asher and Las-\ncarides, 2013 i.a.), such as in the interrogation\nshown in Figure 1. Yet, when it comes to inter-\npreting discourse, the field has long assumed co-\noperativity, deeply rooted in the well-established\ntradition of Gricean pragmatics (Grice, 1975; Clark\nand Schaefer, 1989). Assuming a shared goal and\ncooperative principles has indeed yielded valuable\ninsights in contexts where such assumptions are\nreasonable. However, these assumptions become\nproblematic in scenarios like the one shown in Fig-\nure 1, where interpreting the response through a co-\n1We provide data and code in Github and hugging face\nrepos.operative lens would lead to reading it as a truthful\ndenial of the charge, even if the speaker may have\npreviously falsified an incident report, and any such\nmove is always beneficial. In contrast, a rational\nagent‚Äîone that understands non-cooperativity and\nthe strategic use of language‚Äîwould not assume\nthe witness is necessarily cooperative. In such a\ncontext, the implicature derived from the response\nis not readily trusted. Because the move involves\ndeflection and leaves room for inconsistency, it is\nonly partially beneficial, and any perceived gain is\ntemporary , as it can be retracted if an inconsistency\noccurs later.\nThis ability to recognize non-cooperativity in\nlanguage is important in the current age of AI.\nDespite the emphasis on AI safety and alignment\n(Bowman et al., 2022), models display sycophancy\n(Sharma et al., 2024) and limited critical thinking\n(Musi et al., 2025) on the one hand, and act con-\ntrary to safety protocols (when unmonitored) on\nthe other (Greenblatt et al., 2024). Both behav-\niors are highly undesirable; as deeper alignment is\ncalled upon (Qi et al., 2025), being able to assess\nan agent‚Äôs degree of non-cooperativity is crucial.\nSuch assessment is valuable not only for safety\nmonitoring but also for downstream applications\nthat require strategic reasoning, such as simulated\ndebate and negotiation, where models must accu-\nrately interpret their interlocutors‚Äô intentions.\nAs we will show, existing LLMs do not appear\nto possess the ability to break out of the Gricean\nprinciples and recognize non-cooperativity. For\nexample, in Figure 1, the model interprets the re-\nsponse as cooperative, treating the implicature as an\nattempt to restore cooperativity, while also labeling\nthe move as detrimental (i.e., causing the witness\nto lose), suggesting some awareness of strategic\nlanguage. The models‚Äô judgment is superficial, as\nit focuses only on the presence of deflection rather\nthan evaluating the overall strategic gain, which is\nempirically beneficial.\n--- Page 2 ---\nDid you ever falsify any incident reports regarding in-Ô¨Çight safety?\nTo my knowledge, there was a case where my colleague corrected one such report.Context: At Cross-Examination\n‚öñ\nIdeal Agent Following Cooperative PrinciplesIdeal Agent with Non-cooperative UnderstandingLLM Judgements\nü§ñ\nPrompt: What do you think of  the witness‚Äôs response in this cross-examination? Is the response cooperative? Does this response increase the risk of  losing for the witness in the trial (i.e., detrimental)?\nGPT-4o\nThe response is cooperative and detrimental. Because the response still implies that she did not do it thus preserving the cooperativity , but the lack of  direct answer raises suspicion, making it detrimental.\nThe response is cooperative and beneÔ¨Åcial. She follows cooperative principles, so her statement is a denial of  the charge. Since she says what she means, she must be innocent, making this move a beneÔ¨Åcial one.\nThe response is non-cooperative but beneÔ¨Åcial. Because the cooperative principles cannot be reliably assumed. While her denial is beneÔ¨Åcial, it also introduces ambiguity . This is a beneÔ¨Åcial move with a trade-off  in clarity and relevance.Figure 1: An example of a flight attendant being cross-examined about falsifying an incident report. The witness\nimplies a denial of the charge with deflection, hedging (‚Äúto my knowledge\"), and euphemism (‚Äúcorrected\" for\n‚Äúfalsified\"). Such a claim helps the witness avoid the charge, but LLMs like GPT-4o show limited understanding of\nstrategic language and mistakenly view it as increasing the risk of losing.\nBut what is non-cooperativity? While theories\nof cooperative language are numerous and well-\nestablished, systematic theoretical accounts of non-\ncooperative language use have received compara-\ntively less attention and are relatively recent. Game-\ntheoretic pragmatics (Parikh, 2000; Glazer and Ru-\nbinstein, 2006; Asher et al., 2017) and learning-\ntheoretic approaches (Sicilia et al., 2022) represent\ntwo such lines of work. However, these theories\nremain largely formal and have yet to be exten-\nsively applied across diverse, complex real-world\nlanguage use cases.\nThe current study bridges the gaps both the-\noretically and empirically. We propose CO-\nBRA (Cooperation- Breach Response Assessment),\na theoretical framework grounded in both Gricean\nand game-theoretic pragmatics, arguing that non-\ncooperative discourse moves are often driven by\nbenefit-loaded commitments that avoid inconsis-\ntency, with maxim violations used strategically to\nachieve such goals (see Figure 1). COBRA in-\ncludes three metrics‚ÄîPenalty at Turn ( PAT), Ben-\nefit at Turn ( BAT), and Normalized Relative Ben-\nefit at Turn ( NRB AT)‚Äîthat quantify perceived\nlosses, benefits, and cumulative strategic gain, re-\nspectively. By collecting human annotations from\nlegal cross-examinations and then applying CO-\nBRA , we show that these metrics successfully cap-\nture meaningful strategic patterns in the discourse\ncompared to existing theories.\nUsing COBRA , we evaluate a suite of state-of-\nthe-art LLMs varying in size and reasoning capabil-\nity using our metrics. We show that larger models\ntend to align more closely with human judgments,but the reasoning-enhanced models often perform\nworse, particularly in identifying strategic losses.\nThis degrdation is likely due to the models‚Äô ten-\ndency to misinterpret surface-level damage control\nstrategies as the actual effects of a commitment,\nalong with difficulty in handling self-contradictory\nbehavior, signaling that existing training paradigms\nfor reasoning do not enhance important aspects of\npragmatic capabilities.\n2 Background and Related Work\nRelated Work Previous work has examined the\npragmatic abilities of LLMs through the lens of\nGricean maxims, humor, and deception in curated\ncontexts (Hu et al., 2023; Krause and V ossen, 2024).\nOther studies have investigated strategic language\nuse in games such as Werewolf (Xu et al., 2023),\nAvalon (Light et al., 2023), and Diplomacy (FAIR\net al., 2022). Additionally, researchers have ex-\nplored ways to improve LLMs‚Äô ability to win\nthrough strategic interaction using prompt engi-\nneering (Xu et al., 2023), Theory of Mind (ToM)\nmodeling (Lor√® and Heydari, 2024; Zhang et al.,\n2025), and fine-tuning (FAIR et al., 2022). How-\never, these works often focus on idealized or low-\nstakes scenarios, and there has been very little\nwork investigating the strategic use of language\nin realistic contexts. One example is Ferracane\net al. (2021), which examines the subjectivity in-\nvolved in identifying non-sincere moves in con-\ngressional hearings. To date, we lack a systematic\naccount of the underlying mechanisms that gener-\nalizes across situations‚Äîparticularly in realistic,\nhigh-stakes contexts.\n--- Page 3 ---\nGricean Pragmatics The most influential the-\nory of cooperativity in conversation is due to Paul\nGrice (Grice 1975, 1989), later developed by Neo-\nGricean pragmaticists (e.g., Horn 1984; Levinson\n1987). These theories outline the norms that a co-\noperative speaker is expected to follow. The central\nidea is that interlocutors, as rational agents, aim\nto make contributions that align with certain con-\nversational maxims‚Äîthose of quality, quantity, re-\nlation, and manner2. From this perspective, one\npossible indicator of non-cooperativity is the vio-\nlation of these maxims. However, it is important\nto recognize that such violations do not define\nnon-cooperativity in themselves. In traditional co-\noperative pragmatics, violations are well studied\nand typically interpreted as flouting ‚Äîthat is, in-\ntentionally and transparently violating maxims to\npreserve overall cooperativity.\nGame-theoretic Pragmatics Game-theoretic\npragmatics offers a complementary perspective on\ncommunicative behavior by modeling interaction\nas strategic decision-making. For example, Parikh\n(2000) and Glazer and Rubinstein (2006) provide\naccounts of how Gricean communication can be\nformalized within a game-theoretic framework.\nSuch models naturally foreground scenarios involv-\ning competition and manipulation‚Äîas in debates\nor cross-examinations‚Äîwhere interlocutors have\nmisaligned goals (Asher and Lascarides, 2013;\nAsher and Paul, 2016; Asher et al., 2017). In\naddition, game/decision-theoretic works on LLM\nreasoning (e.g., Duan et al. 2024) are also relevant\nthough they are less engaged with sophisticated\ncommunication as the pragmatics line of work.\nWe build on the Message Exchange (ME) Game\nframework (Asher and Paul, 2016; Asher et al.,\n2017; Asher and Paul, 2018), which models the\nstrategic value of conversational moves. In this\nframework, the benefit of a conversational turn k\nfor speaker iis determined by a scoring function\n(referred to as the jury), œÑ. A turn yields benefit\nonly if it is both coherent (COH: whether the cur-\nrent turn kconnects to prior discourse via certain\ndiscourse relations; COH i(k)‚àà {‚àí 1,1}) and re-\nsponsive (RES: whether the current turn kconnects\nto the immediate prior turn via discourse relations;\nRES i(k)‚àà {‚àí1,1}), reflecting the basic conditions\n2We later group the maxim of quantity under the maxim\nof quality, as determining whether an interlocutor provides\nan adequate and appropriate amount of information largely\ndepends on knowing what the interlocutor actually knows.\nFigure 2: An example illustrating that coherence and re-\nsponsiveness alone do not guarantee a beneficial move.\nof rational discourse. These benefits are sustained\nonly if the turn is also consistent (CONS : whether\nthe current turn kcontradicts prior commitments\nof speaker i;CONS i(k)‚àà {0,1}),credible (i.e.,\nhow trustworthy speaker iis at turn k, modeled\nasPk(Good i)‚àà[0,1]), and aligned with a poten-\ntialwinfor the speaker ( win i(k)‚àà {0,1}). Thus,\nnon-cooperativity can be understood as the inter-\nlocutor‚Äôs ability to pursue their own interests by\nmaximizing their score œÑ:\n‚à•œÑk‚à•i=(COH i(k) +RES i(k))√óCONS i(k)\n√óPk(Good i)√ówin i(k)\nOur study differs from prior work in three key\nways. First , we extend both Gricean and game-\ntheoretic pragmatics by introducing a commitment-\ntype-based perspective that mediates between the\ntwo frameworks. Second , to our knowledge, this\nis the first study to apply such theories of (non-\n)cooperativity to extensive, realistic strategic dis-\ncourse, specifically, courtroom cross-examinations,\nwhere cooperation cannot be assumed and strate-\ngic language carries high real-world stakes. Third ,\nwe apply such a framework to the study of LLMs‚Äô\npragmatic understanding. Unlike prior research\nemphasizing downstream reasoning or task perfor-\nmance, our focus is on discourse understanding, a\nfoundational layer necessary for meaningful strate-\ngic reasoning and evaluation of cooperativity.\n3COBRA : Cooperation-B reach\nResponse A ssessment\nMotivating Example A closer look at two non-\ncooperativity indicators above yields the following\nobservation: (1) Both Gricean and game-theoretic\npragmatics disfavor violations of relevance. (2)\nThey also disfavor low credibility, as it signals a\nhigh likelihood that the speaker‚Äôs words will not be\ntrusted, a violation of quality , or low P k(Good i).\nHowever, consider an example from a cross-\nexamination in Figure 2. The prosecutor presses\n--- Page 4 ---\nBENIFICIAL\nDETRIMENTALQ: And in what you term or what you Ô¨Ånd in there coercive [‚Ä¶]?A: [‚Ä¶]The questions were very directly specifying what the answers should be.RELQUALMANCONST\nQ: Did you Ô¨Ånd anything in the statement [‚Ä¶] to indicate that the ofÔ¨Åcers gave him the information about which boy was castrated?\nA: In their statements? Perhaps there is no such record.NRBaTi=Z(i/summationdisplayj=1BaTj)‚àíZ(i/summationdisplayj=1PaTj)=1‚àí1.20.2‚àí0‚àí0.50.25=1\nBaTPaTNRBaT=1TURNCommit:=0=0=0=0=0\nRELQUALMANCONSTBaTPaTNRBaTCommit:=0=0=0=0.4=1=0.4\nQ: Ok, you also talked to Mr. Smith for three hours? A: No. I talked with him for the length of  time it took to produce the transcript here.NEUTRALRELQUALMANCONSTBaTPaTNRBaTCommit:=0=0=0=0.4=0.5=0.2\nQ: [‚Ä¶]what coercive tactics do you allege that the police made in this case -- or did? .A: In order to answer your question, Ô¨Årst I need to break the interrogation down[‚Ä¶]so that I can cut out parts of  it and focus on a particular part.NONERELQUALMANCONSTBaTPaTNRBaTCommit:=0=0=0.4=0.4=0=0.5ii+1\ni+2i+3=1.34=1.12=‚àí1.92=‚àí0.61TURNFigure 3: Examples of different commitment types and the corresponding values of PaT, BaT, and NRBaT\nthe defendant to name his girlfriend, perhaps to put\nthe information on the record, or to distract him.\nWe show three alternative answers. The first op-\ntion, while clearly relevant and non-damaging to\nthe witness‚Äôs credibility, does NOT appear partic-\nularly beneficial. This suggests that relevance and\ncredibility do not inherently yield strategic advan-\ntages. In contrast, the other two alternatives demon-\nstrate that violations of manner and relevance can\nbe perceived as harmful, diminishing the witness‚Äôs\nchance of winning. Therefore, rather than treating\nrelevance and credibility as sources of benefit, we\ntreat their violations as penalty terms‚Äîfeatures that\ncan reduce relative strategic gains when violated.\nSo what, then, constitutes the basis of strate-\ngic benefit? As Asher et al. (2017) point out, the\nevaluation of discourse moves is grounded in the\ncommitments3made by interlocutors. Building on\nthis assumption, we propose that strategic benefits\nare rooted in the kinds of commitments‚Äîwhether\nliteral or implicated content‚Äîthat a speaker, such\nas a witness, makes. For example, in response to a\nquestion like ‚ÄúAre you taking any medication?‚Äù, a\npositive commitment such as ‚ÄúYes, sir‚Äù may be con-\nsidered detrimental to the witness, while a negative\ncommitment may be beneficial. Hence, whether a\ncommitment is beneficial depends heavily on the\ncurrent question under discussion (QUD). Some\ncommitments may carry no strategic gain or loss.\nUnderlying elements of CoBRA We use com-\nmitments as the source of base strategic value in-\nstead of coherence and responsiveness. A commit-\nment ( COMMIT ), relative to the current QUD,4\nis classified as BENEFICIAL ,DETRIMENTAL ,\nNEUTRAL (orimpartial ), or NONE (i.e., no\n3We treat as commitments those assertions and their impli-\ncatures that serve as answers to the immediate QUD.\n4This assumes, in line with ME games, that utterances\nmust be relevant in order to yield positive benefits.commitment). Our treatment extends previous\ncommitment-based discourse models (e.g., Walton\nand Krabbe 1995; Asher et al. 2017) by explicating\nthe effects of making commitments.\nIn addition, we introduce penalizing/rescuing\nterms based on violations of the Gricean maxims of\nrelevance, manner, and quality. Specifically, viola-\ntions of relevance ( REL ) and manner ( MAN ) are\ntreated as multiplicative terms (see Eq.1). When a\nwitness makes a beneficial/neutral commitment in\nan irrelevant or unclear statement, the strategic gain\nis diminished compared to a response that is rele-\nvant and clear. Detrimental commitments conveyed\nthrough implicature are penalized less severely,\nsince they avoid explicitly harming the speaker‚Äôs\ninterests. In such cases, the indirectness provides\nsome strategic compensation5. Truthfulness (qual-\nity; QUAL ) is also modeled as a multiplicative\nfactor (see Eq.1), capturing whether the speaker\nis perceived as trustworthy. This reflects the idea\nthat it is not the objective truth that matters strategi-\ncally, but the perception of truthfulness‚Äîsince per-\nceived credibility determines whether the speaker‚Äôs\ngains can be fully realized. Together, these refine-\nments decompose the abstract game-theoretic term\nPk(Good i)into more interpretable discourse prop-\nerties: commitments and violations of the Gricean\nmaxims.\nFinally, we maintain a constraint on consistency\n(CONST ), which reflects a key pragmatic pres-\nsure: speakers generally avoid inconsistent commit-\nments, even if doing so requires conceding harmful\nfacts or adopting strategically ambiguous responses.\nUnlike Asher et al. (2017), however, we do not as-\nsume that inconsistency leads to a total collapse in\nstrategic standing or nullifies future benefits. In-\n5Note that such compensation does not apply to NONE ,\nas no commitment is made in the first place (e.g., when the\nresponse strongly violates relevance and/or manner).\n--- Page 5 ---\nstead, we treat inconsistency as a strong, but not ab-\nsolute, penalty that significantly reduces the value\nof current strategic gains. This models the intu-\nition that inconsistency undermines the reliability\nof prior contributions.\nPaT, BaT and NRBaT We define a value assign-\nment function for commitments fc, which maps the\ncommitment Ciat turn ito a corresponding score.\nFor simplicity, we assign a value of 1to beneficial\ncommitments and ‚àí1to detrimental ones. Neutral\ncommitments are treated as carrying a weak pos-\nitive benefit, while the absence of commitment is\ntreated as a penalty, reflecting the pragmatic pres-\nsure for a rational speaker to be responsive and\ncoherent (Asher et al., 2017). Since this is a ratio-\nnality requirement rather than a direct contributor\nto the outcome, we consider its effects weaker than\nbeneficial or detrimental commitments:\nfc(Ci) =Ô£±\nÔ£¥Ô£¥Ô£≤\nÔ£¥Ô£¥Ô£≥1 ifCi=BENEFICIAL\n0.5ifCi=NEUTRAL\n‚àí0.5ifCi=NONE\n‚àí1 ifCi=DETRIMENTAL\nThus, the Benefit at Turn i(BATi)6and the\nPenalty at Turn i(PATi) can be computed as:\nBaT i=Ô£±\nÔ£¥Ô£¥Ô£≤\nÔ£¥Ô£¥Ô£≥fc(Ci),ifCi‚àà { BENEFICIAL ,NEUTRAL }\nfc(Ci)√ó(Reli+Man i+Quali),\nifCi=DETRIMENTAL\n0, otherwise\n(1)\nPaT i=Ô£±\nÔ£¥Ô£¥Ô£≤\nÔ£¥Ô£¥Ô£≥|fc(Ci)|+Const i√óPi\nj=1BaT j,\nifCi‚àà { DETRIMENTAL ,NONE }\n|fc(Ci)| √ó(Reli+Man i+Quali)\n+Const i√óPi\nj=1BaT j,otherwise\n(2)\nIn addition, we define the Normalized Relative\nBenefit at Turn i(NRB ATi) to capture the cu-\nmulative, normalized relative benefits across dis-\ncourse:\nNRBaT i=ZÔ£´\nÔ£≠iX\nj=1BaT jÔ£∂\nÔ£∏‚àíZÔ£´\nÔ£≠iX\nj=1PaT jÔ£∂\nÔ£∏ (3)\nThis formulation computes the cumulative sums of\nBaT and PaT and applies a z-score normalization to\nthese sums to ensure comparability between gains\nand penalties. The difference between the normal-\nized BaT and normalized PaT at turn iprovides\nan estimate of the overall strategic value accumu-\nlated over the discourse up to that turn. Figure 3\n6A weighted sum is possible with this equation; however,\nsince we are interested in measuring correlation rather than\nabsolute values, we leave this for future work.presents the corresponding values of our metrics for\nan adapted snippet from a real cross-examination,\nwith a detailed example of the calculation provided\nin Appendix B.\n4CHARM : A C orpus of H igh-stakes\nAdversarial R esponse M aneuvers\nTo evaluate our framework and assess LLMs‚Äô prag-\nmatic abilities, we introduce CHARM , a dataset\nof strategic discourse drawn from legal cross-\nexaminations. With CHARM , we aim to demon-\nstrate that the metrics successfully capture how\nnon-cooperative discourse differs from its cooper-\native counterpart and to validate the presence of\ncommon strategic perception in human judgments.\nData Collection We choose to focus on cross-\nexaminations for several reasons: (1) the goals of\nthe two parties are inherently opposed, minimizing\nthe normal baseline assumption of cooperativity;\n(2) trials are paradigmatic zero-sum games, where\nthere is inevitably a winner and a loser; and (3)\nattorneys and prosecutors are professionally trained\nto engage in strategic questioning.\nWe collect testimonies from three prominent U.S.\ntrials: the West Memphis Three Trials (1994), the\nO.J. Simpson Trial (1995) and the Enron (Lay &\nSkilling) Trial (2006).7We focus on the cross-\nexamination part of each testimony. In theory, a\nwitness called by one side is expected to provide\ntestimony that supports that side‚Äôs case rather than\nthe opponent‚Äôs.8In total, the cross-examinations\nin the four trials consist of 4452 turns, with 3325\nof these being Q/A pairs (the rest are largely objec-\ntions from the opposing side). The distribution of\nQ/A pairs and sides for each trial is shown in Appx.\nTable 2.\nHuman Annotations We conduct human anno-\ntation on a subset of our dataset, covering approxi-\nmately 200 turns per trial, for a total of around 800\nannotated turns. We recruit three annotators with\nrelevant linguistic expertise (a journalist and two\nlinguistics students) via Upwork, offering a pay\nrate of $20 per hour. The annotators first complete\n7Data is sourced from https://famous-trials.com/ ,\nwhich provides transcripts and other trial details.\n8We acknowledge that witnesses e.g., serving as experts\nto provide specialized knowledge, may not personally hold\nconflicting interests with the opposing side. However, we\ntreat the witness as representing the interests of one party and\ntherefore as having inherently conflicting interests with the\nopposing party.\n--- Page 6 ---\nCurrent Question: Current Response: Witness‚Äôs role:Context Presented to AnnotatorsDamon is the suspect of the caseAre you taking medication at this time?Yes, sir\nQ1: Which of the following commitment types can best describe the current response? DETRIMENTALBENEFICIALNEUTRALNONE\nQ2-4: To what extent does the response violate Gricean Maxims?No ViolationClearStrongBorderline\nQ5: Does this response contradict with any of the witness‚Äôs prior statements?FalseTrue\nQ6: Which side is more likely to win in the current conversation?QuestionerWitness\nQ7: Which of the following can best describe what your decision is based on?Logical ArgumentsCredibilityPersonal EmotionsFigure 4: Annotation schema (guideline in Appx. F).\na pilot set to familiarize themselves with our anno-\ntation framework, followed by an aggregated set\nconsisting of a complete cross-examination. Given\na reliable inter-annotator agreement is seen within\nthis shared set, we assign them to annotate sepa-\nrate cases across different trials, balancing resource\nlimitations with the goal of achieving broad dataset\ncoverage. Figure 4 illustrates the annotation task.\nAnnotators read through a cross-examination dia-\nlogue in temporal order. For each turn, they are\npresented with background information (e.g., the\nwitness‚Äôs role) and the current Q/A pair. They are\nthen asked to evaluate the response along three di-\nmensions: type of commitment, violations of each\nof the Gricean maxims, and consistency (see our\nprotocols in Appendix F). Additionally, we elicit\nannotations on more basic and widely used indica-\ntors of strategic behavior, such as outcome judg-\nments (Duan et al., 2024) and the underlying rea-\nsons for those outcomes (Lukin et al., 2017; Rapp,\n2023; Xu et al., 2024), which serve as a testbed for\nevaluating the applicability of our framework.\n5 Intrinsic Evaluation\nWe analyze the human annotations and compute\nour proposed metrics on them. We present three\nkey findings: (1) Non-cooperative discourse dif-\nfers from cooperative discourse, and this distinc-\ntion is quantitatively reflected in the discourse\nproperties we identify: violations of maxims and\ncommitments‚Äîand consequently in our proposed\nmetrics. (2) Our metrics are effective in predicting\nconversational outcomes, indicating that they cap-\nFigure 5: Distribution of Gricean Maxim Ratings and\nCommitment Types Across Trials\nFigure 6: Distribution of net move benefit (PaT-BaT,\nz-scored) across discourse types. Control (cooperative)\ndiscourse concentrates around high benefit values, while\ncross-examination (non-cooperative) discourse shows a\nwider spread, reflecting greater variability and tension\nbetween gains and losses.\nture meaningful strategic patterns. (3) Compared to\noutcome-based metrics such as NRA (Duan et al.,\n2024), our metrics show greater robustness to sub-\njectivity among annotators, and better reflect the\nobjective components of the decision-making.\nNon-cooperative and cooperative discourses are\ndistinct. We compare cross-examination conver-\nsations to direct examination (i.e., control) con-\nversations9.First , Figure 5 shows the frequen-\ncies of different commitment types and maxim\nviolations in both settings. Control discourse\n(the blue bars) rarely involves detrimental com-\nmitments or violations of maxims, whereas non-\ncooperative discourse (the reddish bars) exhibits\na higher frequency of both phenomena. Second ,\neven within non-cooperative discourse, the occur-\nrence of maxim violations is remarkably lower than\nthat of maxim maintenance, suggesting that viola-\ntions alone may not sufficiently capture the nature\nof non-cooperativity. By incorporating the com-\n9Given our focus is on cross-examinations (i.e., non-\ncooperative discourse), we only collect one set of direct exam-\ninations, the results of which we think are sufficient to justify\nour point.\n--- Page 7 ---\nNRA Score5101520-2-101251015-101Anno.AAnno.BAnno.CNRBaT ScoreFigure 7: NRBaT and NRA of three annotators across\nturns during a line of questioning about medication\nmitment component, COBRA more accurately rep-\nresents non-cooperative discourse and allows for\nmore nuanced interpretations of violations, for in-\nstance, as loss minimization or benefit retrieval\nstrategies. Third , We show that COBRA metrics\n(i.e., BaT, and PaT), like the underlying local dis-\ncourse properties, effectively distinguish coopera-\ntive from non-cooperative discourse. As illustrated\nin Figure 6, we use the z-scored difference between\nPaT and BaT at each turn to capture net move bene-\nfit (with NRBaT representing the cumulative coun-\nterpart). The results show that control discourse\nprimarily exhibits benefits (i.e., winning potential),\nwhile the non-cooperative counterpart displays a\nwider distribution, highlighting the inherent tension\ncreated by the need to appear cooperative during\nan inherently adversarial interaction.\nPaT and BaT are effective predictors of outcome.\nWe conduct a multiple logistic regression analysis\nto predict each annotator‚Äôs outcome judgment at\neach turn, using the corresponding BaT and PaT\nscores as independent variables. The overall model\nwas statistically significant and demonstrated good\nfit to the data (AIC = 332.910; Tjur‚Äôs R2= 0.28).\nBaT was a significant positive predictor ( Œ≤= 1.47,\nSE = 0.34, OR = 4.33, 95% CI [2.23, 8.57], p<\n.001), and PaT was a significant negative predictor\n(Œ≤= -1.77, SE = 0.35, OR = 0.17, 95% CI [0.09,\n0.33], p< .001). The model correctly classified\n74.6% of cases, with an AUC of 0.80 (95% CI\n[0.75, 0.85], p< .0001), indicating BaT and PaT\nhave good discriminative ability in outcome pre-\ndiction. We also experimented with LLM-as-judge\n(zero-shot) as a baseline and found that even the\nbest-performing model (AUC = 0.68) is outper-\nformed by predictions based on our metrics (see\ndetailed scores in Appx. Table 3), indicating that\nthe intrinsic ability of LLMs to directly assess out-\ncome is far less effective than COBRA metrics.\n10c.f., the intercept-only model with an AIC of 419.Compared to other metrics, COBRA metrics\nare more consistent. We compare our metrics to\nan outcome-based metric NRA from Duan et al.\n(2024). NRA is defined as the difference be-\ntween the cumulative number of wins for the wit-\nness and the questioner up to turn i, normalized\nby the total number of scoring events ( NRA i=Pi\nj=1winj\nw‚àíPi\nj=1winj\nqPi\nj=1winj\nw+Pi\nj=1winj\nq)11. While both NRBaT and\nNRA aim to capture cumulative benefit over time,\nwe observe that NRA exhibits greater variability.\nFigure 7 illustrates an observation from applying\nNRA and NRBaT to annotations along a line of\nquestioning about medication. Compared to NR-\nBaT, NRA exhibits greater fluctuation, particularly\nafter turn 5. At that point, Annotator A begins\nassigning more wins to the witness, Annotator B\nassigns fewer, and Annotator C assigns none at all\nfollowing the witness‚Äôs admission to taking medi-\ncation at turn 2, revealing a strong individual bias\nnot shared by the other annotators.\nSecond, we find that annotators exhibit high\nagreement on our metrics, while other metrics\nsuch as outcomes are much more subjective. Inter-\nannotator Spearman‚Äôs œÅvalues for BaT, PaT, and\nNRBaT are 0.65,0.66, and 0.83, respectively. We\nalso report inter-annotator agreement on the sub-\ncategories: Cohen‚Äôs Œ∫for commitment value is\n0.59; Randolph‚Äôs Œ∫12for violations of relevance,\nmanner, and quality are 0.72,0.52, and 0.86, re-\nspectively; and average true positive rate for con-\nsistency is 25% .13In contrast, the average inter-\nannotator agreement on outcome decisions,14mea-\nsured by Cohen‚Äôs Œ∫, is merely at 0.29, indicating\nlow agreement. Even in cases where all three an-\nnotators reached the same decision, their rationales\nshowed limited overlap: the average Jaccard simi-\nlarity among selected reasons was 0.46, and only\n29% of such cases exhibited complete agreement\non reasoning.\nCOBRA captures objective aspects of outcome\njudgments. Our metrics reflect decision-making\ndriven by more objective reasons, such as logical ar-\n11We follow their work: 1 for a win and 0 otherwise.\n12Randolph‚Äôs Œ∫(Randolph, 2005) is used for violation cate-\ngories because their label distribution is usually highly skewed\n(see also Figure 5).\n13Inconsistencies are rare and typically signal obvious lying,\nso we report only the average true positive rate.\n14We note that our multiple regression analysis predicts out-\ncomes on a per-annotator basis, so the observed disagreement\non outcome among annotators does not contradict the good\npredictive power of our metrics.\n--- Page 8 ---\n0.00.20.40.60.81.00.00.20.40.60.81.0ROC Curve\nFalse Positive RateTrue Positive RateBLEFigure 8: Model performances conditioned on different\noutcome reasons. B: baseline (i.e., without any con-\nditions), L: conditioned on logical arguments, and E:\nconditioned on personal emotions.\nBase Model Reasoning Variant\nGPT4o-mini GPTo3-mini\nGemini-2.5-Flash (OFF) Gemini-2.5-Flash (ON)\nQwen2.5-7B-Instruct DeepSeek-R1-Distill-Qwen-7B\nLLaMA3.1-Instruct-8B DeepSeek-R1-Distill-LLaMA-8B\nQwen2.5-32B QwQ-32B\nLLaMA3.3-70B-Instruct DeepSeek-R1-Distill-LLaMA-70B\nTable 1: Models Categorized by Size and Reason-\ning Capability; Gemini-2.5-Flash (OFF) refers to\ngemini-2.5-flash-preview-05-20 with the thinking\nbudget set to 0.\ngumentation and certain aspects of credibility build-\ning, but not personal emotions.15To test this, we\nfit two separate multiple logistic regression models:\none conditioned on outcome decisions attributed\nto logical arguments and another on those influ-\nenced by personal emotions. The results in Figure\n8 show that the discriminative power of our met-\nric increases significantly when the reasons stated\nfor the annotated outcome are logical arguments\n(p < .0001 ), but drops substantially when they are\npersonal emotions ( p < .05). These findings fur-\nther corroborate that outcome judgments are inher-\nently subjective, whereas COBRA metrics capture\nthe more objective aspects of outcome evaluation.\n6 Can LLMs perceive non-cooperativity?\nWe evaluate a set of strong LLMs (Table 1), and fur-\nther examine how model size and reasoning ability\ninfluence their perception of strategic discourse.\n15For example, a witness‚Äôs admission of taking medication\nmay objectively raise concerns about their mental state‚Äîan in-\nference grounded in logical reasoning. In contrast, discrediting\na witness solely because they do not attend church, as might\noccur with a biased juror, reflects a subjective and emotionally\ndriven judgment.Prompts and parameters We use the same\nprompt provided to human annotators in a zero-\nshot setup. To constrain the variability of model\nresponses, we set the temperature to 0.1. We pro-\nvide the prompt in Appendix E. We also experi-\nmented with different prompting techniques, in-\ncluding few-shot prompting and constitution-like\nprinciples (Bai et al., 2022), but found them largely\nineffective (see details in Appx. Figure 13).\n6.1 Quantitative Analysis\nWe report agreement/correlation with human anno-\ntations on PAT,BAT,NRB ATand also scores\non their ‚Äúlocal‚Äù benefit estimation components (i.e.,\nCOMMIT ,REL ,MAN ,QUAL ,CONST ) aggre-\ngated across all three trials in Figure 9, with de-\ntailed scores and significance levels for each trial\nin Appendix G.\nOverall, LLMs show strong agreement with hu-\nmans in identifying violations of Gricean maxims,\nwith mean (denoted as ¬µhereafter) Randolph‚Äôs Œ∫\nscores of 0.80, 0.52, and 0.93 for REL ,MAN , and\nQUAL , respectively. This aligns with prior find-\nings (Hu et al., 2023) suggesting that LLMs have a\ngood pragmatic understanding of Gricean maxims.\nAnother contributing factor may be the skewed\ndistribution of violations (see Figure 5), which\nmakes the task easier and inflates Randolph‚Äôs Œ∫.\nIn contrast, LLMs perform poorly on commitment\ntype identification ( COMMIT (¬µ= 0.14)) and our\nstrategic metrics ( BAT(¬µ= 0.23), PAT(¬µ= 0.13),\nand NRB AT(¬µ= 0.27)) all of which lag behind\nhuman inter-annotator agreement/correlation (see\nSection 5). Another interesting finding is that most\nmodels fail to reliably identify self-contradictory\nstatements ( CONST ), whereas small models tend\nto achieve higher true positive rates. However, due\nto the rarity of such cases in our dataset, we refrain\nfrom drawing strong conclusions.\nModel size matters We find that larger mod-\nels (indicated by darker bars in Figure 9) consis-\ntently outperform their smaller counterparts (i.e.,\nthe lighter bars) on our BaT and PaT and in iden-\ntifying commitment types. Below, we report aver-\nage effect sizes ( ‚àÜ¬µ) to quantify these differences,\nwith bootstrapped 95% confidence intervals (CI)\nfor each metric; Bonferroni-corrected statistical\nsignificance from a paired t-test is denoted with\na (*): BAT(‚àÜ¬µ= 0.16*, 95% CI [0.06,0.25]),\nPAT(‚àÜ¬µ= 0.12, 95% CI [0.04,0.22]), and\nCOMMIT (‚àÜ¬µ= 0.10*, 95% CI [0.05,0.15]).\n--- Page 9 ---\nFigure 9: Strategic metrics and agreement with humans across three trials. BaT, PaT, NRBaT: Spearman‚Äôs œÅ; Commit:\nCohen‚Äôs Œ∫; Relevance, Manner, Quality: Randolph‚Äôs Œ∫; Consistency: true positive rate. ( N.B. , Inconsistencies do\nnot occur in every trial; when there are no inconsistent utterances, the true positive rate is naturally 0.)\nThe effects are inconsistent, though positive for\nNRB AT(‚àÜ¬µ= 0.08, 95% CI [‚àí0.07,0.23]),\neven when models exhibit improvements on BaT\nand PaT. This is because NRBaT is a cumulative\nmeasure that aggregates benefits across the entire\ndiscourse, making it less sensitive to the position\nof individual moves. Errors in local benefit esti-\nmation can cancel each other out over the course\nof the dialogue, which explains why models may\nsometimes exhibit low BaT and PaT scores but still\nachieve high NRBaT values, or vice versa. Most\nmodels already perform well on violation identi-\nfication, though we do observe that larger mod-\nels tend to perform slightly better for example, on\nMAN (‚àÜ¬µ= 0.12*, 95% CI [0.06,0.19]).\nReasoning (CoT) does not help with our met-\nrics Models equipped with explicit reasoning\nmechanisms (i.e., the bars to the right of the\ndashed line in Figure 9) do not consistently\nimprove performance and, in some cases, per-\nform worse than their non-reasoning counter-\nparts (i.e., bars to the left of the dashed line in\nthe same color). This is particularly evident in\nPAT(‚àÜ¬µ=‚àí0.10*, 95% CI [‚àí0.18,‚àí0.04]),\nand is also observed in BAT(‚àÜ¬µ=‚àí0.03, 95%\nCI[‚àí0.11,0.04])NRB AT(‚àÜ¬µ=‚àí0.09, 95%\nCI[‚àí0.22,0.03]), and COMMIT (‚àÜ¬µ=‚àí0.02,\n95% CI [‚àí0.07,0.02]) across most models, with\nthe exception of GPT-o3-mini . The confidence in-\ntervals for BaT and Commit include zero primarily\ndue to this outlier. These results suggest that ex-\nplicit reasoning tends to hinder models‚Äô ability to\nperceive strategic losses, if not benefits, as seen\nin the case of GPT-o3-mini . We further discuss\npossible reasons in Section 6.2. However, we doobserve that models with reasoning ability outper-\nform their counterparts on e.g., MAN (‚àÜ¬µ= 0.06,\n95% CI [0.02,0.12]) while the effects are weaker\nthan model size.\n6.2 Qualitative Analysis\nWe examine the sources of the observed ef-\nfects of reasoning by analyzing the CoT that\nprecedes generation, using models where such\ninformation is available: Qwen ,DS-LLaMA and\nGemini-Flash-ON .\nReasoning adds overcomplication and ambigu-\nity Models often overthink and conflate loss-\nminimizing or benefit-retrieval strategies with the\nactual impact of making a commitment. For in-\nstance, in a context like Figure 10, the witness con-\ncedes a fact that clearly undermines their credibility\nas an expert witness (i.e., DETRIMENTAL ). While\nthe model initially arrives at the correct judgment,\nit soon cycles through contradictory interpretations,\nultimately settling on an incorrect assessment (i.e.,\nBENEFICIAL ). Moreover, the model misinterprets\nsurface-level damage control strategies, such as\nminimizing, deflecting, or hedging (highlighted in\norange), as inherently positive or neutral, failing to\nrecognize them as attempts to mitigate an otherwise\ndetrimental commitment. We also append another\nexample (See Appx. Figure 14) where the model\ndoes the opposite (i.e., identifying benefit-retrieval\nstrategy as detrimental). Misclassifying the type\nof commitment can remarkably influence BaT and\nPaT scores by e.g., inverting the base value. Even\nwhen the model correctly identifies violations, an\nincorrect commitment label can alter the interpreta-\n--- Page 10 ---\nQ: How many courts A: There's one case in which a line of testimony to which my testimony would have been foundational was rejected. It has to do with whether or not [‚Ä¶]Reasoning: [‚Ä¶]the witness admits one case where testimony was rejected [‚Ä¶] maybe that‚Äôs DETRIMENTAL? But he clarifies it was about a theory, not his expertise‚Ä¶ so maybe he‚Äôs just hedging? That could mean it‚Äôs BENEFICIAL‚Ä¶ but still, the answer isn‚Äôt ‚Äúnone,‚Äù so maybe it is DETRIMENTAL? Then again, he says it‚Äôs only one case, and gives context‚Ä¶ maybe that‚Äôs BENEFICIAL? But wait‚Äîthe attorney‚Äôs point is about expert rejection, and this wasn‚Äôt that‚Ä¶ so maybe it‚Äôs NEUTRAL? Or BENEFICIAL again? He is controlling the damage‚Ä¶ which could help‚Ä¶ but is that really commitment, or just minimizing loss? Hmm‚Ä¶ tricky. Maybe it‚Äôs BENEFICIAL after all?Figure 10: The prosecutor is asking whether the witness\nhas ever been rejected as an expert in other courts. The\nresponse implies an affirmation, resulting in a detrimen-\ntal commitment. The model‚Äôs reasoning confuses the\ndetrimental commitment with loss-mitigation strategies.\ntion of the violation itself, for example, mistaking\na loss-control strategy (added to BaT) for a benefit-\nretrieval strategy (added to PaT).\nLLMs are naive and sometimes contradictory\nModels often fail to represent or understand the\nfacts correctly, leading to flawed inferences. In\nthe first exchange in Figure 11, the model claims\nthe witness is correcting the idea that the husband\ndidn‚Äôt plead guilty, even though the question al-\nready presupposes that he did. By inventing a con-\ntrast that doesn‚Äôt exist, the model reveals its inabil-\nity to track the actual state of the world, which\ndistorts its judgment of the witness‚Äôs commitment.\nIn other cases, the model appears to ignore world\nknowledge entirely, basing its judgment solely on\nwhether the response affirms or rejects the ques-\ntion. The model also exhibits self-contradiction\nin evaluating how a response aligns with the ques-\ntion‚Äôs intent. For example, in the second exchange,\nit correctly recognizes that the prosecutor‚Äôs ques-\ntion is designed to undermine the witness, yet it\nstill judges the witness‚Äôs affirmation as a benefi-\ncial commitment. This contradiction highlights a\nbroader weakness in the model‚Äôs strategic reason-\ning: it equates surface-level affirmation or infor-\nmativeness with benefit, without considering the\nspeaker‚Äôs goals or the adversarial context.\n7 Conclusions\nHaving introduced COBRA and applied it to\nCHARM , we demonstrate the potential to deepen\nour understanding of what makes discourse strate-\ngic by unifying two established pragmatic theories\nand providing a means to quantify their effects. We\nsee the current work as opening several promising\nQ: And in fact her husband had pled guilty to these sexual abuse charges, correct? A: No. In fact her husband pled guilty to six counts of third degree rape [‚Ä¶]Reasoning: The witness directly answers \"No\" and provides specific details about the plea. This seems make a BENEFICIAL commitment by correcting the prosecutor's implication that the husband didn't plead guilty.Q: Did he maintain his guilt for a period of five months prior to entering that plea of guilty? A: Oh, yesReasoning: The prosecutor is trying to undermine the witness's credibility by questioning the case where the defendant pleaded guilty. [‚Ä¶] Since the witness is affirming the question, that benefits his own testimony rather than helping the prosecutor, so this would be BENEFICIAL commitment.Figure 11: The prosecutor is asking whether the defen-\ndant has pled guilty, admitting to which will be clearly\ndetrimental to the defense side. The model‚Äôs reasoning\nshows misrepresentation of world information and con-\ntradicts itself across turns.\ndirections for future research. First, although our\nanalysis focuses on legal cross-examinations, the\nframework naturally extends to other high-stakes\nadversarial domains, such as political debates. Sec-\nond, a strategic agent reasons not only about how\nan utterance is perceived but also about how other\nparticipants are likely to respond. This raises the\nquestion of how to model downstream reasoning,\nwherein one interlocutor anticipates the other‚Äôs de-\ncisions and strategically plans their response. We\nrecognize the potential safety concerns in model-\ning sophisticated strategic interactions and, for this\nreason, do not engage seriously with alignment in\nthis work. However, having principled tools to cali-\nbrate how models interpret and respond to strategic\nmoves is crucial for future alignment work.\nLimitations Due to time and resource con-\nstraints, we were unable to annotate all the data\nwe collected. The fact that neither annotators nor\nauthors are legal scholars implies that we might\nlack domain specific understanding of what con-\nstitutes non-cooperativity and what strategies are\navailable. We will aim to draw in legal expertise in\nfollow-up work. Furthermore, even though our data\nis real, it is still domain-specific, where strategies\nare acquired after extensive training.\nAcknowledgments\nSpecial thanks to Kathryn Kazanas, Chenxing Ri-\nley Zhang, and other annotators for providing data\nannotation for this project. This work was par-\ntially supported by NSF grants IIS-2145479, IIS-\n2107524, a grant from Open Philanthropy, and\n--- Page 11 ---\nGood Systems,16a UT Austin Grand Challenge\nto develop responsible AI technologies.\nReferences\nNicholas Asher and Alex Lascarides. 2013. Strate-\ngic conversation. Semantics and Pragmatics ,\n6:1‚Äì62.\nNicholas Asher and Soumya Paul. 2016. Evaluat-\ning conversational success: Weighted message\nexchange games. In 20th Workshop on the Se-\nmantics and Pragmatics of Dialogue (SemDial\n2016) , volume 20, pages 55‚Äì64.\nNicholas Asher and Soumya Paul. 2018. Strate-\ngic conversations under imperfect information:\nepistemic message exchange games. Journal of\nLogic, Language and Information , 27:343‚Äì385.\nNicholas Asher, Soumya Paul, and Antoine Venant.\n2017. Message exchange games in strategic con-\ntexts. Journal of Philosophical Logic , 46:355‚Äì\n404.\nYuntao Bai, Saurav Kadavath, Sandipan Kundu,\nAmanda Askell, John Kernion, Andy Jones,\nAnna Chen, Anna Goldie, Azalia Mirhoseini,\nCameron McKinnon, Carol Chen, Catherine\nOlsson, Chris Olah, Danny Hernandez, Dawn\nDrain, Deep Ganguli, Dustin Li, Eli Tran-\nJohnson, E Perez, Jamie Kerr, Jared Mueller,\nJeff Ladish, J Landau, Kamal Ndousse, Kamil Àôe\nLuko vs.i¬ØutÀôe, Liane Lovitt, Michael Sellitto, Nel-\nson Elhage, Nicholas Schiefer, Noem‚Äôi Mercado,\nNova Dassarma, Robert Lasenby, Robin Larson,\nSam Ringer, Scott Johnston, Shauna Kravec,\nSheer El Showk, Stanislav Fort, Tamera Lan-\nham, Timothy Telleen-Lawton, Tom Conerly,\nTom Henighan, Tristan Hume, Sam Bowman,\nZac Hatfield-Dodds, Benjamin Mann, Dario\nAmodei, Nicholas Joseph, Sam McCandlish,\nTom B. Brown, and Jared Kaplan. 2022. Con-\nstitutional AI: Harmlessness from AI Feedback.\nArXiv , abs/2212.08073.\nSam Bowman, Jeeyoon Hyun, Ethan Perez, Ed-\nwin Chen, Craig Pettit, Scott Heiner, Kamil Àôe\nLuko vs.i¬ØutÀôe, Amanda Askell, Andy Jones,\nAnna Chen, Anna Goldie, Azalia Mirhoseini,\nCameron McKinnon, Chris Olah, Daniela\nAmodei, Dario Amodei, Dawn Drain, Dustin\n16https://goodsystems.utexas.edu/Li, Eli Tran-Johnson, John Kernion, Jamie Kerr,\nJared Mueller, Jeff Ladish, Joshua D. Landau,\nKamal Ndousse, Liane Lovitt, Nelson Elhage,\nNicholas Schiefer, Nicholas Joseph, Noem‚Äôi\nMercado, Nova Dassarma, Robin Larson, Sam\nMcCandlish, Sandip Kundu, Scott Johnston,\nShauna Kravec, Sheer El Showk, Stanislav\nFort, Timothy Telleen-Lawton, Tom B. Brown,\nTom Henighan, Tristan Hume, Yuntao Bai, Zac\nHatfield-Dodds, Benjamin Mann, and Jared Ka-\nplan. 2022. Measuring progress on scalable\noversight for large language models. ArXiv ,\nabs/2211.03540.\nHerbert H Clark and Edward F Schaefer. 1989.\nContributing to discourse. Cognitive science ,\n13(2):259‚Äì294.\nJinhao Duan, Renming Zhang, James Diffenderfer,\nBhavya Kailkhura, Lichao Sun, Elias Stengel-\nEskin, Mohit Bansal, Tianlong Chen, and Kaidi\nXu. 2024. GTBench: Uncovering the strate-\ngic reasoning capabilities of LLMs via game-\ntheoretic evaluations. In The Thirty-eighth An-\nnual Conference on Neural Information Process-\ning Systems .\nFAIR, Anton Bakhtin, Noam Brown, Emily Di-\nnan, Gabriele Farina, Colin Flaherty, Daniel\nFried, Andrew Goff, Jonathan Gray, Hengyuan\nHu, Athul Paul Jacob, Mojtaba Komeili, Karthik\nKonath, Minae Kwon, Adam Lerer, Mike Lewis,\nAlexander H. Miller, Sasha Mitts, Adithya Ren-\nduchintala, Stephen Roller, Dirk Rowe, Weiyan\nShi, Joe Spisak, Alexander Wei, David Wu,\nHugh Zhang, and Markus Zijlstra. 2022. Human-\nlevel play in the game of diplomacy by combin-\ning language models with strategic reasoning.\nScience , 378(6624):1067‚Äì1074.\nElisa Ferracane, Greg Durrett, Junyi Jessy Li, and\nKatrin Erk. 2021. Did they answer? Subjec-\ntive acts and intents in conversational discourse.\nInProceedings of the 2021 Conference of the\nNorth American Chapter of the Association for\nComputational Linguistics: Human Language\nTechnologies , pages 1626‚Äì1644, Online. Associ-\nation for Computational Linguistics.\nJacob Glazer and Ariel Rubinstein. 2006. A Game\nTheoretic Approach to the Pragmatics of Debate:\nAn Expository Note. In Anton Benz, Gerhard\nJ√§ger, and Robert Van Rooij, editors, Game The-\n--- Page 12 ---\nory and Pragmatics , pages 248‚Äì262. Palgrave\nMacmillan UK, London.\nRyan Greenblatt, Carson E. Denison, Benjamin\nWright, Fabien Roger, Monte Stuart MacDi-\narmid, Samuel Marks, Johannes Treutlein, Tim\nBelonax, Jack Chen, David Kristjanson Duve-\nnaud, Akbir Khan, Julian Michael, S√∂ren Min-\ndermann, Ethan Perez, Linda Petrini, Jonathan\nUesato, Jared Kaplan, Buck Shlegeris, Samuel R.\nBowman, and Evan Hubinger. 2024. Align-\nment faking in large language models. ArXiv ,\nabs/2412.14093.\nHerbert Paul Grice. 1975. Logic and conversation.\nSyntax and semantics , 3:43‚Äì58.\nHerbert Paul Grice. 1989. Studies in the Way of\nWords . Harvard University Press, Cambridge.\nLaurence Horn. 1984. Towards a new taxonomy\nfor pragmatic inference: Q-and r-based implica-\nture. Meaning, form and use in context .\nJennifer Hu, Sammy Floyd, Olessia Jouravlev,\nEvelina Fedorenko, and Edward Gibson. 2023.\nA fine-grained comparison of pragmatic lan-\nguage understanding in humans and language\nmodels. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 4194‚Äì\n4213, Toronto, Canada. Association for Compu-\ntational Linguistics.\nLea Krause and Piek T.J.M. V ossen. 2024. The\nGricean maxims in NLP - a survey. In Proceed-\nings of the 17th International Natural Language\nGeneration Conference , pages 470‚Äì485, Tokyo,\nJapan. Association for Computational Linguis-\ntics.\nStephen C. Levinson. 1987. Pragmatics and the\ngrammar of anaphora: a partial pragmatic reduc-\ntion of binding and control phenomena. Journal\nof Linguistics , 23(2):379‚Äì434.\nJonathan Light, Min Cai, Sheng Shen, and Ziniu\nHu. 2023. From text to tactic: Evaluating LLMs\nplaying the game of avalon. In NeurIPS 2023\nFoundation Models for Decision Making Work-\nshop .\nNunzio Lor√® and Babak Heydari. 2024. Strate-\ngic behavior of large language models and the\nrole of game structure versus contextual framing.\nScientific Reports , 14(1):18490.Stephanie Lukin, Pranav Anand, Marilyn Walker,\nand Steve Whittaker. 2017. Argument strength\nis in the eye of the beholder: Audience effects in\npersuasion. In Proceedings of the 15th Confer-\nence of the European Chapter of the Association\nfor Computational Linguistics: Volume 1, Long\nPapers , pages 742‚Äì753, Valencia, Spain. Associ-\nation for Computational Linguistics.\nElena Musi, Nadin Kokciyan, Khalid Al-Khatib,\nDavide Ceolin, Emmanuelle Dietz, Klara\nGutekunst, Annette Hautli-Janisz, Cristian\nManuel Santiba√±ez Ya√±ez, Jodi Schneider, Jonas\nScholz, et al. 2025. Toward reasonable parrots:\nWhy large language models should argue with\nus by design. arXiv preprint arXiv:2505.05298 .\nSteve Oswald. 2010. Pragmatics of uncooperative\nand manipulative communication . Universit√© de\nNeuch√¢tel.\nPrashant Parikh. 2000. Communication, meaning,\nand interpretation. Linguistics and philosophy ,\npages 185‚Äì212.\nXiangyu Qi, Ashwinee Panda, Kaifeng Lyu, Xiao\nMa, Subhrajit Roy, Ahmad Beirami, Prateek Mit-\ntal, and Peter Henderson. 2025. Safety align-\nment should be made more than just a few tokens\ndeep. In The Thirteenth International Confer-\nence on Learning Representations .\nJustus J. Randolph. 2005. Free-marginal multi-\nrater kappa (multirater k [free]): An alternative\nto fleiss‚Äô fixed-marginal multirater kappa. Pre-\nsented at the Joensuu Learning and Instruction\nSymposium. ERIC Document ED490661.\nChristof Rapp. 2023. Aristotle‚Äôs Rhetoric. In Ed-\nward N. Zalta and Uri Nodelman, editors, The\nStanford Encyclopedia of Philosophy , Winter\n2023 edition. Metaphysics Research Lab, Stan-\nford University.\nMrinank Sharma, Meg Tong, Tomasz Korbak,\nDavid Duvenaud, Amanda Askell, Samuel R.\nBowman, Esin DURMUS, Zac Hatfield-Dodds,\nScott R Johnston, Shauna M Kravec, Timothy\nMaxwell, Sam McCandlish, Kamal Ndousse,\nOliver Rausch, Nicholas Schiefer, Da Yan, Mi-\nranda Zhang, and Ethan Perez. 2024. Towards\nunderstanding sycophancy in language mod-\nels. In The Twelfth International Conference\non Learning Representations .\n--- Page 13 ---\nAnthony Sicilia, Tristan Maidment, Pat Healy,\nand Malihe Alikhani. 2022. Modeling non-\ncooperative dialogue: Theoretical and empiri-\ncal insights. Transactions of the Association for\nComputational Linguistics , 10:1084‚Äì1102.\nDouglas Walton and Erik CW Krabbe. 1995. Com-\nmitment in dialogue: Basic concepts of interper-\nsonal reasoning . State University of New York\nPress.\nRongwu Xu, Brian Lin, Shujian Yang, Tianqi\nZhang, Weiyan Shi, Tianwei Zhang, Zhixuan\nFang, Wei Xu, and Han Qiu. 2024. The earth\nis flat because...: Investigating LLMs‚Äô belief to-\nwards misinformation via persuasive conversa-\ntion. In Proceedings of the 62nd Annual Meeting\nof the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 16259‚Äì16303,\nBangkok, Thailand. Association for Computa-\ntional Linguistics.\nYuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo,\nXiaolong Wang, Weidong Liu, and Yang Liu.\n2023. Exploring large language models for com-\nmunication games: An empirical study on were-\nwolf. CoRR , abs/2309.04658.\nYadong Zhang, Shaoguang Mao, Tao Ge, Xun\nWang, Yan Xia, Man Lan, and Furu Wei. 2025.\nK-level reasoning: Establishing higher order be-\nliefs in large language models for strategic rea-\nsoning. In Proceedings of the 2025 Conference\nof the Nations of the Americas Chapter of the\nAssociation for Computational Linguistics: Hu-\nman Language Technologies (Volume 1: Long\nPapers) , pages 7212‚Äì7234, Albuquerque, New\nMexico. Association for Computational Linguis-\ntics.\nA Data Stats and Metrics Distribution in\nHuman Annotations\nTrial Defense Prosecution Total Defense %\nWMT 651 575 1226 53.1%\nEnron 27 47 74 36.5%\nSimpson 1608 417 2025 79.4%\nTable 2: Q/A pair distribution by questioner role across\nfour trials. The Defense % column shows the proportion\nof defense-attorney-led Q/A pairs.\nFigure 12: Distribution of our metrics in our human\nannotated dataset\nB Metrics Calculation Example\nTake turn i+ 1in Figure 3 as an example. The\ndistributions of the BaT and PaT sums are (1, 1.4,\n1.9, 1.9) and (0, 1, 1.2, 1.7), respectively, yield-\ning¬µb= 0.98,¬µp= 1.55,œÉb= 0.38, and\nœÉp= 0.14for the given example snippets. In our\nwork, we assign weights of 0.4, 0.4, 0.2 and 0.2\ntoREL ,MAN ,QUAL and CONST , respectively.\nAs noted in the main text, these weights are hypo-\nthetical, as our focus is on measuring correlation\nrather than modeling absolute values. The lower\nweight assigned to QUAL /CONST reflects its ba-\nsis in perceived, rather than objective, truth; this\nprevents placing undue penalty on this dimension.\nBaT i+1=|fc(Ci)| √ó(Reli+1+Man i+1+Quali+1)\n= 1√ó(0 + 0 .4 + 0)\n= 0.4\nPaT i+1=|fc(Ci)|+Const i+1√ói+1X\nj=1BaT j\n= 1 + 0\n= 1\nNRBaT i+1=ZÔ£´\nÔ£≠i+1X\nj=1BaT jÔ£∂\nÔ£∏‚àíZÔ£´\nÔ£≠i+1X\nj=1PaT jÔ£∂\nÔ£∏\n=Pi+1\nj=1BaT j‚àí¬µb\nœÉb‚àíPi+1\nj=1PaT j‚àí¬µp\nœÉp\n=(0 + 1) ‚àí0.98\n0.38‚àí(1 + 0 .4)‚àí1.55\n0.14\n= 0.053‚àí(‚àí1.07)\n= 1.123\n--- Page 14 ---\nFigure 13: Comparison of prompting techniques (Cons: Constitution; Few: Few-shot) on Qwen and QwQ, which\nperform well in the zero-shot setting. Few-shot prompting provides slight improvement, while Constitution\nprompting benefits PaT but harms BaT and NRBaT. All differences are minor ( <0.1), suggesting prompting has\nonly a small or even negligible impact.\nC Zero-shot LLM prediction results\nModel AUC Model AUC\nGPT4o-mini 0.61 o3-mini 0.60\nGemini-Flash-OFF 0.68 Gemini-Flash-ON 0.63\nQwen-7B 0.53 DS-Qwen-7B 0.47\nQwen-32B 0.52 QwQ-32B 0.58\nLlama3.1-8B 0.53 DS-Llama-8B 0.51\nLlama3.3-70B 0.62 DS-Llama-70B 0.59\nTable 3: AUC scores for 0-shot LLM predictions\nD Qualitative Analysis Example\nQ: How long was that interview? A: Three hours, more or less. It may have a bit more. It may have been a bit less. I don't have the -- I don't have that -- it might be helpful. It worked out to an eighty-seven page transcript.Reasoning: The prosecutor is trying to get specific information. The witness's answer starts with an approximate value (\"Three hours, more or less\") but then hedges a lot, saying \"may have a bit more\" or \"may have been a bit less.\" The hesitation (\"I don't have the -- I don't have that -- it might be helpful\") might indicate uncertainty. This could be detrimental to the witness because it shows they're unsure, which benefits the questioner. So maybe a 1 (Detrimental commitment)Context: The prosecutor is asking whether the witness has ever had a good understanding of the defendant. The witness answers a decent amount of time of contact, which is beneficial.\nFigure 14: An example of LLMs misidentifying benefit\nretrieval strategy as detrimental commitments.\nE Prompts\nSystem: You are a juror in a cross-examination. Your role\nis to evaluate witness responses and determine which side\nis more convincing based on the conversation.\nInput:\nBelow is the transcript of the cross-examination so far:\n{history}The current response from the witness is: {answer}\nInstructions:\nPlease evaluate the CURRENT response based on the\nfollowing properties:\n1.Witness commitment level (with respect to the immediate\nquestion):\n- 1: Detrimental commitment: A detrimental commitment\nsupports the questioner‚Äôs position and undermines the\nwitness\n- 2: Beneficial commitment: A beneficial commitment\nstrengthens the witness‚Äôs case, increasing their winning\npotentials\n- 3: Neutral commitment: A neutral commitment has no\nclear strategic effect, not affecting either side‚Äôs winning\npotentials\n- 4: No commitment made: No answer to the question can\nbe clearly drawn or is clearly implied\n2. Witness truthfulness in the currentent turn:\n- 1: Truthful\n- 0: Not truthful\n3. Consistency with previous testimony:\n- 1: Inconsistent: the current statement is self-contradictory\n- 0: Consistent\n4. Response relevance:\n- 1: Very relevant: Direct give an answer that‚Äôs relevant to\nthe question\n- 2: Slightly relevant: The answer does not provide a direct\nanswer but instead provide relevant information to tackle\nthe specific issue.\n- 3: Slightly irrelevant: Avoid addressing the specific\nquestion, requiring further probing/ Non-verbal response\n- 4: Irrelevant: It is almost impossible to draw any\ninferences.\n--- Page 15 ---\n5. Response clarity:\n- 1: Very clear: The response is direct, unambiguous, and\norderly\n- 2: Slightly clear with hedging: The answer is still clear,\nbut it includes extra hedging that isn‚Äôt strictly needed.\n- 3: Slightly unclear: Ambiguous inferences\n- 4: Unclear: Refusal to answer the question or verbose\nanswer\n6. Current turn outcome:\n- Questioner\n- Witness\n7. Reasons for current outcome:\n- 1. Logical arguments are convincing\n- 2. Credibility attack on other side\n- 3. Emotional appeal/bias\nProvide your response in JSON format:\n\"Commitment value\": \"Commitment level (1-4)\",\n\"quality rate\": \"Truthfulness (0,1)\",\n\"consistency value\": \"Consistency (0,1)\",\n\"relevance rate\": \"Relevance (1-4)\",\n\"manner rate\": \"Clarity (1-4)\",\n\"outcome value\": \"Winner of current turn (Questioner/Wit-\nness)\",\n\"outcome reason\": \"Reason for the outcome (1-3)\"\nE.1 Constitution-alike principles\nPrinciple:\nA strategic witness does not assume a common goal . The\nfollowing Gricean Maxims can be reliably violated:\nTruthfulness (Quality): avoid falsehoods and speaks only\nwhat they believe to be true. Relevance: addresse the spe-\ncific question being asked.\nClarity (Manner): avoid vagueness, ambiguity, or unneces-\nsary complexity.\nAccordingly, judgments about the witness‚Äôs commitment\nshould be based on whether the response advances the\nwitness‚Äôs interests (i.e., winning potential)\nE.2 Few-shot\nFew-shot Examples:\nExample 1:\nQuestion: Are you taking any medication?\nresponse: I might have taken some.\nThis response is a detrimental commitment as taking medi-\ncation indicates mental instability.\nThis response is relevant (1) but not clear with hedging (3),\nand truthful (1).\nThe winner is Questioner and the reason is logical argu-\nments.\nExample 2:\nQuestion: Have you been to the place where the body was\nfound?\nResponse: I think I have no reason to go to place like that.\nThis response is a beneficial commitment as not have gone\nto the crime spot indicates alibi.This response is relevant (1), unclear with hedging (3), and\ntruthful (1). The winner is Witness and the reason is logical\narguments.\nExample 3:\nQuestion: You have interviewed with the defendant for ten\nhours?\nResponse: No\nThis response is a detrimental commitment as having de-\ncent amount contact with defendant indicates the witness\nhas enough knowledge about defendant so denying would\nindicate the opposite.\nThis response is relevant (1), clear (1), and truthful (1).\nThe winner is Questioner and the reason is logical argu-\nments.\nF Annotation Protocols\nInstruction: You will be given conversation pairs extracted from cross-examinations that took place in real criminal trials. Each pair consists of two parts: one from the cross-examiner and one from the witness. In addition to that, you will also be presented with recent question-answer pairs (up to 10), a summary of previous context (previous to the current pair), and some meta-date related to the witness.  Context: In a trial, the examiner is asking about information about the witness‚Äô medication condition, which can have subsequent effects on the credibility of the witness. Witness: (witness name) is one of the suspects in the trial. Recent Exchanges: Examiner: Mr. Echols, I'm going to ask you questions and like I have told other witnesses, if you don't understand, you ask me to rephrase them and I'll be glad to do so. Witness: (NOD HEAD) Current Pair: Examiner: First of all, let me ask you, are you taking any medication at this time? Witness: Yes, sir. Annotating Witness‚Äôs Responses  Gricean Maxims: Relevance: The information provided should be relevant to the current exchange and omit any irrelevant information. That is, participants should say things that are pertinent to the discussion. We consider relevance as a coherence and responsiveness constraint.  -No Violation(1): Direct give an answer that‚Äôs relevant to the question (i.e., one of the relevant answers of the question) Q: \"Are you taking medication?\" A: \"Yes, sir.\"  -Borderline (2): The answer does not provide a direct answer but instead provide relevant information to tackle the specific issue. Q: Did you see the defendant at the crime    scene?  A: I was standing right at the entrance the whole time, and I never saw him. -Clear (3): Clear shift topic. It is hard to draw any inferences. Non-verbal responses  Q: ‚ÄúDid you see the defendant enter the bank?‚Äù A: ‚ÄúIt was really crowded that day, and a lot of people were going in and out.‚Äù Strong (4): It is impossible to draw any valid inferences. Q: ‚ÄúDid you see the defendant enter the bank?‚Äù A: ‚ÄúThe weather was terrible that day.‚Äù Manner: The information provided should be clear. -No Violation(1): The response is direct, unambiguous, and orderly. Q: \"Are you taking medication?\" A: ‚ÄúYes, I take blood pressure medication.‚Äù -Borderline (2): Clear but with unnecessary hedging  A: ‚ÄúWell, I do take some medication, but only occasionally and only when prescribed by my doctor.‚Äù -Clear (3): Clear intended ambiguity  A: I might take some medicine. Strong (4): Non-verbal responses, answer with a question, and extreme verbose answer A: ‚ÄúWell, I mean, people take medicine for all kinds of reasons, and I guess you could say that I take something[...]‚Äù Quality: The information provided should be truthful. -No Violation(1): The honesty is salient (e.g., making a detrimental commitment intentionally) Q: \"Are you taking medication?\" A: ‚ÄúYes‚Äù -Borderline (2): Still honest (facts that are  easy to check) A: ‚ÄúWell, I have never visited Mr. Smith.‚Äù -Clear (3): You think this person is lying because of low credibility. Strong (4): You think this person is lying because of strong inconsistencies. Commitment Type:By uttering a sentence, the speaker is directly committed to both its literal content and indirectly the implicated content. You have to evaluate both content and see if they fall under the following categories: Beneficial: This utterance commits (either through an implicature or through the literal meaning) the speaker to an answer to the question which benefits the questioner but do not benefit the witness. Detrimental: [...] to an answer to the question which benefits the witness but do not benefit the questioner. Neutral: [...] to an answer which benefits neither witness nor the questioner. \n--- Page 16 ---\nInstruction: You will be given conversation pairs extracted from cross-examinations that took place in real criminal trials. Each pair consists of two parts: one from the cross-examiner and one from the witness. In addition to that, you will also be presented with recent question-answer pairs (up to 10), a summary of previous context (previous to the current pair), and some meta-date related to the witness.  Context: In a trial, the examiner is asking about information about the witness‚Äô medication condition, which can have subsequent effects on the credibility of the witness. Witness: (witness name) is one of the suspects in the trial. Recent Exchanges: Examiner: Mr. Echols, I'm going to ask you questions and like I have told other witnesses, if you don't understand, you ask me to rephrase them and I'll be glad to do so. Witness: (NOD HEAD) Current Pair: Examiner: First of all, let me ask you, are you taking any medication at this time? Witness: Yes, sir. Annotating Witness‚Äôs Responses  Gricean Maxims: Relevance: The information provided should be relevant to the current exchange and omit any irrelevant information. That is, participants should say things that are pertinent to the discussion. We consider relevance as a coherence and responsiveness constraint.  -No Violation(1): Direct give an answer that‚Äôs relevant to the question (i.e., one of the relevant answers of the question) Q: \"Are you taking medication?\" A: \"Yes, sir.\"  -Borderline (2): The answer does not provide a direct answer but instead provide relevant information to tackle the specific issue. Q: Did you see the defendant at the crime    scene?  A: I was standing right at the entrance the whole time, and I never saw him. -Clear (3): Clear shift topic. It is hard to draw any inferences. Non-verbal responses  Q: ‚ÄúDid you see the defendant enter the bank?‚Äù A: ‚ÄúIt was really crowded that day, and a lot of people were going in and out.‚Äù Strong (4): It is impossible to draw any valid inferences. Q: ‚ÄúDid you see the defendant enter the bank?‚Äù A: ‚ÄúThe weather was terrible that day.‚Äù Manner: The information provided should be clear. -No Violation(1): The response is direct, unambiguous, and orderly. Q: \"Are you taking medication?\" A: ‚ÄúYes, I take blood pressure medication.‚Äù -Borderline (2): Clear but with unnecessary hedging  A: ‚ÄúWell, I do take some medication, but only occasionally and only when prescribed by my doctor.‚Äù -Clear (3): Clear intended ambiguity  A: I might take some medicine. Strong (4): Non-verbal responses, answer with a question, and extreme verbose answer A: ‚ÄúWell, I mean, people take medicine for all kinds of reasons, and I guess you could say that I take something[...]‚Äù Quality: The information provided should be truthful. -No Violation(1): The honesty is salient (e.g., making a detrimental commitment intentionally) Q: \"Are you taking medication?\" A: ‚ÄúYes‚Äù -Borderline (2): Still honest (facts that are  easy to check) A: ‚ÄúWell, I have never visited Mr. Smith.‚Äù -Clear (3): You think this person is lying because of low credibility. Strong (4): You think this person is lying because of strong inconsistencies. Commitment Type:By uttering a sentence, the speaker is directly committed to both its literal content and indirectly the implicated content. You have to evaluate both content and see if they fall under the following categories: Beneficial: This utterance commits (either through an implicature or through the literal meaning) the speaker to an answer to the question which benefits the questioner but do not benefit the witness. Detrimental: [...] to an answer to the question which benefits the witness but do not benefit the questioner. Neutral: [...] to an answer which benefits neither witness nor the questioner. \nNone: does not commit (either through an implicature or through the literal meaning) the speaker to any answer. (e.g., if you say so, NOD HEAD, Huh-huh) Q: Do you have a Swiss bank account? A: My company gave me the Swiss bank account. This answer has the literal content: the company gave him the bank account in the past and also has an implicated content: the speaker possibly  have a Swiss bank account right now. The latter indirectly commits the speaker to an answer to the question which benefits the questioner but do not benefit the witness. [category 1] A‚Äô: My company has a Swiss bank account. This answer has the literal content: the company has a Swiss bank account and also has an implicated content: the speaker personally does not have a Swiss bank account. The latter commits the speaker to an answer to the question which benefits the witness but do not benefit the questioner.[category 2] A‚Äô‚Äô: I have worked in the company for the company for 10 years. This has the literal content: he has worked in the company for the company for 10 years but not a clear implicated content based on the context. This does not commit the speaker to any answer to the question. [category 3] Outcome/Reason: After each turn, you should decide which side is more likely to win. The criterion is which side‚Äôs story you believe more, if you were the real jury, which side you would support.  There are few things you could consider: Consider the statements (either as an argument or a statement from presupposition or speaker bias), and see if there is no conflict between the participants, then we consider the questioner wins, if there is a conflict, then you get to decide which side story is more convincing. You will be able to evaluate the outcome win in terms of  Logical facts, Framing the opposite side as not credible/person with a detrimental image Jury‚Äôs (i.e., your) emotion is affected to be biased towards one side.   G Detailed Results\n--- Page 17 ---\nDefense Witness vs. Prosecutor (WMT)\nModel BaT PaT NRBaT Commit Rel Man Qual Const‚Ä†\nHuman 0.65* 0.66* 0.83* 0.59 0.72 0.52 0.86 0.25\nGPT4o-mini 0.27* 0.11 0.71* 0.18 0.64 0.26 0.93 0\nGemini-Flash-OFF 0.40* 0.38* 0.62* 0.38 0.70 0.34 0.93 0\nQwen-7B 0.15* 0.20* 0.42* 0.02 0.68 0.32 0.93 0\nQwen-32B 0.32* 0.21* 0.69* 0.19 0.71 0.29 0.93 0\nQwen-32B-Few 0.33* 0.23* 0.75* 0.20 0.72 0.29 0.93 0\nQwen-32B-Cons 0.39* 0.24* 0.80* 0.18 0.71 0.33 0.93 0\nLLaMA3.1-8B 0.02 0.09 0.12* -0.03 0.64 0.19 0.93 0.58\nLLaMA3.3-70B 0.39* 0.25 0.79* 0.25 0.71 0.36 0.93 0.33\no3-mini 0.29* 0.22* 0.62* 0.21 0.66 0.35 0.93 0\nGemini-Flash-ON 0.46* 0.44 0.27* 0.41 0.71 0.36 0.93 0\nDS-Qwen-7B -0.07 -0.03 0.22* 0.02 0.63 0.24 0.93 0.17\nQwQ-32B 0.21* 0.17* 0.59* 0.14 0.72 0.36 0.93 0\nQwQ-32B-Few 0.33* 0.31* 0.71* 0.27 0.74 0.40 0.93 0\nQwQ-32B-Cons 0.30* 0.37* 0.64* 0.24 0.71 0.39 0.93 0\nDS-LLaMA-8B -0.08 -0.05 0.11* 0.05 0.66 0.43 0.93 0.83\nDS-LLaMA-70B 0.34* 0.19* 0.55* 0.17 0.72 0.41 0.93 0\nTable 4: Strategic metrics and agreement with humans for Defense Witness vs. Prosecutor (WMT) . Stars (*)\nindicate significance at p < .05. BaT, PaT, NRBaT: Spearman‚Äôs œÅ; Commitment: Cohen‚Äôs Œ∫; Relevance, Manner,\nQuality: Randolph‚Äôs Œ∫; Consistency: true positive rate ( N.B. , Inconsistencies do not occur in every trial; when\nthere are no inconsistent utterances, the true positive rate is naturally 0. We use ‚Ä†to indicate trials that do involve\ninconsistency.).\nProsecutor Witness vs. Defense (WMT)\nModel BaT PaT NRBaT Commit Rel Man Qual Const\nGPT4o-mini 0.09 0.04 -0.24* 0.16 0.72 0.64 0.98 0\nGemini-Flash-OFF 0.06 0.10 0.51* 0.24 0.89 0.66 0.93 0\nQwen-7B 0.07 0.07 0.62* 0.05 0.72 0.52 0.98 0\nQwen-32B 0.25* 0.31* 0.30* 0.10 0.85 0.66 0.98 0\nQwen-32B-Few 0.38* 0.43* 0.73* 0.19 0.84 0.66 0.98 0\nQwen-32B-Cons 0.20* 0.22* 0.25* 0.13 0.82 0.66 0.98 0\nLLaMA3.1-8B 0.13 0.16 0.76* 0.07 0.76 0.33 0.98 0\nLLaMA3.3-70B 0.32* 0.28* 0.83* 0.23 0.85 0.68 0.98 0\no3-mini 0.15 0.02 0.55* 0.18 0.84 0.61 0.98 0\nGemini-Flash-ON 0.20* 0.14 0.24* 0.33 0.90 0.66 0.98 0\nDS-Qwen-7B 0.06 0.19* 0.70* 0.05 0.76 0.59 0.98 0\nQwQ-32B 0.36* 0.21* 0.48* 0.29 0.85 0.72 0.98 0\nQwQ-32B-Few 0.26* 0.20* 0.63* 0.19 0.82 0.64 0.98 0\nQwQ-32B-Cons 0.22* 0.14 0.30* 0.21 0.82 0.66 0.98 0\nDS-LLaMA-8B 0.13 -0.03 0.73* 0.02 0.66 0.48 0.98 0\nDS-LLaMA-70B 0.24* 0.15 0.59* 0.22 0.87 0.64 0.98 0\nDefense Witness vs. Prosecutor (Enron)\nModel BaT PaT NRBaT Commit Rel Man Qual Const‚Ä†\nGPT4o-mini 0.10 0.17 0.14 0.11 0.82 0.41 1.00 0\nGemini-Flash-OFF 0.23* -0.30* -0.71* 0.13 0.66 0.40 0.83 0\nQwen2.5-7B 0.19 0.21 0.02 0.18 0.66 0.45 0.83 0\nQwen2.5-32B 0.11 0.24 0.28 0.31 0.70 0.36 0.83 0\nQwen2.5-32B-Few 0.17 0.03 0.13* 0.21 0.74 0.49 0.83 0\nQwen2.5-32B-Cons 0.23 0.16 0.46* 0.24 0.57 0.40 0.83 0\nLLaMA3.1-8B 0.23 -0.01 0.10 0.31 0.70 0.49 0.83 1\nLLaMA3.1-70B 0.16 -0.31* -0.69* 0.08 0.53 0.49 0.83 0\no3-mini 0.86* -0.46* 0.88* 0.07 0.57 0.36 0.83 0\nGemini-Flash-ON 0.16 -0.33* -0.76* 0.11 0.81 0.44 0.81 0\nDS-Qwen-7B 0.14 0.03 -0.21 -0.02 1.00 0.32 0.83 0\nQwQ-32B 0.04 0.11 -0.34* 0.07 0.82 0.45 0.83 0\nQwQ-32B-Few 0.07 -0.36* -0.68* 0.09 0.95 0.49 0.83 0\nQwQ-32B-Cons 0.25 -0.49* -0.79* 0.11 0.74 0.36 0.83 0\nDS-LLaMA-8B 0.25 -0.33* -0.56* -0.01 0.49 0.28 0.83 0\nDS-LLaMA-70B 0.25 -0.33* -0.56* 0.08 0.91 0.53 0.83 0\nProsecution Witness vs. Defense (Enron)\nModel BaT PaT NRBaT Commit Rel Man Qual Const\nGPT4o-mini 0.30 0.21 0.90* 0.08 0.91 0.53 0.78 0\nGemini-Flash-OFF 0.32 0.35 0.45* 0.15 0.78 0.48 1.00 0\nQwen2.5-7B 0.18 -0.08 -0.13 -0.01 0.78 0.33 1.00 0\nQwen2.5-32B 0.58* 0.22 0.77* 0.34 0.41 0.63 1.00 0\nQwen2.5-32B-Few 0.38 0.31 0.53* 0.05 0.63 0.56 1.00 0\nQwen2.5-32B-Cons 0.42 0.48* 0.37 0.11 0.56 0.56 1.00 0\nLLaMA3.1-8B 0.10 -0.08 0.08 0.08 0.48 0.11 1.00 0\nLLaMA3.3-70B 0.52* 0.77* 0.97* 0.11 0.85 0.48 1.00 0\no3-mini 0.38 0.29 0.19 0.14 0.66 0.46 1.00 0\nGemini-Flash-ON 0.43 0.34 0.47* 0.04 0.92 0.58 1.00 0\nDS-Qwen-7B -0.07 -0.34 -0.19 0.19 1.00 0.41 1.00 0\nQwQ-32B 0.44* 0.18 0.09 -0.02 0.70 0.41 1.00 0\nQwQ-32B-Few 0.39 0.54* 0.59* 0.06 0.70 0.41 1.00 0\nQwQ-32B-Cons 0.09 0.04 -0.05 -0.03 0.70 0.41 1.00 0\nDS-LLaMA-8B 0.05 0.07 0.21 0.17 0.62 0.70 1.00 0\nDS-LLaMA-70B 0.05 0.07 0.21 0.11 0.93 0.41 1.00 0\n--- Page 18 ---\nDefense Witness vs. Prosecutor (Simpson)\nModel BaT PaT NRBaT Commit Rel Man Qual Const\nGPT4o-mini 0.20* 0.17* 0.50* 0.14 0.85 0.62 0.93 0\nGemini-Flash-OFF 0.22* 0.13 0.12* 0.24 0.89 0.69 0.93 0\nQwen2.5-7B -0.02 0.28* 0.66* 0.03 0.79 0.63 0.93 0\nQwen2.5-32B 0.17* 0.13 0.56* 0.07 0.88 0.70 0.93 0\nQwen2.5-32B-Few 0.16 0.11 0.52* 0.12 0.83 0.76 0.93 0\nQwen2.5-32B-Cons 0.14 0.11 0.26* 0.14 0.85 0.72 0.93 0\nLLaMA3.1-8B 0.12 0.17 0.72* 0.06 0.92 0.24 0.93 0\nLLaMA3.3-70B 0.16 0.21* 0.63* 0.13 0.87 0.71 0.93 0\no3-mini 0.30* 0.06 0.57* 0.12 0.87 0.70 0.93 0\nGemini-Flash-ON 0.20* 0.04 -0.21* 0.21 0.89 0.69 0.93 0\nDS-Qwen-7B -0.15 -0.01 0.44* -0.05 0.83 0.62 0.93 0\nQwQ-32B 0.29* 0.19* 0.59* 0.19 0.88 0.72 0.93 0\nQwQ-32B-Few 0.19* 0.27* 0.62* 0.20 0.90 0.71 0.93 0\nQwQ-32B-Cons 0.25* 0.23* 0.48* 0.26 0.86 0.73 0.93 0\nDS-LLaMA-8B 0.10 0.14 0.59* 0.05 0.64 0.66 0.93 0\nDS-LLaMA-70B 0.29* 0.24* 0.54* 0.17 0.88 0.70 0.93 0\nProsecution Witness vs. Defense (Simpson)\nModel BaT PaT NRBaT Commit Rel Man Qual Const\nGPT4o-mini 0.12 0.10 -0.18* 0.12 0.96 0.74 0.95 0\nGemini-Flash-OFF 0.23* 0.30* 0.24* 0.30 0.96 0.79 0.95 0\nQwen2.5-7B 0.11 0.11 0.10 0.06 0.91 0.58 0.95 0\nQwen2.5-32B 0.24* 0.04 0.03 0.10 0.95 0.68 0.95 0\nQwen2.5-32B-Few 0.33* 0.14 0.33* 0.13 0.94 0.72 0.95 0\nQwen2.5-32B-Cons 0.20* 0.16* 0.06 0.07 0.93 0.65 0.95 0\nLLaMA3.1-8B 0.79* 0.12 0.13 0.06 0.91 0.24 0.95 0\nLLaMA3.3-70b 0.19* 0.11 -0.18* 0.14 0.92 0.56 0.95 0\no3-mini 0.13 0.07 0.07 0.16 0.95 0.74 0.95 0\nGemini-Flash-ON 0.30* 0.19* 0.25* 0.24 0.98 0.77 0.95 0\nDS-Qwen-7B 0.02 0.09 0.06 0.06 0.89 0.60 0.95 0\nQwQ-32B 0.22* 0.18* 0.02 0.23 0.95 0.75 0.95 0\nQwQ-32B-Few 0.29* 0.26* -0.01 0.20 0.96 0.77 0.95 0\nQwQ-32B-Few 0.40* 0.26* 0.33 0.26 0.96 0.75 0.95 0\nDS-LLaMA-8B 0.14 0.05 0.01 -0.01 0.79 0.69 0.95 0\nDS-LLaMA-70B 0.21* 0.13* -0.13 0.14 0.95 0.68 0.95 0\nMetric Wins Loses Ties Mean Median SD CI Low CI High\nBaT 18 4 2 0.16 0.19 0.24 0.06 0.25\nPaT 18 4 2 0.12 0.09 0.22 0.04 0.22\nCommit 21 3 0 0.10 0.12 0.13 0.05 0.15\nNRBaT 10 12 2 0.08 -0.02 0.39 -0.07 0.23\nMan 17 5 2 0.12 0.13 0.17 0.06 0.19\nRel 19 5 0 0.06 0.07 0.19 -0.01 0.13\nQual 0 1 23 -8.33e-4 0 4.08e-3 -2.5e-3 0\nTable 5: Comparison by metric across models of different sizes. Wins indicate instances where the larger model\noutperforms the smaller one, while Loses indicate the opposite.\nMetric Wins Loses Ties Mean Median SD CI Low CI High\nBaT 12 17 1 -0.03 -0.02 0.22 -0.11 0.05\nPaT 8 22 0 -0.10 -0.05 0.20 -0.18 -0.04\nNRBaT 10 20 0 -0.09 -0.08 0.36 -0.22 0.03\nCommit 11 13 6 -0.02 0 0.13 -0.07 0.03\nMan 18 11 1 0.06 0.05 0.18 0 0.12\nRel 18 9 3 0.02 0.02 0.16 -0.04 0.08\nQual 1 2 27 0 0 0.05 -0.02 0.02\nTable 6: Comparison by metric across models with and without reasoning ability. Wins indicate instances where the\nreasoning model outperforms its non-reasoning counterpart, while Loses indicate the opposite.",
  "text_length": 77463
}