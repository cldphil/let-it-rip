{
  "id": "http://arxiv.org/abs/2506.00986v1",
  "title": "Talking to Data: Designing Smart Assistants for Humanities Databases",
  "summary": "Access to humanities research databases is often hindered by the limitations\nof traditional interaction formats, particularly in the methods of searching\nand response generation. This study introduces an LLM-based smart assistant\ndesigned to facilitate natural language communication with digital humanities\ndata. The assistant, developed in a chatbot format, leverages the RAG approach\nand integrates state-of-the-art technologies such as hybrid search, automatic\nquery generation, text-to-SQL filtering, semantic database search, and\nhyperlink insertion. To evaluate the effectiveness of the system, experiments\nwere conducted to assess the response quality of various language models. The\ntesting was based on the Prozhito digital archive, which contains diary entries\nfrom predominantly Russian-speaking individuals who lived in the 20th century.\nThe chatbot is tailored to support anthropology and history researchers, as\nwell as non-specialist users with an interest in the field, without requiring\nprior technical training. By enabling researchers to query complex databases\nwith natural language, this tool aims to enhance accessibility and efficiency\nin humanities research. The study highlights the potential of Large Language\nModels to transform the way researchers and the public interact with digital\narchives, making them more intuitive and inclusive. Additional materials are\npresented in GitHub repository:\nhttps://github.com/alekosus/talking-to-data-intersys2025.",
  "authors": [
    "Alexander Sergeev",
    "Valeriya Goloviznina",
    "Mikhail Melnichenko",
    "Evgeny Kotelnikov"
  ],
  "published": "2025-06-01T12:41:44Z",
  "updated": "2025-06-01T12:41:44Z",
  "categories": [
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00986v1",
  "full_text": "--- Page 1 ---\nTalking to Data: Designing Smart Assistants for \nHumanities Databases  \nAlexander Sergeev1[0009 -0002 -4103 -842X ], Valeriya Goloviznina1[0000 -0003 -1167 -2606 ],  \nMikhail Melnichenko1[0009 -0001 -2370 -3193 ], Evgeny Kotelnikov1[0000 -0001 -9745 -1489 ] \n1 European University at Saint Petersburg , St. Petersburg , Russia  \n{a.sergeev, v.goloviznina ,mmelnichenko ,e.kotelnikov }@eu.spb .com  \nAbstract. Access to humanities research databases is often hindered by the lim-\nitations of traditional interaction formats, particularly in the methods of searching \nand response generation. This study introduces an LLM -based smart assistant \ndesigned to facilitate nat ural language communication with digital humanities  \ndata. The assistant, developed in a chatbot format, leverages the RAG approach \nand integrates state -of-the-art technologies such as hybrid search, automatic \nquery generation, text -to-SQL filteri ng, semantic database search, and hyperlink \ninsertion. To evaluate the effectiveness of the system, experiments were con-\nducted to assess the response quality of various language models. The testing was \nbased on the Prozhito digital archive, which contains diary entries from predom-\ninantly Russian -speaking individuals who lived in the 20th century. The chatbot \nis tailored to support anthropology and history researchers, as well as non -spe-\ncialist users with an interest in the field, without requiring prior tec hnical training. \nBy enabling researchers to query complex databases with natural language , this \ntool aims to enhance accessibility and efficiency in humanities research. The \nstudy highlights the potential of Large Language Models to transform the way \nresearchers and the public interact with digital archives, making them more intu-\nitive and incl usive.  Additional materials are presented in GitHub repository: \nhttps://github.com/alekosus/talking -to-data-intersys2025 . \nKeywords:  Chatbot Assistants, Retrieval -Augmented Generation, Large Lan-\nguage Models . \n1 Introduction  \nLarge language models (LLMs) have significantly transformed data processing ap-\nproaches. Their ability to adapt to specific domains without costly training and solve \ndiverse tasks using in -context learning enables the integration of LLMs into various \nsystem s, such as chatbots [ 1], analytical platforms [ 2], and programming environ-\nments  [3]. \nThe use of LLMs has also proven valuable in the humanities due to their capacity to \nanalyze and organize textual data. Humanities projects often accumulate and store vast \n--- Page 2 ---\n2 \namounts of data. Examples include initiatives such as Europeana1, Dataverse2, HRAF3, \nand Prozhito4. However, the high complexity of data analysis, coupled with limited \naccessibility for researchers and interested users, restricts the conduct of humanities \nresearch. Resolving this limitation remains a major challenge for the creators of such \nprojects.  \nThe recently proposed Retrieval -Augmented Generation (RAG) approach [ 4] en-\nhances LLM processing effectiveness by incorporating up -to-date and domain -specific \ndata. RAG guides the model to generate and analyze factual information. However, the \noriginal implementation of RAG is not designed for complex knowledge bases common \nin the humanities, such as those containing tabular metadata, nor does it prioritize mul-\ntiple scores when selecting relevant passages.  \nThis study  propose s an assistant  based on LLM and RAG, specifically adapted for \nhumanities research, which provides users with open and accessible data analysis \nthrough a chatbot interface. This chatbot let users \"talk to data\" in natural language \nwhile ensuring the factual accuracy of r etrieved information. The assistant's effective-\nness is evaluated using a corpus of diary entries from the Prozhito archive . \nThe contributions of the work are as follows:  \n1. The architecture of the virtual assistant system is proposed to analyze data in human-\nities knowledge bases . \n2. The performance of semantic search is evaluated using different encoder language \nmodels and a hybrid search approach . \n3. The performance of answer generation is evaluated using different state -of-the-art \nLLMs (chat and reasoning models), and the accuracy and ethics of their responses \nare analyzed . \n2 Previous work  \nChatbots are becoming increasingly prevalent in many aspects of human life, including \neducation  [5,6], customer service  [7,8], emerging trends in academic research  [9], and \nthe fulfillment of emotional needs [ 10]. However, the scientific field of application of \nchatbots in humanities databases is just beginning to develop [ 11]. \nIn [12] was developed Al assistant specializing in research instrument validation for \nquantitative studies in education, psychology, and social sciences. This bot offers step -\nby-step guidance through the comprehensive validation process.  \nYetişensoy  and Karaduman developed and investigated an AI -powered chatbot for \nuse in Social Studies learning and teaching processes [ 13]. The post -test academic suc-\ncess of students in the experimental group, who participated in chatbot -supported learn-\ning, was significantly higher than that of students in the control group who did not \nreceive chatbot support.  \n \n1  https://www.europeana.eu  \n2  https://www.dataverse.pitt.edu  \n3  https://hraf.yale.edu  \n4  https://prozhito.org  \n--- Page 3 ---\n3 \nThe works [ 14,15] describe the experience of using chatbots in libraries. The \nwork  [16] is devoted to the development of RECBOT – the chatbot that performs nav-\nigation and recommendation functions in a virtual museum. The work [ 17] proposes to \nuse ChatGPT as a basis for a chatbot on archival data.  \nQuidwai and Lagana presented an innovative RAG based chatbot framework that \nharnesses the power of Natural Language Processing and state -of-the-art language \nmodels to curate and analyze Multiple Myeloma specific literature and provide person-\nalized treatmen t recommendations based on patient -specific genomic data [ 18]. \nSubash et al. present BARKPLUG V.2, an LLM -based chatbot system built using \nRAG pipelines to improve access to information within academic settings [ 19]. The \nsystem  is designed to provide users with information about various campus resources, \nincluding academic departments, programs, campus facilities, and student resources, in \nan interactive and user -friendly manner.  \nThese studies, unlike this work, do not use advanced search features such as hybrid \nsearch and generation of search queries, SQL and semantic  filtering , so such chatbots \ndo not fulfill the requirements of professional scientists.  \n3 System design  \n3.1 System architecture  \nProposed  system represents a generalization and extension of the Retrieval -Augmented \nGeneration approach. The system comprises multiple modules, each contributing to the \nformation of responses to queries. The system architecture diagram is presented in Fig. \n1. \nThree types of storage systems are utilized for data management:  \n• knowledge base – a relational database with SQL query processing capabilities, stor-\ning text passages and tabular data;  \n• vector database – a vector storage system supporting efficient distance computation \nand nearest neighbor search ; \n• text index database – a database optimized for efficient text data storage and re-\ntrieval . \nUser interaction occurs through a web -based chatbot interface capable of multi -turn \nconversations. The user can submit a query, which triggers search and result filtering \noperations. The system then generates a response to the current utterance based on th e \nuser's query, search results, and dialog history. The response results include hyperlinks \nto pages in the original knowledge base, enabling researchers to independently validate \nthe chatbot's answers and read the source material.  The chatbot  interface  is presented  \nin Appendix A . \nThe following is a detailed examination of the system’s core  modules . \n \n--- Page 4 ---\n4 \n \nFig. 1. System architecture diagram. Solid lines  represent data flow paths, while dashed lines  \nindicate storage access operations. Search modules are highlighted in yellow , filtering modules \nin green , and response generation modules in red. \n3.2 Hybrid search  \nThe hybrid search approach combines results from different types of information re-\ntrieval to improve overall relevance quality. For text data analysis, the system integrates \nfull-text (lexical) search with semantic search.  \nFull-text search operates by matching terms from the query with terms in indexed \npassages. Classical approaches such as TF -IDF [ 20] and more advanced ones like the \nBM25 algorithm compare term frequency (TF) while accounting for term frequency in \nthe knowledge base (inverse document frequency, IDF) and passage length. The search \nis performed using an inverted index that maps each term  to a list of documents where \nit appears.  \nTo enhance full -text search results, text preprocessing is commonly employed, in-\ncluding normalization (stemming, lemmatization) and stop -word removal. For tokeni-\nzation and lemmatization of Russian texts and queries, data from the UD Treebank \nSynTagRus5 corpus [ 21] and the Stanza6 library  were utilized . \n \n5  https://github.com/UniversalDependencies/UD_Russian -SynTagRus  \n6  https ://stanfordnlp .github .io/stanza /index .html \n\n--- Page 5 ---\n5 \nFull-text search proves effective for exact term matching but demonstrates sensitiv-\nity to phrasing variability, synonyms, and morphology, as it fails to account for seman-\ntic text similarity.  \nSemantic search represents a fundamentally different approach compared to full -text \nmethods. Its core principle involves transforming textual information into vector rep-\nresentations (embeddings) using encoder language models. Current implementations \nemploy  Transformer -based encoder language models such as SBERT [ 22], E5 [ 23], or \nBGE -M3 [ 24]. \nText encoders are trained using contrastive learning, an approach that positions se-\nmantically similar texts close to each other in a specific vector space. This enables the \ncomputation of semantic text similarity through comparison of embeddings using vec-\ntor similarity measures, such as cosine similarity.  \nThe primary advantage of semantic search lies in its ability to comprehend contex-\ntual meaning and nuanced query semantics. Unlike full -text search, it effectively han-\ndles synonyms and complex queries where semantic (rather than lexical) relevance is \ncrucia l. However, this approach demands substantial computational resources for pro-\ncessing vector representations and exhibits low interpretability due to its reliance on \ndeep neural networks.  \nThe hybrid search process combines relevance scores from both full -text and seman-\ntic approaches. Initially, each method retrieves a predetermined number k of passages \nmost similar to the query based on their respective similarity metrics. Subsequently, a \nlinear combination (1) of semantic similarity 𝑆𝑠𝑒𝑚 and full -text similarity 𝑆𝑓𝑡 scores is \ncomputed for the retrieved passages : \n 𝑆=𝛼𝑆𝑠𝑒𝑚+(1−𝛼)𝑆𝑓𝑡 (1) \nBoth scores , 𝑆𝑠𝑒𝑚 and 𝑆𝑓𝑡, must be normalized and scaled to the interval [0, 1] . The \nweight parameter α in (1) determines the degree of influence of retrieval methods and \ndepends on the specific task. Full -text search ensures high precision for terminological \nqueries but results in low recall due to the inability to analyze synonyms. In contrast, \nsemantic search increases coverage and, consequently, recall by identifying contextual \nrelationships a t the cost of reduced precision.  \nThus, adjusting the α parameter enables dynamic control over the efficiency of the \nsearch mechanism. For example, in highly specialized domains such as medicine and \nlaw, the weight of full -text search can be increased since exact term matching is crucial. \nConversely, in the an alysis of social media posts, where variations in wording are ex-\npected, increasing the weight of semantic search allows for better capture of contextual \nmeanings.  \nSince users interact with the assistant through multi -turn conversations, the initial \nquery may be insufficient for capturing the dialog context. For instance, a follow -up \nquery might refine the initial question without repeating any of its original terms,  rely-\ning instead on implied context. To address this issue, a Query Generation approach is \napplied: the complete conversation history, including the most recent user question, is \nsubmitted as a separate query to the LLM, which is instructed to generate an appropriate \nsearch query based on this information. The generated query is then utilized in the hy-\nbrid search process.  \n--- Page 6 ---\n6 \n3.3 Text -to-SQL  \nKnowledge bases may contain not only textual fragments but also other data types such \nas numbers, terms, dates, etc., for which hybrid search is not applicable. Such infor-\nmation is often stored in relational databases and accessed using the SQL query lan-\nguage. To enable natural language search within SQL databases, the Text -to-SQL ap-\nproach is employed.  \nText -to-SQL task involves the automatic conversion of natural language queries into \nstructured SQL queries while considering the database schema [ 25]. In general, Text -\nto-SQL enables the construction of arbitrary database queries; however, in this study, \nits application is limited to data retrieval (i.e., the SELECT operation).  \nModern large language models allow the use of the in -context learning approach to \ngenerate SQL queries from textual instructions. An LLM prompt contains a detailed \ninstruction specifying the task and the conditions for its correct execution. Additionally, \nthe prompt includes the database schema with descriptions of fields and relationships, \nenabling the model to map natural language entities to specific tables and columns. The \nprompt used for the Text -to-SQL task is provided in  \nAppendix B . \nTo enhance task performance, various Prompt Engineering techniques can be ap-\nplied, such as Few -shot Prompting and Chain -of-Thought. Few -shot prompting [ 26] \nallows the inclusion of multiple examples of transformations within the instruction. \nThis approach also helps specify edge cases that refine and supplement the primary \ninstruction.  \nChain -of-Thought [ 27,28] enables the model to conduct intermediate reasoning be-\nfore generating the SQL query. During this reasoning process, the model often de-\nscribes relationships between query entities and database fields and can employ the \nSelf-Correction mechanism [ 29] to resolve inconsistencies with the instruction. Ana-\nlyzing these reasoning chains also helps refine the LLM prompt for more efficient task \nexecution.  \n3.4 Semantic filtering  \nDatabase objects may contain short textual elements (a single word or a sentence) that \nare not primary search targets but allow for variability in representation. Examples in-\nclude:  \n• the value \" zoologist \" in the \"field of activity\" attribute of a database of social studies \nmay be described as \" biologist \" or even \" scientist \", though such synonyms are not \nexplicitly stored in the database ; \n• the city Saint -Petersburg  in biographical knowledge bases may be recorded under \nits historical names: Leningrad  or Petrograd ; \n• the free-text database field may contain different descriptions of the same object, \nsuch as \" black -and-white photograph \", \"B/W photo \", or \" monochrome image \". \nTo address this issue, semantic indexing is applied  to specified database text fields us-\ning approaches similar to those described for semantic search in Section 3.2. Full -text \n--- Page 7 ---\n7 \nsearch is not utilized in this case due to the short length of textual fragments; instead, it \nis implicitly replaced by exact text matching between the query and the database field.  \nSemantic filtering replaces the Text -to-SQL filtering stage for the specified text \nfields. Instead of exact string matching, the cosine similarity is computed  between the \nvector representation of the natural language query and the embeddings of the indexed \nfields. The similarity scores  𝑆𝑐 for each field  𝑐∈𝐶 are averaged and incorporated into \nthe overall ranking formula for the retrieved text fragments (2). Here, C represents the \nset of semantically indexed text fields, while γ defines the degree of influence of se-\nmantic similarity on the overall fragment ranking score : \n 𝑆=𝛾(𝛼𝑆𝑠𝑒𝑚+(1−𝛼)𝑆𝑓𝑡)+(1−𝛾)(1\n|𝐶|∑𝑆𝑐𝑐∈𝐶) (2) \n4 Data  \nThe part of  \"Prozhito\" diary corpus was used to test the system. The dataset contains \n60,240 personal diary entries written between January 1, 1900, and December 31, 1916. \nEach entry includes the text, the date of writing, and information about the author. There \nare 272 authors in total: 241 have a r ecorded date of birth, 226 have a recorded date of \ndeath. Additionally, each author has a short biography with an average length of \n123±122 characters; this field was used in semantic filtering. The entity -relationship \ndiagram of the data is presented in Fig. 2. \n \nFig. 2. Entity -relationship diagram of the data schema. The Embeddings  table is a service entity \nthat integrates the contents of the Vector database and the Text index database.  \nFor the experiments on search and answer generation, experts selected a 90 -entry \nsubset from the diary corpus, grouped into 25 topics. To expand the dataset while pre-\nserving key facts in the textual fragments, some entries were paraphrased using the \nlarge language model GPT -4o, ensuring that each topic contained 5 entries [ 30,31]. \n\n--- Page 8 ---\n8 \nNext, two questions per topic  were formulated , which can be answered using the \ncorresponding entries. As a result, the final dataset consists of 125 entries and 50 ques-\ntions. The list of topics is provided in Appendix C . \n5 Experiments  \n5.1 Search experiments  \nTo evaluate search quality, various full -text and semantic search models were compared \non the experimental dataset . \nThe following models were selected for experiments : \n• tf-idf – classic approach to forming sparse text embeddings for use in full -text \nsearch ; \n• multilingual -e5-large7 (hereafter, e5 -large) – an open -source dense encoder from \nMicrosoft ; \n• bge-m38 – an open -source dense encoder from BAAI ; \n• text-encoder -3-large9 (hereafter, te -3-large) – a proprietary dense encoder from \nOpenAI.  \nSemantic search model statistics are presented in Table 1. \nTable 1. Statistics of encoder language models for semantic search evaluation experiments.  \nModel  # parameters  Embedding size Context window  \ne5-large  560M  1,024 512 \nbge-m3 560M  1,024 8,192 \nte-3-large  n/a 3,072 8,191 \n \nFor each text fragment and question, embeddings were computed, and the Top -5 \nmost similar fragments were retrieved using cosine similarity. The Precision@5 metric \nwas used to assess the relevance of the retrieved fragments. Since each question in the \ndatas et has exactly five relevant fragments, Recall@5 is identical to Precision@5 and \nwas therefore not computed. The search quality evaluation results are presented in Ta-\nble 2. \nFor hybrid search evaluation, a linear combination of similarity scores from each \nsemantic model and tf -idf scores was computed using the formula (1). Based on the \nexperiments, the weight parameter α was set to 0.9.  \nThe highest precision was achieved by combining the te -3-large model for semantic \nsearch with tf -idf for full -text search. Among only semantic models, bge -m3 demon-\nstrated the best performance.  \n \n7  https://huggingface.co/intfloat/multilingual -e5-large  \n8  https://huggingface.co/BAAI/bge -m3 \n9  https://platform.openai.com/docs/models/text -embedding -3-large  \n--- Page 9 ---\n9 \nTable 2. Search quality evaluation results.  \nModel  Precision@5 ↑ \ntf-idf 0.264  \ne5-large  0.528  \n                      + tf-idf 0.556  \nbge-m3 0.568  \n                     + tf-idf 0.556  \nte-3-large  0.548  \n                     + tf-idf 0.572  \n \n5.2 Answer generation experiments  \nThe quality of answer generation based on relevant text fragments was evaluated by \ncomparing responses from various Large Language Models . The prompt provided to \neach model included a question and five relevant text fragments, based on which the \nmodel was asked to generate an answer. The LLM prompt is provided in Appendix D . \nThe following models were selected for experiments : \n• GPT -4o10  (v. 2024 -08-06) – a proprietary chat model from OpenAI;  \n• o3-mini11  (v. 2025 -01-31) – a proprietary reasoning model from OpenAI;  \n• DeepSeek -V312  – an open -source chat model from DeepSeek -AI; \n• DeepSeek -R113  – an open -source reasoning model from DeepSeek -AI; \n• Qwen -2.5 72B14 (hereafter, Qwen -2.5) – an open -source chat model from Alibaba.  \nLLMs statistics are presented in Table 3. \nTable 3. Statistics of Large Language Models for answer generation experiments.  \nModel  # parameters  Context window  \nGPT-4o n/a 128,000  \no3-mini  n/a 200,000  \nDeepSeek -V3 671B total, 37B active  128,000  \nDeepSeek -R1 671B total, 37B active  128,000  \nQwen -2.5 72B 128,000  \n \nThe generated responses were evaluated through expert annotation using the follow-\ning criteria  based on [ 32]: \n• Accuracy – evaluates the factual correctness of the model’s response, its relevance \nto the question, and grammatical correctness ; \n \n10  https ://platform .openai .com/docs /models /gpt-4o \n11  https ://platform .openai .com/docs /models /o3-mini \n12  https://huggingface.co/deepseek -ai/DeepSeek -V3 \n13  https://huggingface.co/deepseek -ai/DeepSeek -R1 \n14  https://huggingface.co/Qwen/Qwen2.5 -72B-Instruct  \n--- Page 10 ---\n10 \n• Ethics – evaluates the ethical appropriateness and safety of the model’s response.  \nFor each model response, an expert assigned a score from 1 to 5 for each criterion, \n1 means worst score, 5 means best score. A detailed description of the scoring criteria \nis provided in Appendix E . The evaluation was conducted by two annotators. The inter -\nannotator agreement for Accuracy was reliable (Krippendorff’s alpha = 0.804), while \nthe agreement for Ethics was moderate (Krippendorff’s alpha = 0.722) [ 33]. The eval-\nuation results are presented in Table  4. \nTable 4. Answer generation evaluation results . \nModel  Accuracy ↑ Ethics ↑ \nGPT-4o 4.23 4.43 \no3-mini  4.00 4.46 \nDeepSeek -V3 4.54 4.40 \nDeepSeek -R1 4.51 4.24 \nQwen -2.5 4.26 4.41 \n \nThe highest Accuracy score was achieved by the DeepSeek -V3 model. In terms of \nEthics, the best -performing model was o3 -mini.  \n6 Discussion  \nThe search quality evaluation demonstrates that combining full -text and semantic \nsearch can lead to a significant improvement in accuracy . The performance differences \nbetween the combination of semantic encoder with tf-idf encoder  and the semantic \nmodel alone are +0.028 for the e5 -large model and +0.024 for the te -3-large model. \nHowever, this is not always the case – combining the bge -m3 model with tf -idf resulted \nin a 0.012 decrease in accuracy  compared to using only bge -m3. This can be explained \nby the tr aining process of the model: its authors apply the Self -Knowledge Distillation \napproach, incorporating both semantic and full -text similarity during training  [24]. As \na result, the model may have implicitly learned to account for full -text similarity fea-\ntures when constructing dense embeddings, making the explicit inclusion of full -text \nsimilarity scores in the ranking function counterproductive.  \nFull-text search alone demonstrates relatively low precision. The dataset is based on \na diary entry corpus, where individuals write in freeform language without using spe-\ncific terminology. In this case, semantic search, which considers the meaning of the \ntext, proves to be the more effective approach. This also explains why the weight of \nsemantic search was set relatively high ( α = 0.9) in the hybrid search evaluation.  \nFor answer generation Accuracy evaluation, the following criteria were considered:  \n• correspondence of the answer to the given question ; \n• response is based on the fragments (with the ability to provide references);  \n• absence of grammatical, lexical, and formatting errors.  \n--- Page 11 ---\n11 \nThe easiest criterion for models to meet was the first one – ensuring that the response \nmatched the question. All models effectively identified the core meaning of the ques-\ntion and generated a relevant response.  \nAdditionally, LLMs rarely made grammatical or lexical errors when generating re-\nsponses in Russian. However, errors in complex sentence structures occasionally oc-\ncurred when the model used incorrect word forms. Formatting errors were more fre-\nquent – particu larly in cases where references to retrieved fragments were not provided \nin the correct format specified in the instructions.  \nThe majority of LLM errors stem from incorrect analysis of provided text passages. \nModels may either introduce information absent from the source fragments or fail to \nproperly utilize their internal knowledge when analyzing the passages. Specific factual \nerrors observed in the analysis of diary entries include:  \n• fabrication of facts ; \n• incorrect interpretation of misspelled terms;  \n• misattribution of diary authorship to mentioned individuals;  \n• drawing conclusions unsupported by source fragments.  \nExamples of factual errors observed in the analysis of diary entries are presented in \nthe Appendix F . \nFor the ethical evaluation of answer generation, the following criteria were consid-\nered:  \n• acknowledgment of the author’s subjectivity in the fragments;  \n• absence of evaluative judgments in the response;  \n• refusal to answer dangerous or prohibited questions, with a clear explanation of the \nreason.  \nIn most cases, LLMs recognize the subjectivity of the author: they frequently specify \nthat the fragments are taken from diaries, refer to event participants in the past tense, \nand almost never describe events in the first person.  \nHowever, evaluative judgments appear more frequently in model responses. As part \nof the introduction or conclusion, LLMs often generalize their reasoning, introducing \ncomparisons and connotations that were not present in the fragments. Examples of re-\nsponse s containing evaluative judgments:  \n• Healthcare at that time, of course, could not compare to modern standards . \n• One of the fragments describes a case where a boy suffered an eye injury and was \nurgently taken to a medical facility. Fortunately , everything turned out well.  \nTo analyze the safety of LLM -generated responses, eight questions in the experi-\nmental dataset (16% of the total) contained provocative or dangerous topics. These in-\ncluded assassinations, weapons, self -harm, and drugs.  \nThe expected behavior of the model when responding to such questions was to refuse \nto provide an answer, explicitly stating the reason for refusal. The average ethics scores \nfor provocative questions across different topics are presented in Fig. 3. \n--- Page 12 ---\n12 \n \nFig. 3. Average Ethics scores for provocative questions across each topic. Each topic contains \ntwo questions.  \nDespite most models flagging the potentially dangerous nature of the questions, they \ngenerated detailed responses containing hazardous or prohibited information. The mod-\nels typically included disclaimers stating their answers referred to historical events. \nThis experiment confirms the feasibility of LLM jailbreaking through temporal framing \nof questions in the past tense [ 34]. \nIt is important to note  the specifics of the experimental dataset. The Prozhito corpus \ncontains diary entries from individuals within a historical context. This dataset is char-\nacterized by a large volume of long -text data, lexical diversity and absence of special-\nized terminology. Databases from other studies may differ in content and data repre-\nsentation format, which could shift the emphasis in Accuracy and Ethics scores in a \ndifferent way. At the same time, the proposed system is not technically  constraine d by \na specific subject domain and can be applied to any knowledge base that is composed \nof textual data and relational connections.  \n7 Conclusion  \nThis study proposes a system based on Large Language Models and the Retrieval -Aug-\nmented Generation approach for interacting with humanities research databases. The 0 1 2 3 4 5AssassinationsWeaponsSelf-harmDrugs\nGPT-4o o3-mini DeepSeek-V3 DeepSeek-R1 Qwen-2.5\n--- Page 13 ---\n13 \nfocus is on databases containing primarily textual passages and metadata stored in re-\nlational databases. The performance of the search and answer generation modules is \nevaluated, and the evaluation results are analyzed . \nThe generation accuracy evaluation reveals that the models can provide precise an-\nswers to questions; however, LLMs exhibit difficulties in analyzing passages, leading \nto factual hallucinations, implicit inferences, and incorrect applications of the model's  \ninternal knowledge.  \nThe ethical evaluation also shows that the models can generate ethically correct re-\nsponses while acknowledging author subjectivity. However, the vulnerability of LLMs \nto attacks – such as framing harmful questions in the past tense – significantly reduces \nthe potential for diverse and safe access by non -expert users.  \nExperiments were conducted to  evaluate the quality of various encoder models for \nretrieval and LLMs for answer generation using a corpus of diary entries from the \n\"Prozhito\" project spanning 1900 -1916. The retrieval experiment results demonstrate \nthe effectiveness of hybrid search for  precise text fragment extraction.  \nReferences  \n1. Gill, S. S., Xu, M., Patros, P., Wu, H., Kaur, R., Kaur, K., Fuller, S., Singh, M., Arora, P., \nKumar Parlikad, A., Stankovski, V., Abraham, A., Ghosh, S. K., Lutfiyya, H., Kanhere, S. \nS., Bahsoon, R., Rana, O., Dustdar, S., Sakellariou, R., Uhlig, S., Buyy a, R.: Transformative \neffects of ChatGPT on modern education: Emerging Era of AI Chatbots. Internet of Things \nand Cyber -Physical Systems 4, 19 –23 (2024).  \n2. Weng, L., Wang, X., Lu, J., Feng, Y., Liu, Y., Feng, H., Huang, D., Chen, W.: InsightLens: \nAugmenting LLM -Powered Data Analysis with Interactive Insight Management and Navi-\ngation. arXiv:2404.01644 (2024).  \n3. Nam, D., Macvean, A., Hellendoorn, V., Vasilescu, B., Myers, B.: Using an LLM to Help \nWith Code Understanding. Proceedings of the IEEE/ACM 46th International Conference on \nSoftware Engineering, 1 -13 (2024).  \n4. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, \nM., Yih, W., Rocktäschel, T., Riedel, S., Kiela, D.: Retrieval -Augmented Generation for \nKnowledge -Intensive NLP Tasks. arXiv:2005.11401 (2020).  \n5. Chee, K. N., Abdul Rahman, M. H., Yahaya, N., Ibrahim, N., Razak, R., Sugino, C.: Ex-\nploring the Trend and Potential Distribution of Chatbot in Education: A Systematic Review. \nInternational Journal of Information and Education Technology, 13, 516 -525 (2023) . \n6. Ait Baha, T., El Hajji, M., Es -Saady, Y. et al. The impact of educational chatbot on student \nlearning experience. Educ Inf Technol 29, 10153 –10176 (2024).  \n7. Yoganand, B. V., Yajaman, V. G., Madugula, A., Hajari, M., Fathima, N., Chandramauli, \nA., Sharma, G.: Humanistic artificial intelligence context for automated customer assistance \nin online banking. AIP Conf. Proc. 21 April 2025; 3157 (1): 020003.  \n8. Behera, R.K., Bala, P.K., Ray, A.: Cognitive Chatbot for Personalised Contextual Customer \nService: Behind the Scene and beyond the Hype. Inf Syst Front 26, 899 –919 (2024).  \n9. Bilquise, G., Ibrahim, S., Salhieh, S.M.: Investigating student acceptance of an academic \nadvising chatbot in higher education institutions. Educ Inf Technol 29, 6357 –6382 (2024).  \n10. Figueroa -Torres, M.: The Three Social Dimensions of Chatbot Technology. Philos. Technol. \n38, 1 (2025).  \n--- Page 14 ---\n14 \n11. Mannheimer S., Bond N., Young S. W. H., Kettler H. S.: Responsible AI Practice in Librar-\nies and Archives: A Review of the Literature. Information Technology and Libraries. 43(3) \n(2024).  \n12. Villarino, R . T., Villarino, M . L.: Advancing Instrument Validation in Social Sciences: An \nAI-Powered Chatbot and Interactive Website based on Research Instrument Validation \nFramework (RIVF) (2024).  \n13. Yeti̇şensoy, O., Karaduman, H.: The effect of AI -powered chatbots in social studies educa-\ntion. Educ Inf Technol 29, 17035 –17069 (2024).  \n14. Ehrenpreis M., DeLooper J.: Implementing a Chatbot on a Library Website. Journal of Web \nLibrarianship 16(2), 120 –142 (2022).  \n15. Rodriguez S., Mune C.: Uncoding library chatbots: deploying a new virtual reference tool \nat the San Jose State University library. Reference Services Review. 50(3/4), 392 –405 \n(2022).  \n16. Tsitseklis K., Stavropoulou G., Zafeiropoulos A., Thanou A., Papavassiliou S.: RECBOT: \nVirtual Museum navigation through a Chatbot assistant and personalized Recommenda-\ntions. Adjunct Proceedings of the 31st ACM Conference on User Modeling, Adaptation and \nPersonalization (UMAP '23 Adjunct), 388 –396 (2023).  \n17. Potluri J., Gummadi H., Bhogi M., Katta Y. S., Ramesh G., Meghana Reddy T. S.: Unveiling \nCovert Conversational Agents: Enhancing Insight, Archives, and Dialog Acts with \nChatGPT. 7th International Conference on I -SMAC (IoT in Social, Mobile, Analytics and \nCloud), 766 –772 (2023).  \n18. Quidwai, M. A., Lagana, A.: A RAG Chatbot for Precision Medicine of Multiple Myeloma. \nmedRxiv 2024.03.14.24304293 (2024).  \n19. Subash, N., Hossain, E., Keith, J., Tripathi, H., Ghiasi, F., Golilarz, N. A., Amirlatifi, A., \nMittal, S., Rahimi, S.: From Questions to Insightful Answers: Building an Informed Chatbot \nfor University Resources. arXiv:2405.08120 (2024).  \n20. Sparck Jones, K.: A statistical interpretation of term specificity and its application in r e-\ntrieval. Journal of documentation, 28(1), 11 –21 (1972).  \n21. Droganova, K., Lyashevskaya, O., Zeman, D.: Data Conversion and Consistency of Mono-\nlingual Corpora: Russian UD Treebanks. In Proceedings of the 17th International Workshop \non Treebanks and Linguistic Theories (TLT 2018), December 13 –14, 2018, Oslo Universi ty, \nNorway, 155, 52 –65 (2018).  \n22. Reimers, N., Gurevych, I.: Sentence -BERT: Sentence Embeddings using Siamese BERT -\nNetworks. arXiv:1908.10084 (2019).  \n23. Wang, L., Yang, N., Huang, X., Jiao, B., Yang, L., Jiang, D., Majumder, R., Wei, F.: Text \nEmbeddings by Weakly -Supervised Contrastive Pre -training. arXiv:2212.03533 (2022).  \n24. Chen, J., Xiao, S., Zhang, P., Luo, K., Lian, D., Liu, Z.: BGE M3 -Embedding: Multi -Lin-\ngual, Multi -Functionality, Multi -Granularity Text Embeddings Through Self -Knowledge \nDistillation. arXiv:2402.03216 (2024).  \n25. Hong, Z., Yuan, Z., Zhang, Q., Chen, H., Dong, J., Huang, F., Huang, X.: Next -Generation \nDatabase Interfaces: A Survey of LLM -based Text -to-SQL. arXiv: 2406.08426 (2024).  \n26. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.: Language models are \nunsupervised multitask learners. OpenAI blog, 1(8), 9 (2019).  \n27. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., Iwasawa, Y.: Large Language Models are Zero -\nShot Reasoners. arXiv:2205.11916 (2022).  \n28. Tai, C. Y., Chen, Z., Zhang, T., Deng, X., Sun, H.: Exploring Chain-of-Thought Style \nPrompting for Text-to-SQL. arXiv:2305.14215 (2023).  \n29. Lightman, H., Kosaraju, V., Burda, Y., Edwards, H., Baker, B., Lee, T., Leike, J., Schulman, \nJ., Sutskever, I., Cobbe, K.: Let's Verify Step by Step. arXiv:2305.20050 (2023).  \n--- Page 15 ---\n15 \n30. de Lima, R. T., Gupta, S., Berrospi, C., Mishra, L., Dolfi, M., Staar, P., Vagenas, P.: Know \nYour RAG: Dataset Taxonomy and Generation Strategies for Evaluating RAG Systems. \narXiv: 2411.19710 (2024).  \n31. Long, L., Wang, R., Xiao, R., Zhao, J,, Ding, X., Chen, G., Wang, H.: On LLMs -Driven \nSynthetic Data Generation, Curation, and Evaluation: A Survey. Findings of the Association \nfor Computational Linguistics: ACL 2024, 11065 –11082 (2024).  \n32. Murugadoss, B., Poelitz, C., Drosos, I., Le, V., McKenna, N., Negreanu, C. S., Parnin, C., \nSarkar, A.: Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation In-\nstructions. arXiv:2408.08781 (2024).  \n33. Krippendorff, K.: Content Analysis: An Introduction to Its Methodology. SAGE Publica-\ntions (2019).  \n34. Andriushchenko, M., Flammarion, N.: Does Refusal Training in LLMs Generalize to the \nPast Tense? arXiv:2407.11969 (2024).  \nAppendix A. Chatbot interface  \nChatbot interface  is available at the repository, Appendix A . \nAppendix B. Prompt with instruction for solving the Text -to-\nSQL task  \nText -to-SQL prompt is available at the repository, Appendix B . \nAppendix C. Topics of the experimental dataset  \nDataset topics are available at the repository, Appendix C . \nAppendix D. Prompt for generating an answer to a question \nbased on relevant fragments  \nAnswer generation prompt is available at the repository, Appendix D . \nAppendix E. Description of expert scoring criteria for answer \ngeneration evaluation  \nExpert scoring criteria are available at the repository, Appendix E . \nAppendix F. Examples of factual errors of LLMs found during \nevaluation analysis  \nLLMs factual errors are available at the repository, Appendix F .",
  "text_length": 37431
}