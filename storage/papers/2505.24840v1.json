{
  "id": "http://arxiv.org/abs/2505.24840v1",
  "title": "Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are\n  the Bottleneck",
  "summary": "This paper reveals that many state-of-the-art large language models (LLMs)\nlack hierarchical knowledge about our visual world, unaware of even\nwell-established biology taxonomies. This shortcoming makes LLMs a bottleneck\nfor vision LLMs' hierarchical visual understanding (e.g., recognizing Anemone\nFish but not Vertebrate). We arrive at these findings using about one million\nfour-choice visual question answering (VQA) tasks constructed from six\ntaxonomies and four image datasets. Interestingly, finetuning a vision LLM\nusing our VQA tasks reaffirms LLMs' bottleneck effect to some extent because\nthe VQA tasks improve the LLM's hierarchical consistency more than the vision\nLLM's. We conjecture that one cannot make vision LLMs understand visual\nconcepts fully hierarchical until LLMs possess corresponding taxonomy\nknowledge.",
  "authors": [
    "Yuwen Tan",
    "Yuan Qing",
    "Boqing Gong"
  ],
  "published": "2025-05-30T17:40:46Z",
  "updated": "2025-05-30T17:40:46Z",
  "categories": [
    "cs.CV",
    "cs.AI",
    "cs.CL",
    "cs.LG"
  ],
  "pdf_url": "http://arxiv.org/pdf/2505.24840v1"
}