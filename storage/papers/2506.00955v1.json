{
  "id": "http://arxiv.org/abs/2506.00955v1",
  "title": "Leveraging Large Language Models for Sarcastic Speech Annotation in\n  Sarcasm Detection",
  "summary": "Sarcasm fundamentally alters meaning through tone and context, yet detecting\nit in speech remains a challenge due to data scarcity. In addition, existing\ndetection systems often rely on multimodal data, limiting their applicability\nin contexts where only speech is available. To address this, we propose an\nannotation pipeline that leverages large language models (LLMs) to generate a\nsarcasm dataset. Using a publicly available sarcasm-focused podcast, we employ\nGPT-4o and LLaMA 3 for initial sarcasm annotations, followed by human\nverification to resolve disagreements. We validate this approach by comparing\nannotation quality and detection performance on a publicly available sarcasm\ndataset using a collaborative gating architecture. Finally, we introduce\nPodSarc, a large-scale sarcastic speech dataset created through this pipeline.\nThe detection model achieves a 73.63% F1 score, demonstrating the dataset's\npotential as a benchmark for sarcasm detection research.",
  "authors": [
    "Zhu Li",
    "Yuqing Zhang",
    "Xiyuan Gao",
    "Shekhar Nayak",
    "Matt Coler"
  ],
  "published": "2025-06-01T11:00:18Z",
  "updated": "2025-06-01T11:00:18Z",
  "categories": [
    "cs.CL",
    "cs.SD",
    "eess.AS"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00955v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00955v1  [cs.CL]  1 Jun 2025Leveraging Large Language Models for Sarcastic Speech Annotation in\nSarcasm Detection\nZhu Li1, Yuqing Zhang2, Xiyuan Gao1, Shekhar Nayak1, Matt Coler1\n1Speech Technology Lab, University of Groningen, The Netherlands\n2Center for Language and Cognition, University of Groningen, The Netherlands\n{zhu.li, yuqing.zhang, xiyuan.gao, s.nayak, m.coler }@rug.nl\nAbstract\nSarcasm fundamentally alters meaning through tone and con-\ntext, yet detecting it in speech remains a challenge due to data\nscarcity. In addition, existing detection systems often rely on\nmultimodal data, limiting their applicability in contexts where\nonly speech is available. To address this, we propose an anno-\ntation pipeline that leverages large language models (LLMs) to\ngenerate a sarcasm dataset. Using a publicly available sarcasm-\nfocused podcast, we employ GPT-4o and LLaMA 3 for initial\nsarcasm annotations, followed by human verification to resolve\ndisagreements. We validate this approach by comparing anno-\ntation quality and detection performance on a publicly avail-\nable sarcasm dataset using a collaborative gating architecture.\nFinally, we introduce PodSarc, a large-scale sarcastic speech\ndataset created through this pipeline. The detection model\nachieves a 73.63% F1 score, demonstrating the dataset’s poten-\ntial as a benchmark for sarcasm detection research.\nIndex Terms : sarcasm detection, large language models, auto-\nmatic data annotation\n1. Introduction\nSarcasm plays a critical role in communication by convey-\ning meaning that deliberately contradicts literal interpretation.\nThe detection of sarcasm presents unique challenges for speech\ntechnology, as speakers deploy complex combinations of lex-\nical content, prosodic features, and contextual cues to signal\nsarcastic intent. While humans generally interpret these signals\nintuitively, automated systems often struggle to interpret sarcas-\ntic utterances, leading to errors in human-computer interaction.\nAccurate sarcasm detection is crucial for conversational AI sys-\ntems, where misinterpreting sarcastic intent can result in inap-\npropriate responses that damage user trust and system efficacy.\nDespite its importance, sarcasm detection in speech re-\nmains underexplored and is often constrained by small anno-\ntated datasets and challenges in generalization [1, 2, 3]. Pub-\nlicly available datasets such as the Multimodal Sarcasm Detec-\ntion Dataset (MUStARD) [4] and its extension, MUStARD++\n[5] compiled from TV shows, include multimodal data and en-\nable video-level multimodal sarcasm detection. However, these\nmultimodal datasets are limited in size and scope, hindering the\ndevelopment of robust sarcasm detection models.\nIn addition, most existing approaches to detecting sarcasm\nrely on multimodal feature fusion [2, 6, 7, 8]. However, in real-\nworld applications, sarcasm often needs to be detected from\nspeech alone, without the benefit of visual context. This chal-\nlenges the development of sarcasm detection systems for audio-\nonly scenarios like podcasts, radio broadcasts, and telephone\nconversations. Meanwhile, text-based sarcasm detection has\nprogressed significantly in natural language processing (NLP).However, subtle cues in speech cannot be captured in this man-\nner, since sarcasm is often conveyed not just through content,\nbut also through auditory features such as intonation, pitch, pac-\ning, and emphasis [9, 10]. More importantly, the scarcity of sar-\ncastic utterances makes it difficult for detection models to learn\nfine-grained audio representations. As a result, most existing\napproaches rely on low-level acoustic features [5]. Thus, we ur-\ngently need large-scale annotated datasets specifically targeting\nsarcastic speech detection without visual cues.\nRecently, LLMs have shown promise in various NLP tasks,\nincluding emotion [11, 12], humor [13] and sarcasm under-\nstanding [14]. However, most advancements have been in text\nand image modalities [15]. This work leverages LLMs to facili-\ntate sarcasm annotation of real-world “in-the-wild” speech data,\nspecifically Overly Sarcastic Podcast (OSPod)1, a series with a\nrich and diverse use of naturalistic and spontaneous sarcastic\nexpressions. Human annotators are incorporated to resolve dis-\nagreements between LLM-based annotations.\nThis work makes three key contributions: (1) We demon-\nstrate the feasibility of using LLMs to facilitate sarcasm annota-\ntion, enabling the creation of a bi-modal sarcastic speech dataset\nwith reduced reliance on human annotators. (2) We validate the\neffectiveness of our LLM-based annotation approach by com-\nparing annotation performance and testing detection models on\na publicly available dataset. (3) Using this pipeline, we create\na large-scale high-quality sarcastic speech dataset that can be\nused for speech-based bi-modal sarcasm detection, with poten-\ntial applications in real-world, speech-only environments.2\n2. Related Work\nDatasets for sarcasm detection The detection of sarcasm\nin speech has been limited by the availability of annotated\ndatasets. General emotion detection datasets, such as MELD\n[16] and IEMOCAP [17], while rich in their inclusion of emo-\ntional speech, do not specifically capture the subtleties of sar-\ncasm. While sarcasm can overlap with emotions like anger, joy,\nor surprise, it possesses distinct features that emotion-focused\nannotations fail to capture. Existing sarcasm detection datasets\nlike MUStARD [4] and MUStARD++ [5], although instrumen-\ntal in advancing multimodal sarcasm detection, primarily fo-\ncus on incorporating visual and textual cues alongside speech.\nSince some sarcastic labels in these datasets rely on visual con-\ntext (including facial expressions, gestures), audio-only models\nmay show reduced performance. Therefore, their applicability\nto real-world speech-only environments is limited.\n1https://overlysarcasticpodcast.transistor.fm\n2Detailed prompts used for LLM annotations, as well as the anno-\ntated dataset before and after human verification, will be made available\nfor research purposes upon request.\n--- Page 2 ---\n…I. Data ProcessingII. LLM AnnotationsEmilia-Pipeline\nIII. Human Verification\nSameDifferentCompare\nRole: Sarcasm-detection expertRaw Texts: Current utterance, context, timestamps, speaker info, etcFocus: Context, linguistic cues (e.g., exaggeration, contradiction, absurdity), tone, implied meaningsFew-shot Examples: Positive and negative annotation examplesAnnotation Output Format:-Text: Original utterance-Sarcasm: Boolean (true/false)-Comment: Explanation of why the text is sarcastic or not…UtteranceUsually we're separated by oceans and stars, but now we're in the same space, so, uh.… exaggerated language about separation, ‘oceans and stars’ … humorously highlight the rarity of in-person recording … sarcastic in its grandiose description.LLM-based Annotations\nHuman Checking‘oceans and stars’ - hyperbolic metaphor to exaggerate a small distance;‘so, uh.’ - exaggerated hesitation. GPT-4o: SarcasticLLaMA:Not sarcastic… genuine and poetic expression of surprise or wonder at being in close proximity to someone … without any intent to be ironic.Label: Sarcastic\n…Figure 1: Overview of the annotation pipeline used for collecting bimodal sarcasm data.\nAutomatic speech data collection Gathering large-scale,\nhigh-quality training data with appropriate labels has always\nbeen a critical aspect of speech technology development. Over\ndecades, the speech community has invested substantial ef-\nfort in collecting and annotating speech data with segmenta-\ntion, transcription, and speaker labels, significantly advancing\nspeech recognition and synthesis technologies. To automate the\ndata collection process, automatic preprocessing frameworks\nthat generate segmentation, speaker labels, and transcriptions\nfor in-the-wild speech while removing noise, reverberation, and\noverlapping speech have been proposed [18, 19].\nLLMs for data annotation Model training heavily de-\npends on datasets with high-quality annotations. Given their\nsuccess in annotation tasks, LLMs are increasingly being ex-\nplored as data annotators for scenarios with limited or well-\ndefined label sets [20, 21, 22]. Recent studies have explored\nthe affective capabilities of LLMs, demonstrating their ability\nto infer emotions in given contexts and respond with emotional\nsupport in dialogues [15]. Specifically, LLMs like GPT have\nshown promise in identifying emotions and intent from text\n[11, 23]. LLMs have also been evaluated in zero- or few-shot\nemotion recognition tasks and have shown good performance\n[11, 24, 25]. Compared with general emotion recognition tasks,\nsarcasm detection using LLMs remains underexplored, likely\ndue to its greater reliance on nuanced understanding beyond\ngeneral emotional cues.\n3. Dataset\nThis study leverages LLMs to accelerate the process of annotat-\ning sarcasm in speech data, reducing the reliance on human an-\nnotators and enabling large-scale consistent labeling. As illus-\ntrated in Figure 1, the proposed pipeline consists of three stages:\n(1) automatic data collection and processing, (2) sarcasm anno-\ntation using LLMs, and (3) human verification to resolve LLM\nannotation disagreements.\n3.1. Automatic data collection and processing\nAs illustrated in Figure 1, the raw audio from OSPod was sys-\ntematically processed to extract high-quality speech segments\nat utterance level and generate corresponding transcripts us-\ning Emilia-Pipe [19], an open-source preprocessing pipeline\ndesigned to convert in-the-wild speech data into structured\ndatasets with precise annotations (e.g., timestamps, speaker\ninformation). In total, 30 episodes were processed, yielding\n11,024 segments. Each segment was aligned with its transcript\nto create a robust bimodal dataset for annotation. To enhancedata quality, the processed dataset was carefully checked to re-\nmove noise, irrelevant content, and unclear segments.\n3.2. Sarcasm annotation using LLMs\nFor the processed dataset, we used two LLMs as annotators,\nGPT-4o3and LLaMA 3 [26], to perform sarcasm label annota-\ntions. These models were selected for their state-of-the-art per-\nformance in understanding contextual and nuanced language.\nFor each annotator, we provide a carefully designed prompt tai-\nlored to guide the LLM in accurately identifying sarcasm (Fig-\nure 1). The prompts include structured raw texts, highlighted\ncues to focus on, examples of sarcastic and non-sarcastic ex-\npressions, and an annotation output template. The annotation\nprocess was carried out with both GPT-4o and LLaMA 3 in-\ndependently labeling each segment. This dual-annotator ap-\nproach enabled us to compare the outputs and identify samples\nof agreement and disagreement between the two models.\nTo validate the effectiveness of LLM-based annotation, we\ncompared the LLMs’ annotations with the gold labels of the\nMUStARD++ dataset. Table 1 presents the annotation per-\nformance of GPT-4o and two versions of LLaMA 3 on the\nMUStARD++ dataset. Among the models, GPT-4o achieved\nthe highest performance, with a Macro-averaged F1 (Macro-\nF1) of 67.47% and a Unweighted Average Recall (UAR) of\n67.12%, indicating its strong capability in sarcasm annotation.\nThe LLaMA 3 models performed comparably, with LLaMA 3-\n70B slightly outperforming the 8B variant (63.59% vs. 61.52%\nin F1 score).4These results suggest that all evaluated LLMs\nexhibit reasonable proficiency in sarcasm detection.\nTable 1: Annotation Performance on MUStARD++\nLLMs Macro-F1 (%) UAR (%)\nGPT-4o 67.47 67.12\nLLaMA3.1-8B 61.52 62.64\nLLaMA3.1-70B 63.59 64.47\nWe obtain sarcasm annotations from GPT-4o and LLaMA\n3 on transcriptions of OSPod. These annotations serve as an\ninitial step in creating a high-quality labeled dataset, which is\nthen refined through human verification to resolve discrepancies\nand enhance the reliability of the labels.\n3https://chat.openai.com\n4We will use LLaMA 3-70B only for the following experiments.\n--- Page 3 ---\n3.3. Human verification\nWith the LLMs’ annotation capabilities confirmed, we pro-\nceeded to annotate the OSPod dataset. While both models\nshowed strong performance, they produced conflicting labels\nfor 2,884 of the 11,024 utterances. To resolve these discrep-\nancies and ensure high-quality annotations, two PhD students\nspecializing in phonetics manually reviewed these cases.\nSince cases where LLMs produced conflicting labels were\nhighly ambiguous, inter-annotator agreement was calculated\nwith a Kappa score of 0.58. The differences were reconciled\nby a third annotator. Figure 1 illustrates how the discrepan-\ncies were addressed during the human verification phase. An-\nnotators first reviewed the explanations provided by the LLMs.\nSince prosodic cues were missing during the LLM annotation\nphase, the human review placed particular emphasis on prosody\nalongside textual features. For example, in the utterance: “Usu-\nally we’re separated by oceans and stars, but now we’re in the\nsame space, so, uh.” The phrase “so, uh.” features a playful\ntone and hesitation. Combined with the dramatic phrasing of\n“oceans and stars” and the conversational context of a first-time\nin-person recording, this utterance was labeled as sarcastic.\n3.4. Sarcasm dataset: PodSarc\nWe apply the proposed annotation pipeline to process OSPod5,\nobtaining a large-scale bimodal sarcasm dataset, which we call\nPodSarc (Podcast Sarcasm). On average, each segment in Pod-\nSarc has 31.18 words and a duration of 9.61 seconds, provid-\ning a long duration that can capture prosodic and contextual\ncues crucial for sarcasm detection. To analyze the diversity\nof acoustic and semantic features, we randomly sample 1,000\nutterances each from MUStARD++ and PodSarc. We extract\nacoustic representations using a pre-trained WavLM model6and\ntext representations using a pre-trained Sentence-BERT model7.\nAs shown in Figure 2a, PodSarc exhibits a comparable level of\nacoustic and semantic dispersion to MUStARD++, suggesting\nthat it covers diverse speech characteristics.\nAcoustic diversity\nSemantic diversity\nDatasetMUStARD++PodSarcDatasetMUStARD++PodSarc\n(a)Diversity\n0500100015002000\nSpk_00Spk_01Spk_02Spk_03Spk_04Spk_05Spk_06Spk_07\nPodSarcUtterancesType NonSarcastic Sarcastic (b)Speaker statistics\nFigure 2: (a) A comparison of acoustic diversity and seman-\ntic diversity between PodSarc and MUStARD++ datasets. (b)\nSpeaker-label ratio for PodSarc.\nTable 2 presents the number of sarcastic and non-sarcastic\nutterances identified by LLaMA 3, GPT-4o, human verification,\nand the final annotated dataset. LLaMA 3 initially labeled 4,400\nutterances as sarcastic and 6,624 as non-sarcastic, while GPT-\n5The dataset is in English and sourced from U.S. American podcasts,\nthus reflecting U.S. specific sarcasm norms.\n6https://huggingface.co/microsoft/wavlm-base-plus\n7https://github.com/UKPLab/sentence-transformers4o produced a more conservative estimate, identifying 3,902\nsarcastic and 7,122 non-sarcastic utterances. To improve la-\nbel reliability, human verification was conducted to resolve dis-\nagreements between models, refining 1,318 sarcastic and 1,566\nnon-sarcastic utterances. Incorporating these refinements, the\nfinal PodSarc dataset consists of 4,026 sarcastic and 6,998 non-\nsarcastic utterances. This final annotation reflects a balanced\nsarcasm distribution suitable for training and evaluation.\nTable 2: The number of sarcastic and non-sarcastic utterances\nidentified by LLaMA 3, GPT-4o, Human verification and final\nannotation.\nSarcastic Non-Sarcastic\nLLaMA 3 4,400 6,624\nGPT-4o 3,902 7,122\nHuman verification 1,318 1,566\nFinal 4,026 6,998\nAdditionally, PodSarc contains approximately 29.42 hours\nof speech-transcript pairs. Figure 2b further illustrates the dis-\ntribution of sarcastic and non-sarcastic labels per speaker.\n4. Experiments and Results\nThis section presents key findings from our sarcasm detec-\ntion experiments. We first evaluate models trained on MUS-\ntARD++, using both original human-annotated labels and\nLLM-generated, human-verified labels. We then analyze the\nannotation results for PodSarc and its detection performance. A\ncomparative analysis highlights the effectiveness of our annota-\ntion pipeline and model performance across datasets.\n4.1. Experimental setup\nWe follow MUStARD++ for feature extraction and sarcasm de-\ntection [5]. MUStARD++ introduces a collaborative gating ar-\nchitecture that enables multimodal feature fusion, followed by\nclassification through fully connected layers. While the original\nimplementation integrates text, audio, and visual modalities8,\nour work focuses on the text and audio modalities. Below, we\nbriefly describe the extraction process for each modality.\nText modality (T) We encode the text using BART [27]\nLarge model with dt= 1024 and use the mean of the last\nfour transformer layer representations to get a unique embed-\nding representation for each utterance.\nAudio modality (A) we extract MFCC, Mel spectrogram\nand prosodic features of size dm,ds,dprespectively. Then we\ntake the average across segments to get the final feature vector.\nHere dm= 128 ,ds= 128 ,dp= 35 , so our audio feature\nvector is of size da= 291 .\nWe conduct two detection experiments using MUStARD++\nand PodSarc. First, we evaluate our annotation pipeline on\nMUStARD++ to validate that LLM-generated labels can pro-\nduce functional detection models compared to human annota-\ntions. This validation establishes the viability of our approach\nbefore applying it to create PodSarc. Second, we evaluate detec-\ntion performance on PodSarc itself to demonstrate the dataset’s\nutility. MUStARD++ is split into training and testing sets at an\n8:2 ratio (962:240). For PodSarc, we use the entire dataset for\ntraining, reserving three manually annotated episodes for test-\ning with a sarcasm-to-non-sarcasm ratio of 243:504. For all\n8https://github.com/cfiltnlp/MUStARD Plus Plus\n--- Page 4 ---\n69.269.169.167.567.567.570.970.870.8\n505560657075\nPrecisionRecallF1−scoreScore (%)Human\n61.260.660.261.761.661.662.461.461.8PrecisionRecallF1−scoreLLM66.865.665.166.665.765.667.968.167.4\nPrecisionRecallF1−scoreProposed\nModalityTAA+T69.269.169.167.567.567.570.970.870.8\n505560657075\nPrecisionRecallF1−scoreScore (%)Human\n61.260.660.261.761.661.662.461.461.8\nPrecisionRecallF1−scoreLLM\n66.865.665.166.665.765.667.968.167.4\nPrecisionRecallF1−scoreProposed\nModalityTAA+TFigure 3: Sarcasm detection results on MUStARD++ using human-annotated labels (Human), GPT-4o labels (LLM), and GPT-4o\nlabels with human verification (Proposed) across text (T), audio (A), and combined (A+T) modalities.\ntraining runs, we perform hyperparameter tuning with dropout\nvalues in [0.2, 0.3, 0.4], learning rates in [0.001, 0.0001], batch\nsizes in [32, 64, 128], shared embedding sizes in [1024, 2048],\nand projection embedding sizes in [256, 1024].\n4.2. Performance on MUStARD++\nWe evaluate sarcasm detection performance across different\nfeature modalities and label sources, comparing models trained\non real MUStARD++ labels, GPT-4o-generated labels, and la-\nbels from our proposed annotation pipeline (Figure 3). For the\ntext modality, the model trained on real labels achieved 69.1%\nF1 score. Performance dropped slightly when using GPT-4o\nlabels (60.2% F1). Our pipeline’s labels yielded intermediate\nresults (65.1% F1). For the audio modality, the real-label model\nreached 67.5% across all metrics. GPT-4o labels led to lower\nperformance (61.6% F1), while our pipeline achieved 65.6%\nF1. Combining text and audio modality improves performance.\nThe real-label model achieved 70.8% F1, while GPT-4o labels\nresulted in 61.8% F1. Our pipeline’s labels performed better\nthan GPT-4o (67.4% F1). Overall, bimodal detection outper-\nforms individual modalities. While GPT-4o annotations slightly\nreduce performance compared to real labels, they still provide\napproximations for sarcasm detection.\n4.3. Performance on PodSarc\nSimilar to Section 4.2, we evaluate sarcasm detection perfor-\nmance on PodSarc using different feature modalities: text, au-\ndio, and their combination. We compare the performance of\nmodels trained with LLM-generated labels, and human-verified\nlabels annotated through our pipeline.\nTable 3: Sarcasm detection results on PodSarc.\nAnnotations Modalities P (%) R (%) F1 (%)\nLLM T 69.48 70.45 69.88\nA 60.08 60.85 60.28\nA+T 71.12 70.93 71.47\nProposed T 72.70 72.39 72.54\nA 61.36 62.44 61.58\nA+T 73.28 74.03 73.63\nTable 3 shows that multimodal models incorporating both\ntext and audio consistently outperform single-modal models,\nwith the highest F1 score of 73.63% achieved using human-\nverified LLM annotations. Text-based models generally out-\nperform audio-only models, emphasizing the critical role oftextual context in sarcasm detection. Models trained on\nLLM-generated labels perform slightly worse than those us-\ning human-verified annotations but still achieve strong results,\nwith an F1 score of 71.47% in the multimodal setting. This\nsuggests that LLMs provide a valuable starting point for large-\nscale annotation, particularly when followed by human verifi-\ncation. Overall, the results highlight the effectiveness of com-\nbining human expertise with LLM-assisted annotation to create\nhigh-quality datasets for sarcasm detection.\nCompared to the detection results on MUStARD++, mod-\nels trained on LLM-annotated labels on PodSarc show better\nperformance across all settings (e.g., A +T setting: 71.47% vs.\n61.8%). This difference may be due to dataset composition.\nMUStARD++ incorporates three modalities (text, audio, and vi-\nsual), with some sarcastic utterances manually annotated based\non visual cues—an aspect absent in our LLM-based annotation\nmethod and PodSarc. Since our detection models cannot lever-\nage visual context, their performance on MUStARD++ is lower.\nIn contrast, PodSarc consists solely of text and audio-based sar-\ncasm, aligning closely with the features available to the models.\nNevertheless, PodSarc presents certain limitations. While\ndual-LLM annotation with targeted human verification reduces\nnoise, cases where both models agree may still contain unde-\ntected errors. Future work may benefit from partial human val-\nidation to further enhance annotation quality.\n5. Conclusion\nThis work advances sarcasm detection by addressing a funda-\nmental challenge: the scarcity of large-scale annotated multi-\nmodal datasets. We demonstrate that LLMs can serve as ef-\nfective tools for identifying sarcastic speech, presenting a novel\npipeline that combines the complementary strengths of LLMs\nwith targeted human verification. Applying this approach to\nnatural conversational data from OSPod, we introduce PodSarc,\na new large-scale sarcasm dataset. Our results demonstrate that\nLLM-based annotation reduces manual annotation burden while\nmaintaining usable quality for initial dataset creation.\nThese findings have implications for improving human-\ncomputer interaction systems, particularly in applications where\nnuanced interpretation of speaker intent is crucial. This work\nopens promising research directions: extending the annotation\npipeline to distinguish sarcasm from hyperbole, irony, and other\nnon-literal speech, incorporating emerging language models to\nimprove annotation accuracy, and expanding the dataset to en-\ncompass greater linguistic and cultural diversity. Future work\ncould evaluate whether models trained on LLM-annotated data\ntransfer effectively to human-annotated test sets.\n--- Page 5 ---\n6. References\n[1] R. Rakov and A. Rosenberg, “‘sure, i did the right thing’: a system\nfor sarcasm detection in speech.” in Interspeech , 2013, pp. 842–\n846.\n[2] X. Gao, S. Nayak, and M. Coler, “Deep CNN-based Inductive\nTransfer Learning for Sarcasm Detection in Speech,” in Proc. In-\nterspeech 2022 , 2022, pp. 2323–2327.\n[3] Z. Li, X. Gao, S. Nayak, and M. Coler, “Sarcasticspeech: Speech\nsynthesis for sarcasm in low-resource scenarios,” in 12th ISCA\nSpeech Synthesis Workshop (SSW2023) . ISCA, 2023, pp. 242–\n243.\n[4] S. Castro, D. Hazarika, V . P ´erez-Rosas, R. Zimmermann,\nR. Mihalcea, and S. Poria, “Towards multimodal sarcasm\ndetection (an Obviously perfect paper),” in Proceedings of\nthe 57th Annual Meeting of the Association for Computational\nLinguistics , A. Korhonen, D. Traum, and L. M `arquez, Eds.\nFlorence, Italy: Association for Computational Linguistics, Jul.\n2019, pp. 4619–4629. [Online]. Available: https://aclanthology.\norg/P19-1455\n[5] A. Ray, S. Mishra, A. Nunna, and P. Bhattacharyya, “A\nmultimodal corpus for emotion recognition in sarcasm,” in Pro-\nceedings of the Thirteenth Language Resources and Evaluation\nConference , N. Calzolari, F. B ´echet, P. Blache, K. Choukri,\nC. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Mae-\ngaard, J. Mariani, H. Mazo, J. Odijk, and S. Piperidis,\nEds. Marseille, France: European Language Resources As-\nsociation, Jun. 2022, pp. 6992–7003. [Online]. Available:\nhttps://aclanthology.org/2022.lrec-1.756\n[6] Y . Cai, H. Cai, and X. Wan, “Multi-modal sarcasm detection\nin Twitter with hierarchical fusion model,” in Proceedings of\nthe 57th Annual Meeting of the Association for Computational\nLinguistics , A. Korhonen, D. Traum, and L. M `arquez, Eds.\nFlorence, Italy: Association for Computational Linguistics, Jul.\n2019, pp. 2506–2515. [Online]. Available: https://aclanthology.\norg/P19-1239/\n[7] X. Gao, S. Bansal, K. Gowda, Z. Li, S. Nayak, N. Kumar, and\nM. Coler, “Amused: An attentive deep neural network for multi-\nmodal sarcasm detection incorporating bi-modal data augmenta-\ntion,” arXiv preprint arXiv:2412.10103 , 2024.\n[8] D. Raghuvanshi, X. Gao, Z. Li, S. Bansal, M. Coler, N. Kumar,\nand S. Nayak, “Intra-modal relation and emotional incongruity\nlearning using graph attention networks for multimodal sarcasm\ndetection,” in ICASSP 2025-2025 IEEE International Conference\non Acoustics, Speech and Signal Processing (ICASSP) . IEEE,\n2025, pp. 1–5.\n[9] H. Loevenbruck, M. B. Jannet, M. d’Imperio, M. Spini, and\nM. Champagne-Lavau, “Prosodic cues of sarcastic speech in\nfrench: slower, higher, wider,” in Interspeech 2013-14th Annual\nConference of the International Speech Communication Associa-\ntion, 2013, pp. 3537–3541.\n[10] Z. Li, X. Gao, Y . Zhang, S. Nayak, and M. Coler, “A functional\ntrade-off between prosodic and semantic cues in conveying sar-\ncasm,” in Proc. Interspeech 2024 , 2024, pp. 1070–1074.\n[11] J. Santoso, K. Ishizuka, and T. Hashimoto, “Large language\nmodel-based emotional speech annotation using context and\nacoustic feature for speech emotion recognition,” in ICASSP\n2024-2024 IEEE International Conference on Acoustics, Speech\nand Signal Processing (ICASSP) . IEEE, 2024, pp. 11 026–\n11 030.\n[12] Z. Zhang, L. Peng, T. Pang, J. Han, H. Zhao, and B. W. Schuller,\n“Refashioning emotion recognition modelling: The advent of\ngeneralised large models,” IEEE Transactions on Computational\nSocial Systems , 2024.\n[13] Y . Chen, Z. Li, J. Liang, Y . Xiao, B. Liu, and Y . Chen, “Can\npre-trained language models understand chinese humor?” in Pro-\nceedings of the Sixteenth ACM International Conference on Web\nSearch and Data Mining , 2023, pp. 465–480.[14] Y . Zhang, C. Zou, Z. Lian, P. Tiwari, and J. Qin, “Sarcasm-\nbench: Towards evaluating large language models on sarcasm un-\nderstanding,” arXiv preprint arXiv:2408.11319 , 2024.\n[15] W. Zhao, Y . Zhao, X. Lu, S. Wang, Y . Tong, and B. Qin, “Is\nchatgpt equipped with emotional dialogue capabilities?” arXiv\npreprint arXiv:2304.09582 , 2023.\n[16] S. Poria, D. Hazarika, N. Majumder, G. Naik, E. Cambria, and\nR. Mihalcea, “Meld: A multimodal multi-party dataset for emo-\ntion recognition in conversations,” in Proceedings of the 57th An-\nnual Meeting of the Association for Computational Linguistics ,\n2019, pp. 527–536.\n[17] C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower,\nS. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, “Iemocap:\nInteractive emotional dyadic motion capture database,” Language\nresources and evaluation , vol. 42, pp. 335–359, 2008.\n[18] J. Yu, H. Chen, Y . Bian, X. Li, Y . Luo, J. Tian, M. Liu, J. Jiang,\nand S. Wang, “Autoprep: An automatic preprocessing framework\nfor in-the-wild speech data,” in ICASSP 2024-2024 IEEE Inter-\nnational Conference on Acoustics, Speech and Signal Processing\n(ICASSP) . IEEE, 2024, pp. 1136–1140.\n[19] H. He, Z. Shang, C. Wang, X. Li, Y . Gu, H. Hua, L. Liu, C. Yang,\nJ. Li, P. Shi et al. , “Emilia: An extensive, multilingual, and diverse\nspeech dataset for large-scale speech generation,” in 2024 IEEE\nSpoken Language Technology Workshop (SLT) . IEEE, 2024, pp.\n885–890.\n[20] B. Ding, C. Qin, L. Liu, Y . K. Chia, B. Li, S. Joty, and L. Bing, “Is\ngpt-3 a good data annotator?” in Proceedings of the 61st Annual\nMeeting of the Association for Computational Linguistics (Volume\n1: Long Papers) , 2023, pp. 11 173–11 195.\n[21] A. G. Møller, A. Pera, J. Dalsgaard, and L. Aiello, “The parrot\ndilemma: Human-labeled vs. llm-augmented data in classification\ntasks,” in Proceedings of the 18th Conference of the European\nChapter of the Association for Computational Linguistics (Volume\n2: Short Papers) , 2024, pp. 179–192.\n[22] Z. Tan, D. Li, S. Wang, A. Beigi, B. Jiang, A. Bhattacharjee,\nM. Karami, J. Li, L. Cheng, and H. Liu, “Large language models\nfor data annotation and synthesis: A survey,” in Proceedings of\nthe 2024 Conference on Empirical Methods in Natural Language\nProcessing , 2024, pp. 930–957.\n[23] M. Niu, M. Jaiswal, and E. Mower Provost, “From text to emo-\ntion: Unveiling the emotion annotation capabilities of llms,” in\nProc. Interspeech 2024 , 2024, pp. 2650–2654.\n[24] S. Feng, G. Sun, N. Lubis, W. Wu, C. Zhang, and M. Ga ˇsi´c, “Af-\nfect recognition in conversations using large language models,”\narXiv preprint arXiv:2309.12881 , 2023.\n[25] X. Sun, X. Li, J. Li, F. Wu, S. Guo, T. Zhang, and G. Wang,\n“Text classification via large language models,” in Findings of the\nAssociation for Computational Linguistics: EMNLP 2023 , 2023,\npp. 8990–9005.\n[26] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar et al. ,\n“Llama: open and efficient foundation language models. arxiv,”\narXiv preprint arXiv:2302.13971 , 2023.\n[27] M. Lewis, “Bart: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and comprehension,”\narXiv preprint arXiv:1910.13461 , 2019.",
  "text_length": 30332
}