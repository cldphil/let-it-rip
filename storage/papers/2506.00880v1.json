{
  "id": "http://arxiv.org/abs/2506.00880v1",
  "title": "ModuLM: Enabling Modular and Multimodal Molecular Relational Learning\n  with Large Language Models",
  "summary": "Molecular Relational Learning (MRL) aims to understand interactions between\nmolecular pairs, playing a critical role in advancing biochemical research.\nWith the recent development of large language models (LLMs), a growing number\nof studies have explored the integration of MRL with LLMs and achieved\npromising results. However, the increasing availability of diverse LLMs and\nmolecular structure encoders has significantly expanded the model space,\npresenting major challenges for benchmarking. Currently, there is no LLM\nframework that supports both flexible molecular input formats and dynamic\narchitectural switching. To address these challenges, reduce redundant coding,\nand ensure fair model comparison, we propose ModuLM, a framework designed to\nsupport flexible LLM-based model construction and diverse molecular\nrepresentations. ModuLM provides a rich suite of modular components, including\n8 types of 2D molecular graph encoders, 11 types of 3D molecular conformation\nencoders, 7 types of interaction layers, and 7 mainstream LLM backbones. Owing\nto its highly flexible model assembly mechanism, ModuLM enables the dynamic\nconstruction of over 50,000 distinct model configurations. In addition, we\nprovide comprehensive results to demonstrate the effectiveness of ModuLM in\nsupporting LLM-based MRL tasks.",
  "authors": [
    "Zhuo Chen",
    "Yizhen Zheng",
    "Huan Yee Koh",
    "Hongxin Xiang",
    "Linjiang Chen",
    "Wenjie Du",
    "Yang Wang"
  ],
  "published": "2025-06-01T07:44:16Z",
  "updated": "2025-06-01T07:44:16Z",
  "categories": [
    "cs.LG",
    "cs.AI",
    "q-bio.BM",
    "q-bio.QM"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00880v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00880v1  [cs.LG]  1 Jun 2025ModuLM: Enabling Modular and Multimodal\nMolecular Relational Learning with Large Language\nModels\nZhuo Chen1,2, Yizhen Zheng4, Huan Yee Koh4, Hongxin Xiang3, Linjiang Chen5,\nWenjie Du1,2,Yang Wang1,2\n1University of Science and Technology of China, China\n2Suzhou Institute for Advanced Research, USTC, China\n3Hunan University, China4Monash University, Australia\n5State Key Laboratory of Precision and Intelligent Chemistry, USTC, China\n{czchenzhuo, duwenjie}@mail.ustc.edu.cn\n{yizhen.zheng1, huan.koh}@monash.edu\nxianghx@hnu.edu.cn {linjiangchen, angyan}@ustc.edu.cn\nAbstract\nMolecular Relational Learning (MRL) aims to understand interactions between\nmolecular pairs, playing a critical role in advancing biochemical research. With the\nrecent development of large language models (LLMs), a growing number of studies\nhave explored the integration of MRL with LLMs and achieved promising results.\nHowever, the increasing availability of diverse LLMs and molecular structure\nencoders has significantly expanded the model space, presenting major challenges\nfor benchmarking. Currently, there is no LLM framework that supports both\nflexible molecular input formats and dynamic architectural switching. To address\nthese challenges, reduce redundant coding, and ensure fair model comparison, we\npropose ModuLM, a framework designed to support flexible LLM-based model\nconstruction and diverse molecular representations. ModuLM provides a rich\nsuite of modular components, including 8 types of 2D molecular graph encoders,\n11 types of 3D molecular conformation encoders, 7 types of interaction layers,\nand 7 mainstream LLM backbones. Owing to its highly flexible model assembly\nmechanism, ModuLM enables the dynamic construction of over 50,000 distinct\nmodel configurations. In addition, we provide comprehensive results to demonstrate\nthe effectiveness of ModuLM in supporting LLM-based MRL tasks. ModuLM is\navailable at https://anonymous.4open.science/r/ModuLM .\n1 Introduction\nMolecular Relational Learning (MRL) [ 32], which aims to understand the interactions between\nmolecular pairs, has garnered growing attention due to its wide-ranging applications across various\nscientific domains [ 51]. For example, drug-drug interactions (DDIs) are vital for understanding\nthe effects of concurrent drug use, which can inform strategies to prevent adverse drug reactions\nand ensure patient safety [ 38], while solute-solvent interactions (SSIs) are fundamental to solution\nchemistry and are pivotal in the design and optimization of chemical processes [ 62,5]. However, the\nexhaustive experimental validation of these interactions is notoriously time-consuming and costly.\nIn recent years, large language models (LLMs) have emerged as a promising new paradigm in MRL\nresearch due to their powerful capabilities in knowledge integration and reasoning. Compared with\ntraditional methods, LLMs can more efficiently process and understand complex interactions between\nmolecules, significantly improving modeling performance and generalizability. A growing body\nPreprint. Under review.\n--- Page 2 ---\nof research has focused on LLM-based MRL frameworks [ 47,25,13], leveraging the strengths of\nLLMs to achieve strong results on MRL tasks. For instance, ReactionT5[ 53] proposed a text-based\npretrained LLM tailored for MRL tasks, while MolTC[ 13] further advanced this line of research by\nintegrating multimodal data and incorporating 2D molecular graphs for improved performance. These\ndevelopments highlight the research value and application potential of LLMs in MRL. However, with\nthe emergence of an increasing number of encoding methods and backbone models [ 46,24,66,82,\n71,60,61,20], it is now possible to adopt more flexible strategies to recombine components and\nbuild more novel model architectures. However, this flexibility introduces new challenges for the\nbenchmarking and evaluation of LLM-based MRL models.\nLack of diverse input support: Molecular structures can typically be represented in various forms,\nsuch as 1D SMILES strings, 2D molecular graphs, and 3D molecular conformations; however, most\nexisting models support only a single representation modality, commonly 1D SMILES[ 29,18,70]\nor 2D graphs[ 16,55,6,8], which limits their ability to fully capture the complexity of molecular\ninteractions and may result in the loss of critical structural information. In the field of LLMs, MRL\nmodels that accept 3D molecular structure inputs remain extremely rare, despite the fact that specific\n3D conformations are often essential for accurately modeling chemical phenomena, for instance, in\nsmall-molecule binding to target proteins[ 67]. These issues highlight the importance of a unified\nframework that can accommodate 1D, 2D, and 3D molecular inputs to enable more comprehensive,\nflexible, and accurate molecular relational learning across a wide range of task scenarios.\nLack of Flexible Architectures: Current LLM-based MRL models often adopt relatively rigid\narchitectures. For example, ReactionT5 [ 53] uses a unified model to encode both SMILES sequences\nand molecular property descriptions, while MolTC [ 13] employs graph neural networks (GNNs) to\nencode molecular graphs. Although these methods achieve performance improvements, they are still\nsomewhat limited by their encoding strategies. In the non-LLM MRL domain, many more effective\nencoding strategies have been developed, such as MMGNN [ 7], which employs interpretable GNNs\nto extract key subgraphs for solvation free energy prediction, and Uni-Mol [ 79], which introduces\npre-trained SE(3) Transformer models specifically designed for molecular data. However, integrating\nthese encoding methods into existing LLM frameworks remains a challenge. Furthermore, most\ncurrent LLM-based models overlook the modeling of molecular interaction features. These challenges\nhighlight the importance of developing a model framework that can seamlessly combine diverse\nencoding modules while effectively incorporating molecular interaction information.\nTo this end, we propose ModuLM , a unified and extensible framework designed to overcome\nthe limitations of existing LLM-based MRL approaches. ModuLM provides a highly flexible\nmodel construction mechanism that supports a wide range of molecular input formats, multimodal\nintegration strategies, and diverse prompt designs. The framework accepts molecular representations\nin the form of 1D SMILES, 2D molecular graphs and 3D conformations. It includes 8 types of\n2D molecular graph encoders, 11 types of molecular conformation encoders, 7 types of interaction\nfeature encoders, and 7 mainstream LLM backbones, along with specially designed prompt templates\nfor integrating different types of molecular features. To enhance usability and extensibility, ModuLM\nadopts a modular interface design that allows users to flexibly assemble and extend models, supports\nincremental pretraining, and is capable of handling complex molecular interaction modeling tasks.\nModuLM can generate over 50,000 distinct model configurations. We conduct comprehensive\nbenchmark experiments on tasks such as DDI, SSI and CSI. The results demonstrate that ModuLM\nperforms remarkably well in constructing, evaluating, and comparing LLM-based MRL models.\nThese findings highlight ModuLM’s strong potential to advance the development of MRL models\nand provide valuable insights into molecular interaction mechanisms.\n2 Related Work\nMolecular Relational Learning: MRL is critical for drug research, with machine learning offering a\nscalable alternative to costly experimental validation [ 33]. Early methods focused on GNNs [ 29,77,\n73,14], such as Nyamabo et al.’s substructure-level interaction model using GAT and co-attention [ 78],\nand Lee et al.’s CGIB [ 32], which applies the information bottleneck to extract key substructures.\nLLM-based methods have gained momentum. For instance, ReactionT5 [ 48] enhances molecular\nunderstanding by integrating chemical structures with natural language. MolTC [ 13] further advances\nthis direction by combining 2D molecular graph features with chain-of-thought reasoning to support\ncomplex molecular inference.\n2\n--- Page 3 ---\nLLMs in the Molecular Domain: LLMs have been widely applied in 1D, 2D, and 3D molecular\npattern learning. For 1D, methods like MolT5 [ 10] and KV-PLM [ 72] tokenize SMILES strings for\nrepresentation learning. In 2D, approaches such as Text2Mol [ 12], MolCA [ 41], and DrugChat [ 36]\nintegrate molecular graphs with text encoders or LLMs. For 3D, MolLM [ 58] and 3D-MoLM [ 35]\nincorporate spatial relationships via attention mechanisms and 3D encoders. In addition, LLMs have\nalso found applications in MRL, such as ReactionT5 [ 53] and MolTC [ 13], which utilize multimodal\ndata, including molecular graphs (2D), chemical properties, and SMILES (1D), for MRL.\nDeep Learning Frameworks Specialized for MRL: DeepPurpose is a user-friendly deep learning\nlibrary for drug-target interaction prediction. It supports customized model training with 15 compound\nand protein encoders and over 50 neural architectures [ 23]. FlexMol is another toolkit designed\nfor MRL, offering a variety of encoders and interaction layers that support sequence-based and\ngraph-based representations of drugs and proteins [57].\n3 ModuLM\nIn this section, we introduce ModuLM following the model training workflow for LLM-based MRL.\n3.1 Framework\nEncoder InteractionSequenceTasks\nDDI SSI CSI\nCC(C)C[C@@H](C(=O)O)N\nC1=CC=C(C=C1)……\n[C][C][Branch1_1][C][C@\n@Hexpl][Branch1_1]……\n[CH3][CH](C)[CH2][CH](\nC(=O)[OH])[NH][c] 1……\nPipeline\nGCN\nMPNN\nGAT\nNeuralFP\nGIN\n……EGNN\nPaiNN\nGVP\nUni-mol\nGearNet\n……Bilinear \nAttention\n……Self\nAttention\nCross \nAttention(8 encoders) (11 encoders) (7 interactions)\nDeepSeek\n-1.5B\nLLaMa -\n7B\nGalactica -\n1.3B\n……(7 backbones)\nQ-Former\nMLP\nDirect\nCoT\nClassification Regression\nMSE\nRMSE\nMAE\n……\n(6 Metrics) (7 Metrics)Accuracy\nAUCROC\nRecall\n……Components\nMetrics\nR-squared F1 ScoreEncoders LLM\n(2 prompts)\n(2 alignments)\nAligmentEncoder\nLLMCH3COOC6H4COOH\nC9H9NO3\n……\n……Feature 0\nFeature 0Feature 1 Feature 2\nFeature 1 Feature 2The SMILES of the molecule is \n<SMILES0>. The information \nabout its embedding is as follows:\n<Token 0> ,<Token 1> …<Token n> .\nThe SMILES of the molecule is \n<SMILES1>. The information \nabout its embedding is as follows:\n<Token 0> ,<Token 1> …<Token n> .The information about their \ninteraction embeddings is as follows:\n<Token 0>,<Token 1> …<Token n> .\nGenerated Text\nFigure 1: Overview of the ModuLM framework.\nModuLM is an LLM framework designed for MRL, with the overall architecture illustrated in\nFigure 1. It supports three types of molecular text inputs and accommodates a variety of molecular\ninputs across 1D, 2D, and 3D modalities. The framework provides eight 2D molecular graph encoders,\neleven 3D molecular conformation encoders, and incorporates seven feature interaction designs. It\nalso supports evaluation across multiple task types.\n3.2 Post Pretraining\nTo strengthen the domain-specific capabilities of LLMs in chemistry, we begin with incremental\npretraining to better adapt them for MRL tasks. In ModuLM, we conduct a survey of various\n3\n--- Page 4 ---\nTable 1: Text settings for different pretraining methods.\nMolecular Interaction-based Pretraining\nThe first molecule has a SMILES representation of <SMILES0> , which suggests certain structural\ncharacteristics and chemical functionalities. Based on its structure, it may exhibit the property\n[Property0] , such as high solubility, bioactivity, or specific binding affinity. On the other hand,\nthe second molecule is represented by the SMILES string <SMILES1> , and analysis of its structure\nindicates it may exhibit the property [Property1] , potentially contributing to its pharmacokinetic\nbehavior or molecular interaction profile.\nSubstructure-based Pretraining\nThe molecule has a SMILES representation of <SMILES0> , which encodes its atomic connectivity\nand overall molecular structure. It contains notable substructures such as <substructe0> and\n<substructe1> , both of which are known to play significant roles in determining the molecule’s\nphysicochemical and biological properties. Based on the presence of these functional groups or struc-\ntural motifs, the molecule is likely to exhibit the properties [Property0] and[Property1] ,\nwhich may influence its reactivity, solubility, or interaction with biological targets.\nauthoritative biochemical databases, such as PubChem1and DrugBank [ 28], collecting a large\namount of molecular property description texts. We then provide three distinct pretraining strategies:\nMolecular Interaction-based pretraining, Substructure-based pretraining and Structure Similarity-\nguided Grouping pretraining.\nMolecular Interaction-based Pretraining is based on the pretraining method proposed by\nMolTC [ 13]. Its pretraining text setup is shown in the Table 1. Considering that molecular in-\nteraction tasks typically involve two different molecules, MolTC integrates the textual representations\nof both molecules and inputs them jointly during pretraining, enabling the LLM to develop prior\nknowledge in the form of molecular pairs.\nSubstructure-based Pretraining adopts a pretraining text setup as shown in the Table 1, enabling the\nLLM to learn more fine-grained information within molecules. This allows the LLM to make more\naccurate judgments based on the potential substructures of different molecules, thereby enhancing its\ngeneralization ability when encountering previously unseen molecules and improving performance\non downstream tasks.\nStructure Similarity-guided Grouping Pretraining combines substructure-based pretraining with\na grouping strategy based on structural similarity. Molecules with similar structures are grouped\ntogether and input as a group during pretraining, thereby enhancing the LLM’s understanding of this\nclass of molecules. This method shares the same prompt configuration as the substructure-based\npretraining approach, differing in the ordering of the input.\nIt is worth noting that if you use the Q-former approach for aligning textual and molecular data,\nadditional pretraining will be required. The specific pretraining process can be selected based on your\nneeds. Here, we provide MolTC’s [ 13] methods for aligning molecules with text and molecular data.\n3.3 Fine-tuning\n3.3.1 Input Data\nTo transform raw molecules into meaningful representations, ModuLM first performs preprocessing\nfollowed by encoding. The preprocessing stage includes tasks such as tokenization, normalization,\nfeature extraction, fingerprint generation, molecular graph construction, and molecular conformation\ngeneration. The encoding stage is responsible for dynamically constructing the input features for the\nLLM. In this stage, the preprocessed data is processed to generate embeddings that can be utilized by\nsubsequent network layers. The following will present the specific procedures and methods used by\nModuLM to encode different types of data.\n1D Representations of Molecules: The commonly used molecular representations for MRL in\ncurrent LLMs are typically SMILES and SelfIES [ 31]. However, SMILES representations may have\n1https://pubchem.ncbi.nlm.nih.gov\n4\n--- Page 5 ---\ndifficulties clearly expressing certain molecular structures. Therefore, for MRL tasks, we recommend\nusing SelfIES. Nonetheless, to provide a more comprehensive benchmarking framework for previous\nLLM-based approaches, we include both molecular text encoding methods here, and additionally\nincorporate SMARTS. For 1D representations of molecules, the encoding method depends on the\nspecific LLM used.\n2D Molecular Graph Representation: Since 1D molecular representations often fail to capture the\nstructural information of molecules, it is common in MRL tasks to incorporate multimodal molecular\nstructure information. In non-LLM research areas, molecular graph representation is the most widely\nused approach. In most tasks, molecular graphs help models better understand molecular structures,\nthereby enhancing MRL performance. We provide a variety of methods as shown in the Table 2.\n3D Molecular Conformation Representation: In most MRL tasks, 2D molecular graphs are suffi-\ncient for the model to make effective judgments. However, in certain specialized tasks, it is necessary\nto incorporate the 3D spatial information of molecules to accurately determine intermolecular interac-\ntions. This is an aspect that current LLM-based MRL models have largely overlooked. In ModuLM,\nwe address this limitation by providing various 3D structure encoding methods to support more\nadvanced molecular relation learning. The encoding methods are listed in the Table 2.\nInteraction: In current LLM-based MRL model designs, the explicit modeling of molecular interac-\ntion relationships is often overlooked. In ModuLM, we address this issue by introducing specially\ndesigned prompts and interaction layers to incorporate interaction information into the LLM. The\nInteraction Layer is another key building block of the MRL model. These layers serve two main func-\ntions: capturing and modeling the relationships between different molecular entities, and integrating\nmultiple embeddings of the same entity to form a more comprehensive feature representation. The\nInteraction Layer can accept encoded inputs from different molecules, enabling the construction of\nmore complex model architectures. In ModuLM, the interaction designs we provide are shown in\nTable 2.\nTable 2: Encoding methods for different data formats\nEncoder Type Methods\n2D Graph GCN [ 30], MPNN [ 18], GAT [ 64], NeuralFP [ 9], AttentiveFP\n[68], GIN [69], GraphSAGE[21], CoATGIN[75]\n3D Conformation EGNN [ 54], 3D-GeoFormer [ 81], SE3Transformer [ 15], PaiNN\n[55], GVP [ 26], GearNet [ 76], DimeNet++ [ 17], SchNet [ 56],\nSphereNet [40], G-SphereNet[42], Uni-mol [80]\nInteraction Bilinear Attention[ 1], Self Attention[ 63], Cross Attention[ 49],\nHighway[82], Gated Fusion[50], Bilinear Fusion[37], Mean\n3.3.2 Alignment\nSince data from different modalities typically exist in distinct semantic spaces, it is necessary to\nperform alignment before feeding them into the LLM. Currently, two common approaches are used:\nemploying a lightweight MLP [ 39] or using a Q-former [ 34]. In the ModuLM framework we provide,\nboth alignment methods are supported. It is worth noting that when using a Q-former, it is typically\ninvolved during the pretraining stage to enable better alignment performance.\n3.3.3 Backbone\nExisting LLM-based MRL models often adopt different backbone architectures, and there has been\nno systematic investigation into the MRL performance across different LLM backbones. In ModuLM,\nwe provide a streamlined method for switching backbones. We have surveyed and integrated a range\nof mainstream LLMs and offer simple interfaces for replacement, enabling easier comparison of\nperformance differences across various types and scales of LLMs under a unified experimental setup.\nHere, we provide two types of prompts: direct inference and chain-of-thought-based reasoning. The\nspecific prompt designs are detailed in the Appendix A.3.5.\n5\n--- Page 6 ---\n3.4 Evaluation Metrics\nModuLM supports multiple default metrics, aligning with the TDC standard for molecular relational\nlearning[ 22]. Users can specify the metrics in the Trainer for early stopping and testing. These\nmetrics include various regression metrics (Mean Squared Error (MSE), Root-Mean Squared Error\n(RMSE), Mean Absolute Error (MAE), Coefficient of Determination (R2), Pearson Correlation\nCoefficient (PCC), Spearman Correlation Coefficient), binary classification metrics (Area Under\nReceiver Operating Characteristic Curve (AUC-ROC), Area Under the Precision-Recall Curve (PR-\nAUC), Range LogAUC, Accuracy Metrics, Precision, Recall, F1 Score.\n3.5 Supporting Datasets\nModuLM is compatible with all MRL datasets that conform to our specified format. These datasets\ntypically consist of three components: molecular entity one, molecular entity two, and a label. We\nprovide utility functions to facilitate the loading of datasets in this format. In addition, ModuLM\nincludes a wide range of built-in datasets from various domains, such as Drugbank (Version 5.0.3),\nZhangDDI [ 74], ChChMiner [ 83], DeepDDI [ 52], TWOSIDES [ 59], Chromophore [ 27], MNSol\n[43], CompSol [ 45], Abraham [ 19], CombiSolv [ 65], FreeSolv [ 44], and CombiSolv-QM [ 65]. For\nmore details, please refer to the Appendix A.2.\n4 Experiments\nWe conduct validation experiments on MRL tasks using ModuLM to demonstrate the framework’s\ncapability in supporting a wide range of experiments, comparisons, and analyses. The following\nsections present the results for DDI tasks, showcasing the impact of different inputs and encoders on\nthe performance of LLMs in MRL. More experimental details are provided in the Appendix A.5.\n4.1 Experimental Setup\nTable 3: Experimental Settings on DDI Datasets\nExperiment No. Backbone Encoder Interaction Input Feature\n1.1 Galactica-1.3B - - ms\n1.2 Galactica-1.3B GIN - ms+mg\n1.3 Galactica-1.3B GIN Cross Attention ms+mg\n1.4 Galactica-1.3B Uni-mol - ms+mc\n1.5 Galactica-6.7B MPNN Gated Fusion ms+mg\n1.6 DeepSeek-1.5B - - ms\n1.7 DeepSeek-1.5B GIN - ms+mg\n1.8 DeepSeek-1.5B Uni-mol - ms+mc\n1.9 DeepSeek-7B 3D-GeoFormer Highway ms+mc\n1.10 DeepSeek-14B Uni-mol - ms+mc\n1.11 DeepSeek-14B GAT Self Attention ms+mg\n1.12 LLaMA-1B - - ms\n1.13 LLaMA-1B CoATGIN - ms+mg\n1.14 LLaMA-1B EGNN Gated Fusion ms+mc\n1.15 LLaMA-13B SchNet Bilinear Attention ms+mc\nNote: ms= molecular sequence, mg= molecular graph, mc= molecular conformation. ’-’\nindicates that no method is applied.\nGiven the flexibility of ModuLM, which enables a large number of potential model combinations, the\ngoal of this section is not to exhaustively explore the entire model space. Instead, we select several\nmodel combinations as examples to demonstrate ModuLM’s robust capabilities in constructing\nand evaluating diverse model architectures across various datasets and performance metrics. It is\nworth noting that for different backbones, we adopt a unified pretraining strategy. The experimental\nbackbones presented in the main text are LLMs pretrained based on the Structure Similarity-guided\nGrouping pretraining approach.\n6\n--- Page 7 ---\nDuring the evaluation phase on downstream tasks, we utilized the same datasets used in the MolTC\nframework [ 13] for evaluating MRL tasks, including DrugBank (Version 5.0.3), ZhangDDI [ 74],\nChChMiner [ 83], DeepDDI [ 52], TWOSIDES [ 59], Chromophore [ 27], MNSol [ 43], CompSol\n[45], Abraham [ 19], CombiSolv [ 65], FreeSolv [ 44], and CombiSolv-QM [ 65]. We further process\nthese datasets using RDKit by generating multiple conformations for each molecule, aiming to\nexplore the performance of ModuLM on 3D conformation-based LLM-driven MRL tasks. Based on\nModuLM, we construct 15 models, as detailed in Table 3, and compare them with five state-of-the-art\nLLM-based models for MRL tasks: Galactica, ChemT5 [3], MolT5, MolCA [41], and MolTC [13].\nFor the DDI, SSI and CSI datasets, we randomly split the data into training, validation, and testing\nsets in a ratio of 7:2:1. Each experiment was repeated five times to mitigate the effects of randomness,\nand the average results were reported. All experiments were conducted using eight NVIDIA A100\n80G GPUs. For more specific training details, please refer to the Appendix A.5.\n4.2 Experimental Results and Analysis\nTable 4: Performance on DDI Datasets\nExperiment AUC-ROC\n(ChChMiner)Accuracy\n(ChChMiner)AUC-ROC\n(ZhangDDI)Accuracy\n(ZhangDDI)AUC-ROC\n(DeepDDI)Accuracy\n(DeepDDI)\nChem T5[4] 0.867 ±0.012 0.814 ±0.009 0.889 ±0.017 0.751 ±0.021 0.856 ±0.012 0.784 ±0.013\nMolCA[41] 0.924 ±0.006 0.901 ±0.009 0.895 ±0.006 0.745 ±0.010 0.878 ±0.014 0.841 ±0.015\nMolT5[11] 0.914 ±0.019 0.862 ±0.022 0.901 ±0.011 0.802 ±0.015 0.907 ±0.014 0.870 ±0.016\nMolTC[13] 0.964 ±0.008 0.957 ±0.006 0.941±0.006 0.896±0.008 0.977±0.013 0.956±0.011\n1.1 0.933 ±0.011 0.924 ±0.009 0.912 ±0.008 0.854 ±0.004 0.899 ±0.010 0.855 ±0.009\n1.2 0.956 ±0.008 0.943 ±0.009 0.930 ±0.006 0.872 ±0.009 0.924 ±0.008 0.887 ±0.008\n1.3 0.960 ±0.010 0.954 ±0.006 0.933 ±0.007 0.891 ±0.004 0.939 ±0.007 0.904 ±0.008\n1.4 0.955 ±0.005 0.949 ±0.008 0.936 ±0.014 0.901 ±0.010 0.956 ±0.008 0.919 ±0.007\n1.5 0.940 ±0.009 0.932 ±0.008 0.921 ±0.008 0.866 ±0.005 0.948 ±0.009 0.912 ±0.006\n1.6 0.936 ±0.010 0.930 ±0.011 0.920 ±0.009 0.860 ±0.008 0.906 ±0.008 0.872 ±0.008\n1.7 0.957 ±0.008 0.953 ±0.010 0.934 ±0.006 0.889 ±0.004 0.958 ±0.007 0.942 ±0.007\n1.8 0.966±0.007 0.964 ±0.005 0.938±0.005 0.907±0.006 0.972±0.009 0.959±0.010\n1.9 0.944 ±0.010 0.935 ±0.009 0.925 ±0.005 0.870 ±0.003 0.955 ±0.008 0.930 ±0.007\n1.10 0.931 ±0.012 0.918 ±0.010 0.916 ±0.009 0.861 ±0.011 0.943 ±0.010 0.915 ±0.008\n1.11 0.935 ±0.007 0.921 ±0.012 0.906 ±0.009 0.855 ±0.008 0.936 ±0.009 0.908 ±0.007\n1.12 0.925 ±0.013 0.911 ±0.011 0.901 ±0.008 0.852 ±0.006 0.895 ±0.010 0.850 ±0.009\n1.13 0.945 ±0.009 0.937 ±0.008 0.925 ±0.007 0.870 ±0.006 0.935 ±0.008 0.904 ±0.008\n1.14 0.951 ±0.007 0.946 ±0.011 0.928 ±0.004 0.875 ±0.005 0.946 ±0.007 0.918 ±0.006\n1.15 0.915 ±0.016 0.896 ±0.013 0.913 ±0.008 0.860 ±0.002 0.928 ±0.011 0.897 ±0.008\nTable 5: Performance on SSI Datasets\nExperiment MAE\n(FreeSolv)RMSE\n(FreeSolv)MAE\n(CompSol)RMSE\n(CompSol)MAE\n(CombiSolv)RMSE\n(CombiSolv)\nChem T5[4] 0.923 ±0.022 1.511 ±0.043 0.611 ±0.017 0.766 ±0.032 0.840 ±0.040 1.294 ±0.043\nMolCA[41] 0.761 ±0.034 1.303 ±0.039 0.505 ±0.036 0.726 ±0.040 0.771 ±0.033 1.130 ±0.027\nMolT5[11] 0.733 ±0.047 1.135 ±0.059 0.496 ±0.028 0.708 ±0.020 0.677 ±0.024 1.066 ±0.027\nMolTC[13] 0.533 ±0.018 0.726 ±0.022 0.244 ±0.018 0.356 ±0.022 0.237 ±0.019 0.465 ±0.022\n1.1 0.710 ±0.021 1.120 ±0.030 0.472 ±0.024 0.665 ±0.028 0.615 ±0.026 0.984 ±0.032\n1.2 0.570 ±0.020 0.910 ±0.028 0.384 ±0.022 0.540 ±0.025 0.568 ±0.023 0.930 ±0.030\n1.3 0.556 ±0.018 0.840 ±0.025 0.366 ±0.021 0.522 ±0.024 0.487 ±0.021 0.820 ±0.027\n1.4 0.534 ±0.017 0.808 ±0.024 0.347 ±0.020 0.501 ±0.023 0.447 ±0.020 0.780 ±0.026\n1.5 0.580 ±0.016 0.972 ±0.023 0.403 ±0.019 0.575 ±0.021 0.579 ±0.019 0.898 ±0.025\n1.6 0.685 ±0.015 1.086 ±0.022 0.451 ±0.018 0.643 ±0.020 0.602 ±0.018 0.945 ±0.024\n1.7 0.550 ±0.014 0.749 ±0.021 0.271 ±0.017 0.415 ±0.019 0.289 ±0.017 0.515 ±0.023\n1.8 0.510±0.013 0.698 ±0.020 0.191 ±0.016 0.298 ±0.018 0.190 ±0.016 0.388 ±0.022\n1.9 0.555 ±0.014 0.825 ±0.021 0.335 ±0.017 0.490 ±0.019 0.393 ±0.017 0.595 ±0.023\n1.10 0.605 ±0.015 0.850 ±0.022 0.443 ±0.018 0.598 ±0.020 0.548 ±0.018 0.864 ±0.024\n1.11 0.590 ±0.016 0.876 ±0.023 0.458 ±0.019 0.601 ±0.021 0.556 ±0.019 0.839 ±0.025\n1.12 0.745 ±0.017 1.091 ±0.024 0.514 ±0.020 0.692 ±0.022 0.687 ±0.020 1.008 ±0.026\n1.13 0.605 ±0.016 0.880 ±0.023 0.374 ±0.019 0.530 ±0.021 0.538 ±0.019 0.820 ±0.025\n1.14 0.580 ±0.015 0.887 ±0.022 0.360 ±0.018 0.515 ±0.020 0.460 ±0.018 0.790 ±0.024\n1.15 0.630 ±0.018 0.910 ±0.025 0.450 ±0.021 0.633 ±0.023 0.567 ±0.021 0.892 ±0.027\nTable 4 and Table 12 show the experimental results of commonly used MRL LLMs, as well as their\nperformance under our experimental settings. It is worth noting that in our experimental setup, we\nadopt a direct inference approach using LLMs without employing chain-of-thought reasoning. In\nour setup, we design models with different backbones, input formats, and encoders. Due to space\nlimitations, additional experimental results are presented in the Appendix A.5.2.\n7\n--- Page 8 ---\nImpact of Input Data and Encoders: We use the settings {1.1, 1.2, 1.4}, {1.6, 1.7, 1.8}, and {1.12,\n1.13} to evaluate ModuLM’s ability to analyze and integrate different inputs and encoder layers\nwithin LLMs. The results in the table indicate that integrating multimodal information, such as 2D\nmolecular graphs and 3D molecular conformations, can indeed enhance model performance. Notably,\nmodels that incorporate 3D molecular conformation information achieve the best results.\nImpact of Interaction Layers: We use the configurations {1.3, 1.5, 1.9, 1.11, 1.14, 1.15} to evaluate\nModuLM’s ability to analyze the effect of feature interaction layers. We first conduct experiments\nwith various non-interaction designs. The analysis shows that adding interaction layers consistently\nimproves model performance to some extent. This confirms the importance of interaction layers in\nLLM-based MRL models. However, existing LLM comparisons generally ignore multi-molecular\ninteraction information. ModuLM enables multi-dimensional analysis, which helps better assess the\nimpact of different types of multimodal information on model performance.\nImpact of Different Backbones: Existing LLM-based MRL tasks generally lack systematic evalu-\nation across different backbones. However, thoroughly testing LLMs under various experimental\nconfigurations requires significant time and resources. ModuLM offers a framework for efficient\nand rapid evaluation. As shown in Table 4 and Table 12, we conduct experiments using different\nbackbones. Among them, models from the DeepSeek series often achieve better performance. Inter-\nestingly, our results reveal that larger model sizes do not necessarily lead to better performance in\nMRL tasks. This may be because larger LLMs possess stronger generalization ability, which can limit\ntask-specific adaptation during fine-tuning. In contrast, smaller LLMs adapt better during fine-tuning,\nleading to stronger task specialization in MRL scenarios.\n4.3 Custom Model Design and Evaluation\nThis section demonstrates how users can leverage ModuLM to extend, construct, and analyze more\ncomplex models. Figure 2 presents an overview of the newly proposed model architecture. This\nUni-mol\n……A0\nA1\nAn\nAtom EmbeddingsConformer \nEmbeddingsIntra - InteractionAtom EmbeddingsConformer \nEmbeddingsIntra - Interaction\n Self Attention\nThe SMILES of the molecule is \n<SMILES1> . The information \nabout its embedding is as follows:Uni-mol\n…\nConformer_0 Conformer_1 Conformer_n…\nConformer_0 Conformer_1 Conformer_nThe SMILES of the molecule is \n<SMILES0>. The information \nabout its embedding is as follows:Tokenizer\nProjector\nLLM\nA2……A0\nA1\nAnA2\nTokenizer\nProjector\nConsidering the molecular information, the first molecule likely exhibits \n[Property0] , while the second shows [Property1] . Their interaction may \nenhance the reactivity. Hence, they are likely to interact with each other.Considering the molecular information, the first molecule likely exhibits \n[Property0] , while the second shows [Property1] . The solvation Gibbs free \nenergy may be between 10.0 and 10.5, with a predicted value of 10.232.SSI Tasks\nDDI Tasks\nFigure 2: An overview of the custom model designed using ModuLM.\ndesign builds upon the best-performing configuration identified in Experiment 1.8, which utilizes 3D\nmolecular conformations, employs Uni-Mol as the encoder, and adopts DeepSeek-1.5B as the LLM\nbackbone. In this enhanced version, we further refined the encoder and the dual-molecule interaction\nmechanism, and incorporated CoT prompting strategy to boost the model’s reasoning capabilities.\nTo simulate practical scenarios in which users may wish to combine predefined encoders with custom\nmodules, we reimplement the molecular encoder as a user-defined component and integrate it with\nother existing encoder modules to construct a complete, functional model. Specifically, we redesign\nthe representation of atom-level data encoded by Uni-Mol by calculating the attention weights of each\n8\n--- Page 9 ---\natom to all other atoms within the conformation. These weights are then used to reaggregate the atom\nfeatures, and the mean of the weighted features serves as the new conformation-level representation.\nThe full model construction process based on ModuLM is detailed in Appendix A.4.\nWe retained the experimental settings described in Section 4.1 and conducted ablation studies to reflect\nreal-world use cases of ModuLM. In these experiments, w/o M-Encoder refers to the exclusion of the\ncustomized encoder, w/o Interaction indicates the removal of the molecule interaction design, and\nw/o CoT represents the absence of the chain-of-thought reasoning mechanism. The full experimental\nresults are reported in Table 6, while the outcomes of the ablation studies are summarized in Table 7.\nTable 6: Performance of Custom Model on DDI and SSI Datasets\nExperiment Accuracy\n(ChChMiner)Accuracy\n(ZhangDDI)Accuracy\n(DeepDDI)RMSE\n(FreeSolv)RMSE\n(CompSol)RMSE\n(CombiSolv)\n1.7 0.953 ±0.010 0.889 ±0.004 0.942 ±0.007 0.749 ±0.021 0.415 ±0.019 0.515 ±0.023\n1.8 0.964 ±0.005 0.907 ±0.006 0.959 ±0.010 0.698 ±0.020 0.298 ±0.018 0.388 ±0.022\nCustom Model 0.968±0.006 0.911 ±0.006 0.964 ±0.008 0.680 ±0.019 0.288 ±0.013 0.359 ±0.013\nTable 7: Results of the Ablation Study on DDI and SSI Datasets\nExperiment Accuracy\n(ChChMiner)Accuracy\n(ZhangDDI)Accuracy\n(DeepDDI)RMSE\n(FreeSolv)RMSE\n(CompSol)RMSE\n(CombiSolv)\nw/o M-Encoder 0.962 ±0.007 0.905 ±0.005 0.959 ±0.007 0.700 ±0.019 0.299 ±0.017 0.370 ±0.020\nw/o Interaction 0.955 ±0.008 0.896 ±0.006 0.950 ±0.007 0.705 ±0.018 0.317 ±0.016 0.388 ±0.019\nw/o CoT 0.959 ±0.006 0.901 ±0.006 0.956 ±0.008 0.732 ±0.020 0.335 ±0.018 0.382 ±0.021\nFull Model 0.968±0.006 0.911 ±0.006 0.964 ±0.008 0.680 ±0.019 0.288 ±0.013 0.359 ±0.013\nThrough the above experiments, we validated ModuLM’s strong capability in supporting user-defined\nmodels. Users can define custom encoders following our provided protocol and flexibly integrate\nthem with other encoders and interaction layers as modular components. The customized model\ninvolves a more complex configuration, including user-defined blocks and additional operations such\nas stacking and flattening the outputs of ModuLM components. Moreover, with ModuLM’s dynamic\nmodel construction mechanism, users can easily adjust the model structure to perform ablation\nstudies. As shown in Table 6 both the CoT reasoning prompt and the interaction layer contribute to\nperformance improvements. Additionally, our custom encoder module, which incorporates internal\ninteraction mechanisms, also enhances model performance.\n5 Conclusion\nWe propose ModuLM, a framework that supports the dynamic construction of LLM-based MRL\nmodels to address benchmarking challenges in LLM-driven molecular relational learning. ModuLM\naccommodates multiple molecular input formats and enables the flexible assembly of diverse model\narchitectures, facilitating robust and scalable experimentation. The framework simplifies model\ndevelopment and standardizes the evaluation process across different architectures, ensuring fair\nand consistent benchmarking. By providing a flexible and modular platform, ModuLM not only\nadvances research in the MRL field but also lays the foundation for cross-disciplinary collaboration\nand innovation, with broad applications in areas such as drug design and molecular interaction\nanalysis, helping researchers accelerate critical biomedical discoveries.\nLimitations: The benchmark experiments presented in this paper demonstrate the capabilities of\nthe ModuLM framework in constructing and comparing various model architectures, yet they do not\ncover all possible model combinations. Our primary goal is to highlight ModuLM’s advantages in\nenabling flexible model construction and efficient model comparison, showcasing its adaptability and\neffectiveness across diverse model architectures. While the current experiments provide valuable\ninsights into the functionality and potential of the framework, a comprehensive exploration of all\npossible model combinations is beyond the scope of this study and is intended as a key direction\nfor future research. We encourage the research community to further investigate the performance of\ndifferent configurations using our framework, thus promoting the diversity and innovation of model\narchitectures.\nFuture Work: In the future, we will continue to maintain and expand the components within the\nModuLM framework to further enhance its flexibility and applicability. Specifically, we will focus\non introducing additional types of encoders, interaction layers, and evaluation metrics, while also\n9\n--- Page 10 ---\nexpanding support for a broader range of LLMs to improve the generalizability and scalability of the\nframework. At the same time, we will deepen ModuLM’s application in molecular relational learning\ntasks, particularly in areas such as drug discovery and protein interaction analysis. We expect that\nthrough continuous iteration and optimization, ModuLM will become a powerful tool for advancing\nmolecular relational learning and interdisciplinary research, providing flexible and efficient technical\nsupport for future scientific endeavors.\nReferences\n[1]Peizhen Bai, Filip Miljkovi ´c, Bino John, and Haiping Lu. Interpretable bilinear attention\nnetwork with domain adaptation improves drug–target prediction. Nature Machine Intelligence ,\n5(2):126–136, Feb 2023.\n[2]Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui\nDing, Kai Dong, Qiushi Du, Zhe Fu, et al. Deepseek llm: Scaling open-source language models\nwith longtermism. arXiv preprint arXiv:2401.02954 , 2024.\n[3]Dimitrios Christofidellis, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, and Mat-\nteo Manica. Unifying molecular and textual representations via multi-task language modelling.\narXiv preprint arXiv:2301.12586 , 2023.\n[4]Dimitrios Christofidellis, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, and Mat-\nteo Manica. Unifying molecular and textual representations via multi-task language modelling.\nInInternational Conference on Machine Learning , pages 6140–6157. PMLR, 2023.\n[5]Yunsie Chung, Florence H Vermeire, Haoyang Wu, Pierre J Walker, Michael H Abraham, and\nWilliam H Green. Group contribution and machine learning approaches to predict abraham so-\nlute parameters, solvation free energy, and solvation enthalpy. Journal of Chemical Information\nand Modeling , 62(3):433–446, 2022.\n[6]Weitao Du, He Zhang, Yuanqi Du, Qi Meng, Wei Chen, Nanning Zheng, Bin Shao, and Tie-Yan\nLiu. Se (3) equivariant graph neural networks with complete local frames. In International\nConference on Machine Learning , pages 5583–5608. PMLR, 2022.\n[7]Wenjie Du, Shuai Zhang, Jun Xia Di Wu, Ziyuan Zhao, Junfeng Fang, and Yang Wang. Mmgnn:\nA molecular merged graph neural network for explainable solvation free energy prediction. In\nProceedings of the Thirty-Third International Joint Conference on Artificial Intelligence , pages\n5808–5816, 2024.\n[8]Yuanqi Du, Limei Wang, Dieqiao Feng, Guifeng Wang, Shuiwang Ji, Carla P Gomes, Zhi-Ming\nMa, et al. A new perspective on building efficient and expressive 3d equivariant graph neural\nnetworks. Advances in neural information processing systems , 36:66647–66674, 2023.\n[9]David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael Gómez-Bombarelli,\nTimothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs\nfor learning molecular fingerprints. arXiv preprint arXiv:1509.09292 , 2015.\n[10] Carl Edwards, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, and Heng Ji. Translation\nbetween molecules and natural language. arXiv preprint arXiv:2204.11817 , 2022.\n[11] Carl Edwards, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, and Heng Ji. Translation\nbetween molecules and natural language. arXiv preprint arXiv:2204.11817 , 2022.\n[12] Carl Edwards, ChengXiang Zhai, and Heng Ji. Text2mol: Cross-modal molecule retrieval with\nnatural language queries. In Proceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing , pages 595–607, 2021.\n[13] Junfeng Fang, Shuai Zhang, Chang Wu, Zhengyi Yang, Zhiyuan Liu, Sihang Li, Kun Wang,\nWenjie Du, and Xiang Wang. Moltc: Towards molecular relational modeling in language\nmodels. arXiv preprint arXiv:2402.03781 , 2024.\n[14] Tianfan Fu, Cao Xiao, and Jimeng Sun. Core: Automatic molecule optimization using copy &\nrefine strategy. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 34,\npages 638–645, 2020.\n10\n--- Page 11 ---\n[15] Fabian Fuchs, Daniel Worrall, V olker Fischer, and Max Welling. Se (3)-transformers: 3d\nroto-translation equivariant attention networks. Advances in neural information processing\nsystems , 33:1970–1981, 2020.\n[16] Johannes Gasteiger, Florian Becker, and Stephan Günnemann. Gemnet: Universal directional\ngraph neural networks for molecules. Advances in Neural Information Processing Systems ,\n34:6790–6802, 2021.\n[17] Johannes Gasteiger, Janek Groß, and Stephan Günnemann. Directional message passing for\nmolecular graphs. arXiv preprint arXiv:2003.03123 , 2020.\n[18] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural\nmessage passing for quantum chemistry. In International conference on machine learning ,\npages 1263–1272. PMLR, 2017.\n[19] Laura M Grubbs, Mariam Saifullah, E Nohelli, Shulin Ye, Sai S Achi, William E Acree Jr, and\nMichael H Abraham. Mathematical correlations for describing solute transfer into functionalized\nalkane solvents containing hydroxyl, ether, ester or ketone solvents. Fluid phase equilibria ,\n298(1):48–53, 2010.\n[20] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in\nllms via reinforcement learning. arXiv preprint arXiv:2501.12948 , 2025.\n[21] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large\ngraphs. Advances in neural information processing systems , 30, 2017.\n[22] Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec, Connor W.\nColey, Cao Xiao, Jimeng Sun, and Marinka Zitnik. Therapeutics data commons: Machine\nlearning datasets and tasks for drug discovery and development. Advances in Neural Information\nProcessing Systems , 2 2021.\n[23] Kexin Huang, Tianfan Fu, Lucas M Glass, Marinka Zitnik, Cao Xiao, and Jimeng Sun.\nDeeppurpose: A deep learning library for drug–target interaction prediction. Bioinformat-\nics, 36(22–23):5545–5547, Dec 2020.\n[24] Kexin Huang, Cao Xiao, Lucas M Glass, and Jimeng Sun. Moltrans: Molecular interaction\ntransformer for drug–target interaction prediction. Bioinformatics , 37(6):830–836, 2020.\n[25] Kanchan Jha, Sriparna Saha, and Hiteshi Singh. Prediction of protein–protein interaction using\ngraph neural networks. Scientific Reports , 12(1):8360, 2022.\n[26] Bowen Jing, Stephan Eismann, Patricia Suriana, Raphael John Lamarre Townshend, and Ron\nDror. Learning from protein structure with geometric vector perceptrons. In International\nConference on Learning Representations , 2021.\n[27] Joonyoung F Joung, Minhi Han, Minseok Jeong, and Sungnam Park. Experimental database of\noptical properties of organic compounds. Scientific data , 7(1):295, 2020.\n[28] Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li,\nBenjamin A. Shoemaker, Paul A. Thiessen, Bo Yu, Leonid Zaslavsky, Jian Zhang, and Evan E.\nBolton. Pubchem 2023 update. Nucleic Acids Res. , 51(D1):1373–1380, 2023.\n[29] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional\nnetworks. arXiv preprint arXiv:1609.02907 , 2016.\n[30] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional\nnetworks. In Proceedings of the International Conference on Learning Representations (ICLR) ,\n2017.\n[31] Mario Krenn, Qianxiang Ai, Senja Barthel, Nessa Carson, Angelo Frei, Nathan C Frey, Pascal\nFriederich, Théophile Gaudin, Alberto Alexander Gayle, Kevin Maik Jablonka, et al. Selfies\nand the future of molecular string representations. Patterns , 3(10), 2022.\n11\n--- Page 12 ---\n[32] Namkyeong Lee, Dongmin Hyun, Gyoung S. Na, Sungwon Kim, Junseok Lee, and Chanyoung\nPark. Conditional graph information bottleneck for molecular relational learning. In ICML ,\nvolume 202 of Proceedings of Machine Learning Research , pages 18852–18871. PMLR, 2023.\n[33] Namkyeong Lee, Dongmin Hyun, Gyoung S Na, Sungwon Kim, Junseok Lee, and Chanyoung\nPark. Conditional graph information bottleneck for molecular relational learning. arXiv preprint\narXiv:2305.01520 , 2023.\n[34] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-image\npre-training with frozen image encoders and large language models. In International conference\non machine learning , pages 19730–19742. PMLR, 2023.\n[35] Sihang Li, Zhiyuan Liu, Yanchen Luo, Xiang Wang, Xiangnan He, Kenji Kawaguchi, Tat-Seng\nChua, and Qi Tian. 3d-molm: Towards 3d molecule-text interpretation in language models. In\nICLR , 2024.\n[36] Youwei Liang, Ruiyi Zhang, Li Zhang, and Pengtao Xie. Drugchat: Towards enabling chatgpt-\nlike capabilities on drug molecule graphs. ArXiv , abs/2309.03907, 2023.\n[37] Tsung-Yu Lin, Aruni RoyChowdhury, and Subhransu Maji. Bilinear cnn models for fine-grained\nvisual recognition. In Proceedings of the IEEE international conference on computer vision ,\npages 1449–1457, 2015.\n[38] Xuan Lin, Zhe Quan, Zhi-Jie Wang, Tengfei Ma, and Xiangxiang Zeng. Kgnn: Knowledge graph\nneural network for drug-drug interaction prediction. In IJCAI , volume 380, pages 2739–2745,\n2020.\n[39] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances\nin neural information processing systems , 36:34892–34916, 2023.\n[40] Yi Liu, Limei Wang, Meng Liu, Yuchao Lin, Xuan Zhang, Bora Oztekin, and Shuiwang Ji.\nSpherical message passing for 3d molecular graphs. In International Conference on Learning\nRepresentations (ICLR) , 2022.\n[41] Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, and\nTat-Seng Chua. Molca: Molecular graph-language modeling with cross-modal projector and\nuni-modal adapter. arXiv preprint arXiv:2310.12798 , 2023.\n[42] Youzhi Luo and Shuiwang Ji. An autoregressive flow model for 3d molecular geometry\ngeneration from scratch. In International conference on learning representations (ICLR) , 2022.\n[43] Aleksandr V Marenich, Casey P Kelly, Jason D Thompson, Gregory D Hawkins, Candee C\nChambers, David J Giesen, Paul Winget, Christopher J Cramer, and Donald G Truhlar. Min-\nnesota solvation database (mnsol) version 2012. 2020.\n[44] David L Mobley and J Peter Guthrie. Freesolv: a database of experimental and calculated\nhydration free energies, with input files. Journal of computer-aided molecular design , 28:711–\n720, 2014.\n[45] Edouard Moine, Romain Privat, Baptiste Sirjean, and Jean-Noël Jaubert. Estimation of solvation\nquantities from experimental thermodynamic data: Development of the comprehensive compsol\ndatabank for pure and mixed solutes. Journal of Physical and Chemical Reference Data , 46(3),\n2017.\n[46] Thin Nguyen, Hang Le, Thomas P Quinn, Tri Nguyen, Thuc Duy Le, and Svetha Venkatesh.\nGraphdta: Predicting drug–target binding affinity with graph neural networks. Bioinformatics ,\n37(8):1140–1147, Oct 2020.\n[47] Gilchan Park, Sean McCorkle, Carlos Soto, Ian Blaby, and Shinjae Yoo. Extracting protein-\nprotein interactions (ppis) from biomedical literature using attention-based relational context\ninformation. In 2022 IEEE International Conference on Big Data (Big Data) , pages 2052–2061.\nIEEE, 2022.\n12\n--- Page 13 ---\n[48] Qizhi Pei, Wei Zhang, Jinhua Zhu, Kehan Wu, Kaiyuan Gao, Lijun Wu, Yingce Xia, and Rui\nYan. Biot5: Enriching cross-modal integration in biology with chemical knowledge and natural\nlanguage associations. arXiv preprint arXiv:2310.07276 , 2023.\n[49] Ying Qian, Xinyi Li, Jian Wu, and Qian Zhang. Mcl-dti: Using drug multimodal information\nand bi-directional cross-attention learning method for predicting drug–target interaction. BMC\nBioinformatics , 24(1), Aug 2023.\n[50] Wenqi Ren, Lin Ma, Jiawei Zhang, Jinshan Pan, Xiaochun Cao, Wei Liu, and Ming-Hsuan\nYang. Gated fusion network for single image dehazing. In Proceedings of the IEEE conference\non computer vision and pattern recognition , pages 3253–3261, 2018.\n[51] Dan M Roden, Robert A Harrington, Athena Poppas, and Andrea M Russo. Considerations for\ndrug interactions on qtc in exploratory covid-19 treatment. Circulation , 141(24):e906–e907,\n2020.\n[52] Jae Yong Ryu, Hyun Uk Kim, and Sang Yup Lee. Deep learning improves prediction of\ndrug–drug and drug–food interactions. Proceedings of the national academy of sciences ,\n115(18):E4304–E4311, 2018.\n[53] Tatsuya Sagawa and Ryosuke Kojima. Reactiont5: a large-scale pre-trained model towards\napplication of limited reaction data. arXiv preprint arXiv:2311.06708 , 2023.\n[54] Vıctor Garcia Satorras, Emiel Hoogeboom, and Max Welling. E (n) equivariant graph neural\nnetworks. In International conference on machine learning , pages 9323–9332. PMLR, 2021.\n[55] Kristof Schütt, Oliver Unke, and Michael Gastegger. Equivariant message passing for the\nprediction of tensorial properties and molecular spectra. In International Conference on\nMachine Learning , pages 9377–9388. PMLR, 2021.\n[56] Kristof T Schütt, Pieter-Jan Kindermans, Huziel E Sauceda, Stefan Chmiela, Alexandre\nTkatchenko, and Klaus-Robert Müller. Schnet: A continuous-filter convolutional neural net-\nwork for modeling quantum interactions. Advances in Neural Information Processing Systems ,\n30:992–1002, 2017.\n[57] Sizhe Sizhe Liu, Jun Xia, Lecheng Zhang, Yuchen Liu, Yue Liu, Wenjie Du, Zhangyang Gao,\nBozhen Hu, Cheng Tan, Stan Z Li, et al. Flexmol: A flexible toolkit for benchmarking molecular\nrelational learning. Advances in Neural Information Processing Systems , 37:35454–35467,\n2024.\n[58] Xiangru Tang, Andrew Tran, Jeffrey Tan, and Mark B. Gerstein. Mollm: A unified language\nmodel for integrating biomedical text with 2d and 3d molecular representations. bioRxiv , 2024.\n[59] Nicholas P Tatonetti, Patrick P Ye, Roxana Daneshjou, and Russ B Altman. Data-driven\nprediction of drug effects and interactions. Science translational medicine , 4(125):125ra31–\n125ra31, 2012.\n[60] Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis\nSaravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: A large language\nmodel for science. arXiv preprint arXiv:2211.09085 , 2022.\n[61] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-\nthée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open\nand efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n[62] Jithin John Varghese and Samir H Mushrif. Origins of complex solvent effects on chemical\nreactivity and computational tools to investigate them: a review. Reaction Chemistry &\nEngineering , 4(2):165–206, 2019.\n[63] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems ,\n2017.\n[64] Petar Veli ˇckovi ´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua\nBengio. Graph attention networks. In Proceedings of the International Conference on Learning\nRepresentations (ICLR) , 2018.\n13\n--- Page 14 ---\n[65] Florence H Vermeire and William H Green. Transfer learning for solvation free energies: From\nquantum chemistry to experiments. Chemical Engineering Journal , 418:129307, 2021.\n[66] Taras V oitsitskyi, Roman Stratiichuk, Ihor Koleiev, Leonid Popryho, Zakhar Ostrovsky, Pavlo\nHenitsoi, Ivan Khropachov, V olodymyr V ozniak, Roman Zhytar, Diana Nechepurenko, and\net al. 3dprotdta: A deep learning model for drug-target affinity prediction based on residue-level\nprotein graphs. RSC Advances , 13(15):10261–10272, 2023.\n[67] Fang Wu, Shuting Jin, Yinghui Jiang, Xurui Jin, Bowen Tang, Zhangming Niu, Xiangrong Liu,\nQiang Zhang, Xiangxiang Zeng, and Stan Z Li. Pre-training of equivariant graph matching\nnetworks with conformation flexibility for drug binding. Advanced Science , 9(33):2203796,\n2022.\n[68] Zhaoping Xiong, Dingyan Wang, Xiaohong Liu, Feisheng Zhong, Xiaozhe Wan, Xutong Li,\nZhaojun Li, Xiaomin Luo, Kaixian Chen, Hualiang Jiang, and et al. Pushing the boundaries of\nmolecular representation for drug discovery with the graph attention mechanism. Journal of\nMedicinal Chemistry , 63(16):8749–8760, Aug 2019.\n[69] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural\nnetworks? In Proceedings of the International Conference on Learning Representations (ICLR) ,\n2019.\n[70] Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and\nStefanie Jegelka. Representation learning on graphs with jumping knowledge networks. In\nInternational conference on machine learning , pages 5453–5462. PMLR, 2018.\n[71] Mehdi Yazdani-Jahromi, Niloofar Yousefi, Aida Tayebi, Elayaraja Kolanthai, Craig J Neal,\nSudipta Seal, and Ozlem Ozmen Garibay. Attentionsitedti: An interpretable graph-based model\nfor drug-target interaction prediction using nlp sentence-level relation classification. Briefings\nin Bioinformatics , 23(4), Jul 2022.\n[72] Zheni Zeng, Yuan Yao, Zhiyuan Liu, and Maosong Sun. A deep-learning system bridging\nmolecule structure and biomedical text with comprehension comparable to human professionals.\nNature communications , 13(862), 2022.\n[73] D. D. Zhang, S. Xia, and Y . K. Zhang. Accurate prediction of aqueous free solvation energies\nusing 3d atomic feature-based graph neural network with transfer learning. Journal of Chemical\nInformation and Modeling , 62(8):1840–1848, 2022.\n[74] Wen Zhang, Yanlin Chen, Feng Liu, Fei Luo, Gang Tian, and Xiaohong Li. Predicting potential\ndrug-drug interactions by integrating chemical, biological, phenotypic and network data. BMC\nbioinformatics , 18:1–12, 2017.\n[75] Xuan Zhang, Cheng Chen, Zhaoxu Meng, Zhenghe Yang, Haitao Jiang, and Xuefeng Cui.\nCoatgin: Marrying convolution and attention for graph-based molecule property prediction. In\n2022 IEEE international conference on bioinformatics and biomedicine (BIBM) , pages 374–379.\nIEEE, 2022.\n[76] Zuobai Zhang, Minghao Xu, Arian Jamasb, Vijil Chenthamarakshan, Aurelie Lozano, Payel\nDas, and Jian Tang. Protein representation learning by geometric structure pretraining. In\nInternational Conference on Learning Representations , 2023.\n[77] Yi Zhong, Xueyu Chen, Yu Zhao, Xiaoming Chen, Tingfang Gao, and Zuquan Weng. Graph-\naugmented convolutional networks on drug-drug interactions prediction. arXiv preprint\narXiv:1912.03702 , 2019.\n[78] Yujie Zhong, Guangming Li, Jianxin Yang, et al. Learning motif-based graphs for drug–drug\ninteraction prediction via local–global self-attention. Nature Machine Intelligence , 6:1094–1105,\n2024.\n[79] Gengmo Zhou, Zhifeng Gao, Qiankun Ding, Hang Zheng, Hongteng Xu, Zhewei Wei, Linfeng\nZhang, and Guolin Ke. Uni-mol: a universal 3d molecular representation learning framework.\n2023.\n14\n--- Page 15 ---\n[80] Gengmo Zhou, Zhifeng Gao, Qiankun Ding, Hang Zheng, Hongteng Xu, Zhewei Wei, Linfeng\nZhang, and Guolin Ke. Uni-mol: A universal 3d molecular representation learning framework.\n2023.\n[81] Lu Zhou and Rong-Hua Zhang. A self-attention–based neural network for three-dimensional\nmultivariate modeling and its skillful enso predictions. Science Advances , 9(10):eadf2827,\n2023.\n[82] Yan Zhu, Lingling Zhao, Naifeng Wen, Junjie Wang, and Chunyu Wang. Datadta: A multi-\nfeature and dual-interaction aggregation framework for drug–target binding affinity prediction.\nBioinformatics , 39(9), Sep 2023.\n[83] M Zitnik, R Sosi, S Maheshwari, and J Leskovec. Stanford biomedical network dataset\ncollection. Biosn. Datasets Stanford Biomed. Netw. Dataset Collect , 2018.\n15\n--- Page 16 ---\nA Appendix\nA.1 General Information\nA.1.1 Links\nThe code for ModuLM is currently available in our code repository https://anonymous.\n4open.science/r/ModuLM . The repository provides reproduction scripts for the best-\nperforming model, and if you wish to reproduce other experiments conducted in this paper, please\nrefer to the Appendix A.4.\nA.1.2 Licenses\nThe ModuLM is under the CC BY 4.0. We, the authors, bear all responsibility in case of violation of\nrights.\nA.2 Details of Datasets\nIn ModuLM, we provide diverse datasets for DDI, SSI, and CSI tasks to comprehensively evaluate\nModuLM’s flexibility and generalizability. An overview of the datasets is provided in Table 8.\nTable 8: Data statistics.\nTask Dataset G1G2Pairs\nDDIZhangDDI 548 548 48,548\nChChMiner 1322 1322 48,514\nDeepDDI - - 192,284\nTWOSIDES 555 555 3,576,513\nSSIMNSol 372 86 2,275\nFreeSolv 560 1 560\nCompSol 442 259 3,548\nAbraham 1038 122 6,091\nCombiSolv 1,368 291 10,145\nCombiSolv-QM 11,029 284 1,000,000\nCSI Chromophore 7,016 365 20,236\nZhangDDI [74]. Includes 548 drugs and 48,548 labeled interactions, incorporating various drug\nsimilarity metrics for similarity-aware DDI modeling. It is commonly used for evaluating similarity-\nbased prediction methods.\nChChMiner [83]. Provides 1,322 drugs and 48,514 interactions sourced from FDA labels and\nliterature, emphasizing clinically verified DDIs. It is suitable for real-world DDI risk assessment.\nDeepDDI [52]. Contains 192,284 labeled DDIs with side effect annotations extracted from DrugBank.\nThe dataset supports multi-label classification tasks involving adverse interactions.\nTWOSIDES [59]. Offers 555 drugs and over 3.5 million interactions with 1,318 types, derived from\nadverse event reports. It enables exploration of long-tail DDI patterns at scale.\nChromophore [27]. Includes 20,236 chromophore–solvent pairs with optical properties like absorp-\ntion, emission, and lifetime. Unreliable entries are removed, and log-normalization is applied to\nreduce target skew.\nMNSol [43]. Provides 3,037 solvation or transfer free energy records across 790 solutes and 92\nsolvents. We use 2,275 filtered combinations consistent with prior benchmarks.\nFreeSolv [44]. Offers 643 hydration free energy measurements in water for small molecules. We\nretain 560 experimental entries for aqueous solvation prediction tasks.\nCompSol [45]. Contains 3,548 solute–solvent pairs focusing on hydrogen-bonding effects in solvation\nenergy. It evaluates the impact of molecular interactions on solvent behavior.\n16\n--- Page 17 ---\nAbraham [19]. Covers 6,091 combinations from 1,038 solutes and 122 solvents based on Abraham’s\nsolvation parameter model. It supports solvent effect modeling via linear energy relationships.\nCombiSolv [65]. Combines MNSol, FreeSolv, CompSol, and Abraham into a unified dataset of\n10,145 solute–solvent combinations. It serves as a comprehensive benchmark for solvation prediction.\nCombiSolv-QM [65]. Includes 1 million QM-generated solute–solvent pairs with diverse chemical\ncompositions. It evaluates large-scale generalization and robustness of molecular models.\nA.3 Details of ModuLM Components\nA.3.1 2D Graph Encoders\nGCN [30]. Performs graph convolution using a normalized Laplacian to aggregate neighboring node\nfeatures, enabling semi-supervised learning on graph-structured data.\nMPNN [18]. Generalizes message-passing in graphs by learning both message functions and update\nrules, providing a flexible framework for molecular property prediction.\nGAT [64]. Applies self-attention to adaptively weigh neighbor contributions during node embedding\nupdates, improving learning on irregular graph structures.\nNeuralFP [9]. Learns molecular fingerprints via graph convolutional layers, enabling end-to-end\nlearning of molecular representations for property prediction.\nAttentiveFP [68]. Utilizes attention mechanisms to prioritize significant molecular substructures,\nenhancing interpretability and predictive performance in QSAR tasks.\nGIN [69]. Enhances graph discriminative power with injective neighborhood aggregation, theoreti-\ncally achieving maximal expressive capacity among GNNs.\nGraphSAGE [21]. Generates embeddings by sampling and aggregating neighbor features in an\ninductive manner, making it scalable to large dynamic graphs.\nCoATGIN [75]. Integrates convolutional aggregation and attention mechanisms to capture both local\nmotifs and global contexts in molecular graphs.\nA.3.2 3D Conformation Encoders\nEGNN [54]. Preserves equivariance to Euclidean transformations by jointly updating node features\nand coordinates, enabling effective modeling of molecular geometry.\n3D-GeoFormer [81]. Leverages geometric transformers to model spatial relations and interactions\nin molecular structures, enhancing 3D representation learning with attention.\nSE(3)-Transformer [15]. Incorporates SE(3) equivariance using tensor field networks, making it\nwell-suited for complex 3D molecular and protein data.\nPaiNN [55]. Achieves rotational equivariance by separating scalar and vector features in message\npassing, allowing accurate force field and energy predictions.\nGVP [26]. Combines geometric vector perceptrons with scalar and vector features for molecular\nstructure modeling, while being applicable to general 3D molecular graphs.\nGearNet [76]. Builds multi-scale molecular representations by integrating structural and sequential\ninformation, enhancing learning across different biological levels.\nDimeNet++ [17]. Captures directional information and angular relations in molecular graphs with\nimproved message passing and higher efficiency than its predecessor.\nSchNet [56]. Models quantum interactions using continuous-filter convolutions, enabling accurate\npredictions of atomic-level properties in molecular systems.\nSphereNet [40]. Encodes spherical angles and radial distances to capture 3D molecular geometry\nmore precisely, leading to improved performance in quantum property prediction.\nG-SphereNet [42]. Extends SphereNet with an autoregressive generative mechanism, enabling the\nmodeling and generation of complex molecular conformations.\n17\n--- Page 18 ---\nUni-Mol [80]. Unifies molecular pretraining and finetuning in 3D space using a transformer-based\narchitecture, supporting diverse downstream tasks with spatial awareness.\nA.3.3 Interaction Layers\nBilinear Attention [1]. The Bilinear Attention Network (BAN) layer captures interactions be-\ntween 2D feature sets through bilinear transformations, followed by attention pooling and batch\nnormalization.\nSelf Attention [63]. Self-attention mechanisms allow a feature set to focus on its own elements,\nenabling models to capture relationships within the same source of data.\nCross Attention [49]. Cross-attention captures interactions between two distinct feature sets by\napplying attention mechanisms that focus on cross-source dependencies.\nHighway [82]. The Highway mechanism combines 1D features through gated layers, allowing\ninformation to flow selectively by controlling the gates.\nGated Fusion [50]. Gated fusion combines 1D features from two sources by applying gated\ntransformations, producing a unified representation that captures the interactions between them.\nBilinear Fusion [37]. Bilinear Fusion combines 1D features using a bilinear transformation and\nReLU activation, capturing multiplicative interactions to enhance feature representation.\nMean . The Mean method combines feature sets by averaging their values.\nA.3.4 Backbones\nIn ModuLM, we provide seven popular LLMs: DeepSeek-1.5B, DeepSeek-7B, DeepSeek-14B [ 2],\nLLaMA-1B, LLaMA-13B [61], Galactica-1.3B, and Galactica-6.7B [60].\nDeepSeek. The DeepSeek-1.5B, DeepSeek-7B, and DeepSeek-14B models are derived from the\nQwen-2.5 series, which were originally licensed under the Apache 2.0 License, and have now been\nfine-tuned with 800k samples curated using DeepSeek-R1.\nLLama. LLama 1B incorporated logits from the LLama 3.1 8B and 70B models during the pretraining\nstage, using the outputs (logits) from these larger models as token-level targets. Knowledge distillation\nwas applied after pruning to recover performance. LLama-13B was pretrained on 2 trillion tokens of\ndata from publicly available sources and fine-tuned on publicly available instruction datasets, along\nwith over one million new human-annotated examples, making it a general-purpose LLM.\nGalactica. Galactica-1.3B and Galactica-6.7B are large language models developed by Meta for\nscientific research and knowledge-intensive tasks. These models are designed to assist with tasks in\nfields like scientific literature, research summarization, and computational biology.\nTable 9: Prompts settings.\nDirect Reasoning for Qualitative Tasks\nThe first molecule <SMILES0> and the second molecule <SMILES1> are expected to interact with\neach other, potentially forming a molecular complex or influencing each other’s properties.\nCoT-based Reasoning for Qualitative Tasks\nThe first molecule <SMILES0> is likely to exhibit [Property0] , while the second molecule\n<SMILES1> is likely to exhibit [Property1] . Hence, the first drug molecule may alter the\ntherapeutic effects of the second drug molecule. Therefore, they are likely to interact with each other.\nDirect Reasoning for Quantitative Tasks\nThe solvation Gibbs free energy between the first molecule <SMILES0> and the second molecule\n<SMILES1> is 4.6232.\nCoT-based Reasoning for Quantitative Tasks\nThe first molecule <SMILES0> is likely to exhibit [Property0] , while the second molecule\n<SMILES1> is likely to exhibit [Property1] . Therefore, their solvation Gibbs free energy is\nlikely to fall between 4.0 and 4.5, with a precise value potentially being 4.6232.\n18\n--- Page 19 ---\nA.3.5 Prompts\nIn the main text, we mentioned the two prompts involved in our experiments: Direct and Chain-of-\nThought-based reasoning. The prompt design is shown in the Table 9.\nA.4 Example Usage of ModuLM\nThis section demonstrates how to construct example models from the main text using ModuLM. In\nModuLM, we provide a configuration method based on a JSON file. In the modules we offer, users\nonly need to modify the corresponding parameters. It is worth noting that some of the parameters\nbelow are included solely to demonstrate the comprehensiveness of our framework; if the goal is\nsimply to use it, most hyperparameters do not need to be changed.\nA.4.1 Loading the Dataset\nTaking the DeepDDI dataset loading as an example, the path to the dataset is defined using the\nroot parameter. To accelerate data loading, the num_workers parameter is used to enable\nmulti-threaded data processing. Additionally, the use_3d flag controls whether to incorporate 3D\nmolecular conformational data as input. This allows users to flexibly switch between 2D and 3D\nmolecular representations depending on the task requirements and available structural information.\n{\n\"root\": \"data/DDI/DeepDDI/\",\n\"num_workers\": 5,\n\"use_3d\":true\n}\nA.4.2 Initializing Encoder\nIn this setup, we utilize the Uni-Mol model as our 3D molecular conformation encoder. The\nspecific encoder is selected by setting the graph3d parameter accordingly. To fine-tune its behavior\nand architecture, we provide a dedicated configuration file that defines key hyperparameters such\nas the number of layers, embedding dimensions, attention mechanisms, and dropout rates. This\nmodular design allows for flexible customization and seamless integration into various molecular\nrepresentation learning tasks.\n{\n\"graph3d\": \"unimol\",\n\"con_activation_dropout\": 0.0,\n\"con_activation_fn\": \"gelu\",\n\"con_attention_dropout\": 0.1,\n\"con_delta_pair_repr_norm_loss\": -1.0,\n\"con_dropout\": 0.1,\n\"con_emb_dropout\": 0.1,\n\"con_encoder_attention_heads\": 64,\n\"con_encoder_embed_dim\": 512,\n\"con_encoder_ffn_embed_dim\": 2048,\n\"con_encoder_layers\": 15,\n\"con_max_atoms\": 256,\n\"con_max_seq_len\": 512\n}\nIt is important to note that in order to build the example model provided in the main text, we need to\nmake further modifications and extensions to the Uni-Mol model. Once the code has been extended,\nwe can simply place it in the specified directory and continue managing and calling it through the\nconfig file.\nA.4.3 Configuring LLM\nHere, the mode specifies the model’s mode, whether it is pretraining or fine-tuning. The backbone\nparameter indicates the LLM to be used, while min_len andmax_len define the minimum and\nmaximum lengths of the generated text. Additional details and parameters for LLM-based text\n19\n--- Page 20 ---\ngeneration are provided in our code repository; this section highlights only a few key settings as\nexamples.\n{ \"mode\":\"ft\",\n\"backbone\": \"DeepSeek-1.5B\",\n\"min_len\": 10,\n\"max_len\": 40\n}\nA.4.4 Training the Model\nAfter constructing the model, we can fine-tune it by configuring the appropriate LoRA file. To make\nit easier for others to fine-tune using our framework, we provide the LoRA parameter configuration\nfor model training here.\n{\n\"base_model_name_or_path\": null,\n\"bias\": \"none\",\n\"fan_in_fan_out\": false,\n\"inference_mode\": false,\n\"init_lora_weights\": true,\n\"lora_alpha\": 32,\n\"lora_dropout\": 0.1,\n\"target_modules\": [\"q_proj\", \"v_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n\"peft_type\": \"LORA\",\n\"r\": 16,\n\"modules_to_save\": null,\n\"task_type\": \"CAUSAL_LM\"\n}\nThe specific batch size and number of training epochs are also configured in a unified manner. Here,\nthebatch_size specifies the number of samples processed in each training step, which in this\ncase is set to 12. The max_epochs defines the total number of training iterations over the entire\ndataset, set here to 20 epochs. The save_every_n_epochs parameter indicates that the model’s\nstate will be saved every 5 epochs. The scheduler field specifies the learning rate scheduling\nstrategy— linear_warmup_cosine_lr gradually increases the learning rate during a warm-up\nperiod, then decays it following a cosine curve. The seed ensures reproducibility of training results\nby fixing randomness. warmup_lr andwarmup_steps define the initial learning rate and the\nnumber of steps over which it will warm up, respectively. Lastly, weight_decay is used as a\nregularization technique to prevent overfitting by penalizing large weights during optimization.\n{\n\"batch_size\": 12,\n\"max_epochs\": \"30\",\n\"save_every_n_epochs\": 5,\n\"scheduler\": linear_warmup_cosine_lr,\n\"seed\": 42,\n\"warmup_lr\": 1e-06,\n\"warmup_steps\": 1000,\n\"weight_decay\": \"0.05\"\n}\nA.5 More experimental details\nA.5.1 Details of Experimental Setup\nIn this section, we provide a more detailed description of the experimental data and testing configura-\ntions used in the main text.\nTraining Epochs. At the beginning of each experiment, we initiate incremental pretraining by\nrunning 5 epochs on the collected pretraining dataset. During the subsequent fine-tuning stage, the\nnumber of training epochs is task-dependent. Specifically, for the DDI task, we fine-tune the model\nfor 50 epochs. For SSI datasets containing more than 3000 molecular pairs, we adopt a two-stage\n20\n--- Page 21 ---\nfine-tuning strategy: first, the model is fine-tuned on the CombiSolv-QM dataset for 100 epochs,\nfollowed by an additional 30 epochs on the target dataset. In contrast, for SSI datasets with fewer than\n3000 molecular pairs, the fine-tuning stage is shortened to 20 epochs. Notably, both pretraining and\nfine-tuning phases share the same optimizer and learning rate scheduling configurations, as described\nin the following section.\nTraining Strategy. We employ the AdamW optimizer with a weight decay coefficient of 0.05\nto mitigate overfitting and stabilize training. The learning rate is governed by a linear warm-up\nfollowed by cosine decay schedule, which helps accelerate convergence in the early stages and\nenables refined optimization during the later phases. To further enhance efficiency and reduce training\noverhead, we adopt Low-Rank Adaptation (LoRA), implemented using the OpenDelta and PEFT\nlibraries. The rank parameter of LoRA is set to r= 16 . For models in the DeepSeek series, LoRA is\napplied to the following modules: [q_proj, k_proj, v_proj, o_proj, gate_proj,\nup_proj, down_proj] . For the LLaMA and Galactica models, LoRA is instead integrated into\n[q_proj, v_proj, out_proj, fc1, fc2] .\nA.5.2 More Experimental Results\nDue to space limitations in the main text, we present additional experimental results here, with the\nexperimental setup consistent with the one described in the main text.\nTable 10: More Results of DDI Datasets\nExperiment AUC-ROC\n(Drugbank)Accuracy\n(Drugbank)AUC-ROC\n(TWOSIDES)Accuracy\n(TWOSIDES)\nChem T5[4] 0.921 ±0.010 0.859 ±0.013 0.906 ±0.015 0.856 ±0.022\nMolCA[41] 0.934 ±0.018 0.898 ±0.010 0.942 ±0.014 0.907 ±0.015\nMolT5[11] 0.930 ±0.016 0.904 ±0.018 0.940 ±0.013 0.929 ±0.017\nMolTC[13] 0.978 ±0.006 0.951 ±0.005 0.980 ±0.005 0.970 ±0.007\n1.1 0.933 ±0.011 0.891 ±0.012 0.912 ±0.017 0.877 ±0.014\n1.2 0.945 ±0.010 0.922 ±0.011 0.957 ±0.009 0.923 ±0.009\n1.3 0.950 ±0.009 0.935 ±0.010 0.950 ±0.008 0.926 ±0.008\n1.4 0.955 ±0.008 0.938 ±0.009 0.946 ±0.007 0.935 ±0.008\n1.5 0.946 ±0.010 0.931 ±0.010 0.951 ±0.008 0.918 ±0.008\n1.6 0.938 ±0.016 0.901 ±0.012 0.920 ±0.017 0.893 ±0.018\n1.7 0.963 ±0.007 0.944 ±0.007 0.970 ±0.006 0.952 ±0.006\n1.8 0.975 ±0.006 0.950 ±0.006 0.982 ±0.005 0.975 ±0.005\n1.9 0.950 ±0.008 0.937 ±0.008 0.971 ±0.006 0.949 ±0.006\n1.10 0.940 ±0.010 0.926 ±0.010 0.961 ±0.007 0.938 ±0.007\n1.11 0.920 ±0.014 0.886 ±0.010 0.907 ±0.021 0.855 ±0.020\n1.12 0.935 ±0.011 0.920 ±0.010 0.945 ±0.012 0.911 ±0.008\n1.13 0.947 ±0.008 0.933 ±0.009 0.953 ±0.013 0.923 ±0.009\n1.14 0.952 ±0.007 0.931 ±0.009 0.959 ±0.012 0.932 ±0.010\n1.15 0.935 ±0.019 0.877 ±0.020 0.927 ±0.010 0.894 ±0.011\nCustom Model 0.982±0.010 0.956 ±0.007 0.986 ±0.007 0.980 ±0.009\nThe results presented in Table 11 and Table 10 are largely consistent with those reported in the main\ntext, reaffirming the trends observed across different configurations. Notably, the introduction of\nadditional modality information consistently yields substantial improvements in model performance,\nhighlighting the effectiveness of leveraging multimodal signals in enhancing representation learning\nand generalization. In contrast, architectural modifications that increase model complexity—such\nas altering internal modules or adding more parameters—do lead to moderate performance gains.\nHowever, these improvements are generally less pronounced compared to those achieved through the\nintegration of new modalities. This suggests that the diversity and complementarity of multimodal\ndata play a more critical role than mere architectural sophistication in driving performance gains.\n21\n--- Page 22 ---\nTable 11: More Results of SSI Datasets\nExperiment MAE\n(MNSol)RMSE\n(MNSol)MAE\n(Abraham)RMSE\n(Abraham)\nChem T5[4] 0.537 ±0.092 1.011 ±0.083 0.621 ±0.027 0.918 ±0.032\nMolCA[41] 0.511 ±0.034 0.956 ±0.049 0.580 ±0.026 0.910 ±0.032\nMolT5[11] 0.466 ±0.067 0.867 ±0.069 0.544 ±0.028 0.833 ±0.029\nMolTC[13] 0.354 ±0.018 0.625 ±0.023 0.211 ±0.018 0.390 ±0.021\n1.1 0.510 ±0.051 0.971 ±0.063 0.572 ±0.024 0.865 ±0.030\n1.2 0.451 ±0.042 0.890 ±0.028 0.524 ±0.022 0.813 ±0.027\n1.3 0.436 ±0.018 0.877 ±0.027 0.496 ±0.024 0.804 ±0.029\n1.4 0.410 ±0.017 0.808 ±0.024 0.447 ±0.020 0.681 ±0.023\n1.5 0.506 ±0.036 0.944 ±0.043 0.522 ±0.030 0.787 ±0.031\n1.6 0.502 ±0.045 0.936 ±0.052 0.591 ±0.028 0.863 ±0.025\n1.7 0.386 ±0.034 0.727 ±0.035 0.394 ±0.026 0.512 ±0.029\n1.8 0.343 ±0.017 0.618 ±0.024 0.204 ±0.017 0.408 ±0.021\n1.9 0.488 ±0.029 0.834 ±0.031 0.416 ±0.027 0.562 ±0.029\n1.10 0.501 ±0.030 0.851 ±0.032 0.456 ±0.018 0.618 ±0.022\n1.11 0.499 ±0.016 0.859 ±0.023 0.437 ±0.021 0.620 ±0.030\n1.12 0.550 ±0.047 1.118 ±0.064 0.614 ±0.029 0.933 ±0.030\n1.13 0.475 ±0.036 0.878 ±0.033 0.511 ±0.019 0.764 ±0.021\n1.14 0.461 ±0.021 0.818 ±0.027 0.489 ±0.020 0.713 ±0.021\n1.15 0.597 ±0.031 0.864 ±0.035 0.422 ±0.021 0.683 ±0.023\nCustom Model 0.340±0.011 0.601 ±0.010 0.199 ±0.008 0.379 ±0.011\nIn addition to the DDI and SSI datasets, we further evaluate our framework on the CSI dataset to\ndemonstrate its comprehensiveness and scalability. It is worth noting that the performance of models\nunder different configurations on the CSI dataset varies significantly. To facilitate a more intuitive\ncomparison of the performance across different settings, we report the best-performing configuration\nfor each backbone. The results are summarized in the Table 12. Note that the three datasets in the\nCSI domain are all derived by splitting the Chromophore dataset.\nTable 12: Performance on CSI Datasets\nExperiment MAE\n(Absorption)RMSE\n(Absorption)MAE\n(Emission)RMSE\n(Emission)MAE\n(Lifetime)RMSE\n(Lifetime)\nMolTC[13] 17.55 ±1.83 29.10 ±2.15 20.22 ±1.91 34.17 ±2.02 0.911 ±0.052 1.213 ±0.092\n1.4 18.67 ±2.01 31.33 ±2.47 22.37 ±2.01 36.71 ±2.93 1.011 ±0.061 1.502 ±0.103\n1.8 16.71 ±1.82 28.67 ±1.99 19.08 ±1.89 38.00 ±1.87 0.943 ±0.054 1.119±0.077\n1.14 19.01 ±2.01 32.46 ±2.92 21.84 ±1.96 37.56 ±3.02 1.009 ±0.060 1.711 ±0.095\nCustom Model 15.42±1.53 27.65 ±1.91 17.11 ±1.68 31.55 ±1.60 0.929 ±0.064 1.123±0.082\nFrom the data in the Table above, we can clearly analyze the performance differences of various\nmodels under different experimental settings. Leveraging the usability and extensibility of ModuLM,\nwe can implement and compare a wider range of LLM-based MRL models, thereby gaining insights\ninto how model design impacts performance.\n22",
  "text_length": 76585
}