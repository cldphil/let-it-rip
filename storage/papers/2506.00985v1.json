{
  "id": "http://arxiv.org/abs/2506.00985v1",
  "title": "Do LLMs Understand Why We Write Diaries? A Method for Purpose Extraction\n  and Clustering",
  "summary": "Diary analysis presents challenges, particularly in extracting meaningful\ninformation from large corpora, where traditional methods often fail to deliver\nsatisfactory results. This study introduces a novel method based on Large\nLanguage Models (LLMs) to identify and cluster the various purposes of diary\nwriting. By \"purposes,\" we refer to the intentions behind diary writing, such\nas documenting life events, self-reflection, or practicing language skills. Our\napproach is applied to Soviet-era diaries (1922-1929) from the Prozhito digital\narchive, a rich collection of personal narratives. We evaluate different\nproprietary and open-source LLMs, finding that GPT-4o and o1-mini achieve the\nbest performance, while a template-based baseline is significantly less\neffective. Additionally, we analyze the retrieved purposes based on gender, age\nof the authors, and the year of writing. Furthermore, we examine the types of\nerrors made by the models, providing a deeper understanding of their\nlimitations and potential areas for improvement in future research.",
  "authors": [
    "Valeriya Goloviznina",
    "Alexander Sergeev",
    "Mikhail Melnichenko",
    "Evgeny Kotelnikov"
  ],
  "published": "2025-06-01T12:38:01Z",
  "updated": "2025-06-01T12:38:01Z",
  "categories": [
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00985v1",
  "full_text": "--- Page 1 ---\nDo LLMs Understand Why We Write Diaries?  \nA Method for Purpose Extraction and Clustering  \nValeriya Goloviznina1[0000 -0003 -1167 -2606], Alexander Sergeev1[0009 -0002 -4103 -842X], \nMikhail Melnichenko1[0009 -0001 -2370 -3193], Evgeny Kotelnikov1[0000 -0001 -9745 -1489] \n1 European University at Saint Petersburg, St. Petersburg, Russia  \n{v.goloviznina , a.sergeev,  mmelnichenko,  e.kotelnikov }@eu.spb. ru \nAbstract.  Diary analysis presents challenges, particularly in extracting meaning-\nful information from large corpora, where traditional methods often fail to deliver \nsatisfactory results. This study introduces a novel method based on Large Lan-\nguage Models (LLMs) to id entify and cluster the various purposes of diary writ-\ning. By \"purposes,\" we refer to the intentions behind diary writing, such as doc-\numenting life events, self -reflection, or practicing language skills. Our approach \nis applied to Soviet -era diari es (1922 –1929) from the Prozhito digital archive, a \nrich collection of personal narratives. We evaluate different  proprietary and open -\nsource LLMs, finding that GPT -4o and o1 -mini achieve the best performance, \nwhile a template -based baseline is significantly less effective. Additionally, we \nanalyze the retrieved purposes based on gender, age of the authors, and the y ear \nof writing. Furthermore, we examine the types of errors made by the models, \nproviding a deeper understanding of their limitations and poten tial areas for im-\nprovement in future research.  \nKeywords:  LLM, Diaries Analysis, Clustering, Archival Documents, Digital \nHumanities.  \n1 Introduction  \nLarge Language Models (LLMs) are widely used in Digital Humanities (DH) and Com-\nputational Social Sciences (CSS) for tasks such as analyzing archives and forums, topic \nmodeling, cultural analytics, text classification, summarization, and generating human -\nlike text with interpretable explanations across fields such as sociology, psychology, \nliterature, history, and linguistics [1, 2, 3]. \nOne of the important fields of application of LLMs is the analysis of archival docu-\nments such as diaries, letters, journals, etc. It is difficult or impossible to read huge text \ncorpora if it is necessary to extract some important elements from the texts. Simple \ntemplate -based methods do not work efficiently enough. This is where LLMs come to \nthe rescue.  \nHowever, in practice, DH and CSS researchers face the following challenges:  \n1. uncertainty in model selection and in the accuracy of the model for a particular prob-\nlem; \n--- Page 2 ---\n2 \n2. difficulty in using standard interfaces to LLMs to analyze large corpora;  \n3. the need for programming skills to access the APIs and handle the results;  \n4. the high cost of inference.  \nIn this paper, we propose a method to analyze the large diary corpora. In the human \nsciences, the diary is used as a qualitative research tool [4]. The diary analysis allows \nresearchers to study people's experiences, behaviors, and life circumstances in a natural \nsetting. This research area has been actively explored from the 1990s to the present  [5]. \nAmong other things, researchers are interested in the purposes of keeping a diary [6]. \nIn our work, we extract the purposes of diary writing using LLMs. By purposes, we \nmean the intentions with which people keep diaries – both the reasons why a person \nstarted writing (for example, inspiration from someone else's diary, boredom, free time) \nand the purposes for doing so (for example, writing memoirs, tracking your condition, \npracticing foreign languages).  \nAs data we use the corpus of diaries of the post -revolutionary Soviet era (1922 –\n1929) from “Prozhito”, the Center for the Study of Ego -Documents of the European \nUniversity at St. Petersburg, which has been collecting and publishing personal diaries \nin Russ ian and other languages since 2015 and actively developing a digital archive1. \nThe contributions of our work are as follows:  \n1. we test different  proprietary and open -source models for identifying diary entries \nthat contain purposes and for extracting these purposes;  \n2. we evaluate the performance of these models on both tasks – identification and ex-\ntraction – based on manual annotation of the results;  \n3. we propose an iterative algorithm that leverages LLMs to cluster the extracted pur-\nposes and evaluate the results for various  LLMs ; \n4. in addition to advancing Computational Linguistics, our study contributes to Digital \nHumanities and Computational Social Sciences by proposing  a scalable and acces-\nsible methodology for quantitative research on personal narratives ; \n5. this study contributes to the humanities by examining the diverse motivations behind \ndiary writing. By analyzing gender, age, and temporal factors, we uncover the sig-\nnificance of diary entries as tools for self -expression and cultural documentation.  \n2 Previous Work  \nLLMs are often used to extract structured data from unstructured documents. For in-\nstance, in materials science and chemical research, LLMs are employed to extract \nchemical knowledge, such as formulas or bandgap values  [7, 8]. In agriculture, they are \napplied for pest identification  [9], and in medicine, they are used to extract symptoms \nof pulmonary embolism 10]. Baddour propose using LLMs to search for phenotypes in \nclinical reports related to medical research  [11]. The integration of a novel LLM -based \nspan detector component in their work improves results.  \n \n1 https://prozhito.org    \n--- Page 3 ---\n3 \nIn addition to these applications, LLMs are utilized for diary analysis  [6, 12, 13]. \nDiary analysis involves collecting qualitative information about individuals' daily lives \nand is applied in fields such as psychology, education, and healthcare to study human \nbehavior  [14].  \nHowever, processing such data is challenging, as it requires substantial time and effort. \nModern technologies, including LLMs, can streamline this process by accelerating data \nanalysis and providing deeper insights into diary content.  \nPooley  investigated the reasons why individuals begin and cease diary -keeping  [6]. \nHowever, their study relied on labor -intensive manual analysis rather than leveraging \nLLMs. In contrast, Shin et al. used diary analysis to identify depression, employing the \nGPT -3.5 and GPT -4 models  [12]. Using 428 diaries from 91 participants, the fine -tuned \nGPT -3.5 demonstrated higher performance in detecting depression, achieving an accu-\nracy of 0.902 and an F1 -score of 0.685.  \nLi et al. introduced DiaryHelper, a tool that utilizes generative AI techniques to assist \ndiary writers in capturing event details with minimal effort, thereby reducing bias in the \nnote-taking process  [13]. DiaryHelper predicts five dimensions of information critical \nfor episodic memory – time, place, emotion, people, and activity – for each recorded \nevent. The GPT -3.5 model is used to generate possible labels for these dimensions.  \nA related application of LLMs is in social networking analysis. Alhamed et al. used \nthe LLaMA -2-7B-Chat model to detect evidence of suicidal tendencies in Twitter posts, \nachieving an accuracy of 0.96  [15]. \nThe reviewed studies demonstrate the effectiveness of LLMs in extracting data from \nunstructured documents and analyzing diary entries. However, none of the studies ad-\ndress the extraction of diary purposes. Furthermore, unlike the reviewed works, our \nstudy employs different state -of-the-art LLMs, enabling a comparative evaluation of \ntheir performance in extracting data from unstructured documents.  \n3 Methodology  \nOur methodology includes three steps – purpose extraction by different  models, anno-\ntation and evaluation of the extracted sets, and purpose clustering.  \nStep 1. Purpose Extraction.  We process the entire corpus using multiple models \nwith the same prompt (see  Appendix A ). On each run, 10 text diary entries are fed (no \nmore than 15,000 tokens2), from which models extract potential purposes.  \nStep 2. Annotation and Evaluation of Extracted Sets.  The union of the extracted \nsets was given to the three annotators for labeling. Annotators had to answer the ques-\ntion, “Is the purpose(s) of diary writing present in this diary entry, and if so, did the \nmodel(s) correctly extract that purpose(s)?”3 A binary answer was implied in both ques-\ntions . As a result, a set of diary entries containing purposes was identified, relative to \nwhich performance scores were computed. Also, for such entries, scores of the purposes \nextracted by the models were obtained.  \n \n2 The minimum of the limits of the used models . \n3 Annotators were shown extracted purposes only if they indicated that the entry had a purpose . \n--- Page 4 ---\n4 \nWe used Precision, relative Recall, and relative F1 -score as performance scores. Pre-\ncision, defined as the proportion of correct answers given by the model to the total \nnumber of answers provided by the model, serves as an objective measure in this con-\ntext. Recall, as the proportion of correct answers of a model to the total number of \ncorrect answers in the whole corpus, cannot be properly computed because we are not \nable to label the whole corpus. This limitation arises from the labor -intensive of anno-\ntating. \nTo achieve a more comprehensive evaluation, we compute relative Recall and rela-\ntive F1 -score, following the approach used in studies  [16, 17], for example . In our case, \nwe consider the set of all correct answers to be the set of correct answers labeled by the \nannotators.  \nIn addition to evaluating individual models, we also assess unions  of these models, \nhypothesizing that merging their answers may improve the performance of purpose ex-\ntraction . \nStep 3. Purpose Clustering.  The number of purposes extracted by the models turns \nout to be quite large (hundreds of purposes), so it is necessary to combine them into \ncategories (clusters). We evaluate how well LLMs cope with purpose clustering.  \nIn the simplest case, the model is given all purposes as input and asked to cluster \nthem. However, none of the models was able to successfully cluster the purposes in one \nrun because a large number of purposes did not belong to any cluster.  \nTherefore, we used the following algorithm.  \n1. Clustering Initialization: provide  the model with a complete list of purposes and ask \nit to generate cluster names (see the prompt in the  Appendix B ). \n2. Purpose Assignment: provide  the model  with a current list of purposes (initially in-\ncluding all purposes) along with  the generated cluster names. Ask the model to as-\nsign the purposes to the clusters (see the prompt in the  Appendix C ). Check which \npurposes have been assigned to clusters – exclude them from the list of purposes.  \n3. Repeat step 2 until the list of purposes is empty.  \nTo evaluate the quality of the clustering, we manually partitioned each set of pur-\nposes into clusters and used these partitions as references. As a performance measure, \nwe used the Rand index [18] and averaged it over all sets of purposes.  \n4 Data and Models  \n4.1 Data  \nThe texts of 40,222 personal diaries of 247 authors written in Russian between January \n1, 1922 and December 31, 1929 were used as the corpus. Entries that were too short \n(consisting of 1 –2 words) and too long (exceeding 1,400 tokens for any of the tested \nmodels) were removed from this set. The value of 1,400 was derived from the context \nlimitations of the LLM – the prompt included 10 entries , the lower bound on the context \n--- Page 5 ---\n5 \nlimit was 15,000 tokens (DeepSeek V3 model, provided by DeepInfra4, at the time of \nthe experiments).  This leaves 38,332 diary entries.  \nDistributions of diary entries gender, author age category, and period of entries writ-\ning presented in Table 1–3.  \nThe corpus  is unbalanced by gender.  Experts offer the following explanations for \nthis imbalance: women destroyed their diaries; women kept fewer diaries due to the \nlarge number of daily responsibilities, including those related to childbirth.   \nThe time period of entries writing from 1922 to 1929 is divided into three parts: the \nearly years of the decade (1922 –1923), the middle years (1924 –1926), and the late years \n(1927 –1929).  \nTo determine age categories, we rely on Levinson's stages: pre -adulthood (under 17 \nyears old), early adulthood (ages 18 -39), middle adulthood (ages 40 -59), and late adult-\nhood (60 years old and older) [ 19]. \nTable 1. Distribution of entries by gender.  \nGender  # entries  \nMale  32,371 \nFemale    5,961 \nTable 2. Distribution of entries by author age category . \nAge category  # entries  \nunder 1 7 years old   2,514 \n18-39 14,381 \n40-59 15,323 \nover 6 0 years old   5,287 \nTable 3. Distribution of entries by period of entries writing . \nPeriod of writing  # entries  \nearly 1920s (1922 –1923)   8,302 \nmid 1920s (192 4–1926) 14,021 \nlate 1920s (192 7–1929)  16,009 \n4.2 Models  \nThe following models were considered:  \n• OpenAI GPT -4o (v. 2024 -08-06) – a proprietary chat model;  \n• OpenAI o1 -mini (v. 2024 -09-12) – a proprietary reasoning model;  \n• DeepSeek -V3 – an open -source chat model with MoE architecture, has 671B total \nparameters and 37B active parameters to generate each token [20]. Hereafter, we \nwill refer to DeepSeek -V3 simply as DeepSeek.  \n \n4 https://deepinfra.com   \n--- Page 6 ---\n6 \nFor the OpenAI models their own provider was used, for the other models the Deep-\nInfra provider was used.  \nStatistics of the corpus processing for each model are presented in  Table 4. \nTable 4. Statistics of the corpus processing for each model. Number and average number of to-\nkens are the parameters of the corpus with respect to model tokenizers. The number of entries \nand purposes shows for how many diary entries the model indicated the presence  of purposes \nand how many total purposes the model extracted. The cost includes processing of the entire \ncorpus and clustering of purposes (for OpenAI – using BatchAPI).  \nModel  # tokens  Avg. tokens  # entries  # purposes  Processing cost  \nbaseline5 3,868,282  100.9±114.4  177 177 $0 \nGPT -4o 8,111,474  211.6±226.6  108 172 $9.81  \no1-mini 8,111,474  211.6±226.6  71 118 $16.70  \nDeepSeek  9,183,438  239.6±256.3  290 443 $5.81  \n \nWe also tried to use other models – OpenAI GPT -4o-mini, DeepSeek -R1-Distill -\nLlama -70B, Qwen -2.5-72B-Instruct – but the number of entries in which they found \npurposes was too large (GPT -4o-mini – 2,983, DeepSeek -R1 – 685, Qwen -2.5 – \n13,405) and preliminary analysis showed a large number of incorrectly selected entries, \nso it was decided not to analyze them in more depth.  \nBesides LLMs, we tested a simple template -based model (baseline). We created lists \nof nouns (“diary”, “record”, “purpose”, etc.) and verbs (“keep”, “write”, “help”, etc.) \nindicating the purpose of keeping a diary. An entry was considered to potentially con-\ntain a purpose if any of the possible morphology -aware noun+verb pairs occurred in it.  \nIn this case, the purpose was defined as the sentence in the entry that contained th is \npair. Using the baseline, we identified  177 entries , corresponding to  177 purposes . \n5 Results  \nStep 1. Purpose Extraction. We obtained results from 4 models for 38,332 diary en-\ntries. The number of entries for which the models extracted purposes is shown in  Table  \n5. The union of the four sets includes 460 entries. These entries were given to three \nannotators for labeling.  \nTable 5. Results of the models (first four rows) and the union  of the models (last four rows). \nEntries  is the number of diary entries in which the model identified purposes, Correct entries  is \nthe number of diary entries labeled by annotators as actually containing purposes.  \nModel  # entries  # correc t \nentries  Precision  Rel. \nRecall  Rel. \nF1-score  \nbaseline  177 35 0.1977  0.2059  0.2017  \nGPT -4o 108 83 0.7685 0.4882 0.5971  \no1-mini 71 48 0.6761  0.2824  0.3983  \nDeepSeek  290 140 0.4828  0.8235  0.6087  \n \n5 In baseline, tokens are words.  \n--- Page 7 ---\n7 \nContinuation of Table 5 \nModel  # entries  # correct \nentries  Precision  Rel. \nRecall  Rel. \nF1-score  \nGPT -4o ⋃ o1-mini 153 107 0.6993  0.6294  0.6625  \nGPT -4o ⋃ DeepSeek  306 147 0.4804  0.8647  0.6177  \no1-mini ⋃ DeepSeek  319 156 0.4890  0.9177  0.6380  \nGPT -4o ⋃ o1-mini ⋃ DeepSeek  333 161 0.4834  0.9471  0.6402  \n \nStep 2. Annotation and Evaluation of Extracted Sets.  From 460 diary entries, the \nannotators identified 170 entries by majority voting as actually containing the pur-\npose(s). The performance scores of the individual models, as well as their union6, are \nshown in the  Table 5. The inter -annotator agreement was quite high: Krippendorff's \nalpha=0.895.  \nThe best result for Precision is shown by GPT -4o, o1-mini lags behind by 10 p.p. \nDeepSeek extracts a lot of entries  (290), but only 140 of them are correct, which results \nin low Precision. However, this is compensated by high relative Recall, so relative \nF1-score is even slightly higher than GPT -4o. Among the model union , the best result \nis the union  of GPT -4o and o1 -mini in terms of Precision and relative F1-score. This \nunion  represents the optimal balance of Precision and relative Recall.  \nFor diary entries that annotators labeled as containing purposes (170 entries), the \npurposes extracted by the models were also labeled. The results are shown in Table 6.  \nGPT -4o and o1 -mini show comparable results, with DeepSeek lagging behind by 5 –\n6 pp. \nTable 6. Results of the purpose extraction.  Purposes  refers to the number of purposes extracted \nby the model , considering only those diary entries that annotators labeled as containing a pur-\npose. Mean  is the average number of extracted purposes per entry. Correct purposes  is the \nnumber of purposes labeled by annotators as valid purposes.  \nModel  # purposes  mean  # correct purposes  Precision  \nGPT -4o 141 1.70 126 0.8936  \no1-mini 85 1.77 77 0.9059  \nDeepSeek  221 1.58 187 0.8462  \n \nInter -annotator agreement was much lower: Krippendorff's alpha=0.598. It is be-\ncause model -generated purpose statements are often ambiguous and perceived differ-\nently by annotators.  \nExamples of the purposes are shown in the Appendix D  and typical errors are given \nin the Appendix E . The errors were related to diary entries:  \n• mentioning other people's diaries: error in identifying the author (e.g., “to familiarize \noneself with Korolenko's true experience”);  \n• mentioning other types of entries: error in identifying the type of entry (e.g., “writing \non canvas”, “writing down objections to an article”);  \n \n6 Union  with baseline are not given as they show low performance.  \n--- Page 8 ---\n8 \n• mentioning plans, reasoning or style of keeping a diary, but not the purpose: error in \nidentifying the purpose (e.g. “keep a diary neatly”).  \n \nStep 3. Purpose Clustering.  Each LLM clustered all three sets of extracted purposes \n(separately) according to the proposed algorithm . The number of clusters allocated by \neach model for each set of purposes  is shown in Table 7.  \nTable 7. The number of clusters. The rows correspond to the models that performed clustering \nof the purpose sets, the columns correspond to the models that generated these purpose sets.  \nClustering m odel Purpose  extraction  model  \nGPT -4o \n(141 purposes)  o1-mini \n(85 purposes)  DeepSeek  \n(221 purposes)  \nGPT -4o 13 9 10 \no1-mini 10 10 10 \nDeepSeek  10 9 12 \nmanual  11 9 16 \n \nWe compared the resulting partitions with the manual partitions and calculated the \nRand index ( Table 8). The Rand index quantifies the similarity between data clusterings \nby measuring the proportion of pairs of elements that are either assigned to the same \ncluster or assigned to different clusters.  The best results are again GPT -4o and o1 -mini, \nalthough DeepSeek is not far behind, apart from the case of clustering a large number \nof purposes  (221) extracted by DeepSeek itself. Examples of the clusters are given in \nthe Appendix F . \nTable 8. Results of the clustering. The rows correspond to the models that performed clustering \nof the purpose sets, the columns correspond to the models that generated these purpose sets. \nThe values in the cells are the Rand indices  (↑). \nClustering m odel Purpose extraction model  \nGPT -4o o1-mini DeepSeek  \nGPT -4o 0.8693  0.8333  0.8490  \no1-mini 0.8398  0.8076  0.8537  \nDeepSeek  0.8367  0.8280  0.7956  \n6 Discussion  \nWe analyze GPT -4o clusters based on GPT -4o purposes as the best option for clustering \nthe identified purposes  (see the first row and first column i n Table 8), specifically 13 \nclusters  that contain 126 correctly identified purposes . During  this clustering process, \nthe total number of purposes was reduced to 109, as some purposes allocated within a \nsingle entry  were grouped into the same cluster ; such purposes were not considered in \nfurther analysis . The name of these clusters and examples of purposes for each cluster \nare provided in the Appendix F . \n--- Page 9 ---\n9 \nFig. 1 shows the distribution of purposes among the clusters identified by GPT -4o. \nIn the following diagrams, the order of clusters is preserved as in Fig. 1, specifically by \ntheir frequency of occurrence.  \nThree clusters – “Preservation of Memories,” “Personal History and Memoirs,” and \n“Memory of Other People” – are related to memories. They differ as follows: “Preser-\nvation of Memories” refers to keeping personal memories for oneself. “Personal His-\ntory and Memoirs” involves preserving personal memories for others. “Memory of \nOther People” pertains to preserving memories of other individuals.  Examples of diary \nentries from these clusters are shown in Appendix G. \n \nFig. 1. Distribution of purposes among the clusters identified by GPT -4o. \nWe consider the composition of the clusters by gender, author age category, and \nperiod of entries writing (Fig. 2–4). \nThe original corpus contained 5.4 times more male diary entries than female diary \nentries ( Table 1). The manually annotated part of the corpus (460 entries) consists of \n284 male and 176 female  entries. When examining entries that specified a purpose, the \nratio shifted to 1.6, still favoring male entries . This indicates that women were more \ninclined to articulate the purpose behind their diary -keeping.  \nDue to the imbalance in the original corpus, we consider not the number of male and \nfemale entries, but the proportion of these entries with purposes in each cluster relative \nto the total number of male and female entries  with purposes  in the labeled part of the 0 2 4 6 810 12 14 16 18 20Writing Practice and Skill DevelopmentEmotional ReliefCommunication with OneselfMemory of Other PeopleOvercoming BoredomCultural and Historical Legacy PreservationGoals and AchievementsPersonal History and MemoirsPersonal Growth and Self-ImprovementCreative Self-ExpressionSelf-Analysis and Self-AwarenessDaily Records and RoutinePreservation of Memories\nNumber of purposes\n--- Page 10 ---\n10 \ncorpus. Specifically, out of 109 labeled purposes , there were 67 male and 42 female \nentries. Among the 20 entries  containing purposes, the cluster \" Preservation of  Memo-\nries\" included 14 male and 6 female entries. Thus, the proportion of male entries in this \ncluster was 0. 21 (14 out of 67), while the proportion of female entries was 0. 14 (6 out \nof 42). Similar calculations were performed for all clusters, and the results are shown \nin Fig. 2. \n \nFig. 2. The proportions of male and female entries with purposes in clusters . After the #, the \nchart legend indicates the number of purposes  for each category.  \nThe proportions in Fig. 2 allow  us to hypothesize that the purposes  of “Personal \nHistory and Memoirs ” holds equal significance for both genders. Men tend to focus \nmore on retaining memories , personal growth  and recording daily events, while women \nare more likely to emphasize emotional release , achievement  and s elf-analysis  in their \ndiary entries .  0.00 0.03 0.06 0.09 0.12 0.15 0.18 0.21Writing Practice and Skill DevelopmentEmotional ReliefCommunication with OneselfMemory of Other PeopleOvercoming BoredomCultural and Historical Legacy PreservationGoals and AchievementsPersonal History and MemoirsPersonal Growth and Self-ImprovementCreative Self-ExpressionSelf-Analysis and Self-AwarenessDaily Records and RoutinePreservation of Memories\n      Male\n(67 entries)    Female\n(42 entries)\n--- Page 11 ---\n11 \nThe analysis of purposes by the author's age category is shown in Fig. 3 (we also use \nproportions rather than absolute numbers ). \n \n \nFig. 3. The proportions of age categories in clusters . After the #, the chart legend indicates the \nnumber of purposes  for each category.  \nIt is worth noting that in the diaries of the age category over 6 0, only purposes  about \npreserving memories were identified.  The under -17 age category focuses on entries re-\nlated to self -analysis. Interestingly, the cluster “Goals and achievements”  and “Over-\ncoming Boredom”  is divided among two young age categories (under 1 7 and 1 8-39). \nThe analysis of purposes by the period of writing the entries is shown in Fig. 4. 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35Writing Practice and Skill DevelopmentEmotional ReliefCommunication with OneselfMemory of Other PeopleOvercoming BoredomCultural and Historical Legacy\nPreservationGoals and AchievementsPersonal History and MemoirsPersonal Growth and Self-ImprovementCreative Self-ExpressionSelf-Analysis and Self-AwarenessDaily Records and RoutinePreservation of Memories\n  under 17 years old\n         (27 entries)     18-39\n(56 entries)      40-59\n(18 entries)   over 60 years old\n          (6 entries)\n--- Page 12 ---\n12 \n \nFig. 4. The proportions of periods in clusters . After the #, the chart legend indicates the number \nof purposes  for each category.  \nThe cluster “Preservation of Memories” remains consistently popular across all three \nperiods. Meanwhile, the cluster “Self -Analysis and Self -Awareness” experiences a de-\ncline during the mid -1920s. In contrast, the cluster “Daily Records and Routine” sees \nan increase in frequency during the same timeframe. The “Memory of Other People”  \ndecreases from 11% to 0% over three periods, while the \" Overcoming Boredom \" clus-\nter increases in the later period.  0.00 0.05 0.10 0.15 0.20 0.25Writing Practice and Skill DevelopmentEmotional ReliefCommunication with OneselfMemory of Other PeopleOvercoming BoredomCultural and Historical Legacy\nPreservationGoals and AchievementsPersonal History and MemoirsPersonal Growth and Self-ImprovementCreative Self-ExpressionSelf-Analysis and Self-AwarenessDaily Records and RoutinePreservation of Memories\n  early 1920s (1922-1923)\n               (35 entries)    mid 1920s (1924-1926)\n                (34 entries)   late 1920s (1927-1929)\n              (40 entries)\n--- Page 13 ---\n13 \n7 Conclusion  \nIn this study, we propose a method for extracting and clustering purposes in diary en-\ntries using LLMs. We evaluated three state -of-the-art LLMs alongside a template -based \nbaseline. GPT -4o and o1 -mini demonstrated the best performance, while the baseline \nperformed poorly.  \nOur experimental results suggest the following recommendations. If precision is the \nprimary concern, GPT -4o is the best choice. However, if the purpose  is to retrieve the \nmaximum number of potentially relevant entries at a lower cost, followed by manual \nlabeling, DeepSeek is preferable. A balanced approach is to combine the results of \nGPT -4o and o1 -mini, offering a trade -off between precision and recall.  \nWe also highlight common model errors found in the extraction of purposes from \ndiary entries, such as misidentifying the author by referencing other people's diaries, \nconfusing diary entries with other types of writing, and mentioning plans or styles of \ndiary-keeping without clearly stating the actual purpose.  \nThe use of LLMs allows to save a lot of time while obtaining acceptable quality of \nthe analysis. According to our experts' estimates, the time one person would spend \nreading the entire corpus is on the order of 300 hours (37.5 working days), while LLM \nprocessed in an hour.  \nOur analysis of diary -keeping purposes  provides insights into the motivations behind \npersonal writing across different demographics. We found that both genders appreciate \n“Personal History and Memoirs ”, but men are more focused on memory retention and \npersonal growth, while women place greater emphasis on emotional release and self -\nanalysis.  \nAge also plays a significant role; individuals over 60 primarily write to preserve \nmemories, whereas those under 17 engage more in self -reflection.  \nNotably, the “Preservation of Memories ” cluster remains consistently popular across \nall three examined time periods  (1922 –1923, 1924 –1926, 1927 –1929) . In contrast, \n\"Self -Analysis and Self -Awareness\" experiences a decline in the mid -1920s, while the \nfrequency of \"Daily Records and Routine\" increases during the same timeframe.  \nLimitation  \nIt should be noted that the study encounters certain limitations. The main difficulty lies \nin the ambiguous definition of the concept of “purpose of keeping a diary”. This led to \nthe need to write a more detailed prompt and provide examples. This ambiguity  was \nalso the main reason for the disagreement between the annotators.  \nAnother limitation was the chosen time period for the diary entries – the 1920s. Mis-\nunderstanding of the historical context could lead to hallucination of the models and \nincorrect labeling by the annotators.  \nThe reasons mentioned above, as well as the small number of annotators (three per-\nsons), could lead to bias in the quality assessments of the considered models.  \nAnother issue is that we lack information about the complete set of diary entries in \nour corpus that contain purposes, as labeling the entire corpus is too time -consuming. \n--- Page 14 ---\n14 \nTherefore, we utilize relative Recall (and consequently relative F1 -score) since we only \nconsider the set of entries extracted by all four models . \nEthics Statement  \nThis study was conducted with careful consideration of ethical principles. A diary entry \nmay contain sensitive information that the author may not have intended to share. In \nour work, we relied on the principles of the “Prozhito” diary corpus7. In particular, \ndiaries were not used unless the author or their heirs provided permission for publica-\ntion. The diary entries were also anonymized: neither the models nor the annotators had \ninformation about the author of the diary.  \nThe diary corpus was compiled by both professional publishers and interested vol-\nunteers. The original diary entry could be edited by the author, an editor during publi-\ncation, or a center staff member at the center for annotation. Each participant in the \nprocess could have contributed their own personal beliefs and biases, which could have \ndistorted the research results. Like any other personal text, a diary requires critical in-\nterpretation from the reader – it is essential to understand that the author may have \nvarious motivations for keeping a diary, including the desire to distort or alter the de-\nscription of events.  \nThe authors were in close contact with the “Prozhito” Center for the Study of Ego -\nDocuments of the European University at St. Petersburg, and regular consultations were \nheld.  \nReferences  \n1. Ziems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., Yang, D.: Can large language models \ntransform computational social science? Computational Linguistics 50(1), 237 –291 (2024).  \n2. Cigliano, A., Fallucchi, F., Gerardi, M. and others: The Impact of Digital Analysis and Large \nLanguage Models in Digital Humanity. In ICYRIME 2024: 9th International Conference of \nYearly Reports on Informatics, Mathematics, and Engineering, pp. 1. CEUR Wor kshop Pro-\nceedings.  \n3. Kataishi, R.: The Technological Trajectory of Semantic Analysis: A Historical -Methodo-\nlogical Review of NLP in Social Sciences. Available at SSRN 5022988 (2024).  \n4. Hyers, L. L.: Diary Methods. Oxford University Press, New York, NY (2018).  \n5. Lischetzke, T., Könen, T.: Daily Diary Methodology. Encyclopedia of Quality of Life and \nWell -Being Research, pp. 1563 –1570, Springer International Publishing, Cham (2023).  \n6. Pooley, C. G., Pooley, M. E.: The Value of Diary Writing. Everyday Mobilities in Nine-\nteenth - and Twentieth -Century British Diaries, pp. 21 -53, Springer International Publishing, \nCham (2022).  \n7. Schilling -Wilhelmi, M., Ríos -García, M., Shabih, S., Gil, M. V., Miret, S., Koch, C. T., \nMárquez L. A., Jablonka K. M.: From text to insight: large language models for chemical \ndata extraction. Chem. Soc. Rev. 54, 1125 -1150 (2025).  \n8. Patiny, L., Godin, G.: Automatic extraction of FAIR data from publications using LLM. \nPreprint, ChemRxiv (2023).  \n \n7 https://prozhito.org/page/corpus/   \n--- Page 15 ---\n15 \n9. Peng, R., Liu, K., Yang, P., Yuan, Z., Li, S.: Embedding -based Retrieval with LLM for \nEffective Agriculture Information Extracting from Unstructured Data. Preprint, \narXiv:2308.03107.  \n10. Wiest, I. S., Wolf, F., Le βmann, M -E., van Treeck, M ., Ferber, D . Zhu, J., Boehme, H., \nBressem, K. , Ulrich, H., Ebert, M. P., Kather, J . N.: LLM -AIx: An open source pipeline for \nInformation Extraction from unstructured medical text based on privacy preserving Large \nLanguage Models. medRxiv (2024).  \n11. Baddour, M., Paquelet, S., Rollier, P., De Tayrac, M., Dameron, O., Labbe, T.  : Phenotypes \nExtraction from Text: Analysis and Perspective in the LLM Era. In 2024 IEEE 12th Inter-\nnational Conference on Intelligent Systems (IS), pp. 1 –8. \n12. Shin, D., Kim, H., Lee, S., Cho, Y., Jung, W.: Using Large Language Models to Detect \nDepression From User -Generated Diary Text Data as a Novel Approach in Digital Mental \nHealth Screening: Instrument Validation Study. J Med Internet Res 26, e54617 (2024).  \n13. Li, J., He, C., Hu, J., Jia, B., Halevy, A. Y., Ma, X.: DiaryHelper: Exploring the Use of an \nAutomatic Contextual Information Recording Agent for Elicitation Diary Study. In Proceed-\nings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI ’24, New \nYork, NY, USA. Association for Computing Machinery.  \n14. Pezzato, L. M., Bragança, I. F. de S., Prado G. do V. T.: What can a diary do? A look at the \nacademic literature. Revista Brasileira de Educação, 19 (2024).  \n15.  Alhamed, F., Ive, J., Specia, L.: Using Large Language Models (LLMs) to Extract Evidence \nfrom Pre -Annotated Social Media Data. In Proceedings of the 9th Workshop on Computa-\ntional Linguistics and Clinical Psychology (CLPsych 2024), pp. 232 –237, St. Julians,  Malta. \nAssociation for Computational Linguistics.  \n16. Lagisz, M., Yang, Y., Young, S., Nakagawa, S. : A practical guide to evaluating sensitivity \nof literature search strings for systematic reviews using relative recall.  Research Synthesis \nMethods, 1 –14 (2025).   \n17. Hanneke, R., Brunskill, A. Searching for the social determinants of health: observations \nfrom evidence synthesis publications.  Syst Rev  13, 134 (2024).  \n18. Rand, W. M.: Objective Criteria for the Evaluation of Clustering Methods. Journal of the \nAmerican Statistical Association 66(336), 846 -850 (1971).  \n19. Levinson,  D. J.: A conception of adult development.  Am. Psychol.  41, 3 –13 (1986).  \n20. DeepSeek -AI, Liu A., Feng, B., Xue, B., Wang, B. and others: DeepSeek -V3 Technical Re-\nport. Computing Research Repository, arXiv:2412.19437.  \nAppendix A. Prompt for purpose extraction  \nPrompt for purpose extraction is available at the repository , Appendix A . \nAppendix B. Prompt for generating cluster names  \nPrompt for generating cluster names  is available at the  repository , Appendix B . \nAppendix C. Prompt for purpose clustering  \nPrompt for purpose clustering  is available at the repository , Appendix C . \n--- Page 16 ---\n16 \nAppendix D. Examples of purposes  \nExamples of purposes  is available at the repository , Appendix D . \nAppendix E. Errors in extracting diary -keeping purposes by LLMs  \nErrors in extracting diary -keeping purposes by LLMs  is available at the repository , Ap-\npendix E . \nAppendix F. Examples of clusters  \nExamples of clusters  is available at the repository , Appendix F . \nAppendix G. Examples of diary entries  \nExamples of diary entries  is available at the repository , Appendix G .",
  "text_length": 36572
}