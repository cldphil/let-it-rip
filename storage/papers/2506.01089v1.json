{
  "id": "http://arxiv.org/abs/2506.01089v1",
  "title": "Un-considering Contextual Information: Assessing LLMs' Understanding of\n  Indexical Elements",
  "summary": "Large Language Models (LLMs) have demonstrated impressive performances in\ntasks related to coreference resolution. However, previous studies mostly\nassessed LLM performance on coreference resolution with nouns and third person\npronouns. This study evaluates LLM performance on coreference resolution with\nindexical like I, you, here and tomorrow, which come with unique challenges due\nto their linguistic properties. We present the first study examining how LLMs\ninterpret indexicals in English, releasing the English Indexical Dataset with\n1600 multiple-choice questions. We evaluate pioneering LLMs, including GPT-4o,\nClaude 3.5 Sonnet, Gemini 1.5 Pro, and DeepSeek V3. Our results reveal that\nLLMs exhibit an impressive performance with some indexicals (I), while\nstruggling with others (you, here, tomorrow), and that syntactic cues (e.g.\nquotation) contribute to LLM performance with some indexicals, while they\nreduce performance with others. Code and data are available at:\nhttps://github.com/metehanoguzz/LLMs-Indexicals-English.",
  "authors": [
    "Metehan Oguz",
    "Yavuz Bakman",
    "Duygu Nur Yaldiz"
  ],
  "published": "2025-06-01T17:21:49Z",
  "updated": "2025-06-01T17:21:49Z",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.01089v1",
  "full_text": "--- Page 1 ---\narXiv:2506.01089v1  [cs.CL]  1 Jun 2025Un-considering Contextual Information:\nAssessing LLMs’ Understanding of Indexical Elements\nMetehan O ˘guz Yavuz Bakman Duygu Nur Yaldiz\nUniversity of Southern California\n{moguz, ybakman, yaldiz}@usc.edu\nAbstract\nLarge Language Models (LLMs) have demon-\nstrated impressive performances in tasks re-\nlated to coreference resolution. However, pre-\nvious studies mostly assessed LLM perfor-\nmance on coreference resolution with nouns\nand third person pronouns. This study eval-\nuates LLM performance on coreference res-\nolution with indexicals like I, you, here and\ntomorrow , which come with unique challenges\ndue to their linguistic properties. We present\nthe first study examining how LLMs interpret\nindexicals in English, releasing the English\nIndexical Dataset with 1600 multiple-choice\nquestions. We evaluate pioneering LLMs, in-\ncluding GPT-4o, Claude 3.5 Sonnet, Gemini\n1.5 Pro, and DeepSeek V3. Our results reveal\nthat LLMs exhibit an impressive performance\nwith some indexicals ( I), while struggling with\nothers ( you, here, tomorrow ), and that syntac-\ntic cues (e.g. quotation) contribute to LLM\nperformance with some indexicals, while they\nreduce performance with others. Code and\ndata are available at: https://github.com/\nmetehanoguzz/LLMs-Indexicals-English\n1 Introduction\nLarge Language Models (LLMs) have demon-\nstrated remarkable capabilities in zero-shot and\nfew-shot learning, excelling across a wide array\nof tasks such as machine translation, text summa-\nrization, and question answering (OpenAI, 2024;\nYe et al., 2023; Bakman et al., 2024; Yaldiz et al.,\n2024). Their versatility has led to widespread ap-\nplications in diverse domains, including education,\nlaw, and medicine.\nAs the use of LLMs continues to expand, un-\nderstanding their underlying behaviors has become\nincreasingly important. Recent studies have eval-\nuated the performance of large language models\non linguistic tasks such as coreference resolution\n(Gan et al., 2024; Le and Ritter, 2023; Brown et al.,\n2020; Yang et al., 2022; Agrawal et al., 2022).Previous work on coreference resolution mostly\nfocused on how coreference is established between\ntwo third person entities such as proper names (e.g.\nAndy, the mechanic ) and third person pronouns\n(e.g. he, him, himself ) in English and other lan-\nguages (e.g. Yang et al., 2022; Yang, 2025). In this\nstudy, we investigate how LLMs establish coref-\nerence with indexical elements (e.g. I, you, here ),\nwhich differ from third person nouns/pronouns in\nsubstantial ways and bring unique challenges for\nLLMs (see Figure 1 as an example). We investigate\nhow state-of-the-art LLMs interpret the indexical\nelements I, you, here andtomorrow in English sen-\ntences, and whether context or grammatical con-\nstraints influence their decisions. To the best of our\nknowledge, this is the first study examining LLMs’\nhandling of indexical elements in English. Our key\ncontributions are as follows:\n•We introduce the English Indexical Dataset ,\ncomprising 400 interpretation samples for\neach indexical element, I, you, here, tomor-\nrow, totaling 1,600 instances.\n•We evaluate the performance of four frontier\nLLMs, GPT-4o, Claude 3.5 Sonnet, Gemini\n1.5 Pro, and DeepSeek-V3, on the interpreta-\ntion of indexical elements in English.\n•We show that LLM performances are not uni-\nform across different types of indexical ele-\nments: indexical Iis successfully interpreted\nby most LLMs, other indexicals like you,here\nandtomorrow lead to poor performances.\n•We show that quotation affects LLMs perfor-\nmances differently: quotation reduces LLMs’\naccuracies with tomorrow , but it increases ac-\ncuracies with here.\n2 Indexical elements\nIndexical pronominals like I, you, here andnow are\nused to refer to referents of the speech-act coordi-\nnates (e.g. Kaplan, 1977; Schlenker, 2003). For in-\nstance, Irefers to author (speaker) of the utterance,\n1\n--- Page 2 ---\nFigure 1: An example for LLM misinterpreting indexical element ‘here’, uttered by a speaker in Los Angeles.\nwhile here refers to the location where the utter-\nance was made. Thus, a sentence like (1) means\ndifferent things if uttered by different people and/or\nin different places. If John utters (1-a) inLos An-\ngeles , it means that John was born in Los Angeles,\nbut if Mary utters the same sentence in New York it\nmeans that Mary was born in New York.\n(1) a. Iwas born here.\nb. Andrew said that Iwent to Buckhead.\nIndexicals are interpreted inside the context of utter-\nance, referring to the actual speech-act coordinates\nlike the author or the location of the actual utter-\nance. As a result, if (1-b) is uttered by John , the\nindexical Ican only be interpreted as referring to\nJohn as the speaker, leading to a reading like ‘An-\ndrew said that John went to Buckhead’. Crucially,\neven though Andrew’s speech/claim is reported in\n(1-b), the indexical Icannot refer to Andrew.\nDirect quotation is an exception to this gener-\nalization, where reported material is interpreted\nas verbatim utterance/thoughts of its owner. Thus,\nwhen indexicals appear inside direct quotation, they\nare interpreted inside the reported context, rather\nthan the actual context of utterance. In other words,\ndirect quotation ‘shifts’ the interpretations of index-\nicals into the reported context. For example, Iand\nhere in (2) appear inside direct quotation, where\nAndrew’s speech is reported.\n(2) While we were in Atlanta, Andrew said “ I\nwas born here.”\nRegardless of who utters (2), the sentence means\nthatAndrew was born in Atlanta , so both Iand\nhere are ‘shifted’ into the reported context, where\nAndrew is the speaker and Atlanta is the location1\nIndexicals differ from other pronominals in sub-\nstantial ways. First, though syntactic and semantic\nfactors can affect how a pronoun is interpreted (e.g.\nsubject bias), pronouns are typically ambiguous\nregarding what/who they refer to. For example, the\nthird person pronoun hein (3) is most naturally\ninterpreted as referring to the subject John (for syn-\ntactic or contextual reasons), but the object Billis\n1Some languages (not English) allow indexical elements\nto ‘shift’ without quotation. See Deal (2020) for an overview.still a possible antecedent, causing ambiguity be-\ntween two different readings (e.g. Crawley et al.,\n1990; Stewart and Pickering, 1998; Pickering and\nMajid, 2007). In addition, hecan refer to any con-\ntextually salient person that is not mentioned in the\nsentence (e.g. Peter ), which makes pronouns even\nmore ambiguous and context-dependent.\n(3) John hit Bill and heran away.\nAs a result, semantic/contextual information plays\na crucial role in how pronouns are interpreted, and\nspeakers use those cues to establish coreference\nwith pronouns. For instance, if (4) is uttered in\na context where John is a supportive and humble\ncoworker, the most natural interpretation is that\nJohn suggests that Bill should get promoted ( he\n= Bill). However, if John is arrogant and jealous,\nthe most natural interpretation is that John suggests\nthat John should get promoted ( he= John).\n(4) John told Bill that heshould get promoted.\nIndexicals, on the other hand, unambiguously refer\nto the referents of the speech-act coordinates. For\nexample, Iin (5) refers to the speaker regardless of\nwhat we know about John or Bill. Irefers to the\nspeaker even if John and/or Billare arrogant and\njealous, so contextual information like this should\nbe disregarded while interpreteting indexicals.\n(5) John told Bill that Ishould get a promotion.\nIn summary, indexicals are restricted by different\nsyntactic factors than pronouns (e.g. quotation\nvs non-quotation) and are typically unambiguous,\nwhile pronouns are free to refer to a wide range of\nentities. Thus, indexical elements create a unique\nchallenge for LLMs, requiring to ‘disregard’ se-\nmantic/contextual cues that might prime interpreta-\ntions through other antecedents (unlike pronouns).\n3 Experimental design\n3.1 Dataset Curation\nWe curated a dataset specifically designed to test\nhow LLMs interpret indexical elements like I, you,\nhere, andtomorrow in different contexts of ut-\nterance. Specifically, we assess how these mod-\n2\n--- Page 3 ---\nels interpret indexicals in ‘shifted’ context prime,\nwhere context more naturally requires the indexical\nshould be interpreted inside reported context (e.g.\nPeter is one of the most arrogant students in my\nclassroom. ... Peter says that Iam smart. ) vs ’non-\nshifted’ context prime, where context more natu-\nrally requires the indexical should be interpreted\ninside actual speech context (e.g. Peter is very kind\nand supportive. ... Peter says that Iam smart. ).\nWe also included direct quotations in both con-\ntexts (e.g., Peter says, “I am smart” ) to examine\nif LLMs can successfully consider syntactic fac-\ntors (quotation vs regular sentences) while ignor-\ning misleading information from the context during\ncoreference resolution with indexical elements.\nFor each type of indexical, we design 100 sen-\ntences and for each sentence we apply the four\ndifferent transformations explained above. Overall,\nwe have 400 samples per indexical, compromising\na total dataset of size 1600.\nWe utilize GPT-4o to curate the dataset, by giv-\ning a detailed description of the task along with\nsome in-context examples. Then it is asked to gen-\nerate scenarios with a stimulus sentence in two dif-\nferent contexts (See Appendix A.1 for the prompts\nused), along with specific questions addressing the\nreferent of the indexical in each sentence. To en-\nsure the quality of the dataset, 25% of the dataset\n(400 trials = 100 sentences in four conditions) was\nrandomly selected for evaluation, and the evalua-\ntion process consisted of three steps.\nIn the first step, we confirmed that all sentences\nwere grammatically correct. In the second step,\nwe confirmed that all quotation condition sen-\ntences had quoted embedded clauses, and all non-\nquotation condition sentences had regular (non-\nquoted) embedded clauses. We also made sure that\nthe two sentence conditions were maximally simi-\nlar, except for the quotation vs non-quotation status\n(i.e. the only difference between two sentence con-\nditions was the quotation). In the third step, we\nchecked the context prime texts for each condition\nin each sentence, making sure that the correct read-\nings (shifted vs non-shifted) were primed by the\ncontext description. For example, for an item con-\ndition where here was supposed to be shifted, we\nconfirmed that the context description would be\nmost naturally followed by a sentence where here\nwould be shifted.\n100 trials from each indexical item (25% for\neach indexical), 400 trials in total, were ran-\ndomly selected to make sure that the evalua-tion/confirmation was representative of all indexi-\ncal item conditions (i.e. items with I, you, here and\ntomorrow ).\nTo eliminate potential gender bias, each dataset\nsample exclusively uses either male or female\nnames, alternating to ensure a balanced distribution\nwith 50% of the samples containing female names\nand 50% male names. This method promotes gen-\nder neutrality across the dataset. Sample details\nare in Appendix A.2, and the complete dataset is\navailable in the supplementary materials.\n3.2 Models\nIn our evaluation, we utilize four recent state-of-\nthe-art LLMs: GPT-4o (OpenAI, 2024), Claude 3.5\nSonnet (Anthropic), Gemini 1.5 Pro (Team, 2024),\nand DeepSeek-V3 (DeepSeek-AI, 2024). This se-\nlection of diverse models provides a comprehensive\nevaluation of LLM performance with indexicals.\n3.3 Evaluation Strategy\nTo assess the performance of the model, we specifi-\ncally prompt it to answer questions designed to test\nits capabilities as described in Section 3.1. Addi-\ntionally, to ensure focused responses, we restrict\nthe model’s answers to one of two predefined op-\ntions: the ‘shifted’ option and the ‘non-shifted’\noption. We provide the prompt in Appendix B.1.\n3.4 Metrics.\nWe assess model accuracy across four cases for\neach indexical: (i) Non-quoted sentences with\nshifted context prime, (ii) Non-quoted with non-\nshifted prime, (iii) Quoted with shifted prime, and\n(iv) Quoted with non-shifted prime. Optimal perfor-\nmance would be achieved by always selecting the\n‘shifted’ option in quoted conditions and selecting\nthe ‘non-shifted’ option in non-quoted conditions.\n4 Experimental Results\nWe present the experimental results in Figure 2 and\nwe discuss them in detail for each indexical type:\nIndexical I.The results show that all four models\nperform near optimum in sentences without quo-\ntation with an average accuracy of 99% (always\ncorrectly selecting the non-shifted option). For the\nquoted sentences GPT-4o and Gemini 1.5 pro again\nperform almost optimum with a mean accuracy\nlarger than 94%, followed by Claude 3.5 Sonnet\nwith 89% mean accuracy (correctly selecting the\n3\n--- Page 4 ---\nFigure 2: From left to right: Performance analysis plot of for the indexical ‘I’, Performance analysis plot of for the\nindexical ‘you’, Performance analysis plot of for the indexical ‘here’, Performance analysis plot of for the indexical\n‘tomorrow’. Dark blue bars = Shifted context prime, Light blue bars = Non-shifted context prime.\nshifted option). However, DeepSeek V3 fails to al-\nways select the shifted option on quoted sentences.\nEspecially, the model performance drops signif-\nicantly to 17% when context primes non-shifted\nreadings, suggesting that inclusion of quotation\nmakes the model more sensitive to the linguistically\nirrelevant effects of context prime. Moreover, con-\nsidering that the model performance only reaches\n78% accuracy in quotation conditions seems to im-\nply that the model might have a bias towards the\nnon-shifted reading overall, reducing model perfor-\nmance in quotation conditions.\nIndexical you.The results indicate that LLMs\ngenerally perform worse with the indexical you\nthan with I. We see similar patterns across mod-\nels, suggesting they perform mostly at similar lev-\nels. All models are sensitive to the effects of con-\ntext prime, performing lower when the context\nprimes the incorrect option (i.e. shifted reading\nin non-quotation and non-shifted reading in quota-\ntion). Moreover, quotation consistently results in\nlower performance across models. Notably, Gem-\nini 1.5 Pro excels in non-quotation accuracy (92%),\nthough its performance drops significantly under\nquotation conditions to the levels of other models.\nOverall, the results suggest that models interpret\nyoubased on the linguistically irrelevant context\nprime rather than the sentence type, which indeed\ndetermines the correct readings of the indexicals.\nIndexical here.The results show that LLMs, sim-\nilar to you, struggle to interpret the indexical here,\nespecially when context primes the incorrect op-\ntion, leading to poor performance. However, dif-\nferent from you, quotation leads to higher perfor-\nmance with here. In non-quotation conditions, all\nLLMs make their selections almost exclusively\nbased on context prime, with shifted primes show-\ning over 96% accuracy and non-shifted primes less\nthan 2%, where context prime ideally should nothave any effects on the selection. In contrast, under\nquotation conditions, the influence of context prime\ndiminishes, leading to higher performances. Partic-\nularly, DeepSeek V3 and Gemini 1.5 Pro exhibit\nimpressive performance with accuracies above 97%\nand 94%, respectively, followed by Gemini 1.5 Pro\nand GPT-4o, with accuracies above 64% and 37%.\nIndexical tomorrow .The results indicate that\nLLMs have a strong bias towards the non-shifted\ninterpretations of tomorrow . We see that the mod-\nels almost always select the non-shifted option for\ntrials with tomorrow , regardless of context prime or\nsentence type. While Claude 3.5 Sonnet and Gem-\nini 1.5 Pro selects the non-shifted options 100% of\nthe time, GPT-4o and DeepSeek V3 select the non-\nshifted option 94% and 83% of the time, respec-\ntively. This strong bias leads to illusory high accu-\nracies in non-quotation conditions, while causes ex-\ntremely low performance in quotation conditions.\n5 Related Work\nCoreference resolution has been extensively stud-\nied in prior research (Gan et al., 2024; Le and Rit-\nter, 2023; Brown et al., 2020; Yang et al., 2022;\nAgrawal et al., 2022). However, indexical elements\nexhibit distinct syntactic properties compared to\nother (non-indexical) pronominals, as discussed in\nSection 2. Previous work by O ˘guz et al. (2024)\nexplored how LLMs interpret indexicals in Turk-\nish, where indexicals possess different grammatical\nproperties than in English and can shift without\nquotation. To the best of our knowledge, this study\nis the first to evaluate the performance of LLMs in\ninterpreting indexicals in English.\n6 Discussion and Conclusion\nOur results show that LLM performances are not\nuniform across different types of indexical ele-\nments and sentence types. While most LLMs\n4\n--- Page 5 ---\nperform at impressive levels interpreting the in-\ndexical I, their performances drop significantly in\nother indexicals, particularly in here andtomor-\nrow. Moreover, though sentence type (quotation\nvs non-quotation) affects LLMs performances in\ngeneral, the effects are not similar across different\nindexical types and models. While quotation in-\ncreases LLMs’ performance with here, it decreases\ntheir performance with youandtomorrow . In addi-\ntion, tomorrow seems to be affected by quotation\nin a greater magnitude than you. In conclusion, we\nfind that different types of indexicals show unique\npatterns regarding how they are interpreted by the\nLLMs.\nOur results diverge from those reported in O ˘guz\net al. (2024), who tested how first person indexi-\ncal in Turkish ben‘I’ was interpreted by different\nLLMs, including GPT-4o and show that LLMs ex-\nhibit very poor performance interpreting ben‘I’.\nHere, we report that LLMs perform at an almost\nhuman-like level with interpreting the English in-\ndexical I. This might be due to lower amounts of\navailable resources to train the models in Turkish,\ncompared to English. Another reason for low per-\nformance in Turkish could be due to the fact that\nTurkish is a pro-drop language, meaning that the\nsubject pronouns can be dropped (silent). O ˘guz\net al. (2024) used sentences where the first person\nindexical ben‘I’ was dropped, which might have\nmade the task more challenging for the LLMs con-\nsidering that dropped indexicals can show different\nproperties than overt ones (O ˘guz et al., 2020). This\nlinguistic difference between Turkish and English\nmight have caused different results between the\nTurkish and English tests.\n7 Limitations\nOur work explores how LLMs interpret indexical\nelements in a black-box setting but does not pro-\nvide experimental analyses that investigate the un-\nderlying reasons for these behaviors by examining\nthe models’ internals or training data. Future re-\nsearch could adopt a white-box approach to analyze\nthese behaviors in greater depth, offering valuable\ninsights into the mechanisms driving LLMs’ inter-\npretation of indexicals.\nReferences\nMonica Agrawal, Stefan Hegselmann, Hunter Lang,\nYoon Kim, and David A. Sontag. 2022. Large lan-\nguage models are few-shot clinical information ex-tractors. In Conference on Empirical Methods in\nNatural Language Processing .\nAnthropic. The claude 3 model family: Opus, sonnet,\nhaiku.\nYavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp\nBuyukates, Chenyang Tao, Dimitrios Dimitriadis,\nand Salman Avestimehr. 2024. MARS: Meaning-\naware response scoring for uncertainty estimation in\ngenerative LLMs. In Proceedings of the 62nd Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 7752–7767,\nBangkok, Thailand. Association for Computational\nLinguistics.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler,\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. ArXiv ,\nabs/2005.14165.\nRosalind A. Crawley, Rosemary J. Stevenson, and David\nKleinman. 1990. The use of heuristic strategies in\nthe interpretation of pronouns. Journal of Psycholin-\nguistic Research , 14.\nAmy Rose Deal. 2020. A theory of indexical shift:\nmeaning, grammar, and crosslinguistic variation .\nMIT Press, Boston, MA.\nDeepSeek-AI. 2024. Deepseek-v3 technical report.\nPreprint , arXiv:2412.19437.\nYujian Gan, Massimo Poesio, and Juntao Yu. 2024. As-\nsessing the capabilities of large language models in\ncoreference: An evaluation. In International Confer-\nence on Language Resources and Evaluation .\nDavid Kaplan. 1977. Demonstratives: An essay on the\nsemantics, logic, metaphysics, and epistemology of\ndemonstratives and other indexicals. Themes from\nKaplan , pages 565–614.\nNghia T. Le and Alan Ritter. 2023. Are large language\nmodels robust coreference resolvers?\nMetehan O ˘guz, Yusuf Ciftci, and Yavuz Faruk Bak-\nman. 2024. Do LLMs recognize me, when I is not\nme: Assessment of LLMs understanding of Turkish\nindexical pronouns in indexical shift contexts. In\nProceedings of the First Workshop on Natural Lan-\nguage Processing for Turkic Languages (SIGTURK\n2024) , pages 53–61, Bangkok, Thailand and Online.\nAssociation for Computational Linguistics.\nOpenAI. 2024. Gpt-4 technical report. Preprint ,\narXiv:2303.08774.\n5\n--- Page 6 ---\nMetehan O ˘guz, Burak Öney, and Dennis Ryan\nStoroshenko. 2020. Obligatory indexical shift in\nTurkish. In Proceedings of Canadian Linguistic As-\nsociation (CLA) , Western University, London, ON,\nCanada.\nMartin Pickering and Asifa Majid. 2007. What are\nimplicit causality and consequentiality? Language\n& Cognitive Processes , 22.\nPhilippe Schlenker. 2003. A plea for monsters. Linguis-\ntics and Philosophy , 26:29–120.\nAndrew J. Stewart and Martin Pickering. 1998. Implicit\nconsequentiality. In Proceedings of the 20th Annual\nConference of the Cognitive Science Society .\nGemini Team. 2024. Gemini 1.5: Unlocking multi-\nmodal understanding across millions of tokens of\ncontext. Preprint , arXiv:2403.05530.\nDuygu Nur Yaldiz, Yavuz Faruk Bakman, Baturalp\nBuyukates, Chenyang Tao, Anil Ramakrishna, Dim-\nitrios Dimitriadis, Jieyu Zhao, and Salman Aves-\ntimehr. 2024. Do not design, learn: A trainable scor-\ning function for uncertainty estimation in generative\nllms. Preprint , arXiv:2406.11278.\nXiaohan Yang, Eduardo Peynetti, Vasco Meerman, and\nChristy Tanner. 2022. What gpt knows about who is\nwho. In First Workshop on Insights from Negative\nResults in NLP .\nXiulin Yang. 2025. Language models at the syntax-\nsemantics interface: A case study of the long-distance\nbinding of Chinese reflexive ziji. In Proceedings of\nthe 31st International Conference on Computational\nLinguistics , pages 3808–3824, Abu Dhabi, UAE. As-\nsociation for Computational Linguistics.\nJunjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai\nShao, Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao\nGong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui,\nQi Zhang, and Xuanjing Huang. 2023. A comprehen-\nsive capability analysis of GPT-3 and GPT-3.5 series\nmodels. Preprint , arXiv:2303.10420.A Dataset Details\nA.1 Dataset Generation Prompts\nWe provide the prompts used for data generation in\nTables 1, 2, 3, and 4. The prompts used for question\ngeneration per scenario is presented in Tables 5, 6,\n7, and 8.\nA.2 Samples From the Dataset\nWe provide samples from the dataset for each in-\ndexical element we investigate in Tables 9, 10, 11,\nand 12.\nB Experimental Details\nB.1 Prompt Used in Evaluation\nThe prompt we employ for the evaluation is as\nfollows:\nRead the following passage carefully\nand answer the question at the end:\n{stimuli}\n{question}\nPlease provide your answer as: either\n{option1} or {option2}. Do not include\nany additional explanation or text.\n6\n--- Page 7 ---\nI would like you to help me create a stimulus for my project. The stimuli will be English sentences. For\neach sentence, there will be two types of context description. One context description will prime the\nactual meaning of the sentence, but the other description will prime an incorrect reading of the sentence\n(like a misinterpretation). I want you to follow a structure while creating sentences and contexts. You can\nfind more details below:\nDetails for stimulus sentences: Each stimulus sentence will have a structure like \"While John was speaking\nto Travis, he said that Chris appreciates you a lot.\" Please make sure to use the names John, Travis, and\nChris. Make sure that Chris is the subject of the embedded clause, and make sure that the sentence begins\nas “While John was speaking to Travis. . . ” Please use different embedded verbs. For example, rather than\nappreciates you a lot, you can use saw you at the market, etc. But the action should be done by Chris, and\nthe object should be \"you\".\nDetails about the context descriptions: The contexts will prime how \"you\" in the stimulus is interpreted.\nTo manipulate this, I will give contexts in which \"you\" would refer to my addressee, which is you. But,\nto prime the incorrect interpretation, I will give contexts that would naturally follow if \"you\" referred to\nJohn’s addressee. However, since “you” means the current addressee, this will be a misinterpretation. For\nexample, a correct reading prime would be like \"Hi! I am Andrew. I will call you Donald. I am a graduate\nstudent and I live in Los Angeles. I have two friends named John and Chris. Chris asked for help from\nyou a few times in the past, and you always helped him.\" This context makes it sound like Chris would\nappreciate you for all your help, and thus it would not be surprising if Chris appreciated you (Donald).\nHowever, in the incorrect interpretation prime, I will use a context like \"Hi! I am Andrew. I will call you\nDonald. I am a graduate student and I live in Los Angeles. I have two friends named John and Chris.\nChris asked for help from Travis a few times in the past, and Travis always helped him.\" In this context, it\nwould be more natural if Chris appreciated Travis, who helped him, instead of you (Donald), and thus\nwould be natural if \"you\" in the sentence was interpreted as referring to Travis (though “you” should\nrefer to my addressee, which is you (Donald)). This would create the incorrect misinterpretation. Please\nmake sure to keep the person names constant. Also, make sure that the context starts exactly as “Hi! I am\nAndrew. I will call you Donald. I am a graduate student and I live in Los Angeles.”\nThese are some examples you generated before: {previous_generations}. Use these examples as inspira-\ntion to spark creativity. Provide one new stimulus sentence, along with a corresponding correct prime\ncontext and an incorrect prime context, in the following format:\nstimulus_sentence: stimulus stimulus sentence\ncorrect_context: correct prime context sentence\nwrong_context: incorrect prime context sentence\nTable 1: Prompt used to generate dataset samples for indexical ‘you’.\n7\n--- Page 8 ---\nI would like you to help me create a stimulus for my project. The stimuli will be English sentences. For\neach sentence, there will be two types of context description. One context description will prime the\nactual meaning of the sentence, but the other description will prime an incorrect reading of the sentence\n(like a misinterpretation). I want you to follow a structure while creating sentences and contexts. You can\nfind more details below:\nDetails for stimulus sentences: Each stimulus sentence will have a structure like \"When we spoke last\nsummer, John said that Chris was going to go to Greece tomorrow.\" Please make sure to use the names\nJohn, and Chris. Make sure that Chris is the subject of the embedded clause. Please use different embedded\nverbs. For instance, rather than go to Greece, you can use have a visa appointment, etc. But the action\nshould be done \"tomorrow\".\nDetails about the context descriptions: The contexts will prime how \"tomorrow\" in the stimulus is\ninterpreted. To manipulate this, I will give contexts in which \"tomorrow\" would refer to the day after the\nactual (matrix) sentence is uttered. But, to prime the incorrect interpretation, I will give contexts that\nwould naturally follow if \"tomorrow\" referred to the day after John spoke. However, since “tomorrow”\nmeans the day after the current day, this will be a misinterpretation. For example, a correct reading prime\nwould be like \"Hi! I am Andrew. I am a graduate student and I live in Los Angeles. I have two friends\nnamed John and Chris. Chris is very careful about planning everything, and always plans his stuff ahead\nof time.\" This context makes it sound like Chris would plan his trip to Greece ahead of time, and thus it\nwould not be surprising if John said last summer that Chris was going to have a trip tomorrow. However,\nin the incorrect interpretation prime, I will use a context like \"Hi! I am Andrew. I am a graduate student\nand I live in Los Angeles. I have two friends named John and Chris. Chris is very lazy and never plans his\nstuff until the last moment.\" In this context, it would be more natural if Chris was going to go to Greece\nlast summer, the day after John spoke to me, instead of the day after today, and thus would be natural if\n\"tomorrow\" in the sentence was interpreted as the day after John spoke to me (though “tomorrow” should\nrefer to the day after today). This would create the incorrect misinterpretation. Please make sure to keep\nthe person names constant. Also, make sure that the context starts exactly as “Hi! I am Andrew. I am a\ngraduate student and I live in Los Angeles.”\nThese are some examples you generated before: {previous_generations}. Use these examples as inspira-\ntion to spark creativity. Provide one new stimulus sentence, along with a corresponding correct prime\ncontext and an incorrect prime context, in the following format:\nstimulus_sentence: stimulus stimulus sentence\ncorrect_context: correct prime context sentence\nwrong_context: incorrect prime context sentence\nTable 2: Prompt used to generate dataset samples for indexical ‘tomorrow’.\n8\n--- Page 9 ---\nI would like you to help me create a stimulus for my project. The stimuli will be English sentences. For\neach sentence, there will be two types of context description. One context description will prime the\nactual meaning of the sentence, but the other description will prime an incorrect reading of the sentence\n(like a misinterpretation). I want you to follow a structure while creating sentences and contexts. You can\nfind more details below:\nDetails for stimulus sentences: Each stimulus sentence will have a structure like \"Chris thinks that I will\nwin the race.\" Please make sure to use the name Chris as the matrix subject, and “I” as the embedded\nsubject subject. Please use different embedded verbs. For example, rather than win the race, you can use\nstudy hard, etc. But the action should be done by \"I\".\nDetails about the context descriptions: The contexts will prime who \"I\" in the stimulus refers to. To\nmanipulate this, I will give contexts in which \"I\" would refer to the speaker. But, to prime the incorrect\ninterpretation, I will give contexts that would naturally follow if \"I\" referred to Chris. However, since\nChris is not the speaker, this will lead to an incorrect interpretation.\nFor example, a correct reading prime would be like \"Hi! I am Andrew. I am a graduate student and I live\nin Los Angeles. I have a friend named Chris. Chris is a supportive friend, and has always trusted in my\nabilities. There is a race next week.\" This context makes it sound like Chris would support the speaker in\na race, and predict that the speaker would win the race. However, in the incorrect interpretation prime,\nI will use a context like \"Hi! I am Andrew. I am a graduate student and I live in Los Angeles. I have a\nfriend named Chris. Chris is usually very competitive, and has bullied other people in front of me. There\nis a race next week..\" In this context, it would be more natural if Chris thought that he would win the\nrace, instead of the speaker Andrew, and thus would be natural if \"I\" in the sentence referred to Chris\n(though “I” should refer to the speaker Andrew). This would create the incorrect misinterpretation. Please\nmake sure to keep the person names constant. Also, make sure that the context starts exactly as “Hi! I am\nAndrew. I am a graduate student and I live in Los Angeles.\"\nThese are some examples you generated before: {previous_generations}. Use these examples as inspira-\ntion to spark creativity. Provide one new stimulus sentence, along with a corresponding correct prime\ncontext and an incorrect prime context, in the following format:\nstimulus_sentence: stimulus stimulus sentence\ncorrect_context: correct prime context sentence\nwrong_context: incorrect prime context sentence\nTable 3: Prompt used to generate dataset samples for indexical ‘I’.\n9\n--- Page 10 ---\nI would like you to help me create a stimulus for my project. The stimuli will be English sentences. For\neach sentence, there will be two types of context description. One context description will prime the\nactual meaning of the sentence, but the other description will prime an incorrect reading of the sentence\n(like a misinterpretation). I want you to follow a structure while creating sentences and contexts. You can\nfind more details below:\nDetails for stimulus sentences: Each stimulus sentence will have a structure like \"When I was in New\nYork with John, he said that Chris wanted to explore here.\" Please make sure to use the city name New\nYork for the sentence, and the names John and Chris. John will always be the person who says something\nthat Chris will do. In each sentence, Chris will be the person who is doing something \"here\". Please use\ndifferent verbs. For example, rather than explore here, you can use attend a conference here, etc.. Use\nvarious verbs. But the action should be done \"here\".\nDetails about the context descriptions: The contexts will prime where \"here\" in the stimulus refers to. To\nmanipulate this, I will give contexts in which \"here\" would refer to Los Angeles, where the author/speaker\nof the sentence is located. But, to prime the incorrect interpretation, I will give contexts that would\nnaturally follow if \"here\" referred to New York. However, since the speaker is not in New York, this will\nlead to an incorrect interpretation.\nFor example, a correct reading prime would be like \"Hi! I am Andrew. I am a graduate student and I\nam studying in a cafe in Los Angeles. I have two friends named John and Chris. They love exploring\nnew cities, and surprisingly they did not spend much time in Los Angeles.\" This context makes it sound\nlike John and Chris would like to come to Los Angeles to explore around, and thus the \"explore around\nhere\" in the stimulus sentence would be naturally understood as Los Angeles. However, in the incorrect\ninterpretation prime, I will use a context like \"Hi! I am Andrew. I am a graduate student and I am studying\nin a cafe in Los Angeles. I have two friends named John and Chris. They love exploring new cities, and\nsurprisingly they did not spend much time in New York.\" In this context, it would be more natural if John\nand Chris would like to go to New York, and thus would be natural if \"explore around here\" would be\nexploring around New York (though here should refer to the place where the speaker Andrew is, which is\nLos Angeles). This would create the incorrect misinterpretation. Please make sure to keep the person\nnames and city names constant.\nAlso, make sure that the context starts exactly as “Hi! I am Andrew. I am a graduate student and I am\nstudying in a cafe in Los Angeles.”.\nThese are some examples you generated before: {previous_generations}. Use these examples as inspira-\ntion to spark creativity. Provide one new stimulus sentence, along with a corresponding correct prime\ncontext and an incorrect prime context, in the following format:\nstimulus_sentence: stimulus stimulus sentence\ncorrect_context: correct prime context sentence\nwrong_context: incorrect prime context sentence\nTable 4: Prompt used to generate dataset samples for indexical ‘here’.\n10\n--- Page 11 ---\nI would like you to help me create questions to the sentences I will give you for my project. The question\nwill be English sentences. The goal is to create a question that will prime the correct interpretation of the\nindexical in the sentence.\nHere are examples:\nSentences:\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have a friend named Chris. Chris\nknows how dedicated I am to my studies and always encourages me to do my best. The final exams are\ncoming up next week. Chris thinks that I will get good grades on the final exams.\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have a friend named Chris. Chris\nusually outperforms everyone in our classes and often brags about it. The final exams are coming up next\nweek. Chris thinks that I will get good grades on the final exams.\nQuestion: According to the last sencence, who will get good grades on the final exams?\nSentences:\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have a friend named Chris. Chris\nbelieves in my ability to communicate effectively and often praises my public speaking skills. There is an\nimportant conference coming up soon. Chris thinks that I will give a great presentation at the conference.\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have a friend named Chris. Chris is\nknown for his exceptional presentation skills and often receives awards for them. There is an important\nconference coming up soon. Chris thinks that I will give a great presentation at the conference.\nQuestion: According to the last sencence, who will give a great presentation at the conference?\nNow, for the following sentences, you should create a question whose answer can only be either Chris\nor Andrew. The question should be designed to prime the correct interpretation of the indexical in the\nsentence. Provide only the question and always start with \"According to the last sentence, who\"\nSentences:\n{sentences}\nQuestion:\nTable 5: Prompt used to generate question for samples containing indexical ‘I’.\n11\n--- Page 12 ---\nI would like you to help me create questions to the sentences I will give you for my project. The question\nwill be English sentences. The goal is to create a question that will prime the correct interpretation of the\nindexical in the sentence.\nHere are examples:\nSentences:\nHi! I am Andrew. I will call you Donald. I am a graduate student and I live in Los Angeles. I have two\nfriends named John and Chris. You and Chris attended the same conference last month, and you even had\na conversation there. While John was speaking to Travis, he said that Chris saw you at the conference.\nHi! I am Andrew. I will call you Donald. I am a graduate student and I live in Los Angeles. I have two\nfriends named John and Chris. Travis and Chris attended the same conference last month, and they even\nhad a conversation there. While John was speaking to Travis, he said that Chris saw you at the conference.\nQuestion: According to the last sentence, who did John say that Chris saw at the conference?\nSentences:\nHi! I am Andrew. I will call you Donald. I am a graduate student and I live in Los Angeles. I have two\nfriends named John and Chris. You and Chris are both art enthusiasts and attended the same art gallery\nevent last weekend, where you ran into each other. While John was speaking to Travis, he said that Chris\nnoticed you at the art gallery.\nHi! I am Andrew. I will call you Donald. I am a graduate student and I live in Los Angeles. I have two\nfriends named John and Chris. Travis and Chris are both art enthusiasts and attended the same art gallery\nevent last weekend, where they ran into each other. While John was speaking to Travis, he said that Chris\nnoticed you at the art gallery.\nQuestion: According to the last sentence, who did John say that Chris noticed at the art gallery?\nNow, for the following sentences, you should create a question whose answer can only be either Travis\nor Donald. The question should be designed to prime the correct interpretation of the indexical in the\nsentence. Provide only the question and always start with \"According to the last sentence, who did John\nsay that Chris\"\nSentences:\n{sentences}\nQuestion:\nTable 6: Prompt used to generate question for samples containing indexical ‘you’.\n12\n--- Page 13 ---\nI would like you to help me create questions to the sentences I will give you for my project. The question\nwill be English sentences. The goal is to create a question that will prime the correct interpretation of the\nindexical in the sentence.\nHere are examples:\nSentences:\nHi! I am Andrew. I am a graduate student and I am studying in a cafe in Los Angeles. I have two friends\nnamed John and Chris. They are both academics who love to participate in international conferences.\nRecently, I’ve been telling them about the exciting academic events happening right here in Los Angeles.\nWhen I was in New York with John, he said that Chris wanted to attend a conference here.\nHi! I am Andrew. I am a graduate student and I am studying in a cafe in Los Angeles. I have two friends\nnamed John and Chris. They are both academics who love to participate in international conferences.\nRecently, they realized they haven’t attended many conferences in New York, which is quite surprising\ngiven their love for the city. When I was in New York with John, he said that Chris wanted to attend a\nconference here.\nQuestion: According to the last sentence, where does Chris want to attend a conference?\nSentences:\nHi! I am Andrew. I am a graduate student and I am studying in a cafe in Los Angeles. I have two friends\nnamed John and Chris. They both have a deep appreciation for art, and recently I’ve been telling them\nabout the vibrant art scene here in Los Angeles that offers great opportunities for new gallery openings.\nWhen I was in New York with John, he said that Chris wanted to open an art gallery here.\nHi! I am Andrew. I am a graduate student and I am studying in a cafe in Los Angeles. I have two friends\nnamed John and Chris. They both have a deep appreciation for art, and recently they realized they haven’t\nopened a gallery in New York yet, despite its renowned art scene, which is surprising given their passion.\nWhen I was in New York with John, he said that Chris wanted to open an art gallery here.\nQuestion: According to the last sentence, where does Chris want to open an art gallery?\nNow, for the following sentences, you should create a question whose answer can only be either Los\nAngeles or New York. The question should be designed to prime the correct interpretation of the indexical\nin the sentence. Provide only the question and always start with \"According to the last sentence, where\ndoes Chris want to\".\nSentences:\n{sentences}\nQuestion:\nTable 7: Prompt used to generate question for samples containing indexical ‘here’.\n13\n--- Page 14 ---\nI would like you to help me create questions to the sentences I will give you for my project. The question\nwill be English sentences. The goal is to create a question that will prime the correct interpretation of the\nindexical in the sentence.\nHere are examples:\nSentences:\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have two friends named John and\nChris. Chris is meticulous about arranging all his necessary documentation well in advance and likes\nhaving everything sorted before deadlines approach. When we spoke last summer, John mentioned that\nChris would be having his visa appointment tomorrow.\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have two friends named John and\nChris. Chris is quite disorganized and often waits until the last possible moment to schedule important\ntasks such as visa appointments. When we spoke last summer, John mentioned that Chris would be having\nhis visa appointment tomorrow.\nQuestion: According to the last sentence, did Chris already have his visa appointment, or is he going to\ndo so in the future?\nSentences:\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have two friends named John and\nChris. Chris is very disciplined and likes to plan his activities ahead of time. When we spoke last summer,\nJohn told me that Chris was planning go to the bungee jumping event tomorrow.\nHi! I am Andrew. I am a graduate student and I live in Los Angeles. I have two friends named John and\nChris. Chris likes trying different activities but he is very bad at planning and he usually plans his stuff\nat the very last moment. When we spoke last summer, John told me that Chris was planning go to the\nbungee jumping event tomorrow.\nQuestion: According to the last sentence, did Chris already go to the bungee jumping event, or is he going\nto do so in the future?\nNow, for the following sentences, you should create a question in the given format. The question should\nbe designed to prime the correct interpretation of the indexical in the sentence. Provide only the question\nand always structure the sentence as \"According to the last sentence, did Chris already ... or is he going to\ndo so in the future?\".\nSentences:\n{sentences}\nQuestion:\nTable 8: Prompt used to generate question for samples containing indexical ‘tomorrow’.\n14\n--- Page 15 ---\nContext+Stimuli and QuestionShifted\nOptionNon-shifted\nOptionGround\nTruth\nHi! I am Stephen. I am a graduate student and I live\nin Los Angeles. I have a friend named Adam. Adam\nknows how dedicated I am to my studies and always\nencourages me to do my best. The final exams are\ncoming up next week. Adam thinks that I will get\ngood grades on the final exams.\nQuestion: According to the last sentence, who will\nget good grades on the final exams?Adam Stephen Non-shifted\nHi! I am Stephen. I am a graduate student and I\nlive in Los Angeles. I have a friend named Adam.\nAdam usually outperforms everyone in our classes\nand often brags about it. The final exams are coming\nup next week. Adam says that I will get good grades\non the final exams.\nQuestion: According to the last sentence, who will\nget good grades on the final exams?Adam Stephen Non-shifted\nHi! I am Stephen. I am a graduate student and I live\nin Los Angeles. I have a friend named Adam. Adam\nknows how dedicated I am to my studies and always\nencourages me to do my best. The final exams are\ncoming up next week. Adam says \"I will get good\ngrades on the final exams\".\nQuestion: According to the last sentence, who will\nget good grades on the final exams?Adam Stephen Shifted\nHi! I am Stephen. I am a graduate student and I\nlive in Los Angeles. I have a friend named Adam.\nAdam usually outperforms everyone in our classes\nand often brags about it. The final exams are coming\nup next week. Adam says \"I will get good grades on\nthe final exams\".\nQuestion: According to the last sentence, who will\nget good grades on the final exams?Adam Stephen Shifted\nTable 9: Dataset Samples for Indexical \"I\"\n15\n--- Page 16 ---\nContext+Stimuli and QuestionShifted\nOptionNon-shifted\nOptionGround\nTruth\nHi! I am Jerry. I will call you Ryan. I am a grad-\nuate student and I live in Los Angeles. I have two\nfriends named Dylan and Gregory. You and Gregory\nattended the same conference last month, and you\neven had a conversation there. While Dylan was\nspeaking to Samuel, he said that Gregory saw you at\nthe conference.\nQuestion: According to the last sentence, who did\nDylan say that Gregory saw at the conference?Ryan Samuel Non-shifted\nHi! I am Jerry. I will call you Ryan. I am a graduate\nstudent and I live in Los Angeles. I have two friends\nnamed Dylan and Gregory. Samuel and Gregory\nattended the same conference last month, and they\neven had a conversation there. While Dylan was\nspeaking to Samuel, he said that Gregory saw you at\nthe conference.\nQuestion: According to the last sentence, who did\nDylan say that Gregory saw at the conference?Ryan Samuel Non-shifted\nHi! I am Jerry. I will call you Ryan. I am a grad-\nuate student and I live in Los Angeles. I have two\nfriends named Dylan and Gregory. You and Gregory\nattended the same conference last month, and you\neven had a conversation there. While Dylan was\nspeaking to Samuel, he said \"Gregory saw you at the\nconference\".\nQuestion: According to the last sentence, who did\nDylan say that Gregory saw at the conference?Ryan Samuel Shifted\nHi! I am Jerry. I will call you Ryan. I am a graduate\nstudent and I live in Los Angeles. I have two friends\nnamed Dylan and Gregory. Samuel and Gregory\nattended the same conference last month, and they\neven had a conversation there. While Dylan was\nspeaking to Samuel, he said \"Gregory saw you at the\nconference\".\nQuestion: According to the last sentence, who did\nDylan say that Gregory saw at the conference?Ryan Samuel Shifted\nTable 10: Dataset Samples for Indexical \"You\"\n16\n--- Page 17 ---\nContext+Stimuli and QuestionShifted\nOptionNon-shifted\nOptionGround\nTruth\nHi! I am Lisa. I am a graduate student and I am study-\ning in a cafe in Denver. I have two friends named\nDeborah and Jennifer. They are both academics who\nlove to participate in international conferences. Re-\ncently, I’ve been telling them about the exciting aca-\ndemic events happening right here in Denver. When\nI was in Milwaukee with Deborah, she said that Jen-\nnifer wanted to attend a conference here.\nQuestion: According to the last sentence, where\ndoes Jennifer want to attend a conference?Milwaukee Denver Non-shifted\nHi! I am Lisa. I am a graduate student and I am study-\ning in a cafe in Denver. I have two friends named Deb-\norah and Jennifer. They are both academics who love\nto participate in international conferences. Recently,\nthey realized they haven’t attended many conferences\nin Milwaukee, which is quite surprising given their\nlove for the city. When I was in Milwaukee with\nDeborah, she said that Jennifer wanted to attend a\nconference here.\nQuestion: According to the last sentence, where\ndoes Jennifer want to attend a conference?Milwaukee Denver Non-shifted\nHi! I am Lisa. I am a graduate student and I am study-\ning in a cafe in Denver. I have two friends named\nDeborah and Jennifer. They are both academics who\nlove to participate in international conferences. Re-\ncently, I’ve been telling them about the exciting aca-\ndemic events happening right here in Denver. When\nI was in Milwaukee with Deborah, she said \"Jennifer\nwants to attend a conference here\".\nQuestion: According to the last sentence, where\ndoes Jennifer want to attend a conference?Milwaukee Denver Shifted\nHi! I am Lisa. I am a graduate student and I am study-\ning in a cafe in Denver. I have two friends named Deb-\norah and Jennifer. They are both academics who love\nto participate in international conferences. Recently,\nthey realized they haven’t attended many conferences\nin Milwaukee, which is quite surprising given their\nlove for the city. When I was in Milwaukee with Deb-\norah, she said \"Jennifer wants to attend a conference\nhere\".\nQuestion: According to the last sentence, where\ndoes Jennifer want to attend a conference?Milwaukee Denver Shifted\nTable 11: Dataset Samples for Indexical \"Here\"\n17\n--- Page 18 ---\nContext+Stimuli and QuestionShifted\nOptionNon-shifted\nOptionGround\nTruth\nHi! I am Albert. I am a graduate student and I live\nin Los Angeles. I have two friends named Donald\nand Carl. Carl is meticulous about arranging all his\nnecessary documentation well in advance and likes\nhaving everything sorted before deadlines approach.\nWhen we spoke last summer, Donald mentioned that\nCarl would be having his visa appointment tomorrow.\nQuestion: According to the last sentence, did Carl\nalready have his visa appointment, or is he going to\ndo so in the future?will do it in the future did it in the past Non-shifted\nHi! I am Albert. I am a graduate student and I live\nin Los Angeles. I have two friends named Donald\nand Carl. Carl is quite disorganized and often waits\nuntil the last possible moment to schedule important\ntasks such as visa appointments. When we spoke\nlast summer, Donald mentioned that Carl would be\nhaving his visa appointment tomorrow.\nQuestion: According to the last sentence, did Carl\nalready have his visa appointment, or is he going to\ndo so in the future?will do it in the future did it in the past Non-shifted\nHi! I am Albert. I am a graduate student and I live\nin Los Angeles. I have two friends named Donald\nand Carl. Carl is meticulous about arranging all his\nnecessary documentation well in advance and likes\nhaving everything sorted before deadlines approach.\nWhen we spoke last summer, Donald said \"Carl will\nbe having his visa appointment tomorrow\".\nQuestion: According to the last sentence, did Carl\nalready have his visa appointment, or is he going to\ndo so in the future?will do it in the future did it in the past Shifted\nHi! I am Albert. I am a graduate student and I live\nin Los Angeles. I have two friends named Donald\nand Carl. Carl is quite disorganized and often waits\nuntil the last possible moment to schedule important\ntasks such as visa appointments. When we spoke last\nsummer, Donald said \"Carl will be having his visa\nappointment tomorrow\".\nQuestion: According to the last sentence, did Carl\nalready have his visa appointment, or is he going to\ndo so in the future?will do it in the future did it in the past Shifted\nTable 12: Dataset Samples for Indexical \"Tomorrow\"\n18",
  "text_length": 53643
}