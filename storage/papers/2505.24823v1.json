{
  "id": "http://arxiv.org/abs/2505.24823v1",
  "title": "PhySense: Principle-Based Physics Reasoning Benchmarking for Large\n  Language Models",
  "summary": "Large language models (LLMs) have rapidly advanced and are increasingly\ncapable of tackling complex scientific problems, including those in physics.\nDespite this progress, current LLMs often fail to emulate the concise,\nprinciple-based reasoning characteristic of human experts, instead generating\nlengthy and opaque solutions. This discrepancy highlights a crucial gap in\ntheir ability to apply core physical principles for efficient and interpretable\nproblem solving. To systematically investigate this limitation, we introduce\nPhySense, a novel principle-based physics reasoning benchmark designed to be\neasily solvable by experts using guiding principles, yet deceptively difficult\nfor LLMs without principle-first reasoning. Our evaluation across multiple\nstate-of-the-art LLMs and prompt types reveals a consistent failure to align\nwith expert-like reasoning paths, providing insights for developing AI systems\nwith efficient, robust and interpretable principle-based scientific reasoning.",
  "authors": [
    "Yinggan Xu",
    "Yue Liu",
    "Zhiqiang Gao",
    "Changnan Peng",
    "Di Luo"
  ],
  "published": "2025-05-30T17:25:20Z",
  "updated": "2025-05-30T17:25:20Z",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2505.24823v1"
}