{
  "id": "http://arxiv.org/abs/2505.24808v1",
  "title": "RealDrive: Retrieval-Augmented Driving with Diffusion Models",
  "summary": "Learning-based planners generate natural human-like driving behaviors by\nlearning to reason about nuanced interactions from data, overcoming the rigid\nbehaviors that arise from rule-based planners. Nonetheless, data-driven\napproaches often struggle with rare, safety-critical scenarios and offer\nlimited controllability over the generated trajectories. To address these\nchallenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG)\nframework that initializes a diffusion-based planning policy by retrieving the\nmost relevant expert demonstrations from the training dataset. By interpolating\nbetween current observations and retrieved examples through a denoising\nprocess, our approach enables fine-grained control and safe behavior across\ndiverse scenarios, leveraging the strong prior provided by the retrieved\nscenario. Another key insight we produce is that a task-relevant retrieval\nmodel trained with planning-based objectives results in superior planning\nperformance in our framework compared to a task-agnostic retriever.\nExperimental results demonstrate improved generalization to long-tail events\nand enhanced trajectory diversity compared to standard learning-based planners\n-- we observe a 40% reduction in collision rate on the Waymo Open Motion\ndataset with RAG.",
  "authors": [
    "Wenhao Ding",
    "Sushant Veer",
    "Yuxiao Chen",
    "Yulong Cao",
    "Chaowei Xiao",
    "Marco Pavone"
  ],
  "published": "2025-05-30T17:15:03Z",
  "updated": "2025-05-30T17:15:03Z",
  "categories": [
    "cs.RO",
    "cs.AI"
  ],
  "pdf_url": "http://arxiv.org/pdf/2505.24808v1"
}