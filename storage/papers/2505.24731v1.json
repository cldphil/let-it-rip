{
  "id": "http://arxiv.org/abs/2505.24731v1",
  "title": "Circuit Stability Characterizes Language Model Generalization",
  "summary": "Extensively evaluating the capabilities of (large) language models is\ndifficult. Rapid development of state-of-the-art models induce benchmark\nsaturation, while creating more challenging datasets is labor-intensive.\nInspired by the recent developments in mechanistic interpretability, we\nintroduce circuit stability as a new way to assess model performance. Circuit\nstability refers to a model's ability to apply a consistent reasoning\nprocess-its circuit-across various inputs. We mathematically formalize circuit\nstability and circuit equivalence. Then, through three case studies, we\nempirically show that circuit stability and the lack thereof can characterize\nand predict different aspects of generalization. Our proposed methods offer a\nstep towards rigorously relating the generality of models to their\ninterpretability.",
  "authors": [
    "Alan Sun"
  ],
  "published": "2025-05-30T15:53:56Z",
  "updated": "2025-05-30T15:53:56Z",
  "categories": [
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2505.24731v1",
  "full_text": "arXiv:2505.24731v1 [cs.CL] 30 May 2025Circuit Stability Characterizes Language Model Generalization Alan Sun Carnegie Mellon University alansun@andrew.cmu.edu Abstract Extensively evaluating the capabilities of (large) language models is difficult. Rapid de- velopment of state-of-the-art models induce benchmark saturation, while creating more challenging datasets is labor-intensive. Inspired by the recent developments in mechanistic in- terpretability, we introduce circuit stability as a new way to assess model performance. Cir- cuit stability refers to a model’s ability to ap- ply a consistent reasoning process—its circuit— across various inputs. We mathematically for- malize circuit stability and circuit equivalence. Then, through three case studies, we empiri- cally show that circuit stability and the lack thereof can characterize and predict different aspects of generalization. Our proposed meth- ods offer a step towards rigorously relating the generality of models to their interpretability1. 1 Introduction Though there exists a wealth of theoretical tech- niques to analyze and predict generalization, em- pirically benchmarking a given language model’s capabilities remains difficult. This gap between theory and practice stems, in part, from the rapid saturation of existing benchmarks and also the labor-intensive process of creating new, more chal- lenging datasets (Srivastava et al., 2023; Jimenez et al., 2024; Glazer et al., 2024). One way to sidestep these issues is to evaluate a specific ca- pability shared among many tasks. For example, needle-in-the-haystack evaluates language models’ ability to perform long-context recall (Kamradt, 2023), while SKILL -MIX measures skill composi- tion performance (Arora and Goyal, 2023; Yu et al., 2024). Although such datasets can be automatically generated and scaled in difficulty, a fundamental challenge remains: identifying specific capabilities that are meaningful to benchmark in the first place. 1The codebase for our experiments can be found at https: //github.com/alansun17904/circuit-stabilityEven after identifying a capability-of-interest, cre- ating salient tasks that precisely target this capabil- ity is nontrivial. In this paper, we seek to address some of these issues by introducing the concept of circuit stabil- ity. Informally, for a fixed task and model, circuit stability is the consistency of a model’s reason- ing process (its circuit) across collections of sub- tasks. Consider solving an algorithmic problem like parity. We expect a strong model to learn and correctly apply a consistent algorithm regardless of the length of its input. If, however, the model learns a different algorithm for each input length, its finite capacity will guarantee a length past which the model will fail. At the core of our approach are three key in- sights. First, orthogonal to previous approaches that evaluate a model’s performance on small, fi- nite sets of examples by testing inputs one-by-one, we extract and analyze the model’s circuit using techniques from mechanistic interpretability (Olah et al., 2020). Since the extracted circuit can be reused and applied by the model to an infinite class of examples, its stability could be a more robust estimator of performance. This is analogous to the formal verification of an algorithm where we do not need to verify every input-output pair (Cousot and Cousot, 1977). Additionally, instead of speci- fying individual, potentially contentious skills-of- interest, our approach makes a simplifying assump- tion that a learned skill/circuit is useful only if it is consistently applied by the model. Finally, unlike mechanistic interpretability approaches that seek to intractably extract hard circuits, which are discrete subsets of the model’s computational graph, we in- troduce a continuous relaxation: soft circuits. This preserves rich structural insights while enabling more easy computation. Concretely, our contributions are four-fold: • We formally define circuit stability (Section 3). •Through two case studies on arithmetic reason- 1 ing and Boolean expression evaluation, we show that circuit stability can predict length, structural, and compositional generalization (Section 4 and Section 5, respectively). •We show that circuit stability also predicts gen- eralization even on tasks that are not naturally algorithmic like sports understanding (Suzgun et al., 2023). •We demonstrate that circuit stability can be in- duced through prompting methods like chain-of- thought (Section 6). In this paper, we focus our analyses of circuit stabil- ity on language models based on the Transformer architecture (Vaswani et al., 2017). Nevertheless, the formal framework we introduce is modality- and architecture-independent. We discuss this fur- ther in Appendix A. 2 Background Herein, we briefly review the circuits framework and relevant concepts in mechanistic interpretabil- ity, as they lay the foundation for our contribution. Circuits. The goal of the circuits framework is to interpret the decision processes of a neural net- work. This is typically done through two processes: first, identify a minimal subset of the model’s com- putational graph that is responsible for a specific behavior; second, assign human-interpretable ex- planations to each of the extracted components. The former is referred to as circuit discovery while the latter is called mechanistic interpretability. We represent a Transformer’s computational graph using the framework introduced by (Elhage et al., 2021; Conmy et al., 2023). Specifically, we view each MLP layer as single node and, unless otherwise specified, we also split each attention head into four distinct nodes: key, query, value, and output. A directed edge is drawn from nodes 𝑛𝑖→𝑛𝑗if the output of 𝑛𝑖is directly used as an input to𝑛𝑗. A circuit is defined as a computational subgraph. Finding Subcircuits. Let𝐺𝑀=(𝑉𝑀,𝐸𝑀)be the computational graph for a model 𝑀. For a fixed task and model performance metric 𝐿, cir- cuit discovery methods search for a minimal com- putational subgraph: 𝑔𝑀=(𝑣𝑀,𝑒𝑀), where 𝑣𝑀⊂𝑉𝑀,𝑒𝑀⊂𝐸𝑀. Informally, after ablating the edges and nodes not in 𝑔𝑀,𝑔𝑀must maintain model performance within a specified margin of 𝜀 >0(Wang et al., 2022; Shi et al., 2024). Alterna- tively, one can also view this process as searchingfor a binary function, 𝑐:𝐸𝑀→{0,1}, subject to the aforementioned constraints. We refer to 𝑐as a hard circuit because any given edge in the compu- tational graph takes on a binary state. Searching for𝑐is known to be an intractable combinatorial optimization problem (Adolfi et al., 2025). As a result, many approximations to circuit discov- ery have been derived (Nanda, 2023; Hanna et al., 2024; Bhaskar et al., 2024). Even then, it has been shown that the discovered circuit may be highly sensitive to𝐿and𝜀, the performance metric and threshold, respectively (Conmy et al., 2023; Miller et al., 2024). In this paper, we partially circumvent these issues by redefining a circuit as a mapping 𝑐:𝐸𝑀→R. For each𝑒∈𝐸𝑀,𝑐(𝑒)represents the change in𝐿after ablating 𝑒from𝐸𝑀, essentially capturing the importance of 𝑒. In this way, we yield asoft circuit. We formalize this in Section 3. 3 Circuit Stability and Equivalence In this section, we formally define circuit stability. First, we define the notion of a task (Definition 1). Then, tasks are equipped with variable substruc- ture through subtasks (Definition 2). Building on these subtasks, we define the three key concepts of this paper: soft circuitry (Definition 3), 𝜀-circuit stability (Definition 4) and 𝛼-circuit equivalence (Definition 5). Let𝒳,𝒴be the space of all finite input and out- put strings (Du et al., 2023; Cotterell et al., 2023). The exact construction of these spaces are unim- portant. We only require a distribution over 𝒳×𝒴 which we call a task. Definition 1 (Task).Atask is a distribution over 𝒳×𝒴 denoted by𝒟𝒳×𝒴. This is also called the data distribution. A task may itself contain rich substructure. For even a simple task such as two-operand addition2, we can, naturally decompose this into many dis- tinct collections of subtasks by simply partitioning the input-output space. One way is to separate ad- dition problems that require carrying at least one digit versus ones that do not. On the other hand, we could also create another collection of subtasks by varying the number of digits in each operand. Intuitively, an appropriate partitioning of the input- output space should yield a collection of subtasks 2In this case, the marginal of 𝒟𝒳×𝒴 over𝒳assigns posi- tive measure to a subset 𝑋⊂𝒳 only if all𝑥∈𝑋follows the form“a + b = ” where𝑎,𝑏∈Z≥0. And, the conditional distribution of𝒟𝒳×𝒴 on𝒴given“a + b = ” is a point mass on the string 𝑎+𝑏. 2 that make clear the necessary capabilities a model must have to solve the task itself. For example, suc- cess over the aforementioned partitions could indi- cate both compositional and length generalization, respectively (Wiedemer et al., 2023). Without the loss of generality, we assume that all cells of any subsequently discussed partition have positive mea- sure under𝒟𝒳×𝒴. In this way, each cell contains meaningful examples and skills that a model must master in order to achieve perfect performance. By way of its cells, a given partition also elicits its own set of tasks. We call these conditional distributions subtasks. Definition 2 (Subtask).For a task,𝒟𝒳×𝒴 and partition𝒮of𝒳×𝒴. A subtask, over a cell 𝑠∈𝒮, is the conditional distribution 𝒟𝒳×𝒴|𝑠. For brevity, we notate this as𝒟𝑠. Through𝒟𝒳×𝒴, we can also measure the impor- tance of any subtask by leveraging the marginal distribution over𝒮. We call this distribution the partition distribution and notate it as P𝒮. We now precisely define a model’s soft circuit relative to a task (or subtask). Our approach differs from the traditional notion of a circuit defined in mechanistic interpretability. Rather than assign a binary indicator to the edges of the computational graph,𝐸𝑀→{ 0,1}, we perform a continuous relaxation. A comparative analysis of this setting, along with its implications, are provided in Sec- tion 8. Definition 3 (Soft Circuit).Consider a task𝒟𝒳×𝒴, a model𝑀:𝒳→𝒴 with computational graph 𝐺𝑀=(𝑉𝑀,𝐸𝑀), and some performance metric 𝐿:𝒴×𝒴→ R. With respect to𝒟𝒳×𝒴,𝑀’ssoft circuit is a function 𝑐:𝐸𝑀→Rsuch that for any 𝑒∈𝐸𝑀, 𝑐(𝑒)BE (𝑥,𝑦)∼𝒟𝒳×𝒴[𝐿(𝑀{𝑒}(𝑥),𝑦)−𝐿(𝑀(𝑥),𝑦)],(1) where𝑀{𝑒}denotes𝑀after ablating edge 𝑒. As long as𝐿is well-defined, 𝑐always exists. We defer the technical details of 𝐿and the ablation procedure to Appendix B. By our previous con- structions, a subtask (Definition 2) may also induce a soft circuit. So for any subtask 𝒟𝑠, we denote its induced soft circuit as 𝑐𝑠. Intuitively,𝑐(𝑒)captures the singular importance of𝑒. By examining and comparing the collective mapping,𝑐, across subtasks, we gain insight into holistic model behavior. Therefore, we take 𝐾: R𝐸𝑀×R𝐸𝑀→Rto be a measure of the similaritybetween two soft circuits: a kernel-like function3. We are now ready to define circuit stability. Definition 4 (𝜀-Circuit Stable).For𝜀 >0, a model, 𝑀, isε-circuit stable with respect to a task 𝒟𝒳×𝒴 and a collection of partitions Pif inf 𝒮∈PE𝑠,𝑠′∼𝒮[𝐾(𝑐𝑠,𝑐𝑠′)]> 𝜀, (2) where𝑠,𝑠′are two subtasks sampled i.i.d. from the partition distribution P𝒮. In Equation 2, the expression inside the infimum measures the stability of a model’s soft circuit as we move between different subtasks. This stability is weighted by the partition distribution. Thus, if two subtasks have a low probability of occurring with respect to𝒟𝒳×𝒴, we consider the skills required to solve them unimportant. In turn, instability across these subtasks is also disregarded. This allows us to avoid specifying a priori which skills are important for analysis. For all our experiments, we take 𝐾to be Spear- man’s𝜌. Concretely, we take soft circuits 𝑐𝑠,𝑐𝑠′ and individually induce a ranking of 𝐸𝑀through 𝑐𝑠(𝐸𝑀),𝑐𝑠′(𝐸𝑀). Then, we measure the correla- tion coefficient between these ranks. Throughout, we construct collections of partitions Pmanually, based on the task at hand. In Section 6 and 8, we discuss constructing partitions statistically. Next, using𝐾we also define a type of pointwise- equivalence between the soft circuits of any two subtasks. Definition 5 (𝛼-Equivalent).For𝛼 > 0, soft cir- cuits𝑐𝑠,𝑐𝑠′are𝛼-equivalent if𝐾(𝑐𝑠,𝑐′ 𝑠)≥𝛼. 4 Case Study: Arithmetic Reasoning In this section, we explore the circuit stability and equivalence of gemma-2-2b4over the task of two operand addition (Rivière et al., 2024). These prob- lems come in the form of “a + b = ”, where 𝑎,𝑏∈Z≥0. We examine a specific partition where each subtask contains problems where the values of 𝑎all have the same number of digits, and similarly for𝑏. This setup allows us to study two different 3𝐾should be thought of as a reproducing kernel Hilbert space kernel over the function space R𝐸𝑀. However, for sim- plicity, our experiments do not adhere to this guiding principle. Instead we use a more interpretable similarity metric such as rank correlation. A deeper investigation into the theoretical properties of 𝐾and its implications for circuit stability is left for future work 42 billion parameter model containing over 79k circuit edges as defined in Section 2. 3 forms of generalization that have been separately analyzed in the literature: length generalization, where the number of digits in 𝑎,𝑏increase inde- pendently (Cho et al., 2025), and compositional generalization which tests whether models solve addition problems recursively (Kudo et al., 2023; Nikankin et al., 2025). We find that gemma-2-2b ’s circuit instability across subtasks correlates with fluctuations in its performance on those same sub- tasks, indicating a potential causal link between circuit instability and generalization failures. 4.1 Experimental Setup We denote a subtask as an ordered pair (𝑜1,𝑜2) where 1≤𝑜1,𝑜2≤8.𝑜1,𝑜2denote the number of digits in𝑎,𝑏respectively. Over all experimental settings, we provide the model with 𝑘=3few-shot examples. To implement circuit discovery (Defini- tion 3), we choose 𝐿to be the next-token patching metric, defined in Equation 8. Each edge is ablated through noisy-to-clean patching using both noisy and clean samples from the same subtask. These de- sign choices are well-documented in Heimersheim and Nanda (2024) and we explore their implica- tions in Appendix B. We perform circuit discovery over each subtask, resulting in 64 soft circuits for analysis. 4.2 Identifying Arithmetic Circuit Families To analyze the relationships between subtasks, we compute Spearman’s 𝜌,𝐾, between their soft cir- cuits. Using 𝛼=0.6, we apply the notion of 𝛼- equivalence, as defined in Definition 5, to cluster the arithmetic subtasks into roughly five distinct clusters: equal-digit ( 𝑜1=𝑜2), one-digit difference (𝑜1=𝑜2±1), leading-operand heavy ( 𝑜1>𝑜2), single-digit ( 𝑜2=1), and trailing-operand heavy (𝑜2>𝑜1). These subtask clusters are visualized in Figure 1 (top). To confirm that these clusters are not merely an artifact of a particular setting of 𝛼, we perform two complementary experiments. First, we directly compute a set of 𝑡-SNE embeddings using all the soft circuits (Maaten and Hinton, 2008). Notably, these embeddings are independent of 𝛼. The rela- tive distances between the embedded circuits are visualized in Figure 1 (bot). We find that the circuit clusters we identified before form well-separated groups under this representation as well. Next, since we take 𝐾to be Spearman’s 𝜌,𝛼is naturally bounded between [−1,1]. Consequently, we expect the number of distinct subtask clusters to 1,1 1,2 5,4 5,6 2,1 2,3 6,5 6,7 3,2 3,4 7,6 7,8 4,3 4,5 8,7 1,3 1,4 1,5 1,6 1,7 1,8 5,5 2,2 6,6 3,3 7,7 4,4 8,8 2,4 5,8 2,5 2,6 2,7 2,8 3,6 3,7 3,8 4,7 4,8 3,1 4,1 5,1 5,2 5,3 6,1 6,2 6,3 6,4 7,1 7,2 7,3 7,4 7,5 8,1 8,2 8,3 8,4 8,5 8,6 3,5 4,2 4,6 5,7 6,8 Equal-digit Single-digit Trailing-operand heavy One-digit difference Leading-operand heavy Figure 1: (top) Each node represents a distinct subtask. An undirected path exists between two nodes if and only if they are 𝛼-equivalence for 𝛼=0.6.(bot)𝑡-SNE embeddings of the soft circuits for each subtask with perplexity=3. The node shape and color combinations are consistent with the circuit clusters in (top). increase monotonically as 𝛼also increases mono- tonically. This behavior is shown in Figure 2. As 𝛼 approaches its upper bound of 1, the number of sub- task clusters converges to the total number of sub- tasks. This indicates that no two subtasks have iden- tical circuits. On the other hand, for 𝛼=0.4, only one subtask cluster exists. This suggests the pres- ence of a common set of circuit components that are important for arithmetic generally. In other words, no two distinct subtasks reply on entirely disjoint sets of components. This observation aligns with the previous findings of Stolfo et al. (2023); Hanna et al. (2023); Nikankin et al. (2025) that the numer- ical abilities of language models are mediated by a common set of attention heads and MLPs. Surprisingly, there exists a critical threshold 𝛼=0.6where the number of circuit families ex- plodes (see the red region in Figure 2). We visu- alize the circuit families in this critical region in Figure 3. As 𝛼increases from 0.5 to 0.53, a clear separation immediately forms between the trailing- operand and leading-operand heavy subtasks. This could indicate fundamental differences in how the model is handling inputs from these two subtasks. As𝛼continues to increase, we observe the emer- 4 0.0 0.2 0.4 0.6 0.8 1.0 Correlation Threshold0102030405060Number of Componentsgemma-2 (2b) Two-Operand Addition Number of Components vs. Rank Correlation ThresholdFigure 2: The number of 𝛼-circuit equivalence families as𝛼varies between[0,1]. We omit visualization of 𝛼 < 0since the number of circuit families is a monotonic function of 𝛼. The red region shows that 80% of circuit families emerge between 𝛼=0.58 and𝛼=0.79 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 2,1 2,2 2,3 2,4 2,5 2,6 2,7 2,8 3,1 3,2 3,3 3,4 3,5 3,6 3,7 3,8 4,1 4,2 4,3 4,4 4,5 4,6 4,7 4,8 5,1 5,2 5,3 5,4 5,5 5,6 5,7 5,8 6,1 6,2 6,3 6,4 6,5 6,6 6,7 6,8 7,1 7,2 7,3 7,4 7,5 7,6 7,7 7,8 8,1 8,2 8,3 8,4 8,5 8,6 8,7 8,8 1,1 1,2 2,1 2,2 2,3 3,1 3,2 3,3 3,4 4,1 4,2 4,3 4,4 4,5 5,1 5,2 5,3 5,4 5,5 5,6 6,1 6,2 6,3 6,4 6,5 6,6 6,7 7,1 7,2 7,3 7,4 7,5 7,6 7,7 7,8 8,1 8,2 8,3 8,4 8,5 8,6 8,7 8,8 1,3 1,4 1,5 1,6 1,7 1,8 2,4 2,5 2,6 2,7 2,8 3,5 3,6 3,7 3,8 4,6 4,7 4,8 5,7 5,8 6,8 1,1 1,2 2,1 2,2 2,3 3,2 3,3 3,4 4,3 4,4 4,5 5,4 5,5 5,6 6,5 6,6 6,7 7,6 7,7 7,8 8,7 8,8 1,3 1,4 1,5 1,6 1,7 1,8 2,5 2,6 2,7 2,8 3,5 3,6 3,7 3,8 4,6 4,7 4,8 5,7 5,8 6,8 2,4 3,1 4,1 4,2 5,1 5,2 5,3 6,1 6,2 6,3 6,4 7,1 7,2 7,3 7,4 7,5 8,1 8,2 8,3 8,4 8,5 8,6 1,1 1,2 5,4 5,6 2,1 2,3 6,5 6,7 3,2 3,4 7,6 7,8 4,3 4,5 8,7 1,3 1,4 1,5 1,6 1,7 1,8 5,8 2,5 2,6 2,7 2,8 3,6 3,7 3,8 4,7 4,8 5,5 2,2 6,6 3,3 7,7 4,4 8,8 2,4 3,1 4,1 4,2 5,1 5,2 5,3 6,1 6,2 6,3 6,4 7,1 7,2 7,3 7,4 7,5 8,1 8,2 8,3 8,4 8,5 8,6 3,5 4,6 5,7 6,8 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 2,1 5,5 2,2 6,6 3,3 7,7 4,4 8,8 5,4 5,6 2,3 6,5 6,7 3,2 3,4 7,6 7,8 4,3 4,5 8,7 2,4 5,8 2,5 2,6 2,7 2,8 3,7 3,8 4,7 4,8 3,1 3,5 3,6 5,1 6,1 7,1 4,1 8,1 4,2 4,6 5,2 6,2 6,3 7,2 7,3 7,4 8,2 8,3 8,4 8,5 5,3 6,4 7,5 8,6 5,7 6,8 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 2,1 5,5 2,2 6,6 3,3 7,7 4,4 8,8 5,6 2,3 6,7 3,4 7,8 4,5 2,4 2,5 2,6 2,7 2,8 3,7 3,8 4,8 3,1 5,4 6,5 3,2 7,6 4,3 8,7 3,5 3,6 5,1 6,1 7,1 4,1 8,1 4,2 4,6 4,7 5,8 5,2 6,2 6,3 7,2 7,3 7,4 8,2 8,3 8,4 8,5 5,3 5,7 6,4 7,5 8,6 6,8 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 2,1 5,5 2,2 6,6 3,3 7,7 4,4 8,8 5,4 5,6 2,3 6,5 6,7 3,2 3,4 7,6 7,8 4,3 4,5 8,7 2,4 5,8 2,5 2,6 2,7 2,8 3,7 3,8 4,7 4,8 3,1 3,5 3,6 5,1 6,1 7,1 4,1 8,1 4,2 4,6 5,2 6,2 6,3 7,2 7,3 7,4 8,2 8,3 8,4 8,5 5,3 6,4 7,5 8,6 5,7 6,8 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 2,1 2,2 2,3 2,4 2,5 2,6 2,7 2,8 3,1 3,2 5,5 6,6 3,3 7,7 4,4 8,8 3,4 3,5 3,6 3,7 3,8 4,1 4,2 5,4 6,5 7,6 4,3 8,7 4,5 4,6 4,7 4,8 5,1 5,2 5,3 5,6 5,7 5,8 6,1 6,2 6,3 6,4 6,7 7,8 6,8 7,1 7,2 7,3 7,4 7,5 8,1 8,2 8,3 8,4 8,5 8,6 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 2,1 2,2 2,3 2,4 2,5 2,6 2,7 2,8 3,1 3,2 3,3 3,4 3,5 3,6 3,7 3,8 4,1 4,2 4,3 4,4 4,5 4,6 4,7 4,8 5,1 5,2 5,3 5,4 5,5 5,6 5,7 5,8 6,1 6,2 6,3 6,4 6,5 6,6 7,7 8,8 6,7 6,8 7,1 7,2 7,3 7,4 7,5 7,6 7,8 8,1 8,2 8,3 8,4 8,5 8,6 8,7 Figure 3: The emergent families of 𝛼-equivalent sub- tasks as𝛼varies between[0,1]. gence and persistence of distinct families corre- sponding to equal-digit, single-digit, and one-digit difference subtasks. The stability of these families over increasing 𝛼suggests strong internal cohesion, further validating our proposed clustering depicted in Figure 1 (bot). 4.3 Circuit Stability and Generalization The family of 𝛼-equivalences (Definition 5) iden- tified in the previous subsection deviate from our expected clustering of a well-performing model (Section 3). In particular, a model that truly un- derstands two-operand addition should necessarily recognize that addition is both commutative and associative. In this section, we argue that lack of 𝛼-equivalence across these aforementioned circuit families indicates that the model neither adheres to nor fully internalizes these properties of addition. First, an understanding and application of com- mutativity implies that any subtask (𝑜1,𝑜2)shouldbe equivalent both in performance and circuitry to the subtask(𝑜2,𝑜1). This is because a model that learns this axiom could accordingly transpose the two operands before adding, thereby achieving consistent performance across this collections of subtasks. However, as discussed previously, a lack of𝛼-equivalence between leading and trailing-digit heavy families suggest that gemma-2-2b does not respect commutativity. As a result, we expect a significant performance gap as we move between these subtask families. Indeed we observe this to be the case. We benchmark gemma-2-2b across all 64 subtasks. Per task, 𝑛=1000 problems are sampled independently while maintaining the same formatting scheme as before (see Section 4.1). Per- formance is measured through exact string match accuracy (Srivastava et al., 2023). We find that gemma-2-2b ’s performance positively skews to- wards leading-digit heavy subtasks (see Figure 4). In some cases, the performance difference between (𝑜1,𝑜2)and(𝑜2,𝑜1)can be more than 20%. Next, the associativity of addition implies that any two-operand addition problem can be decom- posed into a sequence of (1,1)problems. More generally, a subtask like (8,2)could also be broken down into a sequence of (8,1)and(1,1)problems. Likewise,(6,7)can be decomposed into (6,6)and (1,1). If the model is leveraging associativity, we would expect its errors to also compound in a pre- dictable manner due to the repeated reuse of sim- pler subtasks. But, we observe through the previous subsection, that even adjacent subtasks like (8,1) vs.(8,2)or(6,6)vs.(6,7)belong to different 𝛼- equivalent clusters. This suggests that gemma-2-2b is not exploiting associativity to systemically reuse its circuit components across subtasks. This be- havior is verified quantitatively in Figure 4, where model performance steeply drops off across sub- tasks(6,6),(6,7), etc. Lastly, we hypothesize that within an 𝛼- equivalent cluster, gemma-2-2b isreusing its circuit components. This behavior has been previously identified in other tasks (Merullo et al., 2023). We find that hard circuits within the same 𝛼-equivalent cluster share a large number of components or, in some cases, even function as subcircuits of one an- other (see an example in Figure 5). Here, we greed- ily construct5hard circuits by assigning the top 200 components—as given by the soft circuitry— 5Though this is a naive decoding method, empirically it works quite well as an approximation for the actual cir- cuit (Conmy et al., 2023; Hanna et al., 2024). 5 1 2 3 4 5 6 7 8 Opr2 Digits1 2 3 4 5 6 7 8Opr1 Digits0.95 0.90 0.80 0.81 0.82 0.84 0.75 0.71 0.95 0.94 0.85 0.69 0.58 0.47 0.43 0.29 0.93 0.86 0.88 0.80 0.63 0.41 0.35 0.33 0.93 0.81 0.79 0.85 0.69 0.47 0.20 0.28 0.90 0.79 0.73 0.69 0.75 0.44 0.24 0.07 0.85 0.70 0.63 0.58 0.60 0.67 0.22 0.07 0.78 0.62 0.49 0.34 0.28 0.28 0.48 0.07 0.69 0.43 0.34 0.31 0.08 0.03 0.06 0.22gemma-2 (2b) 0.20.40.60.8 Figure 4: Performance of gemma-2-2b over arithmetic subtasks as Opr1B𝑜1andOpr2B𝑜2increase. Each cell denotes the exact string match accuracy. one (in circuit) and the remaining zero (out of cir- cuit). In contrast to the sharp performance change across non-equivalent subtasks, we find that within 𝛼-equivalent subtasks model performance decays smoothly. This degradation in performance can be characterized using tight-fitting regressions that depend on the number of subtask compositions and their associated error rates. We provide a detailed analysis of this in Appendix C. By combining our insights derived from circuit stability analysis with the benchmark results in Fig- ure 4, we can affirm that the measured performance differences between subtasks are not merely an artifact of statistical noise. Circuit stability and the lack thereof also point to tangible ways that we can improve the model. For example, during training, circuit stability could possibly be improved through causal align- ment (Geiger et al., 2024; Gupta et al., 2024). Al- ternatively, stability could also be induced at infer- ence via prompting. By explicitly breaking down a complex problem into simpler ones, we could encourage component/subtask reuse. We explore this latter possibility in Section 6 through chain-of- thought prompting. 5 Case Study: Boolean Expressions We now extend our analysis of circuit stability to a different task that also exhibits rich subtask struc- ture: Boolean expression evaluation (Suzgun et al., 2023). Previously, we argued that circuit stability implies both length and compositional generaliza- tion. Here, we refine this perspective by showing that circuit non-equivalence or instability can also provide meaingful insights. Specifically, devia- tions in stability may indicate structural general- shared subcircuitry! distinct subcircuitry! (a) (b)(c)Figure 5: Circuits for (a)(8,8)(b)(7,7)and(c)(2,7). (a)and(b)share many subcircuit components and are 𝛼-equivalent for 𝛼=0.6. On the other hand, (c) is not 𝛼-circuit equivalent with either (a) or (b). ization (Ye et al., 2021; He et al., 2024). In other words, circuit stability is not simply a matter of “more is better;” rather, its desirability depends on how well it aligns with our prior knowledge of the task. 5.1 Experimental Setup We usephi-1.56due to its strong performance on logical and mathematical reasoning (Li et al., 2023). We follow the same evaluation setup as Srivastava et al. (2023) for Boolean expression evaluation and prompt the model with 𝑘=3few-shot examples. We construct partitions based on three independent variables: (1) expression length (number of words, e.g.,True and False has length 3); (2) parentheti- cal depth (number of maximum nested parentheses, e.g.,(not (True)) has depth 2); and (3) the set of logical operators used ( not, and, or ). Expres- sion length ranges from 1 to 9, and depth from 0 to 6. Circuit discovery details are largely the same as Section 4.1 and can be found in Appendix B and D. 5.2 Circuit Instability and Generalization Not Subtask. Consider a Boolean expression that contains only the literals True,False, and the op- eratornot. Sincenotis associative, adding and removing an arbitrary number of parentheses to any expression of this form should not change its ground-truth label. Thus, we expect a model that understands this axiom to apply the same circuit whether or not there are parentheticals in the ex- pression. To test if this holds for phi-1.5, we first benchmark its circuit stability separately for sets of expressions with and without parentheses. 6A 1.5 billion parameter model with 128k circuit compo- nents. 6 Not Not+And Not+And+Or Subtask0.00.10.20.30.40.50.6Rank Correlation* **Parentheses No Parentheses CrossFigure 6: Circuit stability for phi-1.5 within and across six subtasks. A permutation test is performed between parenthetical and non-parenthetical pairs of subtasks. “∗” denotes a statistically significant difference with a setting of𝑝<0.05.The error bars denote a 95% confi- dence interval. Concretely, for notexpressions with parenthe- ses, we partition the input space by both parenthet- ical depth and expression length. In contrast, for notexpressions without parentheses, we partition only by expression length. The left two columns of the first bar group in Figure 6 illustrate phi-1.5 ’s respective circuit stability across these two parti- tions. The separately evaluated circuit stability of phi-1.5 on each task provides a baseline for com- puting𝛼-equivalence. If phi-1.5 applies the same set of circuits across both parenthetical and non- parenthetical subtasks, then circuit stability should be consistent even as we permute the subtask soft circuits between these two groups. In particular, we expect this permutation not to cause circuit stability to drop below the minimum stability observed in across the two partitions. We find that phi-1.5 applies statistically significant different circuits be- tween these two tasks (see rightmost bar of first bar group in Figure 6). We hypothesize that this lack of circuit equiva- lence suggests that the model does not understand associativity in notevaluation. Indeed this is the case. Given any expression containing only nots and literals, after adding parentheses, phi-1.5 ’s performance decreases by 40%. Further, the model is not self-consistent: adding parentheses to any expression causes the model to flip its prediction. This behavior is illustrated in the first bar group of Figure 7. Not+And Subtask. Now consider a Boolean expression with logical operators not andand. Adding and removing parentheses from this expres- sion changes the order of evaluation. This may flip Not Not+And Not+And+Or Subtask0.00.10.20.30.40.50.60.7PerformanceDifference ConsistencyFigure 7: (left columns) The performance difference after adding parentheses. (right columns) The self- consistency of phi-1.5 as a result of adding parentheti- cals. The dotted line denotes random chance of 0.5 for the consistency estimates. the ground-truth label7. Consequently, a model that respects operator precedence should apply substan- tially different circuits across not+andexpressions with and without parentheses. We apply the same experimental procedure as the previous notsub- task. As shown in the second bar group of Figure 6, we find that phi-1.5 does employ different soft circuits across these partitions. Accordingly, in Figure 7, we observe that phi-1.5 ’s performance stabilizes between subtasks with and without paren- theses. Additionally, phi-1.5 exhibits increased self-consistency. That is, for any particular ex- pression, adding parentheses does not change the correctness of its prediction. Not+And+Or Subtask. Similar to the previous subtask, adding parentheses to an expression con- taining the operators not,and, andoralters the order of evaluation. As before, we observe that phi-1.5 ’s circuits align with our expectations (see third bar group of Figure 6). As a result, we see consistent performance stability and increased self- consistency (see rightmost bar group in Figure 7). instability. 6 Case Study: Chain-of-Thought In Section 4 and 5, we demonstrated that the stability of a model’s circuit sheds light on its generalization. Now, we examine methods that tractably induce circuit stability. We hypothesize that chain-of-thought improves performance by promoting subtask decomposition and circuit com- ponent reuse (Wei et al., 2022). As a result, we expect chain-of-thought to substantially improve circuit stability. Herein, we present some prelimi- 7(not False) and True!= not False and True 7 nary evidence for this claim. Unlike previous sec- tions, we examine a task that is knowledge-based: sports understanding (Suzgun et al., 2023). Sports understanding is a binary classification task which presents models with sports statements and the model needs to decided whether they are true or false8. We employ both Llama-3.1-8b and Gemma-2-9b9for this case study. Both mod- els are sufficiently large to show significant performance improvements after prompting with chain-of-thought, see Figure 8 (left). As before, model performance is also measured using exact string match accuracy. In contrast to our previous case studies, the sub- task structure of this task much less apparent. As a result, we opt to construct subtasks simply by randomly partitioning the dataset into five disjoint cells. We compute the average circuit stability pair- wise across these five cells before (we use few- shot prompting with 𝑘=3) and after chain-of- thought prompting. These results are shown in Figure 8 (right). Across both models, we see that chain-of-thought significantly circuit stability. It should be noted that technically the partition strategy we employ herein is not creating true sub- tasks (see Definition 2). This is because we are sampling from𝒟𝒳×𝒴 a finite dataset first,then randomly partitioning the resulting dataset. As a result, the partitions we yield are i.i.d. with respect to𝒟𝒳×𝒴. Thus, in some sense we are measuring the variance of the soft circuitry distribution before and after applying chain-of-thought. We could rem- edy this by fixing a partition strategy a priori that with high probability induces similar substasks (in terms of transport distance). For example, we could partition subtasks based on the value of the fifth character of the input prompt. The connections between these two approaches could be explored more in future work. 7 Related Works Most current work in mechanistic interpretability relies on ad hoc interpretations tailored for a fixed task and model (Wang et al., 2022; Stolfo et al., 2023; Conmy et al., 2023; Hanna et al., 2023; Arditi 8For example, the model is presented with a statement like “Santi Cazorla scored a touchdown.” This statement is false because Santi Cazorla is a soccer player and a “touchdown” is a part of American football and rugby (Suzgun et al., 2023). 98 billion parameter model containing over 1.5m circuit edges and 9 billion parameter model with over 720k circuit edges, respectively. Gemma-2-9b Llama-3.1-8B0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Accuracy CoT Shots=3 Gemma-2-9b Llama-3.1-8B0.70 0.75 0.80 0.85 0.90 0.951.00Circuit Stability **Figure 8: (left) Exact string match accuracy of sports understanding task under chain-of-thought versus few- shot prompting. (right) Circuit stability across random partitions. We perform a two-sample 𝑡-test, “∗” denotes a significant difference ( 𝑝<0.05). et al., 2024; Lee et al., 2024; Nikankin et al., 2025, inter alia ). As a result, generalizing these results into actionable insights remains difficult. To ad- dress this limitation, recent research has studied the dynamics of circuits and their mechanisms. This is also the focus of our paper. For example, works like Nanda et al. (2022); Zhong et al. (2023); Hu- mayun et al. (2024); He et al. (2024); Tigges et al. (2024) examine circuits across the training horizon which shed light on circuit formation and phenom- ena such as grokking (Power et al., 2022). Further studies such as Lee et al. (2024) seek to compare the tangible mechanistic differences before and af- ter applying post-training methods like alignment. On the other hand, works such as Lieberum et al. (2023); Wu et al. (2023); Merullo et al. (2023) ex- amine the change in a model’s circuit with respect to scaling. Perhaps most similar to our line of work is the mechanistic interpretability of skill compo- sition (Arora and Goyal, 2023; Yu et al., 2024) which investigates how models combine learned skills to solve novel problems. Notably, Chughtai et al. (2023); He et al. (2024) analyzes the emer- gence of skill composition in modular addition. However, they focus on small, toy models. It is unclear how their arguments and conclusions gen- eralize to pretrained language models. In contrast, our framework of circuit stability provides a gen- eral characterization of circuits, their equivalence, and their stability—independent of the task or any specific model. 8 Conclusion and Discussion In this paper, we introduce and formally define cir- cuit stability andequivalence (Section 3). We pro- vide empirical evidence that circuit stability char- acterizes many key aspects of generalization and 8 argue that this type of stability is actionable (Sec- tion 4 and 5). For example, it can be induced through prompting (Section 6). Our approach, based on methods from mechanistic interpretabil- ity, offers a step towards rigorously bridging the generality of models with their interpretability. Efficiency. Our definition of a soft circuit (Defi- nition 3) involves continuous relaxation of the bi- nary circuit function, 𝑐:𝐸𝑀→{ 0,1}. In most circuit discovery procedures, this relaxation, imple- mented via Equation 3, is necessary for tractabil- ity (Conmy et al., 2023; Nanda, 2023; Syed et al., 2024). As a result, many existing methods first per- form this relaxation, then apply a greedy decoding strategy to extract the binary circuit function. Thus, our choice of both this continuous relaxation and Spearman’s 𝜌aligns with the standard practices of circuit discovery. Approximations for Definition 3 are also computationally efficient. Methods such as Syed et al. (2024); Hanna et al. (2024) only re- quire (a constant factor of) two forward and one backward pass of the model to estimate the entire soft circuitry. Occam’s Razor. Crucially, soft circuitry does not account for higher level algorithmic similari- ties. That is, we could have different soft circuits which also correspond to distinct hard circuits, but algorithmically they implement the same proce- dure (Olsson et al., 2022; Merullo et al., 2023). We do not see this as a limitation of the work but rather a feature of our mathematical framework. From a learning-theoretic perspective, duplicate mecha- nisms necessarily imply longer minimum descrip- tion lengths. In turn, this leads to looser general- ization bounds (Hansen and and, 2001; Sefidgaran et al., 2023, inter alia ). More informally, if we sub- scribe to the principle of Occam’s Razor (Blumer et al., 1987; Shalev-Shwartz and Ben-David, 2014) then we would also prefer a model with less dupli- cate mechanisms. As a result, our analyses implic- itly take into account these learning-theoretic con- structs. Lastly, if one was truly concerned with al- gorithmic differences, then 𝐾could be augmented using metrics from causal abstraction (Beckers and Halpern, 2019; Geiger et al., 2021; Otsuka and Saigo, 2022; Geiger et al., 2024, inter alia ). How- ever, this introduces additional complexities that we leave for future work. Finding Partitions. Throughout Sections 4, 5, we leverage prior knowledge about the task to con- struct partitions of interest. But, for more complex tasks requiring an intricate composition of skills,the appropriate partitions may not be obvious. In Section 6, we demonstrate that this does not hinder the practicality of circuit stability. Even randomly chosen partitions can yield meaningful insights. Alternatively, since soft circuitry is an expecta- tion, we could have also sought to characterize circuit stability through the asymptotic variance of its limiting distribution. Further, we hypothesize that if any of the partitions contain cells that are 𝜀-representative (Shalev-Shwartz and Ben-David, 2014) with respect to both 𝐿and𝒟𝒳×𝒴 in Equa- tion 3, then they should lead to a sharp character- ization of the model’s performance. Investigating this connection could form the basis of interesting future work and reduce reliance on constructing partitions manually. 9 Limitations Our empirical case studies in Sections 4, 5, and 6 are fairly limited in terms of the tasks and models we benchmark. We hope that these preliminary results will give the larger research community a taste of how circuit stability can be used and leave these extensions for future work. Another limitation of the work is the choice of circuit abstraction (Vilas et al., 2024). In Section 2, we loosely defined the model’s circuit as a sub- graph of its computational graph. However, there are many ways this computational graph could be specified. On one extreme, there exists the trivial computation graph: an input and output node with a single edge representing the entire function. On the other extreme, we could define the graph as a trace of the compiled machine code. This is also a challenge that mechanistic interpretability faces. It is unclear how circuit stability would react to these different levels of abstraction. Perhaps future theo- retical analyses of circuit stability could take this into account by involving |𝑉𝑀|into its bounds. Acknowledgments Alan thanks Mariya Toneva for her generous sup- port; Fengwen Sun for his valuable feedback and advice; Ethan Sun and Warren Shepard for their contributions to early iterations of the work; and, Andrew Koulogeorge for the thoughtful discus- sions. References Federico Adolfi, Martina G. Vilas, and Todd Wareham. 2025. The computational complexity of circuit dis- covery for inner interpretability. In The Thirteenth 9 International Conference on Learning Representa- tions. Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and Neel Nanda. 2024. Refusal in Language Models Is Mediated by a Single Direction. In Advances in Neural Informa- tion Processing Systems, volume 37, pages 136037– 136083. Curran Associates, Inc. Sanjeev Arora and Anirudh Goyal. 2023. A theory for emergence of complex skills in language models. arXiv preprint arXiv:2307.15936. Sander Beckers and Joseph Y Halpern. 2019. Abstract- ing causal models. In Proceedings of the AAAI Con- ference on Artificial Intelligence, volume 33, pages 2678–2685. Issue: 01. Adithya Bhaskar, Alexander Wettig, Dan Friedman, and Danqi Chen. 2024. Finding Transformer Circuits With Edge Pruning. In Advances in Neural Informa- tion Processing Systems, volume 37, pages 18506– 18534. Curran Associates, Inc. Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. 1987. Occam’s Razor. Information Processing Letters, 24(6):377–380. Florian Bordes, Richard Yuanzhe Pang, Anurag Ajay, Alexander C Li, Adrien Bardes, Suzanne Petryk, Oscar Mañas, Zhiqiu Lin, Anas Mahmoud, Bar- gav Jayaraman, et al. 2024. An introduction to vision-language modeling. arXiv preprint arXiv:2405.17247. Hanseul Cho, Jaeyoung Cha, Srinadh Bhojanapalli, and Chulhee Yun. 2025. Arithmetic transformers can length-generalize in both operand length and count. InThe Thirteenth International Conference on Learn- ing Representations. Bilal Chughtai, Lawrence Chan, and Neel Nanda. 2023. A Toy Model of Universality: Reverse Engineering how Networks Learn Group Operations. In Proceed- ings of the 40th International Conference on Machine Learning. Arthur Conmy, Augustine Parker-Mavor N., Aengus Lynch, Stefan Heimersheim, and Adria Alonso- Garriga. 2023. Towards Automated Circuit Dis- covery for Mechanistic Interpretability. In Thirty- Seventh Conference on Neural Information Process- ing Systems. Ryan Cotterell, Anej Svete, Clara Meister, Tianyu Liu, and Li Du. 2023. Formal aspects of language model- ing. arXiv preprint arXiv:2311.04329. Patrick Cousot and Radhia Cousot. 1977. Abstract in- terpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In Proceedings of the 4th ACM SIGACT- SIGPLAN Symposium on Principles of Programming Languages, POPL ’77, page 238–252, New York, NY, USA. Association for Computing Machinery.Li Du, Lucas Torroba Hennigen, Tiago Pimentel, Clara Meister, Jason Eisner, and Ryan Cotterell. 2023. A measure-theoretic characterization of tight language models. In Proceedings of the 61st Annual Meet- ing of the Association for Computational Linguistics (Volume 1: Long Papers), pages 9744–9770, Toronto, Canada. Association for Computational Linguistics. Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Das- Sarma, Nova, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Ka- plan, Sam McCandlish, and Chris Olah. 2021. A Mathematical Framework for Transformer Circuits. Atticus Geiger, Hanson Lu, Thomas Icard, and Christo- pher Potts. 2021. Causal abstractions of neural net- works. In Advances in Neural Information Process- ing Systems, volume 34, pages 9574–9586. Curran Associates, Inc. Atticus Geiger, Zhengxuan Wu, Christopher Potts, Thomas Icard, and Noah Goodman. 2024. Finding alignments between interpretable causal variables and distributed neural representations. In Proceed- ings of the Third Conference on Causal Learning and Reasoning, volume 236 of Proceedings of Machine Learning Research, pages 160–187. PMLR. Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan Chen, Alex Gunning, Caroline Falk- man Olsson, Jean-Stanislas Denain, Anson Ho, Emily de Oliveira Santos, et al. 2024. Frontiermath: A benchmark for evaluating advanced mathematical reasoning in ai. arXiv preprint arXiv:2411.04872. Albert Gu, Isys Johnson, Karan Goel, Khaled Saab, Tri Dao, Atri Rudra, and Christopher Ré. 2021. Com- bining recurrent, convolutional, and continuous-time models with linear state space layers. In Advances in Neural Information Processing Systems, volume 34, pages 572–585. Curran Associates, Inc. Rohan Gupta, Iván Arcuschin, Thomas Kwa, and Adrià Garriga-Alonso. 2024. InterpBench: Semi- Synthetic Transformers for Evaluating Mechanistic Interpretability Techniques. In Advances in Neural Information Processing Systems, volume 37, pages 92922–92951. Curran Associates, Inc. Michael Hanna, Ollie Liu, and Alexandre Variengien. 2023. How does GPT-2 compute greater-than?: In- terpreting mathematical abilities in a pre-trained lan- guage model. In Thirty-seventh Conference on Neu- ral Information Processing Systems. Michael Hanna, Sandro Pezzelle, and Yonatan Belinkov. 2024. Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms. InFirst Conference on Language Modeling. Mark H Hansen and Bin Yu and. 2001. Model se- lection and the principle of minimum description 10 length. Journal of the American Statistical Associa- tion, 96(454):746–774. Tianyu He, Darshil Doshi, Aritra Das, and Andrey Gro- mov. 2024. Learning to grok: Emergence of in- context learning and skill composition in modular arithmetic tasks. In The Thirty-eighth Annual Con- ference on Neural Information Processing Systems. Stefan Heimersheim and Neel Nanda. 2024. How to use and interpret activation patching. arXiv preprint arXiv:2404.15255. Ahmed Imtiaz Humayun, Randall Balestriero, and Richard Baraniuk. 2024. Grokking and the geometry of circuit formation. In ICML 2024 Workshop on Mechanistic Interpretability. Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik R Narasimhan. 2024. Swe-bench: Can language mod- els resolve real-world github issues? In The Twelfth International Conference on Learning Representa- tions. Greg Kamradt. 2023. LLM Test - Needle in a Haystack. János Kramár, Tom Lieberum, Rohin Shah, and Neel Nanda. 2024. Atp*: An efficient and scalable method for localizing llm behaviour to components. arXiv preprint arXiv:2403.00745. Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Ana Brassard, Masashi Yoshikawa, Keisuke Sakaguchi, and Kentaro Inui. 2023. Do deep neural networks capture compositionality in arithmetic reasoning? In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Lin- guistics, pages 1351–1362, Dubrovnik, Croatia. As- sociation for Computational Linguistics. Andrew Lee, Xiaoyan Bai, Itamar Pres, Martin Wat- tenberg, Jonathan K. Kummerfeld, and Rada Mihal- cea. 2024. A mechanistic understanding of align- ment algorithms: A case study on DPO and toxicity. InForty-first International Conference on Machine Learning. Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee. 2023. Textbooks are all you need ii: phi-1.5 technical report. Preprint, arXiv:2309.05463. Tom Lieberum, Matthew Rahtz, János Kramár, Neel Nanda, Geoffrey Irving, Rohin Shah, and Vladimir Mikulik. 2023. Does circuit analysis interpretability scale? evidence from multiple choice capabilities in chinchilla. arXiv preprint arXiv:2307.09458. Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data using t-SNE. Journal of Machine Learning Research, 9(86):2579–2605. Kevin Meng, David Bau, Alex J. Andonian, and Yonatan Belinkov. 2022. Locating and Editing Factual Asso- ciations in GPT. In Advances in Neural Information Processing Systems.Jack Merullo, Carsten Eickhoff, and Ellie Pavlick. 2023. Circuit Component Reuse Across Tasks in Trans- former Language Models. In The Twelfth Interna- tional Conference on Learning Representations. Joseph Miller, Bilal Chughtai, and William Saunders. 2024. Transformer circuit evaluation metrics are not robust. In First Conference on Language Modeling. Neel Nanda. 2023. Attribution patching: Activation patching at industrial scale. URL: https://www. neel- nanda. io/mechanistic-interpretability/attribution- patching. Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. 2022. Progress mea- sures for grokking via mechanistic interpretability. In The Eleventh International Conference on Learning Representations. Yaniv Nikankin, Anja Reusch, Aaron Mueller, and Yonatan Belinkov. 2025. Arithmetic without algo- rithms: Language models solve math with a bag of heuristics. In The Thirteenth International Confer- ence on Learning Representations. Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and Shan Carter. 2020. Zoom in: An introduction to circuits. Distill. Https://distill.pub/2020/circuits/zoom-in. Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Con- erly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jack- son Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022. In-context learning and induction heads. Transformer Circuits Thread. Https://transformer-circuits.pub/2022/in- context-learning-and-induction-heads/index.html. Jun Otsuka and Hayato Saigo. 2022. On the Equiva- lence of Causal Models: A Category-Theoretic Ap- proach. In Proceedings of the First Conference on Causal Learning and Reasoning, volume 177 of Pro- ceedings of Machine Learning Research, pages 634– 646. PMLR. Judea Pearl. 2009. Causality. Cambridge University Press. Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, and Vedant Misra. 2022. Grokking: Generalization Beyond Overfitting on Small Datasets. Morgane Rivière, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, et al. 2024. Gemma 2: Improving open language models at a practical size. CoRR, abs/2408.00118. 11 Milad Sefidgaran, Abdellatif Zaidi, and Piotr Kras- nowski. 2023. Minimum Description Length and Generalization Guarantees for Representation Learn- ing. In Advances in Neural Information Processing Systems, volume 36, pages 1489–1525. Curran Asso- ciates, Inc. Shai Shalev-Shwartz and Shai Ben-David. 2014. Un- derstanding machine learning: From theory to algo- rithms. Cambridge university press. Claudia Shi, Nicolas Beltran-Velez, Achille Nazaret, Carolina Zheng, Adrià Garriga-Alonso, Andrew Jes- son, Maggie Makar, and David M. Blei. 2024. Hy- pothesis testing the circuit hypothesis in llms. In Advances in Neural Information Processing Systems, volume 37, pages 94539–94567. Curran Associates, Inc. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, et al. 2023. Beyond the imitation game: Quantifying and extrapolating the capabili- ties of language models. Transactions on Machine Learning Research. Featured Certification. Alessandro Stolfo, Yonatan Belinkov, and Mrinmaya Sachan. 2023. A mechanistic interpretation of arith- metic reasoning in language models using causal mediation analysis. In Proceedings of the 2023 Con- ference on Empirical Methods in Natural Language Processing, pages 7035–7052, Singapore. Associa- tion for Computational Linguistics. Alan Sun, Chiyu Ma, Kenneth Ge, and Soroush V osoughi. 2024. Achieving domain-independent cer- tified robustness via knowledge continuity. In The Thirty-eighth Annual Conference on Neural Informa- tion Processing Systems. Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se- bastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny Zhou, and Jason Wei. 2023. Challenging BIG-bench tasks and whether chain-of-thought can solve them. InFindings of the Association for Computational Lin- guistics: ACL 2023, pages 13003–13051, Toronto, Canada. Association for Computational Linguistics. Aaquib Syed, Can Rager, and Arthur Conmy. 2024. Attribution patching outperforms automated circuit discovery. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Net- works for NLP, pages 407–416, Miami, Florida, US. Association for Computational Linguistics. Curt Tigges, Michael Hanna, Qinan Yu, and Stella Bi- derman. 2024. LLM Circuit Analyses Are Consistent Across Training and Scale. In The Thirty-eighth An- nual Conference on Neural Information Processing Systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Pro- cessing Systems, volume 30.Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Yaron Singer, and Stuart Shieber. 2020. Investigating gender bias in language models using causal mediation analysis. In Advances in neural information processing systems, volume 33, pages 12388–12401. Martina G. Vilas, Federuci Adolfi, David Poeppel, and Gemma Roig. 2024. Position: An Inner Interpretabil- ity Framework for AI Inspired by Lessons from Cog- nitive Science. In Proceedings of the 41st Interna- tional Conference on Machine Learning. Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. 2022. Inter- pretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small. In The Eleventh Inter- national Conference on Learning Representations. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In Advances in Neural Information Processing Systems, volume 35, pages 24824–24837. Curran Associates, Inc. Thaddäus Wiedemer, Prasanna Mayilvahanan, Matthias Bethge, and Wieland Brendel. 2023. Compositional generalization from first principles. In Thirty-seventh Conference on Neural Information Processing Sys- tems. Zhengxuan Wu, Atticus Geiger, Thomas Icard, Christo- pher Potts, and Noah Goodman. 2023. Interpretabil- ity at scale: Identifying causal mechanisms in alpaca. InAdvances in Neural Information Processing Sys- tems, volume 36, pages 78205–78226. Curran Asso- ciates, Inc. Haotian Ye, Chuanlong Xie, Tianle Cai, Ruichen Li, Zhenguo Li, and Liwei Wang. 2021. Towards a theo- retical framework of out-of-distribution generaliza- tion. In Advances in Neural Information Processing Systems, volume 34, pages 23519–23531. Curran As- sociates, Inc. Dingli Yu, Simran Kaur, Arushi Gupta, Jonah Brown- Cohen, Anirudh Goyal, and Sanjeev Arora. 2024. SKILL-MIX: a flexible and expandable family of evaluations for AI models. In The Twelfth Interna- tional Conference on Learning Representations. Zhiqian Zhong, Ziming Liu, Max Tegmark, and Jacob Andreas. 2023. The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks. In Advances in Neural Information Processing Systems. A Circuit Stability Beyond Transformer Language Models In this paper, we focused our case studies on Trans- former language models, as their circuits are well- studied in the the literature (Elhage et al., 2021; 12 Olsson et al., 2022; Wang et al., 2022; Hanna et al., 2023). However, the concept of the circuit stabil- ity can be extended to any neural network as long as it admits a consistent computational graph. In this section, we present three distinct neural ar- chitectures associated with applications outside of the language domain and demonstrate that even in these cases, circuit stability is a well-defined notion. In this way, circuit stability is a modality- independent concept. An interesting line of future work could be to extend this framework to study the circuits and generalization of vision-language models (Bordes et al., 2024). Fully-Connected Neural Networks. A fully- connected network consists of successive linear layers with activation functions: 𝑀=𝑓𝑛◦...◦𝑓1 where𝑓𝑖:R𝑑𝑖→R𝑑𝑖+1. Here,𝑑1,𝑑𝑛+1are the input and output dimensions. For given ac- tivation functions 𝜎𝑖:R→R, a single fully- connected layer is defined as 𝑓𝑖(𝑥)=𝜎𝑖(𝑊𝑖𝑥), where𝑊𝑖∈R𝑑𝑖+1×𝑑𝑖and𝜎𝑖is applied element- wise. There are many ways to construct a valid computational graph upon this architecture. For brevity, we only show the most intuitive construc- tion: a node in the 𝑖thlayer is simply an entry in 𝑥. Specifically, we can decompose the 𝑗thentry in layer𝑖as(𝜎𝑖(𝑊𝑖𝑥))𝑗=𝜎𝑖\u0010Í𝑑𝑖 𝑘=1𝑊𝑗𝑘𝑥𝑘\u0011. Note also that each entry in the input should also be as- signed a node. Therefore, this node forms edges with all nodes in the previous layer. Convolutional Neural Networks. We take a similar approach to the decomposition of fully- connected neural networks. For simplicity, we only consider the case of a single 2d-convolution layer, a convolutional network with higher dimen- sions or more layers can be derived inductively. We directly lift this description of a convolutional layer from (Sun et al., 2024). Let 𝑓:R𝑐×ℎ×𝑤→ R𝑐′×ℎ′×𝑤′. Suppose that this layer is parameterized by kernels𝑊𝑖∈R𝑘×𝑘for1≤𝑖≤𝑐′and some 𝑘∈Nas well as a bias 𝑏∈R𝑐′. Then, it follows that 𝑓(𝑥)𝑗= 1ℎ′×𝑤′𝑏𝑗+𝑐Õ 𝑖=1𝑊𝑗∗𝑥[𝑖,:,:]!, for1≤𝑗≤𝑐′where𝑓(𝑥)𝑗∈Rℎ′×𝑤′forℎ′,𝑤′ being the resulting dimension after convolution with a𝑘×𝑘kernel. Here, 1ℎ′×𝑤′∈Rℎ′×𝑤′is a one matrix. Then, one convolutional layer needs 𝑐′ℎ′𝑤′+𝑐ℎ𝑤 nodes: one for each input and outputcoordinate. A directed edge is drawn from all input nodes to each output node10. State-Space Language Models. A state-space model processes input tokens sequentially. Each token,𝑥𝑡is processed in constant time (Gu et al., 2021) via a hidden state 𝑠𝑡such that 𝑠𝑡+1=A𝑠𝑡+B𝑥𝑡, 𝑦𝑡=C𝑠𝑡+D𝑥𝑡. Thus, we can the computational at each time-step to essentially be a combination of two fully-connected neural networks. We can specify a well-defined computational graph by unrolling the recursive equations above. We define each 𝑥𝑡for all𝑡as a node and each entry of 𝑠𝑡to also be a node. The, the edges are given by the same schema we used to define the fully-connected layers. Putting it All Together. These examples demon- strate that as long as we can specify a computa- tional graph, the circuit of a model is well-defined. Therefore, the existence of circuit stability as well as its implications depends largely on the task dis- tribution (Definition 1), its subtask distributions (Definition 2), and the granularity of the computa- tional graph. To this last point, a priori it is unclear what the correct level of abstraction one should impose on the nodes and edges. On one end, we could define the nodes as the input/output of each FLOP of compute. However, though this might pro- vide lots of insight, the computation of its circuit (Definition 3) would be intractable. On the other end, we could define the computational graph as a single node with no edges. Though this is com- putationally more favorable, it yields no insights. The subfield of causal abstraction addresses some of these issues and we refer the reader to Geiger et al. (2021). B Circuit Discovery Details For all of our circuit discovery experiments, we perform attribution patching (Nanda, 2023). Attri- bution patching is a linear approximation to acti- vation patching also called causal mediation anal- ysis (Heimersheim and Nanda, 2024). First intro- duced by Vig et al. (2020) and extended upon by Meng et al. (2022); Wang et al. (2022); Conmy et al. (2023), activation patching seeks to determine the 10This may not be the tightest graph that we can build in terms of the number of edges we need to construct. However, after performing any ablations, we should expect those edges that are non-tight to contribute a score of 0. 13 effect of a single neural component on the entire model’s output, for some fixed task. Then, by iso- lating all such components, we have effectively found the subcircuit responsible for the model’s behavior on this specific task. More formally, let 𝐿(·)be a function that maps a model’s output into a scalar, generically this could be some loss function. This is the patching metric. For notational brevity, we omit𝐿’s dependency on the ground truth label. Let𝑐be an arbitrary neural network component that we wish to patch, and also denote by 𝑥an ar- bitrary input to our model 𝑀. Using Pearl’s (2009) notion of do-calculus, activation patching can be written as Patch𝑐(𝑥,𝑐★)B𝐿(𝑀do(𝑐=𝑐★)(𝑥))−𝐿(𝑀(𝑥)),(3) where𝑐★is acounterfactual output of activation 𝑐 that we patch in. In natural language, Patch𝑐(𝑥,𝑐★) can be expressed as “if we replace only the out- put of component 𝑐with𝑐★, how will the model now behave?” We encourage the reader to refer to Heimersheim and Nanda (2024) for a detailed in- troduction to activation patching and instead briefly explain attribution patching, our design choices, as well as our extensions to the multi-token setting. One drawback of activation patching is its com- putational cost. Consider a dataset of 𝑛data points and a model with 𝑘neural components we are inter- ested in patching, activation patching would require 𝒪(𝑛𝑘)forward passes. This becomes prohibitively expensive when 𝑘≫1(Kramár et al., 2024). Thus, using Equation 3 as a jumping off point, attribu- tion patching seeks to make activation patching more efficient. Consider a first-order Taylor se- ries approximation of 𝐿around𝑐assuming that 𝑐★≈𝑐′, where𝑐′is the unpatched activation of 𝑐 on𝑥. Then, it follows that Patch𝑐(𝑥,𝑐★)≈(𝑐′−𝑐★)∇𝑐𝐿(𝑥). (4) Crucially, Nanda (2023); Syed et al. (2024) argue that this new metric can be computed in two for- ward passes and one backward pass for all com- ponents. Thus, we only require 𝒪(𝑛)forward and backward passes. Throughout the paper, we use a variant of attribution patching introduced by (Hanna et al., 2024) called edge attribution patching with integrated gradients (EAP-IG). In short, EAP-IG deduces a more accurate approxima- tion to activation patching than vanilla attribution patching in Equation 4. EA-IG operates by com-puting a path integral from 𝑐′→𝑐★: Δ𝑐′,𝑐∗∫1 0𝜕𝐿 𝜕𝑐′𝑀do(𝑐=Δ𝑐′,−𝛼(𝑐★−𝑐′))(𝑥)𝑑𝛼(5) ≈Δ𝑐′,𝑐∗1 𝑚𝑚Õ 𝑘=1𝜕𝐿 𝜕𝑐′𝑀do(𝑐=Δ𝑐′,−𝑘(𝑐★−𝑐′)/𝑚)(𝑥),(6) whereΔ𝑐′,𝑐=𝑐′−𝑐and𝑚is a hyperparameter representing the number of steps to approximate the integral. Equation 6 can be understood as a Monte-Carlo estimate of the integral in Equation 5. Generally, for such estimates to be accurate it re- quires𝑚≫1, potentially on the order of ∼105. However, empirically Hanna et al. (2024) finds even𝑚=5works quite well. These hyperparame- ters are adopted for all of the circuit experiments. B.1 Patching Multi-token Tasks Herein, we detail circuit discovery in the case of multitoken tasks. To the best of our knowledge, almost all of the mechanistic interpretability litera- ture deals with tasks that require only a single token output. So, our methods represent one attempt to generalize these existing approaches. We present two distinct approaches, and briefly discuss their interpretations (Table 1). Denote by𝑝some prompt. Let 𝑡1,𝑡2,...,𝑡𝑛 be new tokens generated autoregressively by some model𝑀. We fix𝑛≥1and focus most of our analysis on the case where 𝑛=2as any finite 𝑛 can be derived inductively. Also denote by Pthe probability distribution over 𝑡1,𝑡2,...,𝑡𝑛condi- tioned on some prompt 𝑝induced by the model 𝑀 (Cotterell et al., 2023; Du et al., 2023). Let Pdobe the model after intervention by one of the methods described previously. Next-token patching. Let𝑡★ 1,𝑡★ 2,...,𝑡★ 𝑛be the expected output for a given prompt 𝑝. For a fixed prompt, next-token patching defines the following patching metric NextToken(𝑝)BKL(P[𝑡1|𝑝]∥Pdo[𝑡1|𝑝])+ (7) 𝑛Õ 𝑖=2KL\u0010 P[𝑡𝑖|𝑝,𝑡★ [:𝑖]]∥Pdo[𝑡𝑖|𝑝,𝑡★ [:𝑖]]\u0011.(8) KL(P∥Pdo)denotes the KL-divergence between PandPdo. Essentially, Equation 8 measures the ef- fect of patching any given component on model 𝑀’s next word prediction ability. Specifically, this metric captures a “local property” of 𝑀since in each summand, we assume that 𝑀has previ- ously generated the correct tokens. To compute 14 Feature Next-token Patching Joint-token Patching Granularity Token Sequence Focus Localized, stepwise effects Global multi-token coherence Computational Cost Can compute exactly High; requires approximations Insight Fine-grained, task-specific behavior Broader token dependencies Table 1: Features of next-token patching versus joint-token patching. The former can be seen as grokking the local token-level behavior of the model compared to the latter which can be viewed as uncovering global token dependencies. the patching metric across the entire task distri- bution, we simply take the expectation over 𝑝: E𝑝[NextToken(𝑝)]. Joint-token patching. As discussed previously, a language model can be thought of as a measure over the space of all sentences: P. Joint-token patching directly measures the difference between the measure P(induced by𝑀) andPdo(induced by an intervention on 𝑀) over the joint distribution of all𝑛-tokens. Concretely, for a fixed prompt 𝑝, JointToken(𝑝)BKL(P[𝑡1...𝑡𝑛|𝑝]∥Pdo[𝑡1...𝑡𝑛|𝑝]). By expanding the definition of KL(·∥·), it is easy to see that for 𝑛=2: JointToken(𝑝)=KL(P[𝑡1|𝑝]∥Pdo[𝑡1|𝑝])+ E𝑡1∼P[𝑡1|𝑝]\u0002 KL(P[𝑡2|𝑝,𝑡 1]∥Pdo[𝑡2|𝑝,𝑡 1])\u0003. Note the expectation in the second summand. This is with respect to the token 𝑡1generated by the model without any intervention. The computation of this expectation is hard especially if 𝑛is large. In both next-token and joint-token patching KL- divergence is used. This follows from the rec- ommendation and positive results of Conmy et al. (2023), but one can technically use any other pre- ferred metric. The key idea being that the metric should capture the performance decrease of the model after ablating an individual edge. B.2 Noisy-to-Clean Patching In Section 4 and 5, we perform noisy-to-clean patching. That is, for a model 𝑀, we run the model on a given example 𝑥and cache all of the activa- tions across all of the edges. Then, we take another example𝑥′which is associated with a different ground truth example. While the model runs on 𝑥′, we patch in activations from 𝑥and check to see how much performance decreases with respect to the label associated with 𝑥′. In the case of attribution patching, we apply the same Taylor-expansion as above. Noisy-to-clean activation gives us a picture of the necessary components of the model. 2 4 6 8 10 12 14 16 Total Number of Digits0.20.30.40.50.60.70.80.9Exact String Match Accuracy R2=0.9978 y10.027(0.95)4.066x Figure 9: Exponential regression on exact string accu- racy for equal-digit subtasks. That is, 𝑜1=𝑜2. The 𝑥-axis of the regression is the sum of the number of digits in both operands. B.3 Clean-to-Clean Patching In cases where there is not necessarily a ground- truth label, noisy-to-clean patching is not well- defined. Herein, we propose a new type of patching which we call clean-to-clean patching. This is ap- plied in Section 6 and generally useful for circuit discovery where the output is some open-form gen- eration for autoregressive language models. Let 𝑥be the input and 𝑥★be the model’s sampled re- sponse of𝑥. We first run the model on 𝑥with padding tokens such that 𝑥and𝑥★have the same length. Similar to the procedure above, we cache all of the intermediate activations. Then, we run the model on 𝑥★and patch in the appropriate acti- vations from this “blanked” out 𝑥. The idea here is that we are finding the necessary components that exactly recover the model’s response on this input, where the baseline is if the model had not generated anything at all. In the case of attribution patching, we apply the same Taylor-expansion as above. C Within-Task Regressions In Section 4, we argued that within an 𝛼-equivalent circuit family, performance decreases predictability. 15 1 2 3 4 5 6 7 8 Number of Digits0.700.750.800.850.900.95Exact String Match Accuracy R2=0.9953 y0.9660.0079(0.95)8.70x Figure 10: Exponential regression on exact string accu- racy for one-digit subtasks. That is 𝑜2=1. The𝑥-axis of the regression is simply the number of digits in 𝑜1as 𝑜2is constant. Herein, we perform a regression analysis to analyze this hypothesis. Specifically, we examine whether the subtask performances shown in Figure 4 can be predicted through an exponential regression using the performance of the (1,1)subtask. We perform an exponential regression since we expect error to be compounded. That is, for a (2,2)task, at least 4(1,1)subtasks need to be computed. Thus, the error should be compounding on the order of 0.954. Likewise, a subtask that requires 𝑛,(1,1)subtask decompositions should require incur error on the order of𝒪(0.95𝑛). Therefore, consider a regres- sion of the form 𝑦=𝑏−𝑐(0.95)𝑎𝑥, where𝑎,𝑏,𝑐 are learnable parameters and 𝑥is the total number of digits across both operands, and 𝑎𝑥is the total number of subtask decompositions. These regres- sion results are shown in Figure 9 and Figure 10. We find that a strong 𝑅2is observed >0.99. D Reproducibility Throughout the paper, we do not perform any finetuning or training. Rather, we directly eval- uate the pretrained models. All of our exper- iments were conducted on two NVIDIA A100 80GB GPUs. Our codebase including the im- plementations of the proposed algorithms and figures can be found at https://github.com/ alansun17904/circuit-stability. The mod- els and their weights used as case study through- out the paper are loaded directly from the transformer_lens package, its documentation can be found at https://transformerlensorg. github.io/TransformerLens/index.html. We use all of the default hyperparameters and settings of the package. 16",
  "text_length": 71342
}