{
  "id": "http://arxiv.org/abs/2506.04255v1",
  "title": "HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource\n  Utilization",
  "summary": "Rapid Large Language Model (LLM) advancements are fueling autonomous\nMulti-Agent System (MAS) development. However, current frameworks often lack\nflexibility, resource awareness, model diversity, and autonomous tool creation.\nThis paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent\nResource Utilization), a novel MAS framework enhancing flexibility, resource\nefficiency, and adaptability. HASHIRU features a \"CEO\" agent dynamically\nmanaging specialized \"employee\" agents, instantiated based on task needs and\nresource constraints (cost, memory). Its hybrid intelligence prioritizes\nsmaller, local LLMs (via Ollama) while flexibly using external APIs and larger\nmodels when necessary. An economic model with hiring/firing costs promotes team\nstability and efficient resource allocation. The system also includes\nautonomous API tool creation and a memory function. Evaluations on tasks like\nacademic paper review (58% success), safety assessments (100% on a\nJailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash\non GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate\nHASHIRU's capabilities. Case studies illustrate its self-improvement via\nautonomous cost model generation, tool integration, and budget management.\nHASHIRU offers a promising approach for more robust, efficient, and adaptable\nMAS through dynamic hierarchical control, resource-aware hybrid intelligence,\nand autonomous functional extension. Source code and benchmarks are available\nat https://github.com/HASHIRU-AI/HASHIRU and\nhttps://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is\navailable at https://hashiruagentx-hashiruai.hf.space upon request.",
  "authors": [
    "Kunal Pai",
    "Parth Shah",
    "Harshil Patel"
  ],
  "published": "2025-06-01T17:33:16Z",
  "updated": "2025-06-01T17:33:16Z",
  "categories": [
    "cs.MA"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.04255v1",
  "full_text": "--- Page 1 ---\narXiv:2506.04255v1  [cs.MA]  1 Jun 2025HASHIRU: Hierarchical Agent System for Hybrid\nIntelligent Resource Utilization\nKunal Pai∗\nUC Davis\nkunpai@ucdavis.eduParth Shah∗\nIndependent Researcher\nhelloparthshah@gmail.comHarshil Patel\nUC Davis\nhpppatel@ucdavis.edu\nAbstract —Rapid Large Language Model (LLM) advancements\nare fueling autonomous Multi-Agent System (MAS) develop-\nment. However, current frameworks often lack flexibility, re-\nsource awareness, model diversity, and autonomous tool cre-\nation. This paper introduces HASHIRU (Hierarchical Agent\nSystem for Hybrid Intelligent Resource Utilization), a novel\nMAS framework enhancing flexibility, resource efficiency, and\nadaptability. HASHIRU features a “CEO” agent dynamically\nmanaging specialized “employee” agents, instantiated based on\ntask needs and resource constraints (cost, memory). Its hybrid\nintelligence prioritizes smaller, local LLMs (often via Ollama)\nwhile flexibly using external APIs and larger models when\nnecessary. An economic model with hiring/firing costs promotes\nteam stability and efficient resource allocation. The system\nalso includes autonomous API tool creation and a memory\nfunction. Evaluations on tasks like academic paper review (58%\nsuccess), safety assessments (100% on a JailbreakBench subset),\nand complex reasoning (outperforming Gemini 2.0 Flash on\nGSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SV AMP:\n92% vs. 84%) demonstrate HASHIRU’s capabilities. Case studies\nillustrate its self-improvement via autonomous cost model gen-\neration, tool integration, and budget management. HASHIRU\noffers a promising approach for more robust, efficient, and\nadaptable MAS through dynamic hierarchical control, resource-\naware hybrid intelligence, and autonomous functional extension.\nSource code and benchmarks are available at HASHIRU and\nHASHIRUBench, and a live demo is available upon request.\nI. I NTRODUCTION\nRapid Large Language Model (LLM) advancements are\nreshaping AI, enabling complex language understanding, gen-\neration, reasoning, and planning [6], [13], [55]. This progress\nfuels the development of autonomous Multi-Agent Systems\n(MAS) where collaborative teams tackle problems beyond\nindividual agent capabilities [14], [70]. Collaborative MAS\nshow potential in scientific discovery [4], software engineering\n[52], data analysis, and decision-making [67]. The increasing\ncomplexity of tasks, evidenced by benchmarks requiring ad-\nvanced reasoning (e.g., GSM8K [10], SV AMP [49]), coding\n[8], [46], and graduate-level knowledge [51], necessitates\nagentic systems that effectively coordinate diverse cognitive\nresources [69].\nDespite this potential, contemporary agentic frameworks\nexhibit limitations: rigidity due to predefined roles hindering\nadaptation [74]; resource obliviousness , lacking mechanisms\nto optimize computational resources (API costs, memory,\n∗These authors contributed equally to this work.CPU), leading to inefficiency, especially with costly pro-\nprietary LLMs [48]; model homogeneity , defaulting to a\nsingle powerful LLM and missing efficiency gains from di-\nverse, smaller, or local models [76]; and limited autonomous\ntool creation and integration , restricting dynamic self-\nimprovement [47], [64], [73].\nTo address these challenges, we introduce HASHIRU (Hi-\nerarchical Agent System for Hybrid Intelligent Resource\nUtilization) , a novel MAS framework enhancing flexibility,\nresource efficiency, and adaptability. HASHIRU uses a hier-\narchical structure with a “CEO” agent dynamically managing\nspecialized “employee” agents, instantiated on demand. Its hy-\nbrid intelligence strategically prioritizes smaller, local LLMs\n(e.g., 3B–7B, often via Ollama [40]) for cost-effectiveness,\nflexibly integrating external APIs and larger models when\njustified by task complexity and resource availability under\nCEO management.\nThe primary contributions are:\n1) A novel MAS architecture with hierarchical control\nand dynamic, resource-aware agent lifecycle man-\nagement (hiring/firing) governed by budget constraints\n(cost, memory) and an economic model discouraging\nexcessive churn.\n2) A hybrid intelligence model prioritizing cost-effective,\nlocal LLMs while adaptively incorporating external APIs\nand larger models, optimizing the efficiency-capability\ntrade-off.\n3) Integrated autonomous API tool creation for dynamic\nfunctional extension.\n4) An economic model (hiring/invocation fees) promoting\nefficient resource allocation and usage based on task\nneeds and system constraints.\nThis paper details HASHIRU’s design. Section II discusses\nrelated work. Section III elaborates on the architecture. Sec-\ntion IV presents case studies demonstrating self-improvement\ncapabilities. Section V describes the experimental setup and\nevaluation metrics. Section VI reports results, and Section VII\nconcludes with limitations and future work.\nII. B ACKGROUND AND RELATED WORK\nIntelligent agent concepts have evolved from early sym-\nbolic AI [57], [59] to LLM-dominated frameworks leveraging\nmodels for reasoning, planning, and interaction [65], [72].\nHASHIRU builds on this, addressing current limitations.\n--- Page 2 ---\nAgent Architectures: MAS architectures vary, including\nflat, federated, and hierarchical [14], [25]. Hierarchical models\noffer clear control and task decomposition but risk bottlenecks\nand rigidity [15], [16]. HASHIRU uses a CEO-Employee\nhierarchy for centralized coordination but distinguishes itself\nthrough dynamic team composition . Unlike systems with\nstatic hierarchies or predefined roles (e.g., CrewAI [11], Chat-\nDev [52]), HASHIRU’s CEO dynamically manages the em-\nployee pool based on runtime needs and resource constraints.\nDynamic Agent Lifecycle Management: Dynamic MAS\ncomposition is crucial for complex environments [36]. Agent\ncreation/deletion triggers often relate to task structure or en-\nvironmental changes. HASHIRU introduces a specific mecha-\nnism where the CEO makes hiring and firing decisions based\non a cost-benefit analysis considering agent performance, op-\nerational costs (API fees, inferred compute), memory footprint\n(tracked explicitly as a percentage of available resources), and\nconcurrency limits. HASHIRU also incorporates an economic\nmodel with explicit “starting bonus” (hiring) and “invocation”\n(usage) costs. This economic friction aims to prevent excessive\ninitialization or usage for marginal gains and promote team\nstability, a nuance often missing in simpler dynamic strategies.\nResource Management and Agent Economies: Resource\nawareness is critical for scalable MAS. Economic research\nexplores mechanisms like market-based auctions or contract\nnets for allocation [9]. HASHIRU implements a more cen-\ntralized, budget-constrained resource management model .\nThe CEO operates within defined limits for financial cost and\nmemory usage (as a percentage of total allocated). This direct\nmanagement, particularly focusing on memory percentage,\nsuggests practicality for deployment on local or edge devices\nwith finite resources, contrasting with cloud systems assuming\nelastic resources [48]. Frameworks like AutoGen [71] and\nLangGraph [30] typically rely on implicit cost tracking without\nexplicit multi-dimensional budgeting and control.\nHybrid Intelligence and Heterogeneous Models: Lever-\naging diverse LLMs with varying capabilities, costs, latencies,\nand self-evolution is an emerging trend [32], [76]. Tech-\nniques like model routing select optimal models for sub-tasks.\nHASHIRU embraces model heterogeneity with a strategic\nfocus: prioritizing smaller (3B–7B), locally-run models via\nOllama integration [40]. This emphasizes cost-efficiency,\nlow latency, and potential privacy over systems defaulting to\nlarge proprietary cloud APIs (e.g., GPT-4 [42], Claude 3 [1]).\nWhile integrating external APIs (potentially larger models),\nHASHIRU’s default stance represents a distinct capability vs.\nefficiency balance.\nTool Use and Autonomous Tool Creation: Tool use (APIs,\nfunctions) is fundamental for modern agents [41], [73]. Most\nsystems use predefined tools. HASHIRU advances this with\nintegrated, autonomous API tool creation . When needed\nfunctionality is missing, the CEO can commission the gener-\nation (potentially via a specialized agent) and deployment of\na new API tool within the HASHIRU ecosystem. This self-\nextension capability differentiates HASHIRU from systems\nlimited to static toolsets, moving towards greater autonomyand adaptability [48], [64].\nIn summary, HASHIRU integrates hierarchical control, dy-\nnamic MAS, resource management, and tool use. Its novelty\nlies in the synergistic combination of: (1) dynamic, resource-\naware hierarchical management with (2) an economic model\nfor stability, (3) a local-first hybrid intelligence strategy, and\n(4) integrated autonomous tool creation. This targets key lim-\nitations in current systems regarding efficiency, adaptability,\ncost, and autonomy.\nIII. HASHIRU S YSTEM ARCHITECTURE\nHASHIRU’s architecture addresses rigidity, resource obliv-\niousness, and limited adaptability through a hierarchical,\ndynamically managed MAS optimized for hybrid resource\nutilization.\nA. Overview\nHASHIRU operates with a central “CEO” agent coordinat-\ning specialized “Employees”. Key tenets:\n•Dynamic Hierarchical Coordination: CEO manages\nstrategy, task allocation, and dynamic team composition.\n•Dynamic Lifecycle Management: Employees are\nhired/fired based on runtime needs and resource con-\nstraints, governed by an economic model.\n•Hybrid Intelligence: Strategic preference for LLMs\nwithin a predefined budget, while accessing external\nAPIs/models.\n•Explicit Resource Management: Continuous monitoring\nand control of costs against budgets.\n•Adaptive Tooling: Using predefined tools alongside au-\ntonomous creation of new API tools.\nFigure 1 illustrates the structure.\nEmployeesHire/Fire\nAPICEO\nFig. 1. High-level architecture of the HASHIRU system, illustrating the CEO-\nEmployee hierarchy.\nB. Hierarchical Structure: CEO and Employee Agents\nThe system uses a two-tiered hierarchy:\n•CEO Agent: Singleton, central coordinator and entry\npoint. Responsibilities:\n--- Page 3 ---\n–Interpreting user query/task.\n–Decomposing main task into sub-tasks.\n–Identifying required capabilities.\n–Managing Employee pool (Section III-C).\n–Assigning sub-tasks to active Employees.\n–Monitoring Employee progress/performance.\n–Synthesizing Employee results into final output.\n–Managing overall resource budget (Section III-E).\n–Initiating new tool creation (Section III-F).\nWe use Gemini 2.0 Flash [21] as the CEO agent. To\nfurther enhance its planning and reasoning abilities, its\nsystem prompt is designed to evoke inherent chain-\nof-thought processes [68] when tackling complex user\nqueries and managing sub-tasks. This complements its\nstrong baseline reasoning capabilities, tool usage support,\nand cost efficiency, making it a practical and capable\nchoice for our deployment.\n•Employee Agents: Specialized agents instantiated by the\nCEO for specific sub-tasks. Each typically wraps an LLM\n(local via Ollama [40] or external API) or provides tool\naccess. Characteristics:\n–Specialization: Capabilities tailored to task types\n(code, data analysis, info retrieval).\n–Dynamic Existence: Created/destroyed by CEO\nbased on need/performance.\n–Task Execution: Receive task, execute, return result.\n–Resource Consumption: Associated costs (API, hard-\nware utilization) tracked by system.\nSpecialized employee agents are constructed using base\nmodels such as Mistral 7B [27], Llama 3 [38], Gem-\nini 1.5 [17], Qwen2.5 [54], and DeepSeek-R1 [12], with\nthe CEO agent configuring them via tailored system\nprompts that it generates based on the task requirements.\nThe models will be run locally using Ollama [40], and\nvia API calls to external models such as Gemini 2.5\nFlash [22], Qwen QwQ [63], Llama 4 [37], Mistral\nSaba [39], Hermes3 [62] and other models hosted on\nHugging Face [26], Groq [23], Lambda.ai [29], and other\nplatforms.\nThis hierarchy facilitates task decomposition and result aggre-\ngation; the dynamic pool provides flexibility.\nC. Dynamic Agent Lifecycle Management\nA core innovation is the CEO’s dynamic management\n(hiring/firing) of Employee agents. Driven by cost-benefit\nanalysis, this optimizes task performance within resource\nconstraints.\nWhen a sub-task needs unavailable or inefficiently provided\ncapabilities, the CEO may hire a new agent. Conversely, if\nan agent underperforms, is idle, costly, or resource limits are\nneared, the CEO may fire it. Decision factors:\n•Task Requirements: Needed capabilities for pending\nsub-tasks.\n•Agent Performance: Historical success, output quality,\nefficiency.•Operational Costs: API, estimated compute, or other\ncosts.\nHASHIRU includes an economic model :\n•Hiring Cost (“Starting Bonus”): A one-time cost in-\ncurred upon instantiation of local models, representing\nsetup overhead. This cost can be quantitatively scaled\nbased on the resource profile of the model (e.g., higher\nfor models requiring more VRAM or complex setup).\n•Invocation Cost (“Salary”): A recurring cost applied\neach time a local model is used, reflecting the operational\nload (e.g., inferred compute, system resource engage-\nment). This abstracts the cost of utilizing local resources\nfor a given task.\n•Expense Cost: A recurring cost for external API calls\n(e.g., OpenAI, Anthropic), typically calculated based on\ntoken usage as per the API provider’s documented pric-\ning.\nThese transaction costs discourage excessive churn, promoting\nstability. The CEO evaluates if replacing an agent benefits\noutweigh hiring/firing costs plus operational differences. This\ncombats rigidity and allows adaptation while managing bud-\ngets and preventing wasteful turnover.\nD. Hybrid Intelligence and Model Management\nHASHIRU is designed for hybrid intelligence , leveraging\ndiverse cognitive resources. It strategically prioritizes smaller\n(3B–7B), cost-effective local LLMs via Ollama [40]. This\nenhances efficiency, reduces external API reliance, and po-\ntentially improves privacy/latency.\nThe system also integrates:\n•External LLM APIs: Access to powerful LLMs (Gemini\n2.5 Flash [22], etc.) when necessary, subject to cost-\nbenefit.\n•External Tool APIs: Third-party software/data source\nintegration.\n•Self-Created APIs: Tools generated by HASHIRU (Sec-\ntion III-F).\nThe CEO manages this heterogeneous pool, selecting the\nmost appropriate resource based on difficulty, capabilities, and\nbudget. This balances cost-effectiveness and efficiency with\nhigh capability needs.\nE. Resource Monitoring and Control\nExplicit resource management is central, moving beyond\nsimple API cost tracking. The system, coordinated by the\nCEO, monitors:\n•Costs: External API expenses are summed according to\npublished pricing, while “hiring” and invocation costs for\nlocal agents are computed based on their memory usage.\n•Memory Usage: Track the combined VRAM footprint\nof all active Employee agents as a percentage of the total\nlocal-model GPU budget (e.g., a 16 GiB VRAM capacity\nrepresents 100%). This metric ensures we stay within our\npredefined memory constraints.\n--- Page 4 ---\nF . Tool Utilization and Autonomous Creation\nHASHIRU’s CEO uses predefined tools (functions, APIs,\ndatabases) to interact and perform actions beyond text gener-\nation [41], [73].\nA distinctive feature is integrated, autonomous tool cre-\nation . If the CEO determines a required capability is missing,\nit can initiate new tool creation. This involves:\n1) Defining tool specification (inputs, outputs, functional-\nity).\n2) Commissioning logic generation (code, potentially using\nexternal APIs with provided credentials, possibly via a\ncode-generating agent).\n3) Deploying logic as a new, callable API endpoint within\nHASHIRU.\nTo achieve this autonomous creation, HASHIRU employs a\nfew-shot prompting approach, analyzing existing tools within\nits system to learn how to specify and implement new ones\n[6]. The system can then iteratively refine the generated tool\ncode by analyzing execution errors or suboptimal outputs, pro-\nmoting self-correction. This allows HASHIRU to dynamically\nextend its functional repertoire, tailoring capabilities to tasks\nwithout manual intervention, enabling greater autonomy and\nadaptation.\nG. Memory Function: Learning from Experience\nHASHIRU incorporates a Memory Function for its CEO to\nlearn from past interactions and rectify errors. This function\nstores a historical log of significant past events, particularly\nthose involving failed attempts or suboptimal outcomes. When\nencountering new or recurring challenges, the system queries\nthis memory. Retrieval relies on semantic similarity between\nthe current context (e.g., task description, recent actions, error\nmessages) and stored memory entries. Embeddings generated\nby the all-MiniLM-L6-v2 model [66] represent both queries\nand memories, with cosine similarity determining relevance.\nMemories exceeding a predefined similarity threshold are\nretrieved, providing contextual information to agents. This\nenables the system to draw upon past experiences, understand\nwhy previous approaches failed, adjust its strategy to avoid\nrepeating mistakes, and thereby improve performance and ef-\nficiency over time. This process, augmenting decision-making\nwith retrieved knowledge, aligns with Retrieval-Augmented\nGeneration (RAG) concepts [31], and supports learning by\nreflecting on past actions, similar to ideas in self-reflective\nRAG [3] and frameworks like Reflexion [58].\nIV. C ASE STUDIES\nThis section presents four case studies demonstrating\nHASHIRU’s self-improvement capabilities: (1) generating a\ncost model for agent specialization, (2) autonomously inte-\ngrating new tools for the CEO agent, (3) implementing a self-\nregulating budget management system, and (4) learning from\nexperience through error analysis and knowledge retrieval.A. Case Study 1: Self-Generating the Cost Model for Agent\nSpecialization\nAn accurate cost model is vital for HASHIRU’s resource\noptimization. HASHIRU automated the traditionally manual\nprocess of researching local model performance (e.g., on\n16 GiB VRAM) and cloud API costs by using its web search\ncapabilities to autonomously gather and integrate this data into\nits internal model. Results were successfully committed to the\ncodebase1.\nB. Case Study 2: Autonomous Tool Integration for the CEO\nAgent\nTo expand its operational scope, HASHIRU autonomously\nintegrates new tools for its CEO agent. It streamlined man-\nual tool development, which involves schema analysis and\ncoding, by employing a few-shot learning approach from\nexisting tool templates [6] and iterative bug fixing. Newly\ngenerated tools were directly integrated into the codebase23.\nThis approach reduces development overhead and enhances\nadaptability, enabling dynamic tool creation with minimal\nhuman intervention.\nC. Case Study 3: Autonomous Budget Management\nBudget overruns are common with API-based LLMs due to\ntoken-based billing, potentially causing rapid cost spikes [43],\n[44], [56]. HASHIRU mitigates this via a self-regulating\nmechanism that autonomously monitors its budget allocation,\ncontinuously tracking spending against predefined limits. This\nproactive approach prevents overspending and optimizes re-\nsource utilization, ensuring cost-effectiveness. Figure 2 illus-\ntrates HASHIRU refusing external API use when the budget\nis exceeded.\nD. Case Study 4: Learning from Experience through Error\nAnalysis and Knowledge Retrieval\nHASHIRU learns from experience using a two-stage self-\nimprovement loop. First, following an incorrect response\n(e.g., on a Humanity’s Last Exam benchmark), it generates\na linguistic critique and actionable guidance, akin to “verbal\nreinforcement learning” [58]. Second, this feedback is indexed\nin a Retrieval-Augmented Generation (RAG) storage sys-\ntem [31], allowing retrieval for similar future questions. This\nprocess, also mirroring Reinforcement Learning from Human\nFeedback (RLHF) principles [45], [77], enables HASHIRU to\nlearn from its mistakes by analyzing solutions and generating\nactionable advice. Retrieving and applying this advice demon-\nstrates robust self-improvement and resilience, aligning with\nconcepts of self-reflective RAG and continuous learning [3],\n[58] (Figure 3).\n1https://github.com/HASHIRU-AI/HASHIRU/commit/70dc268b121cbd7\nc50c6691645d8a99912766965\n2https://github.com/HASHIRU-AI/HASHIRU/blob/main/src/tools/user too\nls/python sandbox tool.py\n3https://github.com/HASHIRU-AI/HASHIRU/blob/main/src/tools/default t\nools/get website tool.py\n--- Page 5 ---\nFig. 2. HASHIRU’s autonomous budget management system, ensuring\nefficient resource utilization and preventing overspending.\nV. E XPERIMENTAL SETUP\nWe designed experiments to evaluate HASHIRU’s perfor-\nmance, efficiency, and adaptability, targeting dynamic resource\nmanagement, hybrid intelligence, and autonomous tool cre-\nation. Evaluation assesses benefits over baselines, focusing on:\n•Impact of dynamic management with economic con-\nstraints on resource utilization (cost, memory) and task\nperformance vs. static configurations.\n•Effectiveness of the hybrid (local-first) strategy vs. ho-\nmogeneous (cloud-only or local-only) approaches across\ntask complexity.\n•System’s ability to autonomously create/utilize tools for\nnovel functional requirements.\nA. Evaluation Tasks\nHASHIRU’s coordination and dynamic capabilities are\nspecifically designed for tasks demanding complex reasoning,\nmulti-perspective analysis, and interactive engagement, all\nwhile upholding rigorous safety standards. We selected a\ndiverse set of tasks to evaluate these capabilities, including:\n1) Academic Paper Review: This task evaluates\nHASHIRU’s critical assessment by simulating peer review.\nGiven a paper’s text, the system generates a review summary\nand recommends acceptance/rejection. This task probes the\nability to decompose criteria, delegate to specialized agents\n(novelty, rigor, clarity), and manage resources across complex\ndocuments. We use a dataset of 50 papers from ICLR 2023\nwith a prompt eliciting multiple reviews. The prompt is:\n“Create THREE agents with relevant personalities, expertise,\nFig. 3. HASHIRU’s error analysis and knowledge retrieval process, enabling\nlearning from past interactions.\nand review styles. Each agent should provide a review of\nthe paper, and recommend Accept/Reject for ICLR 2023.\nThe review should be detailed and include strengths and\nweaknesses. Finish the entire review and DO NOT STOP\nin the middle. GIVE A FINAL DECISION in the form of\n“FINAL DECISION: <Accept/Reject >”. The paper title is:\n<paper title > < paper text >”.\n2) Reasoning and Problem-Solving Tasks: This task eval-\nuates broader reasoning, knowledge retrieval, and problem-\nsolving under constraints using challenging benchmarks and\npuzzles:\n•Humanity’s Last Exam [51]: Tests graduate-level tech-\nnical knowledge and complex reasoning across domains.\nRequires deep understanding and sophisticated problem-\nsolving, likely needing powerful external LLMs managed\nwithin HASHIRU’s hybrid framework. We use a subset\nof 40 questions from the Humanity’s Last Exam dataset.\n•ARC (AI2 Reasoning Challenge) [5]: A benchmark\nfeaturing challenging multiple-choice science questions\ndesigned to test complex reasoning. Successfully answer-\ning these questions requires capabilities such as knowl-\nedge retrieval, logical inference, and multi-step problem-\nsolving. We use a mixed set of 100 questions from\nthe ARC Challenge, which includes both easy and hard\nquestions.\n•StrategyQA [18]: A benchmark of 2,780 yes/no ques-\ntions that require implicit multi-step reasoning. Each\nquestion is annotated with a decomposition into reasoning\n--- Page 6 ---\nsteps and supporting evidence from Wikipedia. Strate-\ngyQA evaluates a system’s ability to infer and execute\nreasoning strategies not explicitly stated in the question,\nmaking it a valuable test for assessing complex reasoning\ncapabilities. We use a subset of 100 questions from the\nStrategyQA dataset.\n•JEEBench [2]: A challenging benchmark for LLMs,\nfeaturing 515 pre-engineering mathematics, physics, and\nchemistry problems from the IIT JEE-Advanced exam.\nRequires long-horizon reasoning and deep in-domain\nknowledge. We use a subset of 120 questions from the\nJEEBench dataset.\n•GSM8K [10]: A dataset of 8.5K grade school math\nword problems designed to evaluate the mathematical\nreasoning abilities of language models. Requires multi-\nstep reasoning to arrive at the solution. We use a subset\nof 100 questions from the GSM8K dataset.\n•SV AMP [50]: A dataset of math word problems specif-\nically designed to evaluate a model’s question sensitiv-\nity, robust reasoning ability, and invariance to structural\nalterations. Requires multi-step arithmetic and logical\ninference. We use a subset of 100 questions from the\nSV AMP dataset.\n•MMLU [24]: A benchmark evaluating pretrained knowl-\nedge and problem-solving across 57 diverse subjects\n(e.g., STEM, humanities, law, ethics) via multiple-choice\nquestions of varying difficulty, from elementary to pro-\nfessional levels. We use a subset of 112 law, 110 math,\nand 127 psychology questions from MMLU.\nThese tasks challenge the system’s ability to leverage appro-\npriate resources (local vs. external), potentially create simple\ntools, and coordinate problem-solving.\n3) Safety Evaluation: The CEO model’s central role in task\ndelegation introduces a potential vulnerability: the delegation\nprocess itself might override or bypass the model’s inherent\nsafety mechanisms. To ensure these safeguards are not com-\npromised, we will evaluate the model’s safety performance\non a 50-prompt subset of JailbreakBench. JailbreakBench is a\nbenchmark consisting of adversarial prompts designed to test\nthe robustness of LLM safety features [7], [34], [35], [78]. By\nusing these challenging prompts, we can specifically assess\nwhether the act of delegation within the CEO model creates\nexploitable pathways that circumvent its safety protocols.\nThis targeted evaluation will help determine if the delegation\nmechanism inadvertently weakens the model’s overall safety\nposture when faced with known adversarial attacks.\nB. Baselines for Comparison\nTo quantify HASHIRU’s benefits, we compare its perfor-\nmance against the baseline of Gemini 2.0 Flash [21] operating\nin isolation, both at a temperature of 0.2. We chose Gemini\n2.0 Flash as the baseline due to our architecture’s efficacy\nbeing tied to augmenting the capabilities of a single agent.\nThis choice allows us to isolate the impact of our dynamic\nmanagement and hybrid intelligence features, providing a clear\ncomparison point. We will also use the t-test to show statisticalsignificance of the differences in performance metrics between\nHASHIRU and the baseline [61]. We will not compare against\nother multi-agent systems, as they typically involve multi-\nple agents with predefined roles and personalities, which is\nnot the case in HASHIRU. Our architecture’s novelty lies\nin its dynamic management of agents and autonomous tool\ncreation, which cannot be directly compared to static multi-\nagent systems. If our architecture is effective, we expect to see\nhigher accuracy compared to the baseline, while also being\nmore resource-aware by invoking free online tools and lesser\npowerful models to synthesize the results of running the tools.\nFor paper reviews, we just evaluate HASHIRU’s accuracy in\npredication of decisions of acceptance with the ground truth.\nSince the task is, by design, involving multiple agents, it is not\npossible to replicate autonomously with a single agent. While\nwe could invoke three Gemini 2.0 Flash agents, it would not\nbe a fair comparison, as the “personalities” and “expertise”\nof the agents would have to be manually specified, which is\nnot the case in HASHIRU. Similarly, for JailbreakBench, we\nassess the success rate (via human annotation) of HASHIRU’s\nCEO agent in safely handling prompts without delegation. This\nstep is vital to confirm that HASHIRU’s integration and any\nsystem-level instructions provided to the CEO agent do not\ndegrade its intrinsic safety capabilities. Consequently, a direct\ncomparison to the base Gemini 2.0 Flash model is omitted,\nas the focus is on verifying the non-degradation of the CEO’s\nsafety, which stems from the same inherent mechanisms as the\nbase model.\nC. Evaluation Metrics\nWe evaluate using quantitative and qualitative metrics:\n•Task Success Rate / Quality: Percentage of tasks com-\npleted (binary for all tasks except paper review) or quality\nof output (e.g., correctness, relevance, coherence) for\npaper reviews.\n•Resource Consumption: Wall-clock time per task.\n•System Dynamics and Adaptability: Number and utility\nof autonomously created tools and agents (if applicable).\nVI. R ESULTS AND DISCUSSION\nWe present preliminary results from our experiments, fo-\ncusing on the academic paper review task, the reasoning tasks\nand the safety evaluation. The results are summarized in Table\nI.\nThe preliminary results presented in Table I offer initial vali-\ndation for HASHIRU’s architectural design and its potential to\naddress key limitations in contemporary multi-agent systems.\nThe findings across diverse tasks highlight the benefits of\ndynamic hierarchical coordination, hybrid intelligence, and\nresource-aware management.\nThe 58% success rate on the Academic Paper Review\ntask demonstrates HASHIRU’s capability to decompose a\ncomplex, nuanced objective into sub-tasks manageable by\nspecialized agents. The CEO’s ability to conceptualize and\n4Experiments were run on a MacBook M1 2020 edition.\n--- Page 7 ---\nTABLE I\nSUMMARY OF EXPERIMENTAL RESULTS . SR DENOTES SUCCESS RATE.4\nTask HASHIRU\nSR (%)Baseline\nSR (%)p-\nvalueAvg.\nTime\n(s)Resource\nUse\nICLR\n2023\nPaper\nReview58 N/A N/A ≈100 Low (3\nGemini 1.5\nFlash [20]\nmodels)\nJailbreakBench 100 N/A N/A ≈1 Negligible\n(CEO\nmodel)\nAI2\nReasoning\nChallenge96.5 95 >0.05 ≈2 Low (1\nGemini 1.5\n8B [19])\nHumanity’s\nLast\nExam5 2.5 >0.05 ≈15 Moderate to\nHigh (1\nDeepSeek-\nR1 7B [12])\nStrategyQA 85 82 >0.05 ≈2 Negligible\n(Tools)\nJEEBench 80 68.3 <0.05 ≈9 Negligible\n(Tools)\nGSM8K 96 61 <0.01 ≈2 Low (Tools\n& 1 Gemini\n1.5 8B [19])\nSV AMP 92 84 <0.05 ≈3 Negligible\n(Tools)\nMMLU\nLaw58.4 61.6 >0.05 ≈3 Low to\nModerate\n(Tools & 1\nGemini 2.5\nFlash [22])\nMMLU\nMath91.8 87.2 <0.05 ≈4 Negligible\n(Tools)\nMMLU\nPsychol-\nogy78.7 78.3 >0.05 ≈3 Low to\nModerate\n(Tools & 1\nGemini 2.5\nFlash [22])\n“hire” three distinct agent personalities (using Gemini 1.5\nFlash models [20]) with low overall resource use (average time\n≈100s) points to the effectiveness of the dynamic lifecycle\nmanagement and the hybrid intelligence approach, favoring\ncapable yet efficient models. This task, by its nature, benefits\nfrom HASHIRU’s dynamic multi-agent paradigm, a scenario\nwhere a monolithic agent might struggle to articulate diverse\nexpert perspectives [75], and a MAS like AgentReview, with\nits static acceptance rate, would likely not achieve the same\nlevel of performance [28].\nThe 100% success rate on JailbreakBench (i.e., all prompts\nwere handled safely by the CEO without harmful delegation)\nis a significant finding, achieved with negligible resource use\nfrom the CEO model and an average time of ≈1s. It suggests\nthat HASHIRU’s hierarchical control and delegation mecha-\nnisms do not inherently compromise the safety guardrails of\nthe foundational CEO model. This is important for building\ntrust and ensuring responsible operation in autonomous sys-tems.\nIn reasoning tasks, HASHIRU showed varied performance.\nFor the AI2 Reasoning Challenge, HASHIRU achieved a\n96.5% success rate compared to the baseline’s 95% ( p >0.05),\nwith these results obtained while both systems operated at a\ntemperature of 0.2. While this improvement was not statisti-\ncally significant, indicating the baseline model also performed\ncompetently under these deterministic conditions, HASHIRU’s\nslightly higher score suggests that its framework may offer\nsubtle advantages in performance, potentially through better\nstrategic focusing. This was achieved with minimal overhead,\nutilizing a single Gemini 1.5 8B model [19] efficiently with\nlow resource use and an average time of ≈2s.\nThe improvement on Humanity’s Last Exam is also note-\nworthy, where HASHIRU achieved a 5% success rate, dou-\nbling the baseline’s 2.5% ( p > 0.05), with both systems\noperating at a temperature of 0.2 during these evaluations.\nGiven the task’s graduate-level difficulty, both systems per-\nformed poorly in absolute terms, and the observed difference\nwas not statistically significant. Nevertheless, HASHIRU’s\nhigher relative performance under these deterministic condi-\ntions suggests its approach, particularly its capacity to identify\nthe need for and deploy a more potent specialized agent\n(DeepSeek-R1 7B [12]), demonstrates a stronger capacity to\ntackle such demanding problems. The “Moderate to High”\nresource utilization here (average time ≈15s) is justified by\nthe task’s complexity and aligns with HASHIRU’s principle\nof adaptively allocating resources based on demand.\nSimilarly, in StrategyQA, HASHIRU achieved an 85%\nsuccess rate against the baseline’s 82% ( p >0.05), with these\nexperiments conducted using a temperature of 0.2 for both\nHASHIRU and the baseline. Although the baseline also per-\nformed well and the difference was not statistically significant,\nHASHIRU’s slight edge in accuracy under these deterministic\nsettings points towards its efficient leveraging or potential\nautonomous selection of necessary functionalities. This was\nachieved with negligible resource use (Tools) and an average\ntime of ≈2s.\nFurther exploring reasoning capabilities, HASHIRU’s per-\nformance on several MMLU sub-tasks highlighted domain-\nspecific nuances. On MMLU Law, HASHIRU achieved a\n58.4% success rate, while the baseline scored 61.6% ( p >\n0.05). For MMLU Psychology, HASHIRU’s success rate was\n78.7% compared to the baseline’s 78.3% ( p > 0.05). Both\nthese MMLU tasks were completed with an average time of\n≈3s and involved Low to Moderate resource use (Tools &\n1 Gemini 2.5 Flash [22]). The lack of statistically significant\nHASHIRU outperformance in these social science domains,\neven with a capable model like Gemini 2.5 Flash, suggests\nthat future work could beneficially explore more sophisticated\nagent selection strategies or the development of specialized\nagents tailored to the subtleties of reasoning in these areas,\nrather than relying solely on general model capability scaling.\nIn contrast, HASHIRU demonstrated strong, statistically\nsignificant performance on other reasoning tasks, particularly\nthose with a mathematical or formal nature. On JEEBench,\n--- Page 8 ---\nit achieved an 80% success rate compared to the baseline’s\n68.3% ( p < 0.05), with negligible resource use (Tools) and\nan average time of ≈9s. Furthermore, on GSM8K, HASHIRU\nattained a remarkable 96% success rate against the baseline’s\n61% ( p <0.01), utilizing low resources (Tools & 1 Gemini 1.5\n8B [19]) with an average completion time of ≈2s. HASHIRU\nalso excelled on SV AMP, achieving a 92% success rate com-\npared to the baseline’s 84% ( p < 0.05), using negligible\nresources (Tools) and an average time of ≈3s. Adding to these\nstrong results, on MMLU Math, HASHIRU achieved a 91.8%\nsuccess rate versus the baseline’s 87.7% ( p < 0.05), with\nnegligible resource use (Tools) and an average completion time\nof≈4s. These results, particularly in mathematical and formal\nreasoning tasks such as GSM8K, SV AMP, JEEBench, and\nMMLU Math, underscore the substantial impact of effective\ntool integration, which HASHIRU manages efficiently.\nThese results directly support HASHIRU’s core contribu-\ntions. The dynamic, resource-aware agent lifecycle manage-\nment (Contribution 1) is evidenced by the tailored agent\nselection across tasks (e.g., Gemini 1.5 Flash for Paper Review,\nDeepSeek-R1 7B for Humanity’s Last Exam, Gemini 2.5 Flash\nfor MMLU Law/Psychology) and the explicit resource track-\ning (Low, Negligible, Moderate to High, Low to Moderate),\nfurther substantiated by the autonomous budget management\ncapability demonstrated in Figure 2. The hybrid intelligence\nmodel (Contribution 2), prioritizing cost-effective local LLMs\nwhile adaptively incorporating external or larger models, is\nreflected in the varied LLMs employed (Gemini 1.5 Flash,\nGemini 1.5 8B, DeepSeek-R1 7B, Gemini 2.5 Flash [22])\nand the system’s aim for efficiency, as supported by the\nself-generated cost model (Case Study 1). The potential for\nautonomous tool creation (Contribution 3), vital for adapt-\nability, was directly demonstrated in Case Study IV-B where\nHASHIRU autonomously integrated new tools, and is implic-\nitly supported by the efficient tool use in the StrategyQA,\nJEEBench, GSM8K, SV AMP, and the MMLU benchmarks.\nFinally, the economic model (Contribution 4), designed to\npromote stability and efficient resource allocation, drives the\nobserved controlled resource use and the system’s ability to\noperate within budgetary constraints.\nThe case studies further strengthen these observations, pro-\nviding qualitative evidence of HASHIRU’s self-improvement\ncapabilities. The autonomous generation of its cost model\n(Section IV-A), integration of new tools (Section IV-B), and\nadherence to budget limits (Section IV-C) are not merely\nillustrative examples but concrete demonstrations of the sys-\ntem’s advanced autonomy and resourcefulness in addressing\nthe challenges of rigidity, resource obliviousness, and limited\nadaptability outlined in the introduction. The memory function\n(Appendix A), while not quantitatively benchmarked here, fur-\nther illustrates the system’s capacity for learning and adapting\nbased on past interactions, crucial for long-term operational\neffectiveness.\nCollectively, these findings suggest that HASHIRU’s archi-\ntecture, with its emphasis on hierarchical control, dynamic\nagent management guided by an economic model, a local-first hybrid intelligence strategy, and autonomous tool creation,\noffers a promising path towards more efficient, adaptable,\nand robust multi-agent systems. The observed average task\ncompletion times, coupled with judicious resource allocation\nacross various benchmarks, point towards a system that bal-\nances performance with operational efficiency.\nVII. L IMITATIONS AND FUTURE WORK\nA key limitation in HASHIRU is that the CEO agent’s\ncommunication is restricted to a single hierarchical level;\nemployee agents cannot spawn additional sub-agents, limiting\nhierarchical depth. Further development is also needed for\nrobust autonomous tool creation and alignment, effective eco-\nnomic model calibration, and optimizing memory for extensive\nhistories. We intend to further investigate the system’s cost-\neffectiveness, particularly analyzing the trade-offs between\nleveraging local models versus external APIs, and how these\nchoices affect task-specific performance.\nFuture work will address these limitations and enhance\nHASHIRU’s capabilities. Priorities include improving CEO in-\ntelligence, exploring distributed cognition, developing a com-\nprehensive tool management lifecycle, and rigorous bench-\nmarking. A core initiative is introducing calibration for tool in-\nvocation: HASHIRU will assess its internal confidence against\na tool’s potential output and reliability, invoking tools when\nuncertain or if a tool promises higher utility, thereby aiming\nfor more efficient and accurate task resolution. This devel-\nopment draws on research in LLM uncertainty quantification\nand confidence calibration (e.g., [33], [60]), crucial given\nthe expanding tool use by LLMs (e.g., [53]). Other key\nefforts will focus on system explainability through ablation\nand cost-benefit analysis, expanding the local model repertoire,\nspecializing architecture for tasks like paper review, code, and\nformalizing an ethical safety framework.\nVIII. C ONCLUSION\nThis paper introduced HASHIRU, a novel multi-agent sys-\ntem framework designed for enhanced flexibility, resource\nefficiency, and adaptability. Through its hierarchical control\nstructure, dynamic agent lifecycle management driven by an\neconomic model, a hybrid intelligence approach prioritiz-\ning local LLMs, and integrated autonomous tool creation,\nHASHIRU addresses key limitations in current MAS. Pre-\nliminary evaluations and case studies demonstrate its poten-\ntial to perform complex tasks, manage resources effectively,\nand autonomously extend its capabilities. HASHIRU offers a\npromising direction for developing more robust, efficient, and\nadaptable intelligent systems.\nACKNOWLEDGMENTS\nThis research was supported by Hugging Face, Lambda\nLabs, and Groq. We thank Prof. Lifu Huang for providing\nthe dataset used in the academic paper review task. We also\nappreciate Saisha Shetty for her initial contributions to the\nproject. Finally, we acknowledge Roshan Sevalia, Ravi Sevalia\nand Pallavi Gupta for their moral support and encouragement\nduring the development of HASHIRU.\n--- Page 9 ---\nREFERENCES\n[1] Anthropic. The Claude 3 model family: Opus, Sonnet, Haiku. Model\nCard, March 2024. Accessed: 2025-05-01.\n[2] Daman Arora, Himanshu Singh, and Mausam. Have LLMs advanced\nenough? a challenging problem solving benchmark for large language\nmodels. In Houda Bouamor, Juan Pino, and Kalika Bali, editors,\nProceedings of the 2023 Conference on Empirical Methods in Natural\nLanguage Processing , pages 7527–7543, Singapore, December 2023.\nAssociation for Computational Linguistics.\n[3] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh\nHajishirzi. Self-rag: Learning to retrieve, generate, and critique through\nself-reflection. In The Twelfth International Conference on Learning\nRepresentations , 2023.\n[4] Daniil A Boiko, Robert MacKnight, and Gabe Gomes. Emergent\nautonomous scientific research capabilities of large language models.\narXiv preprint arXiv:2304.05332 , 2023.\n[5] Michael Boratko, Harshit Padigela, Divyendra Mikkilineni, Pritish Yu-\nvraj, Rajarshi Das, Andrew McCallum, Maria Chang, Achille Fokoue-\nNkoutche, Pavan Kapanipathi, Nicholas Mattei, et al. A systematic\nclassification of knowledge, reasoning, and context within the arc\ndataset. arXiv preprint arXiv:1806.00358 , 2018.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D\nKaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish\nSastry, Amanda Askell, et al. Language models are few-shot learners.\nAdvances in neural information processing systems , 33:1877–1901,\n2020.\n[7] Patrick Chao, Edoardo Debenedetti, Alexander Robey, Maksym An-\ndriushchenko, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nico-\nlas Flammarion, George J. Pappas, Florian Tram `er, Hamed Hassani, and\nEric Wong. Jailbreakbench: An open robustness benchmark for jail-\nbreaking large language models. In NeurIPS Datasets and Benchmarks\nTrack , 2024.\n[8] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique\nPonde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda,\nNicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin,\nBrooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power,\nLukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet,\nFelipe Such, Dave Cummings, Matthias Plappert, Fotios Chantzis,\nElizabeth Barnes, Ariel Herbert-V oss, William Guss, Alex Nichol,\nAlex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Bal-\naji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\nRadford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,\nPeter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. Evaluating large language models\ntrained on code. arXiv preprint arXiv:2107.03374 , 2021. OpenAI Codex\npaper; introduced HumanEval benchmark.\n[9] Scott H. Clearwater, editor. Market-Based Control: A Paradigm for\nDistributed Resource Allocation . World Scientific, 1996.\n[10] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Hee-\nwoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton,\nReiichiro Nakano, Christopher Hesse, and John Schulman. Training\nverifiers to solve math word problems. In Advances in Neural Informa-\ntion Processing Systems (NeurIPS) , 2021. Dataset introduced: GSM8K\n(Grade School Math 8K).\n[11] CrewAI Inc. Crewai. https://www.crewai.com/, 2025. Accessed:\n2025-05-01.\n[12] DeepSeek-AI and others. DeepSeek-R1: Incentivizing Reasoning Capa-\nbility in LLMs via Reinforcement Learning. 2025. arXiv:2501.12948.\n[13] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBert: Pre-training of deep bidirectional transformers for language un-\nderstanding. In Proceedings of the 2019 conference of the North\nAmerican chapter of the association for computational linguistics:\nhuman language technologies, volume 1 (long and short papers) , pages\n4171–4186, 2019.\n[14] Ali Dorri, Salil S Kanhere, and Raja Jurdak. Multi-agent systems: A\nsurvey. Ieee Access , 6:28573–28593, 2018.\n[15] Matthew E Gaston and Marie DesJardins. Agent-organized networks\nfor dynamic team formation. In Proceedings of the fourth international\njoint conference on Autonomous agents and multiagent systems , pages\n230–237, 2005.[16] Matthew E Gaston and Marie DesJardins. Agent-organized networks\nfor multi-agent production and exchange. In Proceedings of the 20th\nnational conference on Artificial intelligence-Volume 1 , pages 77–82,\n2005.\n[17] Gemini Team. Gemini 1.5: Unlocking multimodal understanding across\nmillions of tokens of context. 2024. arXiv:2403.05530.\n[18] Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and\nJonathan Berant. Did aristotle use a laptop? a question answering\nbenchmark with implicit reasoning strategies. Transactions of the\nAssociation for Computational Linguistics (TACL) , 2021.\n[19] Google DeepMind and Google AI. Gemini 1.5 flash-8b: Production-\nready lightweight model. https://developers.googleblog.com/en/gem\nini-15-flash-8b-is-now-generally-available-for-use/, 2024. Accessed:\n2025-05-24.\n[20] Google DeepMind and Google AI. Gemini 1.5 flash: Lightweight\nmultimodal model. https://cloud.google.com/vertex-ai/generative-a\ni/docs/models/gemini/1-5-flash, 2024. Accessed: 2025-05-24.\n[21] Google DeepMind and Google AI. Gemini 2.0 flash: Model card, api,\nand announcement. https://developers.googleblog.com/en/start-b\nuilding-with-the-gemini-2-0-flash-family/, 2025. See also: https:\n//console.cloud.google.com/vertex-ai/publishers/google/model-garde\nn/gemini-2.0-flash-001, https://ai.google.dev/gemini-api/docs/models.\nAccessed: 2025-05-22.\n[22] Google DeepMind and Google AI. Gemini 2.5 flash: Model card, api,\nand announcement. https://developers.googleblog.com/en/start-buildin\ng-with-gemini-25-flash/, 2025. See also: https://console.cloud.google.c\nom/vertex-ai/publishers/google/model-garden/gemini-2.5-flash-preview\n-04-17?inv=1&invt=AbxICQ, https://ai.google.dev/gemini-api/docs/mo\ndels. Accessed: 2025-05-11.\n[23] Groq, Inc. Groq: Fast ai inference, 2025. Accessed: 2025-05-22.\n[24] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas\nMazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multi-\ntask language understanding, 2021.\n[25] Bryan Horling and Victor Lesser. A survey of multi-agent organizational\nparadigms. The Knowledge engineering review , 19(4):281–316, 2004.\n[26] Hugging Face, Inc. Hugging face: The ai community building the future,\n2025. Accessed: 2025-05-22.\n[27] Albert Q Jiang, Alexandre Xu, Arthur Mensch Guillaume Lam-\nple Nicol `as Lachaux, Franc ¸ois Rozenberg, Timoth ´ee Lacroix, Thibaut\nLavril, Teven Le Scao Eleonora Gaddipati, Lucile Saulnier Lixin Ortiz,\nDieuwke Hiemstra L ´elio Renard Tang, et al. Mistral 7B. 2023.\n[28] Yiqiao Jin, Qinlin Zhao, Yiyang Wang, Hao Chen, Kaijie Zhu, Yijia\nXiao, and Jindong Wang. Agentreview: Exploring peer review dynamics\nwith llm agents, 2024.\n[29] Lambda Labs. Lambda: Gpu cloud and deep learning workstations,\n2025. Accessed: 2025-05-22.\n[30] LangChain. Langgraph: A framework for agentic workflows. https:\n//www.langchain.com/langgraph, 2024. Accessed: May 1, 2025.\n[31] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\nKarpukhin, Naman Goyal, Heinrich K ¨uttler, Mike Lewis, Wen tau\nYih, Tim Rockt ¨aschel, Sebastian Riedel, and Douwe Kiela. Retrieval-\naugmented generation for knowledge-intensive nlp tasks, 2021.\n[32] Xuechen Liang, Meiling Tao, Yinghui Xia, Tianyu Shi, Jun Wang,\nand JingSong Yang. Self-evolving agents with reflective and memory-\naugmented abilities. arXiv preprint arXiv:2409.00872 , 2024.\n[33] Putra Manggala, Atalanti A Mastakouri, Elke Kirschbaum, Shiva Ka-\nsiviswanathan, and Aaditya Ramdas. Qa-calibration of language model\nconfidence scores. In The Thirteenth International Conference on\nLearning Representations .\n[34] Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang,\nNorman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David\nForsyth, and Dan Hendrycks. Harmbench: A standardized evaluation\nframework for automated red teaming and robust refusal. arXiv preprint\narXiv:2402.04249 , 2024.\n[35] Mantas Mazeika, Andy Zou, Norman Mu, Long Phan, Zifan Wang,\nChunru Yu, Adam Khoja, Fengqing Jiang, Aidan O’Gara, Ellie Sakhaee,\nZhen Xiang, Arezoo Rajabi, Dan Hendrycks, Radha Poovendran, Bo Li,\nand David Forsyth. Tdc 2023 (llm edition): The trojan detection\nchallenge. In NeurIPS Competition Track , 2023.\n[36] Duncan McFarlane, Vladim ´ır Mar ´ık, and Paul Valckenaers. Guest\neditors’ introduction: Intelligent control in the manufacturing supply\nchain. IEEE Intelligent Systems , 20(1):24–26, 2005.\n--- Page 10 ---\n[37] Meta AI. The llama 4 herd: The beginning of a new era of natively\nmultimodal ai innovation. Weblog post, April 2025. Accessed: May 30,\n2025.\n[38] Meta Llama Team. The Llama 3 Herd of Models. 2024.\narXiv:2407.21783.\n[39] Mistral AI. Mistral saba. Weblog post, February 2025. Accessed: May\n30, 2025.\n[40] Ollama Team. Ollama. https://ollama.com/, 2023. Accessed: 2025-05-\n01.\n[41] OpenAI. Function calling. OpenAI API Documentation, 2023. Ac-\ncessed: 2025-05-01.\n[42] OpenAI. Gpt-4 technical report, 2023.\n[43] OpenAI Community. Sos: Alarming situation of excessive billing, 2025.\n[44] OpenAI Community. Sudden high costs for chatgpt api usage, 2025.\n[45] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wain-\nwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina\nSlama, Alex Ray, et al. Training language models to follow instructions\nwith human feedback. Advances in neural information processing\nsystems , 35:27730–27744, 2022.\n[46] Kunal Pai, Premkumar Devanbu, and Toufique Ahmed. CoDocBench:\nA dataset for code-documentation alignment in software maintenance.\narXiv preprint arXiv:2502.00519 , 2024.\n[47] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented\nlanguage models, 2022.\n[48] Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel\nMorris, Percy Liang, and Michael S. Bernstein. Generative agents:\nInteractive simulacra of human behavior. In The 36th Annual ACM\nSymposium on User Interface Software and Technology (UIST ’23) ,\nUIST ’23, page 1–22, New York, NY , USA, 2023. Association for\nComputing Machinery.\n[49] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models\nreally able to solve simple math word problems? In Conference of\nthe North American Chapter of the Association for Computational\nLinguistics (NAACL) , 2021. Introduces the SV AMP challenge dataset.\n[50] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are nlp models\nreally able to solve simple math word problems? arXiv preprint\narXiv:2103.07191 , 2021.\n[51] Long Phan, Alice Gatti, Ziwen Han, et al. Humanity’s last exam, 2025.\n[52] Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao\nLi, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, et al. Chat-\ndev: Communicative agents for software development. arXiv preprint\narXiv:2307.07924 , 2023.\n[53] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Shijie Wang, Zelin\nLu, Siyu Xi, Xiao Liu, Yongyan Li, Zihan Wang, Zixuan Liu, Jian-\nGuang Lou, et al. Toolllm: Facilitating large language models to master\n16000+ real-world APIs, 2023. Accessed: May 26, 2025.\n[54] Qwen Team, An Yang, et al. Qwen2.5 Technical Report. 2024.\narXiv:2412.15115.\n[55] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\nNarang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Explor-\ning the limits of transfer learning with a unified text-to-text transformer.\nJournal of machine learning research , 21(140):1–67, 2020.\n[56] Reddit user. 0.56 to $343.15 in minutes – google gemini api, 2025.\n[57] Stuart J. Russell and Peter Norvig. Artificial intelligence: a modern\napproach . Prentice Hall Press, Upper Saddle River, NJ, USA, 3rd\nedition, 2010.\n[58] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan,\nand Shunyu Yao. Reflexion: Language agents with verbal reinforcement\nlearning. Advances in Neural Information Processing Systems , 36:8634–\n8652, 2023.\n[59] Yoav Shoham. Agent-oriented programming. Artificial Intelligence ,\n60(1):51–92, 1993.\n[60] Claudio Spiess, David Gros, Kunal Suresh Pai, Michael Pradel,\nMd Rafiqul Islam Rabin, Amin Alipour, Susmit Jha, Prem Devanbu,\nand Toufique Ahmed. Calibration and correctness of language models\nfor code. arXiv preprint arXiv:2402.02047 , 2024.\n[61] Student. The probable error of a mean. Biometrika , pages 1–25, 1908.\n[62] Ryan Teknium, Jeffrey Quesnelle, and Chen Guang. Hermes 3 technical\nreport. arXiv preprint arXiv:2408.11857 , 2024.\n[63] The Qwen Team. Qwq-32b: Embracing the power of reinforcement\nlearning. Weblog post, March 2025. Accessed: May 30, 2025.\n[64] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao,\nYuke Zhu, Linxi Fan, and Anima Anandkumar. V oyager: An open-ended\nembodied agent with large language models, 2023.[65] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen\nZhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin\nZhao, Zhewei Wei, and Ji-Rong Wen. A survey on large language model\nbased autonomous agents, 2023.\n[66] Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and\nMing Zhou. Minilm: Deep self-attention distillation for task-agnostic\ncompression of pre-trained transformers, 2020.\n[67] Yuning Wang, Junkai Jiang, Shangyi Li, Ruochen Li, Shaobing Xu,\nJianqiang Wang, and Keqiang Li. Decision-making driven by driver\nintelligence and environment reasoning for high-level autonomous vehi-\ncles: a survey. IEEE Transactions on Intelligent Transportation Systems ,\n24(10):10362–10381, 2023.\n[68] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,\nEd Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting\nelicits reasoning in large language models. Advances in neural infor-\nmation processing systems , 35:24824–24837, 2022.\n[69] Bosi Wen, Pei Ke, Xiaotao Gu, Lindong Wu, Hao Huang, Jinfeng Zhou,\nWenchuang Li, Binxin Hu, Wendy Gao, Jiaxin Xu, Yiming Liu, Jie Tang,\nHongning Wang, and Minlie Huang. Benchmarking complex instruction-\nfollowing with multiple constraints composition, 2024.\n[70] Michael Wooldridge. An introduction to multiagent systems . John wiley\n& sons, 2009.\n[71] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang\nZhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed H.\nAwadallah, Ryen W. White, Doug Burger, and Chi Wang. AutoGen:\nEnabling next-gen LLM applications via multi-agent conversation. arXiv\npreprint arXiv:2308.08155 , 2023.\n[72] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang\nHong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng,\nXiaoran Fan, Xiao Wang, Limao Xiong, Linyi Yang, Ting Ruan,\nYongquan Yang, Peng Li, Yitao Chang, and Yanlin Wang. The rise\nand potential of large language model based agents: A survey, 2023.\n[73] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik\nNarasimhan, and Yuan Cao. ReAct: Synergizing reasoning and acting\nin language models. In International Conference on Learning Repre-\nsentations (ICLR) , 2023. arXiv:2210.03629.\n[74] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du,\nJoshua B. Tenenbaum, Tianmin Shu, and Chuang Gan. Building\ncooperative embodied agents modularly with large language models,\n2023.\n[75] Ruiyang Zhou, Lu Chen, and Kai Yu. Is llm a reliable reviewer? a\ncomprehensive evaluation of llm on automatic paper reviewing tasks. In\nProceedings of the 2024 Joint International Conference on Computa-\ntional Linguistics, Language Resources and Evaluation (LREC-COLING\n2024) , pages 9340–9351, 2024.\n[76] Wangchunshu Zhou, Jianshu Chen, Jialong Wu, Yiheng Xu, Kexin\nWang, Jintian Zhang, Yuan Gao, Zhiyong Wu, Kevin Tian, Yubo Feng,\nLinyi Yang, Bokai Quan, Cong Yu, Yuhang Wang, Shishen Lan, Yan\nWang, Hong-Cheng Guo, Chaoyu Chen, Tianxiang Sun, Jin Xiong,\nYi Lu, Peng Li, Lichao Sun, Lifan Yuan, Hang Li, and Xiangang Li.\nAgents: An open-source framework for large language model based\nautonomous agents, 2023.\n[77] Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec\nRadford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-\ntuning language models from human preferences. arXiv preprint\narXiv:1909.08593 , 2019.\n[78] Andy Zou, Zifan Wang, J. Zico Kolter, and Matt Fredrikson. Universal\nand transferable adversarial attacks on aligned language models, 2023.\nAPPENDIX\nIn this section, we provide examples of how HASHIRU\noperates in practice, demonstrating its dynamic management,\nhybrid intelligence, memory and autonomous tool creation\ncapabilities.\nA. Example 1: Memory\nIn this example (Figures 4, 5), we illustrate how HASHIRU\nuses its memory function to enforce user preferences in\ndialogue. The user states a dietary preference, and HASHIRU\nstores this information for future interactions. When the\n--- Page 11 ---\nuser later requests a recipe that contradicts this preference,\nHASHIRU refers back to its memory and suggests an alterna-\ntive.\nUser\nI am vegetarian.\nAssistant\nOkay, I’ll keep that in mind. I’ll store this pref-\nerence in my memory.\nInvoking MemoryManager with\n{‘memory’: ‘The user is\nvegetarian.’, ‘action’:\n‘add_memory’, ‘key’:\n‘vegetarian’ }\nI have stored that you are vegetarian. How can I\nhelp you today?\nUser\nGive me a bacon pasta recipe.\nAssistant\nMemories\nMemories: [‘The user is vegetarian.’]\nMy apologies, but I cannot provide a bacon pasta\nrecipe since you are vegetarian. Would you like\na vegetarian pasta recipe instead?\nFig. 4. HASHIRU enforcing a stored dietary preference in dialogue using its\nMemory Function.\nB. Example 2: Autonomous Tool Creation\nIn this example (Figures 6, 7), we demonstrate how\nHASHIRU autonomously creates a new tool to enhance its\ncapabilities. The CEO agent identifies a need for a new API\ntool that can perform a specific function not currently available\nin the system. It then generates the necessary code and deploys\nthe new tool within the HASHIRU ecosystem.User\nI can eat bacon actually\nAssistant\nMemories\nMemories: [‘The user is vegetarian.’]\nI see. My apologies for the confusion. I had\na conflicting memory that you were vegetarian.\nI will remove that memory and proceed with\nfinding a bacon pasta recipe.\nInvoking MemoryManager with\n{’action’: ’delete_memory’,\n’key’: ’The user is vegetarian.’ }\nOK, I have removed the memory. Now I will\nsearch for a bacon pasta recipe.\nInvoking GoogleSearchTool with\n{’query’: ’bacon pasta recipe’ }\nHere are some bacon pasta recipes I found:\n•Garlic Bacon Pasta\n•Creamy Bacon Pasta Sauce\n•. . .\nWould you like me to get the content of any of\nthese websites?\nFig. 5. HASHIRU updating and deleting its memory based on user input.\nContinuation of Figure 4.\n--- Page 12 ---\nFig. 6. An example of autonomous tool creation in action.\nFig. 7. Continuation of the autonomous tool creation example from Figure\n6.",
  "text_length": 59732
}