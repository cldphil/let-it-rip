{
  "id": "http://arxiv.org/abs/2506.00980v1",
  "title": "LEMONADE: A Large Multilingual Expert-Annotated Abstractive Event\n  Dataset for the Real World",
  "summary": "This paper presents LEMONADE, a large-scale conflict event dataset comprising\n39,786 events across 20 languages and 171 countries, with extensive coverage of\nregion-specific entities. LEMONADE is based on a partially reannotated subset\nof the Armed Conflict Location & Event Data (ACLED), which has documented\nglobal conflict events for over a decade.\n  To address the challenge of aggregating multilingual sources for global event\nanalysis, we introduce abstractive event extraction (AEE) and its subtask,\nabstractive entity linking (AEL). Unlike conventional span-based event\nextraction, our approach detects event arguments and entities through holistic\ndocument understanding and normalizes them across the multilingual dataset. We\nevaluate various large language models (LLMs) on these tasks, adapt existing\nzero-shot event extraction systems, and benchmark supervised models.\nAdditionally, we introduce ZEST, a novel zero-shot retrieval-based system for\nAEL.\n  Our best zero-shot system achieves an end-to-end F1 score of 58.3%, with LLMs\noutperforming specialized event extraction models such as GoLLIE. For entity\nlinking, ZEST achieves an F1 score of 45.7%, significantly surpassing OneNet, a\nstate-of-the-art zero-shot baseline that achieves only 23.7%. However, these\nzero-shot results lag behind the best supervised systems by 20.1% and 37.0% in\nthe end-to-end and AEL tasks, respectively, highlighting the need for further\nresearch.",
  "authors": [
    "Sina J. Semnani",
    "Pingyue Zhang",
    "Wanyue Zhai",
    "Haozhuo Li",
    "Ryan Beauchamp",
    "Trey Billing",
    "Katayoun Kishi",
    "Manling Li",
    "Monica S. Lam"
  ],
  "published": "2025-06-01T12:24:05Z",
  "updated": "2025-06-01T12:24:05Z",
  "categories": [
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00980v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00980v1  [cs.CL]  1 Jun 2025\nLEMONADE : A Large Multilingual Expert-Annotated\nAbstractive Event Dataset for the Real World\nSina J. Semnani1Pingyue Zhang2Wanyue Zhai1Haozhuo Li1\nRyan Beauchamp1Trey Billing3Katayoun Kishi3Manling Li2Monica S. Lam1\n1Stanford University2Northwestern University3ACLED\n{sinaj, wzhai702, tommy01, rmb87, lam}@cs.stanford.edu ,\n{pingyue.zhang, manling.li}@northwestern.edu ,\n{t.billing, k.kishi}@acleddata.com\nAbstract\nThis paper presents LEMONADE , a large-scale\nconflict event dataset comprising 39,786 events\nacross 20 languages and 171 countries, with\nextensive coverage of region-specific entities.\nLEMONADE is based on a partially reannotated\nsubset of the Armed Conflict Location & Event\nData (ACLED), which has documented global\nconflict events for over a decade.\nTo address the challenge of aggregating multi-\nlingual sources for global event analysis, we in-\ntroduce abstractive event extraction ( AEE ) and\nits subtask, abstractive entity linking ( AEL ).\nUnlike conventional span-based event extrac-\ntion, our approach detects event arguments\nand entities through holistic document under-\nstanding and normalizes them across the multi-\nlingual dataset. We evaluate various large lan-\nguage models (LLMs) on these tasks, adapt ex-\nisting zero-shot event extraction systems, and\nbenchmark supervised models. Additionally,\nwe introduce ZEST, a novel zero-shot retrieval-\nbased system for AEL.\nOur best zero-shot system achieves an end-to-\nendF1score of 58.3%, with LLMs outperform-\ning specialized event extraction models such\nas GoLLIE. For entity linking, ZESTachieves\nanF1score of 45.7%, significantly surpassing\nOneNet, a state-of-the-art zero-shot baseline\nthat achieves only 23.7%. However, these zero-\nshot results lag behind the best supervised sys-\ntems by 20.1% and 37.0% in the end-to-end\nandAEL tasks, respectively, highlighting the\nneed for further research.1\n1 Introduction\nEvent Extraction (EE) involves extracting struc-\ntured information about events and their arguments\nfrom unstructured text, such as news articles. This\ntask is fundamental for understanding and analyz-\ning real-world phenomena at scale.\n1The dataset and code are available at https://github.\ncom/stanford-oval/Lemonade .This paper refines the EE task to better serve\nthe study of global real-world phenomena. As a\ncase study, we analyze data from the Armed Con-\nflict Location & Event Data (ACLED), a non-profit\norganization that has systematically documented vi-\nolent conflict and protest events worldwide for over\na decade (Raleigh et al., 2010). ACLED’s data sup-\nports critical humanitarian work by organizations\nincluding the United Nations’ International Orga-\nnization for Migration, the International Rescue\nCommittee, and the European Commission, who\nuse it to track forced displacement and evaluate\nhumanitarian interventions (ACLED, 2023).\nBased on this analysis, we introduce LEMON -\nADE, a cleaned and partially reannotated version\nof the ACLED dataset tailored for NLP research.\nLEMONADE addresses several critical gaps in ex-\nisting event extraction resources:\nMultilinguality and Geographic Diversity To\nprovide a truly global perspective, event extraction\nmust extend beyond the Global North to include\nperspectives from the Global South and interna-\ntional regions (Braha, 2012). Unlike existing EE\ndatasets that focus primarily on English or Chi-\nnese, LEMONADE encompasses events across 171\ncountries reported in 20 languages.\nTail Entity Coverage Entity linking is essential\nfor aggregating information about event partici-\npants. While general-purpose entity databases like\nWikidata (Wen et al., 2021) and Wikipedia (Li et al.,\n2019, 2020b) offer broad coverage, they often lack\nspecialized domain entities. LEMONADE addresses\nthis gap with a database of 10,707 entities, includ-\ning:\n• Generic terms (e.g., “Students”)\n•Specialized political entities (e.g., “Liwa’ Al\nHashemiyoun”, a Syrian political militia ac-\ntive since 2023)\n•Regional organizations (e.g., “NNO: Nagorik\n1\n--- Page 2 ---\nNari Oikya”, the women’s wing of Nagarik\nOikya in Bangladesh)\nMany of these entities lack Wikipedia entries,\ncreating unique challenges for entity linking sys-\ntems. This is particularly significant because most\nlarge language models (LLMs) are pre-trained on\nWikipedia and tend to memorize common enti-\nties.2\nExpert Annotations High-quality annotations\nare essential when EE systems inform high-stakes\npolicy decisions, such as international peacemak-\ning efforts (Andrea Ruggeri and Dorussen, 2011),\nwhere annotation errors can lead to biased con-\nclusions. While prior work (Raleigh et al., 2010;\nCaselli and Huang, 2012) has emphasized the\nimportance of domain expertise, most existing\ndocument-level EE datasets rely on crowdsourc-\ning (Ebner et al., 2020; Liu et al., 2024a; Ren et al.,\n2024; Wang et al., 2020), student annotators (Li\net al., 2021b), or weakly supervised methods (Li\net al., 2023). In contrast, ACLED employs about\n200 regional experts who conduct multiple review\nrounds, ensuring high annotation quality and con-\nsistency.\nOur contributions are threefold:\n•TheAbstractive Event Extraction Task. Rec-\nognizing that one of the primary applications\nof event data is trend discovery and aggre-\ngate reporting (Li et al., 2019, 2020c, 2021a;\nReddy et al., 2023), we introduce the AEE\ntask. This task extracts events from complete\ndocuments following a structured codebook,\nrequiring all event arguments to be normal-\nized to numerical values, categorical labels, or\nentities from a predefined database.\n•The LEMONADE Dataset. We present\nLEMONADE (Large Expert-Annotated Multi-\nlingual Ontology- Normalized Abstractive\nDocument-Level Event) dataset, for the multi-\nlingual AEE task. LEMONADE is a high-\nquality document-level dataset based on hu-\nman expert annotations on real-world conflicts\ncomprising 39,786 events across 20 languages\nand 171 countries.\n2This limitation extends beyond event datasets. For in-\nstance, Cao et al. (2022) found that models without entity-\nlinking modules achieved 90% accuracy on a Wikidata\nquestion-answering dataset, suggesting over-reliance on mem-\norized entities.•Models for the Multilingual AEE Task. We\nadapt and evaluate diverse models from ex-\nisting literature alongside several LLMs on\nLEMONADE in both zero-shot and supervised\nsettings. Additionally, we introduce ZEST, a\nnovel multilingual ZEro-ShoT entity linking\nsystem that achieves 45.7% accuracy on the\nentity linking subtask, substantially outper-\nforming all zero-shot baselines.\n2 Related Work\nEvent Extraction Task. The Message Under-\nstanding Conferences (MUC) pioneered the use\nof text spans as a unit for system outputs in\ninformation extraction. While the MUC-3 and\nMUC-4 (Sundheim, 1992; Grishman and Sund-\nheim, 1996) datasets originally included non-span\nevent arguments, subsequent work has standard-\nized evaluation on span-based arguments, as noted\nby Gantt et al. (2024) and Chambers and Jurafsky\n(2011).\nContemporary EE research largely follows the\nACE05 project’s (Walker et al., 2006) task for-\nmulation, which decomposes event extraction into\nsentence-level subtasks using span-based interme-\ndiate annotations. Recent work has expanded this\nscope: Li et al. (2021b) extended EE to capture\narguments from surrounding sentences and intro-\nduced the concept of the “most informative span”\nfor argument selection. Building on this, Tong et al.\n(2022) introduced the DocEE dataset, where event\narguments are, on average, scattered across 10 sen-\ntences in the document, establishing EE as a truly\ndocument-level task.\nEntity Detection and Linking. Entity Linking\n(EL) connects entity mentions in text to entries\nin a database (Milne and Witten, 2008; Liu et al.,\n2024b). Traditional EL pipelines first detect entity\nmention spans, then disambiguate them against the\ntarget database. In contrast, our abstractive entity\nlinking ( AEL ) approach directly maps input text\nto a list of linked entities, without explicit span\ndetection.\nZero-shot EL, which enables linking to new\nentity databases without direct supervision, is\nparticularly relevant to our work. Logeswaran\net al. (2019a) demonstrated the effectiveness of\npre-trained models for zero-shot EL and intro-\nduced ZESHEL, now a popular benchmark. Re-\ncent advances include Xu et al. (2023)’s read-and-\n2\n--- Page 3 ---\nFormer Member of Government of India:  It refers to the pr evious administrations or r epresentatives of India's central ...                      \nRioters:  Loosely assembled gr oups or mobs that engage in spontaneous or or ganized acts of violence ...                                                 \nCivilians:  Civilians ar e unarmed and vulnerable individuals or gr oups who can be victims of violent acts ...                                            \nMember of Government of India:   The Government of India is the central authority r esponsible for the governance ...                            \nWomen:  Women ar e individuals identified as female who may be involved in various types of events ...                                                     \nEvent Extraction (EE) OutputEntity\nDatabase\nMobViolence(\n    perpetrators=[\n        ' Former Member of Government of India ',\n        ' Rioters'\n    ],\n    victims=[\n        ' Civilians ',\n        ' Member of Government of India ',\n    ],\n    mob_size=None,\n    fatalities=0,\n    targets_civilians=True,\n    targets_local_administrators=True,\n    targets_women=True\n    women_targeted=[WomenTargetedCategory.GOVERNMENT_OFFICIALS]\n...\n)Abstractive Event Extraction (AEE) OutputLady sa rpanch , husband  'attacked' by ex-sarpanch  in Odisha's Jajpur\nBhubaneswar , Jan. 19 -- A lady sa rpanch  and her husband  have been \ncritically injur ed after they wer e allegedly attacked by a former sarpanch  \nand supporters  in Chaskhand panchayat in Jajpur district. \nThe lady sarpanch, P ratibha Mallick , and her husband  were thrashed by \nthe ex-sarpanch's husband and her family members  following a dispute \nover laying of pipeline under the Basudha scheme.\n... Text Input\nMobViolence(\n    mention=\"attacked\",\n    perpetrators=[\n        'ex-sarpanch ',\n        ' ex-sarpanch's husband and her family members '\n    ]\n    victims=[\n        ' husband',\n        ' The lady sarpanch, Pratibha Mallick ',\n    ],\n...\n)Lady sarpanch , husband  'attacked' by ex-sarpanch  in Odisha's Jajpur\nBhubaneswar , Jan. 19 -- A lady sarpanch  and her husband  have been \ncritically injur ed after they wer e allegedly attacked by a former sarpanch  \nand supporters  in Chaskhand panchayat in Jajpur district. \nThe lady sarpanch, Pratibha Mallick,  and her husband  were thrashed by \nthe ex-sarpanch's husband and her family members  following a dispute \nover laying of pipeline under the Basudha scheme.\n... Text InputFigure 1: An example from LEMONADE showing abstractive event annotation. The input text and annotations\nare summarized for clarity. A hypothetical extractive annotation is included for comparison, illustrating the key\ndifferences between abstractive and extractive approaches.\nselect framework using fine-tuned RoBERTa mod-\nels for entity disambiguation, and OneNet (Liu\net al., 2024c), which achieves state-of-the-art\nperformance through a three-module LLM-based\npipeline.\n3 The Abstractive Event Extraction Task\nTheAEE task shifts focus from surface text forms\nto grounding events in predefined ontologies and\nrepresenting arguments as categorical, numerical,\nor string values. AEE removes two key constraints\ncompared to traditional event extraction: argu-\nments need not be text spans, and they need not be\nexplicitly mentioned in the text.\nDefinition 3.1. An event extraction codebook C=\n(T,D, S)consists of:\n•T: the set of possible event types.\n•D: a collection of domains, where each D∈\nDis a domain such as integers, strings, or a\nset of known entities.\n•S= [(t1, a1,1, . . . , a 1,n1), . . . ,\n(tm, am,1, . . . , a m,n m)]: a list of mevent sig-\nnatures, where niis the number of arguments\nfor event type ti, and each argument field ai,j\nin in domain Di,j∈ D.\nDefinition 3.2. The Abstractive Event Extrac-tion (AEE ) task is: given codebook C= (T,D, S)\nand text w, extract abstractive event(s) of the form\n(ti, v1, . . . , v ni)fromw, where ti∈Tis an event\ntype, each vj∈Di,jis a value for argument aj,\nandniis the number of arguments for event type\nti.\nFigure 1 demonstrates how AEE can, for ex-\nample, facilitate studying violence against women\nglobally. For event type ti=MobViolence ∈\nT, its first two arguments, perpetrators and\nvictims represent the two sides in the violence,\nwithDi,1, Di,2being the set of all subsets of possi-\nble entities from the event database. The seventh\nargument targets_women is a boolean, thus Di,7\nis{True,False}. The AEE annotation captures crit-\nical information not explicitly stated as text spans\nin the input:\n1. Women were specifically targeted.\n2.The targeted women were government offi-\ncials.\n3. No fatalities occurred.\n4.The mob size was unspecified\n(mob_size=None ).\nThese abstract arguments—represented as\nboolean, enum, and numerical fields—enable\nstraightforward aggregation for analytical queries\n3\n--- Page 4 ---\nsuch as “How many casualties resulted from vi-\nolence against female government officials in\n2024?”\nAEE eliminates the need for intermediate an-\nnotations such as event triggers and entity men-\ntions (Huang et al., 2024), avoiding the common\npractice of annotating multiple spans for the same\nargument. Instead, AEE directly annotates events\nand their linked entities, enabling direct evalua-\ntion against gold annotations. This streamlined\napproach reduces annotation complexity, produces\ncleaner labels, and allows simple exact-match eval-\nuation, addressing limitations of existing EE met-\nrics (Lu et al., 2024). The AEE framework com-\nprises three core subtasks:\n•Event Detection (ED) : Identify from code-\nbookCthe event type(s) in text w.\nED(w, C) ={t1, . . .} ⊆T\n•Abstractive Event Argument Extraction\n(AEAE) : Given gold event type tin codebook\nC, extract non-entity arguments from w.\nAEAE (w, C, t ) = [v1, . . .]\nwhere aiare non-entity arguments.\n•Abstractive Entity Linking (AEL) : Given\ntextwand a gold event type tin codebook\nC, identify relevant entities from the database\nand assign them to appropriate event argu-\nments.\nAEL(w, C, t ) = [v1, . . .]\nwhere aiare entity arguments.\nAn end-to-end AEE system first performs ED,\nthen uses predicted event types (rather than gold\ntypes) to separately perform AEAE and AEL.\n4\n LEMONADE : An AEE Dataset\nLEMONADE spans 20 typologically diverse lan-\nguages (Clark et al., 2020), ordered by the number\nof examples in LEMONADE from most to least: En-\nglish, Spanish, Arabic, French, Italian, Russian,\nGerman, Turkish, Burmese, Indonesian, Ukrainian,\nKorean, Portuguese, Dutch, Somali, Nepali, Chi-\nnese, Persian, Hebrew, and Japanese.\nIt surpasses existing event datasets in linguistic\ncoverage and is the first event extraction dataset that\nincludes Burmese, Indonesian, Hebrew, Somali,and Nepali. Table 9 compares LEMONADE with\nother document-level event datasets.\nWe construct LEMONADE by extending expert\nannotations from ACLED. To ensure compatibility\nwith NLP systems, we reannotated several event\nargument types, transformed event-centric anno-\ntations into a document-centric format, and gen-\nerated descriptions for 10,707 entities to facilitate\nretrieval-based entity linking.\nEach example in LEMONADE consists of a news\narticle with its primary event annotated, following\nthe document-level single-event configuration es-\ntablished in DocEE (Tong et al., 2022; Liu et al.,\n2024a). The dataset includes 25 event types within\nthe socio-political domain, ranging from peaceful\nprotests to chemical weapons deployment. Annota-\ntions comprise the event type and associated entity\nand non-entity arguments with their corresponding\nroles. Appendix I details all event types and their\narguments.\n4.1 Dataset Construction\nACLED’s original annotations operate at the event\nlevel, with individual events potentially spanning\nmultiple articles. These annotations integrate mul-\ntiple sources, including maps and images, to deter-\nmine event locations and participants. The primary\nchallenge in developing LEMONADE involves en-\nsuring document-level annotations contain only in-\nformation extractable from individual documents.\nWe summarize the construction process below; see\nAppendix A for more details.\nWe utilize ACLED data spanning January 2024\nto January 2025 (13 months), comprising 344,116\nevents. Each event links to one or more source\nURLs, and has one corresponding event annotation.\nWe filter URLs lacking substantive event informa-\ntion in text form (e.g., image-heavy social media\nposts) and keep news articles. We obtain the full\ntext from the provided URLs and clean the texts by\nremoving advertisements and other extraneous con-\ntent. We then use GPT-4o for language detection.\nLocation Argument Reannotation ACLED’s\noriginal location annotations derive from multi-\nple sources, including external maps and field re-\nports. Since this information may not appear in\narticle text, text-based extraction systems cannot\nreliably identify locations. We address this by rean-\nnotating all location arguments through automated\ntools and manual verification by the authors. Loca-\ntion arguments—from country to city block level—\n4\n--- Page 5 ---\nfollow the guideline: “ The location argument is the\nmost specific place supported by the text .” There-\nfore, EE systems are expected to extract location\nentirely from the text. During evaluation, we nor-\nmalize locations using OpenStreetMaps, eliminat-\ning the need for EE systems to have detailed geo-\ngraphical knowledge of remote regions.\nSchema Standardization We refine the event\nschema and convert annotations to Python classes\nfollowing Wang et al. (2023). This format en-\nables structured decoding (Dong et al., 2024), sub-\nstantially improving performance of generative EE\nmodels.\nEntity Database ACLED annotates the entities\ninvolved in each event, yielding a total of 10,707\nunique entities. Note that this database is a superset\nof the 4,305 entities included in LEMONADE and\nthe 2,648 entities in its development and test splits.\nConsequently, entity linking systems evaluated on\nthis dataset must be proficient at distinguishing\nrelevant entities from distracting ones.\nSpecialized domains require domain-specific\nknowledge for effective entity linking. We pro-\nvide one-paragraph descriptions for each entity,\nsupplying context and domain knowledge essential\nfor understanding specialized entities, particularly\nlong-tail instances (Mallen et al., 2023). This ap-\nproach parallels the Zeshel entity linking dataset\ndesign (Logeswaran et al., 2019b). Entity linking\nsystems utilize these descriptions to identify the\nentities relevant to the input text. Appendix D in-\ncludes sample entities and their descriptions.\nData Splits We implement temporal splits: train-\ning data comprises events from January – March\n2024, while validation and test sets contain events\nfrom April 2024 – January 2025. This design re-\nflects real-world scenarios where event and entity\ndistributions evolve temporally. Notably, 44.3%\nof validation and test entities are absent from the\ntraining data. Validation and test sets are ran-\ndomly divided. Appendix B.3 details the language,\nevent type, and geographical distributions within\nLEMONADE .\n5 Z EST: A Novel Abstractive Entity\nLinker\nZESTemploys a multi-stage approach to linking\nentities: first, it leverages information retrieval tech-\nniques to narrow down candidate entities; second,\nit filters these candidates based on their relevance;and finally, it assigns each entity to the appropriate\nevent argument. For instance, in Figure 1, the en-\ntity “Member of Government of India” is assigned\nto the event argument victims .\nStage 1: Entity Retrieval. In the first stage,\nwe construct a vector database by embedding all\nentities along with their descriptions using an em-\nbedding model. Given an input document, ZEST\nutilizes the underlying LLM to generate multiple\nqueries for searching the entity database. These\nqueries aim to closely match the descriptions of\nthe gold entities, thus increasing the likelihood of\nretrieving relevant candidates. At test time, since\nthe model does not have access to the gold entity\ndescriptions, the LLM approximates these descrip-\ntions based solely on the information available in\nthe input document.\nFor example, given the document shown in Fig-\nure 1, the system generates multiple queries for\npossible entities, including: “The former sarpanch\nof Chaskhand panchayat, involved in a political\nrivalry with the current sarpanch, Pratibha Mallick,”\nand “The state government of Odisha, India, re-\nsponsible for implementing development schemes\nand maintaining law and order in the region.” The\nunion of all entities retrieved by these queries is\nthen passed to the next stage.\nStage 2: Entity Filtering. In the second stage,\neach candidate entity (along with its description)\nretrieved from Stage 1 is evaluated using a dedi-\ncated prompt (see Table 17). This prompt helps\ndetermine whether there is sufficient evidence in\nthe document to support the entity’s involvement\nin the event. Entities lacking supporting evidence\nare removed from the candidate set.\nStage 3: Entity Assignment. In the final stage,\nthe remaining entities are matched to their correct\nevent arguments. To accomplish this, we employ\nanother prompt (see Table 18), which takes as input\nthe list of filtered entities and the available event ar-\ngument roles, and outputs the appropriate mapping\nbetween them.\n6 Experiments\n6.1 Baselines for AEE\nForAEE and its various subtasks, we experiment\nwith adapted versions of prior state-of-the-art so-\nlutions, as discussed below. Further details can be\nfound in Appendix G.\nAllAEE Tasks: Supervised LMs. We fine-tune\nLLMs to autoregressively generate the complete\n5\n--- Page 6 ---\nstructured output from the input document. The\ngenerated output begins with the event type, fol-\nlowed by event arguments and entities, all format-\nted in JSON. We experiment with several multi-\nlingual LLMs of varying sizes: the base versions of\nLLaMA-3.2 with 1B and 3B parameters, as well as\nLLaMA-3.1 with 8B parameters. Additionally, we\nevaluate Aya Expanse (Dang et al., 2024), an 8B-\nparameter model specifically optimized for multi-\nlingual performance in 16 of the 20 languages cov-\nered by L EMONADE .\nAllAEE Tasks: GoLLIE. For the EDand\nAEAE subtasks, we employ GoLLIE (Sainz et al.,\n2024), a model specifically instruction-tuned from\nCodeLLaMA (Rozière et al., 2023) for information\nextraction tasks. We also use it as an entity span\ndetection model in the AEL subtask.\nED: XLM-R-RetroMAE (XLM-RRM). For\nthe ED subtask, we fine-tune the XLM-R\nmodel (Conneau et al., 2020), whose context length\nwas extended to 8,192 tokens by Chen et al. (2024)\nand further pre-trained using RetroMAE (Xiao\net al., 2022). We select this model because it has\nbeen pre-trained on 100 languages and provides\nsufficient context length for LEMONADE . We refer\nto this model as XLM-RRM.\nED: In-Context Learning with LLMs. Given\nthat the set of event types ( T) is relatively small (25\nevent types in LEMONADE ), event detection can\nbe naturally formulated as a zero-shot in-context\nlearning task. We design a prompt (Table 15) that\nincludes the input text wand a list of event types\nwith their descriptions. The model is tasked with re-\nturning the most likely event type t. We experiment\nwith GPT-4o, GPT-4o mini, and the 8B-parameter\ninstruction-tuned LLaMA-3.1 (Dubey et al., 2024).\nAEAE : Abstractive Code4Struct (AC4S).\nFor the AEAE subtask, we develop Abstractive\nCode4Struct (AC4S) by modifying the instructions\nof Code4Struct (Wang et al., 2023) to adapt it to the\ndocument-level abstractive setting. Specifically, we\ninstruct the LLM to directly output event arguments\nand their roles from the input article, rather than\nperforming sentence-level span extraction as in the\noriginal paper. This is achieved using a prompt\n(Table 19) that, given the input text wand the event\ntype signature for t, outputs all non-entity argument\nvalues.\nAEAE : Zero-shot Question Answering with\nLLMs. Models that rely on question answering\nfor event argument extraction (Li et al., 2020a; Liu\net al., 2020a; Choudhary and Du, 2024; Lu et al.,2023) can be naturally extended to our abstractive\nsetting. We adopt the zero-shot LLM-based ques-\ntion generation method proposed by Uddin et al.\n(2024) as a baseline for AEAE.\nAEL : OneNet. For the AEL subtask, we adopt\nOneNet (Liu et al., 2024c), a state-of-the-art few-\nshot entity linking model. OneNet leverages re-\ntrieval and entity descriptions to identify the best\nmatch for a given entity mention. We experiment\nwith applying OneNet to entity mentions extracted\nby GoLLIE and GPT-4o.\nWe use greedy constrained decoding (Shin\nand Van Durme, 2022) for all models. For en-\ntity retrieval, we employ the mGTE embedding\nmodel (Zhang et al., 2024a). To ensure a fair com-\nparison, we modify OneNet and the QA baseline\nto use GPT-4o, and we further adapt OneNet to\nuse mGTE for entity retrieval, just like ZEST. Ad-\nditional details on the baselines are provided in\nAppendix G.3.\n6.2 Evaluation Metrics\nTo evaluate a predicted event against a gold-\nstandard event from LEMONADE , we first normal-\nize location arguments by performing a lookup in\nthe OpenStreetMap geographic database. We then\nuse exact string matching to calculate precision, re-\ncall, and micro-averaged F1scores (Manning et al.,\n2008).\nFor event detection ( ED), we compare the pre-\ndicted event type with the gold-standard event type\nand report the micro-averaged EDF1. For ab-\nstractive event argument extraction ( AEAE ), the\nmodel generates event arguments and their values\n(a′\n1, v′\n1), . . .. We treat this set as the predicted re-\nsult and compute precision, recall, and F1scores\nagainst the gold set (a1, v1), . . .. We report this\nmetric as AEAE F1. Two arguments are consid-\nered equal only if both their argument roles and\nvalues exactly match.\nFor entity linking, we report AEL F1, computed\nby comparing the predicted entity IDs with the\ngold-standard entity IDs. This calculation is simi-\nlar to the AEAE F1but considers only entity argu-\nments.\nFinally, in the end-to-end (E2E) setting, the sys-\ntem first predicts the event type and then uses that\nprediction to extract event arguments and entities.\nIn this scenario, an incorrect event type prediction\nresults in false positives for all predicted event ar-\nguments and entities, and false negatives for all\ngold-standard event arguments and entities.\n6\n--- Page 7 ---\n7 Results\n7.1 Event Detection\nTable 1 summarizes the results for the EDsub-\ntask. In the zero-shot setting, GPT-4o achieves the\nhighest performance across all languages, with an\naverage F1score of 79.6. GPT-4o mini trails by\n9.8 points, achieving an F1score of 69.8, while\nthe 8B-parameter Llama 3.1 lags further behind by\nan additional 10.3 points. Llama 3.1 8B performs\nparticularly poorly for Indonesian (id) and Somali\n(so). The variation in performance across different\nlanguages increases from GPT-4o to GPT-4o mini\nto Llama 3.1 8B, with the differences in perfor-\nmance between the best and worst languages being\n18.7, 40.2, and 61.2 points, respectively. Interest-\ningly, the performance ranking is consistent across\nthe three models for almost all languages, with the\nexception that GPT-4o mini is significantly worse\nin Chinese (zh) than Llama 3.1 8B.\nGoLLIE 7B performs significantly worse than\nall other models, even compared to the similarly\nsized Llama model in English, a language on which\nGoLLIE was specifically instruction-tuned. This\nsuggests that instruction-tuning on extractive event\ndatasets does not readily transfer to our abstractive\nsetting.\nIn the supervised setting, all models, from the\nsmallest 0.5B-parameter XLM-RRM to the larger\n8B-parameter models, achieve similar performance.\nAya Expanse slightly outperforms the other models\non average, achieving an F1score of 87.5. XLM-\nRRM performs particularly well on Burmese (my),\nIndonesian (id), Somali (so), and Japanese (ja),\nsurpassing other models. This advantage is likely\ndue to XLM-RRM being the only model in this\ngroup pre-trained on Burmese and Somali.\nOverall, there is a 7.9 percentage-point per-\nformance gap between the best zero-shot model\n(GPT-4o) and the best supervised model (Aya Ex-\npanse). Remarkably, GPT-4o surpasses supervised\nmodels on Burmese, Somali, and Hebrew, which\nare among the lowest-resource languages in our\ndataset.\nThe variance in performance across languages\ncan be partially explained by the differences in\nevent types present in each language (see Table 7).\nSince the ACLED data aims to reflect real-world\nevents, the distribution of event types in each lan-\nguage is heavily influenced by the political stability\nof countries where that language is spoken. For\ninstance, nearly all events in Korean and Japaneseare Peaceful Protest events. To further analyze this\nphenomenon, we include a simple baseline, major-\nity class (Mohammad et al., 2016), which always\npredicts the most frequent event type for each lan-\nguage. We observe extremely high scores for all\nsupervised models on Korean and Japanese. Italian\n(it), German (de), Indonesian (id), and Chinese (zh)\nfollow a similar pattern, though to a lesser extent.\n7.2 Abstractive Event Argument Extraction\nTable 2 presents the results for the AEAE subtask.\nIn the supervised setting, Aya Expanse achieves\nthe best overall performance, reaching an average\nF1score of 89%, ranging from 76% for Burmese\n(my) to 97% for Italian (it). It consistently ranks\neither first or within 1.3 percentage points of the\ntop-performing model across all languages. The\nLlama models are within 4.6% on average com-\npared to the Aya Expanse model.\nIn the zero-shot setting, Abstractive Code4Struct\nwith GPT-4o outperforms all other models, achiev-\ning performance within 4.4 percentage points of the\nbest supervised model. Notably, it even surpasses\nthe best supervised model by 0.5 to 1.8 percentage\npoints on Spanish (es), Farsi (fa), and Japanese (ja).\nThe QA-based model performs, on average, 9.3\npercentage points worse, indicating that directly\ngenerating event arguments is more effective than\nformulating the task as question answering. Simi-\nlar to the event detection results, GoLLIE performs\nworse than all other models, even in English, and\ncompletely fails on Burmese and Somali. This poor\nperformance can be attributed to the limited multi-\nlingual capabilities of its underlying base model,\nCodeLLaMA.\n7.3 Abstractive Entity Linking\nTable 3 presents the complete results for the AEL\nsubtask. In the zero-shot setting, our proposed\nmethod, ZEST(GPT-4o), achieves an F1score of\n45.7%, substantially outperforming all baselines,\nincluding the state-of-the-art OneNet model (also\nusing GPT-4o), by 20.0 percentage points. When\nusing GoLLIE to extract entity spans, OneNet’s\nperformance drops significantly, achieving only an\n11.1% F1score. These results demonstrate that\nspan detection is a critical limiting factor for entity\nlinking performance on LEMONADE , as the dataset\ncontains many abstractive entities. Appendix E\nprovides side-by-side examples of system outputs.\nAll supervised models significantly outperform\nzero-shot models, with Aya Expanse achieving the\n7\n--- Page 8 ---\nModel All en es ar fr it ru de tr my id uk ko pt nl so ne zh fa he ja\nZero-shot\nGPT-4o 79.6 72.2 76.0 73.8 73.0 89.0 76.6 88.8 84.8 71.4 78.0 75.6 85.6 74.2 90.1 80.4 77.4 85.0 83.8 76.2 86.0\nGPT-4o mini 69.8 65.0 66.8 65.2 64.4 85.4 68.8 83.6 77.0 51.6 74.2 68.8 71.8 72.4 86.6 58.1 64.5 46.4 81.6 66.9 85.7\nLlama 3.1 8B 59.5 55.0 55.0 54.0 51.8 85.2 45.4 79.4 65.0 37.8 76.4 57.6 51.2 56.0 76.4 24.0 62.6 66.8 66.8 50.9 75.4\nGoLLIE 7B 23.6 35.8 36.8 6.2 34.6 49.6 29.0 61.2 7.8 0.2 11.2 41.0 1.4 46.2 36.6 0.0 0.2 38.6 6.2 5.4 7.4\nTrained on L EMONADE\nXLM-RRM 85.0 76.8 83.0 76.0 73.0 95.0 74.8 93.2 94.8 69.2 94.2 75.6 98.6 88.2 92.6 74.6 89.1 94.6 88.0 72.3 98.5\nLlama 3.2 1B 85.0 79.6 85.4 80.4 74.8 97.0 81.6 93.0 94.2 60.6 92.0 76.0 99.2 89.6 95.4 65.1 88.4 95.4 88.2 65.1 98.2\nLlama 3.2 3B 86.6 81.4 86.6 82.8 77.2 97.0 82.8 94.8 95.4 68.8 93.2 77.4 99.2 89.8 94.4 66.2 88.6 96.2 89.2 70.8 97.8\nLlama 3.1 8B 86.2 82.0 87.2 80.6 77.0 97.4 83.4 93.8 94.0 63.8 92.2 77.0 99.0 90.8 94.0 69.8 87.7 96.4 88.8 69.9 97.8\nAya Expanse 8B 87.5 80.4 87.0 82.6 79.6 97.6 83.2 94.8 96.0 66.2 92.8 80.2 99.6 91.8 95.4 70.9 89.3 96.6 91.4 75.9 98.2\nMajority Class 50.4 31.0 33.0 15.8 29.8 91.6 23.2 86.2 66.0 19.0 86.0 40.4 98.8 42.6 82.4 49.4 77.0 89.4 63.2 40.1 98.5\nTable 1: ED F1results on the L EMONADE test set. The best result in each setting is highlighted in bold.\nModel All en es ar fr it ru de tr my id uk ko pt nl so ne zh fa he ja\nZero-shot\nAC4S (GPT-4o) 84.6 85.2 91.0 73.1 85.0 94.1 82.9 90.9 89.0 70.9 93.2 74.4 90.2 91.1 92.2 72.1 87.9 89.3 83.6 64.4 94.4\nAC4S (GPT-4o mini) 81.0 83.1 87.1 71.1 84.1 94.3 80.1 89.7 86.4 60.0 91.5 73.5 82.2 81.7 89.0 68.3 82.5 83.2 82.9 63.4 90.9\nAC4S (Llama 3.1 8B) 49.0 58.9 56.4 15.5 57.5 55.0 57.1 68.1 50.5 41.7 47.4 36.5 51.4 49.2 65.5 38.1 47.5 36.6 42.8 50.9 50.2\nQA (GPT-4o) 75.3 74.0 79.7 56.3 73.3 88.5 57.2 86.7 83.0 61.7 87.7 61.2 79.2 82.3 91.2 64.5 80.8 79.0 79.7 65.0 84.2\nGoLLIE 7B 40.0 47.5 45.9 21.9 46.8 54.1 42.7 59.9 27.5 1.3 49.1 39.3 30.7 49.7 54.4 0.7 12.6 58.3 31.7 22.0 49.2\nTrained on L EMONADE\nLlama 3.2 1B 85.4 87.1 85.9 78.6 81.2 94.3 78.8 91.6 90.7 71.4 93.8 84.6 94.5 95.1 94.4 71.6 88.0 86.1 77.1 72.5 86.0\nLlama 3.2 3B 87.7 89.0 88.4 79.7 86.3 95.5 83.5 93.5 93.2 77.3 95.0 85.4 96.1 95.7 95.0 75.6 90.2 87.3 79.8 75.4 87.1\nLlama 3.1 8B 87.6 88.5 89.7 80.4 87.2 96.2 83.8 94.1 92.1 76.4 94.5 85.1 95.8 95.7 94.7 76.6 91.0 89.2 78.3 71.9 85.8\nAya Expanse 8B 89.0 88.9 90.5 81.4 88.3 97.7 85.2 94.2 93.5 76.3 96.3 87.5 97.2 96.1 95.7 75.4 90.3 91.6 82.8 77.8 92.6\nTable 2: AEAE F1results on the L EMONADE test set. The best result in each setting is highlighted in bold.\nModel All en es ar fr it ru de tr my id uk ko pt nl so ne zh fa he ja\nZero-shot\nZEST(GPT-4o) 45.7 49.7 46.6 46.0 52.2 44.8 42.3 41.8 43.7 44.8 45.1 51.2 37.7 50.2 52.8 55.2 46.4 55.2 56.4 33.3 22.4\nZEST(GPT-4o mini) 27.2 34.1 28.7 31.8 36.8 20.2 28.5 19.7 24.4 28.8 19.2 50.5 15.6 31.3 26.6 39.7 22.1 26.2 26.6 31.2 11.2\nSpan (GoLLIE 7B) + OneNet 11.1 18.7 13.0 7.8 19.3 13.4 12.4 21.1 8.7 0.0 6.9 24.9 4.3 11.8 18.7 0.0 0.4 5.2 11.1 1.7 4.6\nSpan (GPT-4o) + OneNet 23.7 26.0 20.8 30.7 31.1 28.4 16.5 28.9 28.5 10.9 16.5 25.6 18.8 18.2 30.1 41.1 18.7 9.8 20.9 22.0 19.1\nTrained on L EMONADE\nLlama 3.2 1B 81.9 79.2 81.7 79.1 72.7 85.1 81.7 82.0 87.9 67.9 89.7 90.0 87.5 86.2 84.8 59.4 82.9 90.7 84.9 78.5 80.7\nLlama 3.2 3B 82.1 79.6 81.0 80.5 72.7 85.2 81.2 80.7 86.4 70.0 89.8 90.2 88.1 86.9 85.0 62.7 85.7 91.0 84.5 78.4 79.3\nLlama 3.1 8B 80.0 78.9 78.8 80.1 68.0 82.8 80.6 79.4 85.0 66.6 88.5 88.5 85.4 84.4 84.3 57.6 82.1 89.5 83.3 76.6 78.8\nAya Expanse 8B 82.7 79.8 80.5 81.2 74.3 86.2 81.7 82.1 87.5 69.6 90.5 89.4 88.7 87.1 85.1 60.9 86.1 91.3 85.1 83.0 81.2\nTable 3: AEL F1results on the L EMONADE test set. The best result in each setting is highlighted in bold.\nbest average performance. To better understand\nthis performance gap, we further analyze entity\nlinking performance across several subsets of enti-\nties. Table 4 compares results for entities appearing\nin the LEMONADE training set ( Seen ) versus those\nnot appearing ( Unseen ), as well as for Generic en-\ntities (e.g., “Student”) versus Specific entities (e.g.,\n“Government of Panama”). We observe that super-\nvised methods lag behind zero-shot methods ( ZEST\nand OneNet) in the Unseen category. Addition-\nally, while supervised models exhibit a notable per-\nformance drop for Specific entities, the decline is\nmuch smaller for ZEST(7.0% compared to 17.4%),\nwith OneNet performing even better in this regard.\nWhile models generally perform well on the seenentities, all significantly struggle with new entities,\nwith the best model achieving only 30.4%.\n7.4 End-to-End Results\nTable 5 summarizes the end-to-end (E2E) results\nfor selected combinations of subtask systems, eval-\nuated across all languages and specifically on En-\nglish.\nAmong the zero-shot systems, the pipeline com-\nbining GPT-4o and ZESTachieves the highest per-\nformance, with an F1score of 58.3%. In contrast,\nthe best supervised model achieves an F1score of\n78.4%, representing a 20.1% improvement over\nthe best zero-shot system. We also see that the\nquality of the underlying LLM is important, as for\n8\n--- Page 9 ---\nAll Seen Unseen Generic Specific\nZero-shot\nZEST(GPT-4o) 45.7 48.9 20.0 49.6 42.6\nZEST(GPT-4o mini) 27.2 31.5 8.0 31.1 25.0\nSpan (GoLLIE 7B) + OneNet (GPT-4o) 11.1 10.9 14.7 7.2 15.9\nSpan (GPT-4o) + OneNet 23.7 23.2 30.4 10.5 37.2\nTrained on L EMONADE\nLlama 3.2 1B 81.9 83.7 8.8 89.4 70.9\nLlama 3.2 3B 82.1 83.9 10.6 89.2 71.8\nLlama 3.1 8B 80.0 81.8 9.4 88.3 68.0\nAya Expanse 8B 82.7 84.5 12.6 89.8 72.4\nTable 4: AEL F1results on the L EMONADE test set, grouped by entity categories.\nTraining Data ED AEAE AEL All English\n- GPT-4o AC4S (GPT-4o) Zest (GPT-4o) 58.3 55.9\n- GPT-4o AC4S (GPT-4o) Span (GPT-4o) + OneNet 54.6 51.0\n- Llama 3.1 8B AC4S (Llama 3.1 8B) Zest (Llama 3.1 8B) 20.6 21.2\n- GoLLIE 7B GoLLIE 7B Span (GoLLIE 7B) + OneNet 14.2 18.3\nLEMONADE (all of train set) Aya Expanse 8B 78.4 71.6\nLEMONADE (10% of train set) Aya Expanse 8B 68.2 65.0\nLEMONADE (5% of train set) Aya Expanse 8B 65.5 59.2\nLEMONADE (1% of train set) Aya Expanse 8B 57.9 48.9\nLEMONADE (English subset of train set) Aya-Expanse 8B 64.0 71.3\nTable 5: End-to-end F1results on the LEMONADE test set. The best result in each setting is highlighted in bold.\nSupervised experiments include training on the entire training set of LEMONADE , training on randomly sampled\nsubsets of it, and only on its English subset.\nexample, switching from GPT-4o to Llama 3.1 8B\nreduces the overall score by 37.7%. As expected,\nGoLLIE performs worse than its similarly-sized\nmodel in all settings.\nWe also investigate the impact of training data\navailability in the supervised setting. When fine-\ntuning Aya Expanse solely on the English sub-\nset, overall performance drops by 14.4 percent-\nage points, although the performance on English\nremains nearly unchanged. Reducing the overall\namount of training data negatively impacts perfor-\nmance on both English and non-English languages.\nNotably, we observe that the best zero-shot model\nperforms comparably to a supervised model trained\non 1 – 5% (214 – 1,007 examples) of the training\ndata.\n7.5 Discussion\nFrom the results on the EDandAEAE subtasks,\nwe can conclude that for many languages, the best\nmodels perform reasonably well, and can perhaps\nbe used in practice to augment (but not replace)\nmanual news monitoring efforts in this domain.\nNotable exceptions are Somali and Burmese lan-\nguages where even the best models lag behind. The\nAEL subtask, however, paints a different picture as\nall models struggle with unseen entities.\nAs such, we believe future work on LEMONADEcan especially focus on 1) entity linking for un-\nseen entities, and 2) closing the performance gap\nbetween supervised and zero-shot models on all\nsubtasks.\n8 Conclusion\nIn this paper, we introduced the task of abstractive\nevent extraction ( AEE ), a formulation that better\naligns with the requirements of real-world event\nextraction applications. To support research in this\ndirection, we created a large-scale, high-quality\ndataset for AEE in 20 languages, derived from\nexpert-annotated data provided by ACLED.\nOur experiments demonstrate that existing span-\nbased models, such as GoLLIE and OneNet, are in-\nherently unsuitable for the abstractive setting, con-\nsistently performing worse than models based on\nin-context learning.\nAdditionally, we proposed a novel zero-shot en-\ntity linking system, ZEST, which significantly nar-\nrows the performance gap in the abstractive entity\nlinking ( AEL ) subtask. Despite this improvement,\na substantial gap remains between zero-shot and\nfully supervised models. We hope that the release\nofLEMONADE will inspire further research, ulti-\nmately expanding the capabilities of future zero-\nshot event extraction models.\n9\n--- Page 10 ---\nLimitations\nThis paper focuses on document-level event ex-\ntraction and does not address event coreference\nresolution across multiple documents (Eirew et al.,\n2022), which is essential for aggregate event anal-\nysis. Existing event coreference methods, such as\nthose proposed by Gao et al. (2024), could poten-\ntially be adapted to the abstractive event extraction\n(AEE ) setting. We leave this promising direction\nfor future research.\nAdditionally, LEMONADE currently excludes\nother common information extraction tasks, such as\nrelation extraction, and provides annotations only\nfor event and entity extraction.\nFinally, the domain of LEMONADE is limited\nto violent conflict and protest events, emphasizing\nsubtle distinctions between closely related event\ntypes. For instance, a peaceful protest met with ex-\ncessive force is treated as a distinct event type from\none without such force. In contrast, datasets like\nGLEN (Li et al., 2023) offer broader topical cov-\nerage, encompassing events ranging from conflicts\nto sports and other domains.\nEthics Statement\nNo human subjects were involved in this study, and\nno crowdsourced annotations were performed. All\nannotation tasks were conducted either by expert\nannotators from ACLED or by the authors of this\npaper. The dataset is derived exclusively from pub-\nlicly accessible news articles and does not include\npersonally identifiable information (such as names,\naddresses, or mobile device identifiers) of private\nindividuals.\nAcknowledgment\nWe thank Professor Clionadh Raleigh, the CEO\nof ACLED, for her assistance and insights on this\nproject. We also thank the reviewers for their valu-\nable comments and suggestions. This work is sup-\nported in part by the Verdant Foundation and Mi-\ncrosoft Azure AI credits.\nReferences\nACLED. 2020. Coding review process. Accessed:\n2024-09-30.\nACLED. 2023. 2023 impact report. Accessed: 2024-\n09-28.\nACLED. 2023. Armed conflict location\n& event data project (acled) codebook.https://acleddata.com/knowledge-base/codebook/.\nLast updated: 27 September 2024.\nTheodora-Ismene Gizelis Andrea Ruggeri and Han\nDorussen. 2011. Events data as bismarck’s sausages?\nintercoder reliability, coders’ selection, and data qual-\nity.International Interactions , 37(3):340–361.\nAli Balali, Masoud Asadpour, and Seyed Hossein Jafari.\n2022. Cofee: A comprehensive ontology for event\nextraction from text. SSRN Electronic Journal .\nLuisa Bentivogli, Pamela Forner, Claudio Giu-\nliano, Alessandro Marchetti, Emanuele Pianta, and\nKateryna Tymoshenko. 2010. Extending English\nACE 2005 corpus annotation with ground-truth links\nto Wikipedia. In Proceedings of the 2nd Workshop on\nThe People‘s Web Meets NLP: Collaboratively Con-\nstructed Semantic Resources , pages 19–27, Beijing,\nChina. Coling 2010 Organizing Committee.\nDan Braha. 2012. Global civil unrest: Contagion, self-\norganization, and prediction. PLOS ONE , 7(10):1–9.\nShulin Cao, Jiaxin Shi, Liangming Pan, Lunyiu Nie,\nYutong Xiang, Lei Hou, Juanzi Li, Bin He, and Han-\nwang Zhang. 2022. KQA pro: A dataset with explicit\ncompositional programs for complex question an-\nswering over knowledge base. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n6101–6119, Dublin, Ireland. Association for Compu-\ntational Linguistics.\nTommaso Caselli and Chu-Ren Huang. 2012. Sourcing\nthe crowd for a few good ones: Event type detection.\nInProceedings of COLING 2012: Posters , pages\n1239–1248, Mumbai, India. The COLING 2012 Or-\nganizing Committee.\nNathanael Chambers and Dan Jurafsky. 2011. Template-\nbased information extraction without the templates.\nInProceedings of the 49th Annual Meeting of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , pages 976–986, Portland,\nOregon, USA. Association for Computational Lin-\nguistics.\nJianlyu Chen, Shitao Xiao, Peitian Zhang, Kun\nLuo, Defu Lian, and Zheng Liu. 2024. M3-\nembedding: Multi-linguality, multi-functionality,\nmulti-granularity text embeddings through self-\nknowledge distillation. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2024 ,\npages 2318–2335, Bangkok, Thailand. Association\nfor Computational Linguistics.\nMilind Choudhary and Xinya Du. 2024. QAEVENT:\nEvent extraction as question-answer pairs generation.\nInFindings of the Association for Computational Lin-\nguistics: EACL 2024 , pages 1860–1873, St. Julian’s,\nMalta. Association for Computational Linguistics.\nJonathan H. Clark, Eunsol Choi, Michael Collins, Dan\nGarrette, Tom Kwiatkowski, Vitaly Nikolaev, and\nJennimaria Palomaki. 2020. TyDi QA: A benchmark\n10\n--- Page 11 ---\nfor information-seeking question answering in typo-\nlogically diverse languages. Transactions of the As-\nsociation for Computational Linguistics , 8:454–470.\nCamiel Colruyt, Orphée De Clercq, Thierry Desot, and\nVéronique Hoste. 2023. Eventdna: a dataset for\ndutch news event extraction as a basis for news di-\nversification. Language Resources and Evaluation ,\n57(1):189–221.\nSamuel Colvin, Eric Jolibois, Hasan Ramezani,\nAdrian Garcia Badaracco, Terrence Dorsey, David\nMontague, Serge Matveenko, Marcelo Trylesinski,\nSydney Runkle, David Hewitt, and Alex Hall. 2024.\nPydantic.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nLuís Filipe Cunha, Purificação Silvano, Ricardo Cam-\npos, and Alípio Jorge. 2024. Ace-2005-pt: Corpus\nfor event extraction in portuguese. In Proceedings\nof the 47th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval ,\nSIGIR ’24, page 661–666, New York, NY , USA. As-\nsociation for Computing Machinery.\nJohn Dang, Shivalika Singh, Daniel D’souza, Arash\nAhmadian, Alejandro Salamanca, Madeline Smith,\nAidan Peppin, Sungjin Hong, Manoj Govindassamy,\nTerrence Zhao, Sandra Kublik, Meor Amer, Viraat\nAryabumi, Jon Ander Campos, Yi-Chern Tan, Tom\nKocmi, Florian Strub, Nathan Grinsztajn, Yannis\nFlet-Berliac, Acyr Locatelli, Hangyu Lin, Dwarak\nTalupuru, Bharat Venkitesh, David Cairuz, Bowen\nYang, Tim Chung, Wei-Yin Ko, Sylvie Shang Shi,\nAmir Shukayev, Sammie Bae, Aleksandra Piktus, Ro-\nman Castagné, Felipe Cruz-Salinas, Eddie Kim, Lu-\ncas Crawhall-Stein, Adrien Morisot, Sudip Roy, Phil\nBlunsom, Ivan Zhang, Aidan Gomez, Nick Frosst,\nMarzieh Fadaee, Beyza Ermis, Ahmet Üstün, and\nSara Hooker. 2024. Aya expanse: Combining re-\nsearch breakthroughs for a new multilingual frontier.\nArXiv preprint , abs/2412.04261.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nYixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang\nLai, Ziyi Xu, Yilong Zhao, and Tianqi Chen. 2024.Xgrammar: Flexible and efficient structured gener-\nation engine for large language models. Preprint ,\narXiv:2411.15100.\nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,\nAbhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,\nAkhil Mathur, Alan Schelten, Amy Yang, Angela\nFan, et al. 2024. The llama 3 herd of models. ArXiv\npreprint , abs/2407.21783.\nSeth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins,\nand Benjamin Van Durme. 2020. Multi-sentence ar-\ngument linking. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics , pages 8057–8077, Online. Association for\nComputational Linguistics.\nAlon Eirew, Avi Caciularu, and Ido Dagan. 2022. Cross-\ndocument event coreference search: Task, dataset and\nmodeling. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing ,\npages 900–913, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nWilliam Gantt, Shabnam Behzad, Hannah An, Yunmo\nChen, Aaron White, Benjamin Van Durme, and\nMahsa Yarmohammadi. 2024. MultiMUC: Multi-\nlingual template filling on MUC-4. In Proceedings\nof the 18th Conference of the European Chapter of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 349–368, St. Julian’s,\nMalta. Association for Computational Linguistics.\nQiang Gao, Bobo Li, Zixiang Meng, Yunlong Li, Jun\nZhou, Fei Li, Chong Teng, and Donghong Ji. 2024.\nEnhancing cross-document event coreference reso-\nlution by discourse structure and semantic informa-\ntion. In Proceedings of the 2024 Joint International\nConference on Computational Linguistics, Language\nResources and Evaluation (LREC-COLING 2024) ,\npages 5907–5921, Torino, Italia. ELRA and ICCL.\nRalph Grishman and Beth Sundheim. 1996. Message\nUnderstanding Conference- 6: A brief history. In\nCOLING 1996 Volume 1: The 16th International\nConference on Computational Linguistics .\nM. O. Hill. 2010. Diversity and evenness: A unify-\ning notation and its consequences. ArXiv preprint ,\nabs/10.2307.\nI-Hung Hsu, Kuan-Hao Huang, Elizabeth Boschee,\nScott Miller, Prem Natarajan, Kai-Wei Chang, and\nNanyun Peng. 2022. DEGREE: A data-efficient\ngeneration-based event extraction model. In Pro-\nceedings of the 2022 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n1890–1908, Seattle, United States. Association for\nComputational Linguistics.\nI-Hung Hsu, Kuan-Hao Huang, Shuning Zhang, Wenxin\nCheng, Prem Natarajan, Kai-Wei Chang, and Nanyun\nPeng. 2023. TAGPRIME: A unified framework\nfor relational structure extraction. In Proceedings\nof the 61st Annual Meeting of the Association for\n11\n--- Page 12 ---\nComputational Linguistics (Volume 1: Long Papers) ,\npages 12917–12932, Toronto, Canada. Association\nfor Computational Linguistics.\nKuan-Hao Huang, I-Hung Hsu, Prem Natarajan, Kai-\nWei Chang, and Nanyun Peng. 2022. Multilingual\ngenerative language models for zero-shot cross-\nlingual event argument extraction. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\npages 4633–4646, Dublin, Ireland. Association for\nComputational Linguistics.\nKuan-Hao Huang, I-Hung Hsu, Tanmay Parekh, Zhiyu\nXie, Zixuan Zhang, Prem Natarajan, Kai-Wei Chang,\nNanyun Peng, and Heng Ji. 2024. TextEE: Bench-\nmark, reevaluation, reflections, and future challenges\nin event extraction. In Findings of the Association\nfor Computational Linguistics: ACL 2024 , pages\n12804–12825, Bangkok, Thailand. Association for\nComputational Linguistics.\nFilip Ilievski, Piek V ossen, and Stefan Schlobach. 2018.\nSystematic study of long tail phenomena in entity\nlinking. In Proceedings of the 27th International\nConference on Computational Linguistics , pages 664–\n674, Santa Fe, New Mexico, USA. Association for\nComputational Linguistics.\nAlbert Q. Jiang, Alexandre Sablayrolles, Arthur Men-\nsch, Chris Bamford, Devendra Singh Chaplot, Diego\nde las Casas, Florian Bressand, Gianna Lengyel, Guil-\nlaume Lample, Lucile Saulnier, Lélio Renard Lavaud,\nMarie-Anne Lachaux, Pierre Stock, Teven Le Scao,\nThibaut Lavril, Thomas Wang, Timothée Lacroix,\nand William El Sayed. 2023. Mistral 7b. Preprint ,\narXiv:2310.06825.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics ,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nFayuan Li, Weihua Peng, Yuguang Chen, Quan Wang,\nLu Pan, Yajuan Lyu, and Yong Zhu. 2020a. Event\nextraction as multi-turn question answering. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020 , pages 829–838, Online. Association\nfor Computational Linguistics.\nManling Li, Sha Li, Zhenhailong Wang, Lifu Huang,\nKyunghyun Cho, Heng Ji, Jiawei Han, and Clare\nV oss. 2021a. The future is not one-dimensional:\nComplex event schema induction by graph modeling\nfor event prediction. In Proceedings of the 2021 Con-\nference on Empirical Methods in Natural Language\nProcessing , pages 5203–5215.\nManling Li, Ying Lin, Joseph Hoover, Spencer White-\nhead, Clare V oss, Morteza Dehghani, and Heng Ji.2019. Multilingual entity, relation, event and hu-\nman value extraction. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics (Demon-\nstrations) , pages 110–115, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nManling Li, Alireza Zareian, Ying Lin, Xiaoman Pan,\nSpencer Whitehead, Brian Chen, Bo Wu, Heng Ji,\nShih-Fu Chang, Clare V oss, Daniel Napierski, and\nMarjorie Freedman. 2020b. GAIA: A fine-grained\nmultimedia knowledge extraction system. In Pro-\nceedings of the 58th Annual Meeting of the Associa-\ntion for Computational Linguistics: System Demon-\nstrations , pages 77–86, Online. Association for Com-\nputational Linguistics.\nManling Li, Qi Zeng, Ying Lin, Kyunghyun Cho, Heng\nJi, Jonathan May, Nathanael Chambers, and Clare\nV oss. 2020c. Connecting the dots: Event graph\nschema induction with path language modeling. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) ,\npages 684–695, Online. Association for Computa-\ntional Linguistics.\nSha Li, Heng Ji, and Jiawei Han. 2021b. Document-\nlevel event argument extraction by conditional gen-\neration. In Proceedings of the 2021 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , pages 894–908, Online. Association for\nComputational Linguistics.\nSha Li, Qiusi Zhan, Kathryn Conger, Martha Palmer,\nHeng Ji, and Jiawei Han. 2023. GLEN: General-\npurpose event detection for thousands of types. In\nProceedings of the 2023 Conference on Empirical\nMethods in Natural Language Processing , pages\n2823–2838, Singapore. Association for Computa-\ntional Linguistics.\nJian Liu, Yubo Chen, Kang Liu, Wei Bi, and Xiaojiang\nLiu. 2020a. Event extraction as machine reading\ncomprehension. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP) , pages 1641–1651, Online. As-\nsociation for Computational Linguistics.\nMinghui Liu, MeiHan Tong, Yangda Peng, Lei Hou,\nJuanzi Li, and Bin Xu. 2024a. DocEE-zh: A fine-\ngrained benchmark for Chinese document-level event\nextraction. In Findings of the Association for Compu-\ntational Linguistics: EMNLP 2024 , pages 637–649,\nMiami, Florida, USA. Association for Computational\nLinguistics.\nShicheng Liu, Sina Semnani, Harold Triedman, Jialiang\nXu, Isaac Dan Zhao, and Monica Lam. 2024b.\nSPINACH: SPARQL-based information navigation\nfor challenging real-world questions. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2024 , pages 15977–16001, Miami, Florida,\nUSA. Association for Computational Linguistics.\n12\n--- Page 13 ---\nXukai Liu, Ye Liu, Kai Zhang, Kehang Wang, Qi Liu,\nand Enhong Chen. 2024c. OneNet: A fine-tuning\nfree framework for few-shot entity linking via large\nlanguage model prompting. In Proceedings of the\n2024 Conference on Empirical Methods in Natural\nLanguage Processing , pages 13634–13651, Miami,\nFlorida, USA. Association for Computational Lin-\nguistics.\nYinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey\nEdunov, Marjan Ghazvininejad, Mike Lewis, and\nLuke Zettlemoyer. 2020b. Multilingual denoising\npre-training for neural machine translation. Transac-\ntions of the Association for Computational Linguis-\ntics, 8:726–742.\nLajanugen Logeswaran, Ming-Wei Chang, Kenton Lee,\nKristina Toutanova, Jacob Devlin, and Honglak Lee.\n2019a. Zero-shot entity linking by reading entity de-\nscriptions. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics ,\npages 3449–3460, Florence, Italy. Association for\nComputational Linguistics.\nLajanugen Logeswaran, Ming-Wei Chang, Kenton Lee,\nKristina Toutanova, Jacob Devlin, and Honglak Lee.\n2019b. Zero-shot entity linking by reading entity de-\nscriptions. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics ,\npages 3449–3460, Florence, Italy. Association for\nComputational Linguistics.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In 7th International\nConference on Learning Representations, ICLR 2019,\nNew Orleans, LA, USA, May 6-9, 2019 . OpenRe-\nview.net.\nDi Lu, Shihao Ran, Joel Tetreault, and Alejandro Jaimes.\n2023. Event extraction as question generation and\nanswering. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers) , pages 1666–1688, Toronto,\nCanada. Association for Computational Linguistics.\nYi-Fan Lu, Xian-Ling Mao, Tian Lan, Chen Xu, and\nHeyan Huang. 2024. Beyond exact match: Semanti-\ncally reassessing event extraction by large language\nmodels. Preprint , arXiv:2410.09418.\nAyush Maheshwari, Hrishikesh Patel, Nandan Rathod,\nRitesh Kumar, Ganesh Ramakrishnan, and Push-\npak Bhattacharyya. 2019. Tale of tails using rule\naugmented sequence labeling for event extraction.\nPreprint , arXiv:1908.07018.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2023.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. In Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 9802–9822, Toronto,\nCanada. Association for Computational Linguistics.Christopher D. Manning, Prabhakar Raghavan, and Hin-\nrich Schütze. 2008. Introduction to Information Re-\ntrieval . Cambridge University Press, USA.\nDavid Milne and Ian H. Witten. 2008. Learning to link\nwith wikipedia. In Proceedings of the 17th ACM Con-\nference on Information and Knowledge Management ,\nCIKM ’08, page 509–518, New York, NY , USA. As-\nsociation for Computing Machinery.\nSaif Mohammad, Svetlana Kiritchenko, Parinaz Sob-\nhani, Xiaodan Zhu, and Colin Cherry. 2016.\nSemEval-2016 task 6: Detecting stance in tweets.\nInProceedings of the 10th International Workshop\non Semantic Evaluation (SemEval-2016) , pages 31–\n41, San Diego, California. Association for Computa-\ntional Linguistics.\nThi-Nhung Nguyen, Bang Tien Tran, Trong-Nghia Luu,\nThien Huu Nguyen, and Kiem-Hieu Nguyen. 2024.\nBKEE: Pioneering event extraction in the Vietnamese\nlanguage. In Proceedings of the 2024 Joint In-\nternational Conference on Computational Linguis-\ntics, Language Resources and Evaluation (LREC-\nCOLING 2024) , pages 2421–2427, Torino, Italia.\nELRA and ICCL.\nOpenStreetMap contributors. 2017. Planet\ndump retrieved from https://planet.osm.org .\nhttps://www.openstreetmap.org/copyright.\nGiovanni Paolini, Ben Athiwaratkun, Jason Krone,\nJie Ma, Alessandro Achille, Rishita Anubhai, Ci-\ncero Nogueira dos Santos, Bing Xiang, and Stefano\nSoatto. 2021. Structured prediction as translation\nbetween augmented natural languages. Preprint ,\narXiv:2101.05779.\nSteven T Piantadosi. 2014. Zipf’s word frequency law\nin natural language: A critical review and future di-\nrections. Psychonomic bulletin & review , 21:1112–\n1130.\nAmir Pouran Ben Veyseh, Javid Ebrahimi, Franck Der-\nnoncourt, and Thien Nguyen. 2022. MEE: A novel\nmultilingual event extraction dataset. In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing , pages 9603–9613,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nSuhan Prabhu, Pranav Goel, Alok Debnath, and Man-\nish Shrivastava. 2019. Incorporating sub-word level\ninformation in language invariant neural event de-\ntection. In Proceedings of the 16th International\nConference on Natural Language Processing , pages\n36–44, International Institute of Information Tech-\nnology, Hyderabad, India. NLP Association of India.\nMaxim Rabinovich, Mitchell Stern, and Dan Klein.\n2017. Abstract syntax networks for code generation\nand semantic parsing. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , pages 1139–\n1149, Vancouver, Canada. Association for Computa-\ntional Linguistics.\n13\n--- Page 14 ---\nClionadh Raleigh, Rew Linke, Håvard Hegre, and\nJoakim Karlsen. 2010. Introducing acled: An armed\nconflict location and event dataset. Journal of peace\nresearch , 47(5):651–660.\nJeff Rasley, Samyam Rajbhandari, Olatunji Ruwase,\nand Yuxiong He. 2020. Deepspeed: System opti-\nmizations enable training deep learning models with\nover 100 billion parameters. In KDD ’20: The 26th\nACM SIGKDD Conference on Knowledge Discovery\nand Data Mining, Virtual Event, CA, USA, August\n23-27, 2020 , pages 3505–3506. ACM.\nRevanth Gangi Reddy, Yi R Fung, Qi Zeng, Manling\nLi, Ziqi Wang, Paul Sullivan, and Heng Ji. 2023.\nSmartbook: Ai-assisted situation report generation.\nArXiv preprint , abs/2303.14337.\nYubing Ren, Yanan Cao, Hao Li, Yingjie Li, Zixuan ZM\nMa, Fang Fang, Ping Guo, and Wei Ma. 2024. DEIE:\nBenchmarking document-level event information ex-\ntraction with a large-scale Chinese news dataset. In\nProceedings of the 2024 Joint International Con-\nference on Computational Linguistics, Language\nResources and Evaluation (LREC-COLING 2024) ,\npages 4592–4604, Torino, Italia. ELRA and ICCL.\nBaptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten\nSootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,\nJingyu Liu, Romain Sauvestre, Tal Remez, Jérémy\nRapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna\nBitton, Manish Bhatt, Cristian Canton Ferrer, Aaron\nGrattafiori, Wenhan Xiong, Alexandre Défossez,\nJade Copet, Faisal Azhar, Hugo Touvron, Louis Mar-\ntin, Nicolas Usunier, Thomas Scialom, and Gabriel\nSynnaeve. 2023. Code llama: Open foundation mod-\nels for code. Preprint , arXiv:2308.12950.\nChanatip Saetia, Areeya Thonglong, Thanpitcha Amorn-\nchaiteera, Tawunrat Chalothorn, Supawat Taerungru-\nang, and Pakpoom Buabthong. 2024. Streamlining\nevent extraction with a simplified annotation frame-\nwork. Frontiers in Artificial Intelligence , 7:1361483.\nECollection 2024.\nOscar Sainz, Iker García-Ferrero, Rodrigo Agerri,\nOier Lopez de Lacalle, German Rigau, and Eneko\nAgirre. 2024. GoLLIE: Annotation guidelines im-\nprove zero-shot information-extraction. In The\nTwelfth International Conference on Learning Repre-\nsentations .\nSam Jones. 2022. New expansion brings ACLED to full\nglobal coverage. Accessed: 2024-09-28.\nRichard Shin and Benjamin Van Durme. 2022. Few-\nshot semantic parsing with language models trained\non code. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , pages 5417–5425, Seattle, United States.\nAssociation for Computational Linguistics.\nBeth M. Sundheim. 1992. Overview of the fourth Mes-\nsage Understanding Evaluation and Conference. InFourth Message Understanding Conference (MUC-\n4): Proceedings of a Conference Held in McLean,\nVirginia, June 16-18, 1992 .\nMeiHan Tong, Bin Xu, Shuai Wang, Meihuan Han,\nYixin Cao, Jiangqi Zhu, Siyu Chen, Lei Hou, and\nJuanzi Li. 2022. DocEE: A large-scale and fine-\ngrained benchmark for document-level event extrac-\ntion. In Proceedings of the 2022 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, pages 3970–3982, Seattle, United States. Asso-\nciation for Computational Linguistics.\nLewis Tunstall, Edward Beeching, Nathan Lambert,\nNazneen Rajani, Kashif Rasul, Younes Belkada,\nShengyi Huang, Leandro von Werra, Clémentine\nFourrier, Nathan Habib, Nathan Sarrazin, Omar San-\nseviero, Alexander M. Rush, and Thomas Wolf. 2023.\nZephyr: Direct distillation of lm alignment. Preprint ,\narXiv:2310.16944.\nMd Nayem Uddin, Enfa George, Eduardo Blanco, and\nSteven Corman. 2024. Generating uncontextual-\nized and contextualized questions for document-level\nevent argument extraction. In Proceedings of the\n2024 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies (Volume 1: Long Pa-\npers) , pages 5612–5627, Mexico City, Mexico. Asso-\nciation for Computational Linguistics.\nDavid Wadden, Ulme Wennberg, Yi Luan, and Han-\nnaneh Hajishirzi. 2019. Entity, relation, and event\nextraction with contextualized span representations.\nInProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 5784–\n5789, Hong Kong, China. Association for Computa-\ntional Linguistics.\nChristopher Walker, Stephanie Strassel, Julie Medero,\nand Kazuaki Maeda. 2006. Ace 2005 multilingual\ntraining corpus ldc2006t06.\nXiaozhi Wang, Ziqi Wang, Xu Han, Wangyi Jiang, Rong\nHan, Zhiyuan Liu, Juanzi Li, Peng Li, Yankai Lin,\nand Jie Zhou. 2020. MA VEN: A Massive General\nDomain Event Detection Dataset. In Proceedings\nof the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP) , pages 1652–\n1671, Online. Association for Computational Linguis-\ntics.\nXingyao Wang, Sha Li, and Heng Ji. 2023. Code4Struct:\nCode generation for few-shot event structure predic-\ntion. In Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 3640–3663, Toronto,\nCanada. Association for Computational Linguistics.\nHaoyang Wen, Ying Lin, Tuan Lai, Xiaoman Pan, Sha\nLi, Xudong Lin, Ben Zhou, Manling Li, Haoyu\nWang, Hongming Zhang, Xiaodong Yu, Alexander\n14\n--- Page 15 ---\nDong, Zhenhailong Wang, Yi Fung, Piyush Mishra,\nQing Lyu, Dídac Surís, Brian Chen, Susan Windisch\nBrown, Martha Palmer, Chris Callison-Burch, Carl\nV ondrick, Jiawei Han, Dan Roth, Shih-Fu Chang,\nand Heng Ji. 2021. RESIN: A dockerized schema-\nguided cross-document cross-lingual cross-media in-\nformation extraction and event tracking system. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies:\nDemonstrations , pages 133–143, Online. Association\nfor Computational Linguistics.\nBrandon T. Willard and Rémi Louf. 2023. Effi-\ncient guided generation for large language models.\nPreprint , arXiv:2307.09702.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2019. Hug-\ngingface’s transformers: State-of-the-art natural lan-\nguage processing. Preprint , arXiv:1910.03771.\nShitao Xiao, Zheng Liu, Yingxia Shao, and Zhao Cao.\n2022. RetroMAE: Pre-training retrieval-oriented lan-\nguage models via masked auto-encoder. In Proceed-\nings of the 2022 Conference on Empirical Methods in\nNatural Language Processing , pages 538–548, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nZhenran Xu, Yulin Chen, Baotian Hu, and Min Zhang.\n2023. A read-and-select framework for zero-shot\nentity linking. ArXiv preprint , abs/2310.12450.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A massively multilingual\npre-trained text-to-text transformer. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 483–498, On-\nline. Association for Computational Linguistics.\nHang Yang, Dianbo Sui, Yubo Chen, Kang Liu, Jun\nZhao, and Taifeng Wang. 2021. Document-level\nevent extraction via parallel prediction networks. In\nProceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers) , pages 6298–\n6308, Online. Association for Computational Lin-\nguistics.\nVanni Zavarella, Dilek Küçük, Hristo Tanev, and Ali\nHürriyeto ˘glu. 2014. Event extraction for Balkan lan-\nguages. In Proceedings of the Demonstrations at the\n14th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics , pages 65–68,\nGothenburg, Sweden. Association for Computational\nLinguistics.Xin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie,\nZiqi Dai, Jialong Tang, Huan Lin, Baosong Yang,\nPengjun Xie, Fei Huang, Meishan Zhang, Wenjie Li,\nand Min Zhang. 2024a. mGTE: Generalized long-\ncontext text representation and reranking models for\nmultilingual text retrieval. In Proceedings of the 2024\nConference on Empirical Methods in Natural Lan-\nguage Processing: Industry Track , pages 1393–1412,\nMiami, Florida, US. Association for Computational\nLinguistics.\nXin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie,\nZiqi Dai, Jialong Tang, Huan Lin, Baosong Yang,\nPengjun Xie, Fei Huang, Meishan Zhang, Wen-\njie Li, and Min Zhang. 2024b. mgte: General-\nized long-context text representation and reranking\nmodels for multilingual text retrieval. Preprint ,\narXiv:2407.19669.\nMengna Zhu, Zijie Xu, Kaisheng Zeng, Kaiming Xiao,\nMao Wang, Wenjun Ke, and Hongbin Huang. 2024.\nCMNEE:a large-scale document-level event extrac-\ntion dataset based on open-source Chinese military\nnews. In Proceedings of the 2024 Joint International\nConference on Computational Linguistics, Language\nResources and Evaluation (LREC-COLING 2024) ,\npages 3367–3379, Torino, Italia. ELRA and ICCL.\n15\n--- Page 16 ---\nA Creation of L EMONADE\nIn this section, we describe the detailed steps in-\nvolved in creating LEMONADE , including data\ncleaning and the reannotation of specific event ar-\nguments. The overall process combined domain\nexpert spot-checks, iterative improvements by au-\nthors of this paper, and assistance from a large\nlanguage model (GPT-4o) for straightforward yet\nlabor-intensive tasks.\nA.1 Original ACLED Annotation Process\nThe Armed Conflict Location and Event Data\n(ACLED) project (Raleigh et al., 2010), first pub-\nlished in 2010, provides comprehensive annota-\ntions of civil wars, subnational and transnational\nviolent events, political violence, and civil unrest\nacross 243 countries and territories. The dataset\ncovers events reported in approximately 100 lan-\nguages and is updated in near real-time (Sam Jones,\n2022; ACLED, 2023).\nACLED annotations are produced by a team of\naround 200 domain experts and updated weekly.\nThe data sources include news media, reports from\ninternational organizations, NGOs, security agen-\ncies, local partner organizations, and social media\nchannels.\nAnnotations are conducted by researchers famil-\niar with the specific region and language of the\nevents they annotate. These researchers also pro-\nvide an English-language “summary and note,” ex-\nplaining the event, its context, and any uncertain-\nties regarding its labeling. Annotators utilize a\ndedicated annotation tool that maintains an up-to-\ndate list of entities and locations, and they regu-\nlarly communicate with each other to resolve chal-\nlenging annotation decisions. Finally, annotations\nundergo a rigorous multi-step review and quality\nassurance process (ACLED, 2020), consisting of\nthree distinct review stages:\n1.Initial Review: Annotations are first re-\nviewed by another researcher familiar with\nthe same region.\n2.Regional Manager Review: A region-\nspecific research manager, familiar with some\n(but not necessarily all) languages of the re-\ngion, conducts a second review, primarily re-\nlying on the provided English summaries and\nnotes.\n3.Centralized Review: A central team per-\nforms a final review, again using the Englishsummaries and notes, to ensure methodologi-\ncal consistency across different regions.\nIn addition to these review rounds, the ACLED\nquality assurance team conducted a separate re-\nview of 1,265 randomly selected events against the\nACLED codebook, reporting the following find-\nings:\n• 5 events had incorrect event types.\n• 32 events had missing entities.\n• 12 events had inaccurate locations.\n•30 events exhibited other miscellaneous is-\nsues.\nWhen analyzed at the level of individual data points\n(e.g., event type, entities, location, casualties),\nfewer than 1% of researcher-coded labels contained\nerrors.\nA.2 Converting ACLED to L EMONADE\nData Filtering and Cleaning We obtained all\nACLED events from January 2024 to January 2025\n(13 months) totaling 344,116 events. Each event\nwas associated with one or more URLs linking to\nrelevant online sources. Upon analysis, we found\nthat many social media posts included images (e.g.,\nprotest flyers), making text alone insufficient for\naccurate annotation. Consequently, we excluded\nall social media posts from our dataset.\nWe also removed the shortest and longest 1% of\ndocuments. Very short documents, often sourced\nfrom local partner organizations, lacked sufficient\ncontext for accurate annotation, while very long\ndocuments were frequently concatenations of mul-\ntiple news articles included erroneously.\nWe used GPT-4o to detect the language of each\ndocument. Additionally, we retrieved the full text\nfrom the provided URLs and cleaned the docu-\nments by removing advertisements and irrelevant\ncontent using LLM prompts.\nBalancing the Dataset Since ACLED data re-\nflects real-world distributions, the frequency of\nevent types within each language heavily depends\non the political stability of countries where the\nlanguage is spoken. For instance, most events in\nEnglish and Korean are categorized as “Peaceful\nProtest,” whereas Burmese events (from Myanmar)\npredominantly fall under “Armed Clash.” Such\nimbalance can negatively impact AI system per-\nformance. To mitigate this, we downsampled the\n16\n--- Page 17 ---\nmost frequent event types within each language,\nresulting in a balanced dataset of 114,743 events.\nFurthermore, we restricted our dataset to languages\nwith at least 500 events each, ensuring sufficient\ndata for robust model evaluation.\nConverting ACLED to a Document-Level\nDataset As mentioned earlier, each ACLED\nevent is associated with one or more documents.\nTo facilitate document-level event extraction re-\nsearch, we converted the dataset to a one-event-per-\ndocument format by pairing each document with its\ncorresponding event. However, a document might\ncontain only partial information about an event, for\nexample, mentioning only the “attacker” in a Mob\nViolence event, while the “victim” is described in\nanother document). To address this, we processed\neach event-document pair independently, ensuring\nthat each event annotation contained only informa-\ntion explicitly mentioned in its paired document.\nAfter processing, we deduplicated event-document\npairs by retaining only the most complete annota-\ntion for each event.\nLocation Reannotation For location reannota-\ntion, we leveraged the original ACLED location an-\nnotations to query the OpenStreetMap geographic\ndatabase (OpenStreetMap contributors, 2017), re-\ntrieving the full hierarchical location structure\nabove the neighborhood level. Starting from the\nlowest location level, we removed any location\ncomponents not explicitly supported by the doc-\nument, continuing upward until we identified a\nsupported location. We retained this location and\nall higher-level locations. This final step was per-\nformed using a carefully designed LLM prompt.\nThe authors conducted spot-checks on the final\nlocation annotations, confirming that 97% were ac-\ncurate according to the above criteria. Below is an\nexample illustrating the location annotation before\nand after our reannotation process:\nExample Event (Armed Clash): “Balochistan\nLiberation Front Claims Responsibility for... the\nattack on the Pakistani army occupying Mand in a\npress release issued to the media. The spokesper-\nson stated that the Sarmachars attacked the main\ncamp of the enemy army in the Mand area of Kech .\nAt nine o’clock last night, the Sarmachars launched\nan attack on the main camp of the occupying Pak-\nistani army in Mand Soro with rockets, resulting\nin... ”\n•Location Before Reannotation: Bolan Mach,Kachhi, Balochistan, Pakistan\n•Location After Reannotation: Mand Tehsil,\nKech District, Balochistan, Pakistan\nThe authors carried out all annotation work\nfor this paper, communicating with the original\nACLED team to clarify their annotation processes\nand ensure compatibility with their codebook.\nSchematization ACLED employs uniform event\nargument roles across all event types, resulting in\nsome roles consistently remaining empty or overly\ngeneric. To address this, we defined distinct event\nargument roles tailored specifically to each event\ntype. For example, we removed the “fatalities” ar-\ngument from the “Peaceful Protest” event type and\nrenamed “actor 1” to “Abductor” for the “Abduc-\ntion or Forced Disappearance” event type. Addi-\ntionally, we provided concise descriptions for each\nevent type and each event argument, facilitating the\ndevelopment of zero-shot models.\nFollowing recent trends in event extraction, we\nrepresented annotations using Python code. This\napproach has been shown to improve the perfor-\nmance of supervised (Sainz et al., 2024) and few-\nshot (Wang et al., 2023) models by aligning labels\nmore closely with the code data on which many\nlanguage models are pre-trained. Moreover, this\nrepresentation enables the use of constrained de-\ncoding algorithms (Rabinovich et al., 2017; Willard\nand Louf, 2023), effectively eliminating malformed\noutputs. The complete schema for LEMONADE is\nprovided in Appendix I.\nEntity Descriptions As discussed earlier, we\nprovide a short description for each entity in the\ndatabase to facilitate entity linking. These descrip-\ntions are generated by GPT-4o using the news arti-\ncles that are annotated to have involved each entity.\nB Properties of L EMONADE\nB.1 One Event per Document\nInLEMONADE , only the main event described in\neach document is annotated, excluding background\nor historical events typically mentioned to provide\ncontext. The rationale behind this approach is that\nnews articles generally focus on a single new event.\nFor example, an article titled “Anti-war protests\nspurred by recent missile strikes” likely covers\nprotests as the main event, while the missile strikes\nthemselves would have been reported separately in\n17\n--- Page 18 ---\nearlier articles. Thus, annotating one event per doc-\nument can achieve comprehensive event coverage\nwhile minimizing redundancy, making it suitable\nfor real-world applications such as automated news\nmonitoring systems.\nThis formulation also simplifies the task for\nevent extraction systems, leading to higher accu-\nracy compared to multi-event scenarios. For in-\nstance, Yang et al. (2021) demonstrated that single-\nevent formulations yield superior model accuracy\ncompared to multi-event formulations.\nB.2 Entity Distribution\nFigure 2 illustrates the frequency distribution of\nentities in the original ACLED dataset. The entity\ndistribution follows Zipf’s law (Piantadosi, 2014),\na phenomenon previously studied in entity distribu-\ntions by Ilievski et al. (2018).\nFigure 2: Entity frequency distribution in the original\nACLED data, plotted on a log-log scale from the most\nfrequent (rank 1) to the least frequent (rank 10,707).\nExamples are provided at every 10% interval.\nB.3 L EMONADE Statistics\nTable 6 presents the number of events per language\nin each data split of LEMONADE . It also includes\nthe full language names along with the abbrevia-\ntions used throughout this paper.\nTable 7 shows the Hill number (Hill, 2010), or\nthe effective number of event types, in LEMONADE .\nThe Hill number is a diversity metric originating\nfrom ecology. We calculate it using ( q= 1), which\ncorresponds to the exponential of the Shannon en-\ntropy computed with natural logarithms.\nTable 8 and Figure 3 illustrate the distribution\nof event types and the geographical distribution\nof events at the country level in the LEMONADE\ndataset, respectively.\nWe show another example from LEMONADE\nwith abstractive event annotation in Figure 4CComparison of LEMONADE with Other\nDocument-Level Event Datasets\nWhile most EE datasets primarily focus on English\nand Chinese (Zhu et al., 2024; Ren et al., 2024;\nWalker et al., 2006), several datasets have been de-\nveloped for other languages. These datasets vary\nsignificantly in annotation quality and often focus\nsolely on the simpler event detection subtask. No-\ntable examples include:\nBKEE (Nguyen et al., 2024) for Vietnamese,\nInDEE-2019 (Maheshwari et al., 2019) for five In-\ndic languages, MEE (Pouran Ben Veyseh et al.,\n2022) for Portuguese, Spanish, Polish, Turkish,\nHindi, Japanese, and Korean, Zavarella et al. (2014)\nfor Bulgarian, Romanian, and Turkish, Balali et al.\n(2022) for Farsi, Li et al. (2019) for Russian and\nUkrainian, Prabhu et al. (2019) for English, Span-\nish, Italian, and French, Saetia et al. (2024) for\nThai, Colruyt et al. (2023) for Dutch, and Cunha\net al. (2024) for Portuguese.\nTheAEE definition unifies several traditionally\nseparate subtasks. Traditional document-level EE\n(illustrated on the right side of the figure) typically\ninvolves the following sequential steps (Huang\net al., 2024):\n1.Event Detection (ED): Identifying trigger\nspans and their corresponding event types\n(e.g., a MobViolence event).\n2.Event Argument Extraction (EAE): Identi-\nfying argument spans and their roles for each\nevent.\n3.Entity Detection: Finding text spans (men-\ntions) that refer to entities.\n4.Entity Coreference Resolution and/or Link-\ning: Resolving entity coreferences and link-\ning them to corresponding entries in an entity\ndatabase.\nIt is worth noting that conventional EE systems\noften limit event arguments exclusively to enti-\nties (Wadden et al., 2019).\nDExamples of Entities from LEMONADE\nTables 10, 11, 12, 13 and 14 contain examples\nof L EMONADE entities and their description.\nE Examples of AEL System Outputs\nTo illustrate the comparative performance of Span\n(GoLLIE-7B) + OneNet, Span (GPT-4o) + OneNet,\n18\n--- Page 19 ---\nLanguage (language code) Train Dev Test\nEnglish (en) 4593 500 500\nSpanish (es) 1528 500 500\nArabic (ar) 3171 500 500\nFrench (fr) 805 500 500\nItalian (it) 773 500 500\nRussian (ru) 482 500 500\nGerman (de) 1422 500 500\nTurkish (tr) 925 500 500\nBurmese (my) 932 500 500\nIndonesian (id) 754 500 500\nUkrainian (uk) 1157 500 500\nKorean (ko) 1167 500 500\nPortuguese (pt) 1759 500 500\nDutch (nl) 256 284 284\nSomali (so) 251 358 358\nNepali (ne) 389 439 439\nChinese (zh) 332 500 500\nPersian/Farsi (fa) 368 500 500\nHebrew (he) 177 332 332\nJapanese (ja) 175 272 272\nTotal 21,416 9,185 9,185\nTable 6: L EMONADE statistics per language and split.\nLanguage (language code) Train Dev Test Total\nEnglish (en) 11.1 11 10.8 11.2\nSpanish (es) 8 9 8.2 8.3\nArabic (ar) 12.5 13.5 14 13\nFrench (fr) 10.2 11.3 10.8 10.9\nItalian (it) 1.4 1.5 1.6 1.5\nRussian (ru) 7.1 8.5 8.8 8.5\nGerman (de) 1.3 1.8 2 1.5\nTurkish (tr) 3.7 4 3.7 3.8\nBurmese (my) 11.2 11.6 11.5 11.7\nIndonesian (id) 2.3 1.9 2 2.1\nUkrainian (uk) 4.6 4.4 4.4 4.5\nKorean (ko) 1.1 1.1 1.2 1.1\nPortuguese (pt) 4.2 4.8 4.7 4.4\nDutch (nl) 1.7 1.8 2 1.9\nSomali (so) 7.5 6.7 6.8 7.2\nNepali (ne) 2.4 2.5 2.8 2.6\nChinese (zh) 1.5 1.6 1.5 1.6\nPersian/Farsi (fa) 4 4 3.5 3.9\nHebrew (he) 5.3 5.2 5.4 5.6\nJapanese (ja) 1.1 1.1 1.1 1.1\nTotal 8.6 7.2 7.1 8\nTable 7: Hill number (effective number of event types) calculated for each language in L EMONADE .\n19\n--- Page 20 ---\n(a) Train set\n (b) Validation set\n (c) Test set\nFigure 3: Distribution of event locations in the LEMONADE dataset. Although the dataset contains more specific\nlocation information, only country-level data are shown here. In addition to linguistic diversity, the dataset also\nexhibits substantial geographical diversity.\nEvent Type Count\nGovernmentRegainsTerritory 50\nNonStateActorOvertakesTerritory 130\nArmedClash 3,473\nExcessiveForceAgainstProtestors 49\nProtestWithIntervention 1,001\nPeacefulProtest 18,481\nViolentDemonstration 1,050\nMobViolence 1,398\nAirOrDroneStrike 2,074\nSuicideBomb 13\nShellingOrArtilleryOrMissileAttack 2,226\nRemoteExplosiveOrLandmineOrIED 783\nGrenade 145\nSexualViolence 79\nAttack 3,418\nAbductionOrForcedDisappearance 674\nAgreement 87\nArrest 910\nChangeToArmedGroup 667\nDisruptedWeaponsUse 1,126\nBaseEstablished 16\nLootingOrPropertyDestruction 1,204\nNonViolentTransferOfTerritory 42\nOtherStrategicDevelopment 690\nTotal 39,786\nTable 8: Distribution of event types across all splits of\ntheLEMONADE dataset. Although the distribution is im-\nbalanced, it accurately reflects real-world occurrences.\nFor instance, peaceful protests constitute the majority\nof events.andZEST, we present four representative examples\nin English and Chinese. These examples are shown\nin Figures 5, 6, 7, and 8.\nF Prompts Used in Experiments\nIn this section, we provide the prompts used for\nvarious baselines, including ZEST. The prompts are\nwritten using the Jinja2 template language, which\nsupports Python-like loops ( {% for %}{% endfor\n%}), conditional statements ( {% if %}{% endif\n%}), variables ( {{ var }} ), and comments ( #).\nAfter substituting the variables into the prompt\ntemplates, the resulting strings under the sections\nlabeled # instruction and# input are sent to\nthe LLM as the system prompt and user message,\nrespectively.\nG Experiment Details\nG.1 Hyperparameters\nAll models were fine-tuned for 3 epochs with a\nbatch size of 64. The final model checkpoint was\nselected for evaluation. We used a learning rate of\n2×10−5, a cosine learning rate scheduler, and the\nAdamW optimizer (Loshchilov and Hutter, 2019).\nTraining was conducted on a machine equipped\nwith four NVIDIA A100 GPUs (80GB each), us-\ning DeepSpeed (Rasley et al., 2020) and the Trans-\nformers library (Wolf et al., 2019). The fine-tuning\nprocess took approximately 3 hours in total.\nFor GPT-4o, we accessed the model through\nthe OpenAI API. The total API usage cost was\napproximately $2,500.\nFor geolocation information, we utilized the pub-\nlicly hosted OpenStreetMap service via Nominatim\n(https://nominatim.openstreetmap.org/ ).\nG.2 Model Versions\nWe use the following models:\n20\n--- Page 21 ---\nPolice For ces of Ethiopia - Addis Ababa City Police:  The Police For ces of Ethiopia - Addis Ababa City Police ar e a state law ...          \nPolice For ces of Ethiopia - Federal Police:  The Police For ces of Ethiopia - Federal Police is a state for ce responsible for ...                \nCivilians:  Civilians ar e unarmed and vulnerable individuals or gr oups who ar e often victims of violent acts ...                                         \nLabor Gr oup: A \"Labor Gr oup\" is a collective entity composed of workers or trade unions that advocate for labor rights ...                    \nEvent Extraction (EE) OutputDomain\nEntities\nAbductionOrForcedDisappearance(\n    targets_local_administrators=False,\n    women_targeted=[], \n    abductor=[\n'Police Forces of Ethiopia - Addis Ababa City Police ',\n'Police Forces of Ethiopia - Federal Police '\n    ], \n    abductee=[\n'Civilians ',\n'Labor Group '\n    ],\n...\n)Abstractive Event Extraction (AEE) Output\nAbductionOrForcedDisappearance (\n    mention=\" taken\",\n    abductor =[\n        'security forces '\n    ]\n    abductee =[\n        ' One detainee ',\n'Another former detainee ',\n        ' Mechemegeta Andualem ',\n'52 cases '\n    ],\n...\n)The Ethiopian Human Rights Commission\nhas called for ur gent action to ensur e accountability and justice \nafter documenting 52 cases of enfor ced disappearances and arbitrary \ndetentions between July 2023 and October 2024, with detentions \noccurring in military camps and undisclosed locations outside Addis Abeba .\n...\nThe r eport detailed how individuals  were taken fr om their homes or \nworkplaces by security for ces, often in unmarked vehicles \nand in the pr esence of witnesses.\n...\n“I was held in solitary confinement ... ,” said Mechemegeta Andualem , \nwho was r eleased in Mar ch 2024 ...\nAnother former detainee , who r equested anonymity , described ...\nOne detainee  reported being moved thr ough multiple sites, ...\n...Text Input\nThe Ethiopian Human Rights Commission\nhas called for ur gent action to ensur e accountability and justice \nafter documenting 52 cases  of enfor ced disappearances and arbitrary \ndetentions between July 2023 and October 2024, with detentions \noccurring in military camps and undisclosed locations outside Addis Abeba.\n...\nThe r eport detailed how individuals  were taken fr om their homes or \nworkplaces by security for ces, often in unmarked vehicles \nand in the pr esence of witnesses.\n...\n“I was held in solitary confinement ... ,” said Mechemegeta Andualem , \nwho was r eleased in Mar ch 2024 ...\nAnother former detainee , who r equested anonymity , described ...\nOne detainee  reported being moved thr ough multiple sites, ...\n...Text InputFigure 4: Another example from the LEMONADE dataset, shown with its abstractive event annotation. The input\ntext and annotations have been summarized for clarity. A hypothetical extractive annotation for the same event is\nalso provided for comparison. Note that identifying the abductors as “Ethiopian Police Forces” requires inference\nbased on the event location (Addis Ababa) and contextual information.\n•XLM-RRM :https://huggingface.co/\nBAAI/bge-m3-retromae\n•mGTE (for entity retrieval) :\nhttps://huggingface.co/Alibaba-NLP/\ngte-multilingual-base\n•Aya Expanse 8B :https://huggingface.\nco/CohereForAI/aya-expanse-8b\n•GPT-4o-mini :gpt-4o-mini-2024-07-18\n•GPT-4o :gpt-4o-2024-11-20\nG.3 Baselines\nSelection of EE Baselines Many existing EE\nmodels rely on pre-trained language models with\ncustom architectural modifications specifically de-\nsigned for extractive EE tasks. Notable ex-\namples include DEGREE (Hsu et al., 2022),\nTANL (Paolini et al., 2021), X-GEAR (Huang\net al., 2022), and TagPrime (Hsu et al., 2023).However, these models are not suitable for eval-\nuation on LEMONADE . They typically use pre-\ntrained models such as BART (Lewis et al., 2020),\nmT5 (Xue et al., 2021), mBART (Liu et al., 2020b),\nand BERT (Devlin et al., 2019), which have been\npre-trained on sequences limited to 512 tokens,\nwhile approximately 39% of the inputs in LEMON -\nADE exceed this length. Furthermore, these models\nhave primarily been evaluated on sentence-level\nEE datasets. Additionally, these models rely on ex-\nplicit event triggers and argument spans, which are\nnot provided in the AEE formulation or in LEMON -\nADE.\nGoLLIE GoLLIE achieved state-of-the-art zero-\nshot generalization results on several event ex-\ntraction datasets, including document-level EE\ndatasets (Li et al., 2021b). Notably, GoLLIE has\nbeen trained on RAMS (Ebner et al., 2020) and\nACE05 document-level event datasets, making it a\nstrong candidate for evaluating the EDandAEAE\nsubtasks in a zero-shot setting. We use the GoLLIE-\n21\n--- Page 22 ---\nACE05 DocEE L EMONADE WikiEvents RAMS Maven-Arg\nLanguages English, Chi-\nnese, Arabic,\nPortugueseEnglish,\nChinese∗20 Languages English English English\nEvent Argu-\nment Typesstring string string, numeri-\ncal, categorical,\nbooleanstring string string\nEntity\nDatabaseWikipedia∗– Domain Expert\nCurated– – –\nAvg. Doc len 2,410 2,052 6,428 3,919 591 1,589\nAnnotators LDC Annota-\ntion GroupCrowdworkers ACLED Do-\nmain ExpertsGraduate Stu-\ndentsCrowdworkers Crowdworkers\nNum. Docs 1,635 64,214∗39,786 246 3,993 4,480\nNum. Events 8,878 64,214∗39,786 3,951 9,124 98,591\nSource News Wikipedia News Wikipedia News Wikipedia\nTable 9: Comparison of LEMONADE with several other document-level event datasets. LEMONADE covers the\nlargest number of languages and has the longest average document length. As an AEE dataset, it also includes a\nbroader range of event argument types. An en-dash (–) indicates that the dataset does not include an entity linking\nsubtask.\nNote:∗Includes aggregate statistics from multiple datasets. Entity linking was added to ACE05 by Bentivogli et al.\n(2010). Cunha et al. (2024) translated ACE05 into Portuguese using automatic translation. Liu et al. (2024a) created\nanother dataset in Chinese using the same ontology as DocEE.\nProtestWithIntervention(\n    location=Location(\n        country='Afghanistan',\n        address='Kabul'\n    ),\n    crowd_size='Scores',\n    protestors=[],\n    perpetrators=['Government of Afghanistan'],\n    fatalities=None\n)The T aliban has abolished the pension system \nin Afghanistan, which is gripped by a devastating \neconomic and humanitarian crisis. \nThe move has trigger ed pr otests by r etirees \nwho say they cannot survive without state assistance. \nScores of r etired civil servants and r etired members \nof the armed for ces staged a rally in Kabul on April 20. \nThe pr otest was dispersed by the T aliban.\nProtestWithIntervention(\n    location=Location(\n        country='Afghanistan',\n        address='Kabul, Afghanistan'),\n    crowd_size='Scores',\n    protestors=[],\n    perpetrators=[' Military Forces of Afghanistan '],\n    fatalities=None\n)ProtestWithIntervention(\n    location=Location(\n        country='Afghanistan',\n        address='Kabul, Afghanistan'),\n    crowd_size='scores',\n    protestors=[\n        'Former Military Forces of Afghanistan ',\n        'Labor Group',\n        'Protestors '\n    ],\n    perpetrators=[' Military Forces of Afghanistan '],\n    fatalities=0\n)\nProtestWithIntervention(\n   location=Location(\n      country='Afghanistan',\n      address='Kabul, Afghanistan'\n   ),\n   crowd_size='Scores',\n   protestors=[\n      'Protestors ',\n      'Former Military Forces of Afghanistan ',\n      'Former Police Forces of Afghanistan'\n    ],\n   perpetrators=[\n      'Military Forces of Afghanistan ',\n      'Government of Afghanistan'\n    ],\n   fatalities=None\n)GoLLIE + OneNet\nGPT-4o + OneNetGroundT ruth\nZest\nFigure 5: Example 1. The term “retired” in the input document indicates the involvement of the “Former Military\nForces of Afghanistan” in the event. However, OneNet-based systems fail to capture this detail.\n22\n--- Page 23 ---\nEntity Name Entity Description\nWomen Women are adult human females who can play diverse roles in\nsociety, ranging from caregivers and economic participants to po-\nlitical and social activists. They may be involved in a variety of\nsocial, economic, and political events, sometimes facing unique\nchallenges such as discrimination or violence. Women’s roles\nand their societal impact can be profound, as seen in their in-\nvolvement in protests, advocacy for rights, and even in conflict\nsituations where they may be victims or participants. Globally,\nwomen continue to strive for gender equality and empowerment,\noften organizing and mobilizing to address issues affecting their\ncommunities and themselves.\nMen Men are adult human males who may be involved in a variety of\nsocietal roles and activities. As an entity, men can be participants\nin diverse events ranging from everyday community interactions to\nmore extreme scenarios such as protests, violence against civilians,\nand riots. Men, as a group, can be both perpetrators and victims of\nviolence, including sexual violence, as evidenced in various global\nincidents. Their involvement in these events can be influenced\nby cultural, social, and political contexts. This entity operates\nglobally across all countries and societies.\nPolice Forces of the United\nStatesThe Police Forces of the United States are a collective entity com-\nposed of various local, state, and federal law enforcement agencies\ntasked with maintaining public order, enforcing laws, and ensuring\npublic safety across the nation. These forces include municipal po-\nlice departments, sheriff’s offices, and specialized agencies such as\nthe Federal Bureau of Investigation. They are recognized for their\ninvolvement in a wide range of activities, from managing public\nprotests and investigating crimes to ensuring security during emer-\ngencies. While they play a crucial role in law enforcement, they\nhave also faced scrutiny and legal challenges related to incidents\nof misconduct and use of force. Their operations are governed by\nstate and federal laws, and they are accountable to governmental\noversight bodies. They have been active since at least 1993 and\ncontinue to operate across the United States.\nMilitary Forces of Russia The Military Forces of Russia are the armed forces of the Russian\nFederation, responsible for national defense and military opera-\ntions both within and outside Russia. Established in 2000, they\noperate under the command of the President of Russia, who is the\nsupreme commander-in-chief. These forces are composed of vari-\nous branches, including the Ground Forces, Navy, and Air Force,\nalong with strategic missile troops and airborne troops. They\nhave been involved in international military operations, peacekeep-\ning missions, and domestic security tasks. The Russian military\nis recognized for its significant involvement in various conflicts,\nincluding actions in Ukraine, Syria, and other regions, often col-\nlaborating with or opposing other nations’ forces. The Military\nForces of Russia are known for their extensive use of armored\nvehicles, aerial support, and advanced military technology.\nTable 10: 20 entities in L EMONADE entity database – Part 1\n23\n--- Page 24 ---\nEntity Name Entity Description\nProtestors Protestors are individuals or groups who actively participate in\ndemonstrations to express opposition or demand action on spe-\ncific issues. They can be found globally and may engage in\npeaceful protests or civil disobedience to draw attention to their\ncauses. Protestors often advocate for political, social, or economic\nchanges and can be associated with various movements, including\nanti-corruption, electoral fairness, and human rights. While they\nprimarily aim for peaceful expression, their activities can some-\ntimes lead to confrontations with authorities or opposing groups.\nProtestors play a crucial role in civil society by challenging per-\nceived injustices and influencing public discourse and policy.\nCivilians Civilians are unarmed, non-combatant individuals who are often\nvulnerable to violence and conflict, particularly in areas of political\nor social unrest. They can be affected by or involved in a wide\nrange of events, including riots, protests, and violence, as seen\nin various global contexts. Civilians may participate in social\nmovements, such as protests at educational institutions, or be\nsubject to violence and negotiation processes in conflict zones,\nlike settlements in Syria or mass violence in Colombia. Their\ninvolvement can manifest in active participation in civic actions\nor as victims of political and criminal violence, highlighting their\ndiverse roles and the threats they face in unstable environments.\nRioters Rioters are loosely assembled groups or mobs that engage in\nviolent and disruptive behavior during demonstrations or sponta-\nneously, often in response to perceived injustices or grievances.\nThey may be civilians acting without inherent organization, and\ntheir actions typically involve confrontations with law enforcement\nor other entities. Rioters can be motivated by various social, politi-\ncal, or economic factors and are known to participate in actions\nsuch as vandalism, clashes, and other forms of violence. Their\nactivities can occur in any country and are often part of broader\nsocial movements or tensions.\nStudents Students are individuals enrolled in educational institutions, rang-\ning from primary schools to universities, and are often involved in\nvarious social and political activities. They can be a diverse and\ndynamic group that participates in protests, movements against\ndiscrimination, and other forms of activism, sometimes leading\nto confrontations with law enforcement or political opposition.\nStudents can also be impacted by external conflicts, such as gang\nviolence, which may directly affect their safety and educational\nenvironment. While they are typically associated with learning\nand academic pursuits, students have historically played signifi-\ncant roles in advocating for change and challenging established\nsystems, sometimes at the risk of becoming involved in violent or\ncontroversial situations.\nTable 11: 20 entities in L EMONADE entity database – Part 2\n24\n--- Page 25 ---\nEntity Name Entity Description\nFarmers Farmers are individuals or communities engaged in agriculture,\nresponsible for cultivating crops and raising livestock. They op-\nerate globally and can be involved in various socio-political and\neconomic events such as land disputes, protests, and negotiations\naffecting their livelihoods. Farmers often face challenges like\nresource competition, violence from armed groups, and policy\nchanges impacting their work conditions and income. Their role is\ncrucial in food production and sustainability, and they frequently\ninteract with governments, organizations, and other agricultural\nstakeholders to address issues like land rights, security, and agri-\ncultural policies.\nLabor Group A “Labor Group\" is a collective of workers united to advocate\nfor their rights and interests in various sectors of the economy.\nThese groups often engage in activities such as protests, strikes,\nand negotiations to address issues related to working conditions,\nwages, and employment security. They may also become involved\nin larger civil unrest, participating in events like riots or demon-\nstrations to exert pressure on employers or authorities. While\nnot typically associated with violent activities, labor groups can\nsometimes be connected to broader social movements that may\nencounter conflicts with law enforcement or political entities. La-\nbor groups operate globally, often organized at local, national, or\nindustry levels, and play a crucial role in labor relations and policy\nadvocacy.\nGuatemalan Group The “Guatemalan Group\" refers to a collective of Guatemalan im-\nmigrants and workers who engage in activism, particularly around\nlabor rights, in countries like the United States and Australia. This\ngroup is involved in protests and rallies advocating for fair labor\nconditions and justice for immigrant workers. Their activism is\nexemplified through participation in events such as May Day ral-\nlies, where representatives like Eder Juarez highlight issues such\nas wage theft and lack of employee rights, making them a voice\nfor immigrant labor struggles.\nJI: Jamiat-e-Islami Jamiat-e-Islami (JI) is a significant political and military organiza-\ntion in Afghanistan, primarily composed of ethnic Tajiks. Estab-\nlished in the 1970s, it played a crucial role in the resistance against\nthe Soviet invasion and later in the Afghan civil war. Historically\naligned with prominent leaders such as Ahmad Shah Masoud, JI\nhas maintained influence in Afghan politics, often representing\nnon-Pashtun interests. Despite the Taliban’s dominance, JI contin-\nues to be active, reflecting ongoing ethnic and political tensions\nwithin the country. Its members, including prominent diplomats\nand officials, have been involved in key governmental roles and\nresistance efforts against various regimes.\nTable 12: 20 entities in L EMONADE entity database – Part 3\n25\n--- Page 26 ---\nEntity Name Entity Description\nChang Tribal Group The Chang Tribal Group is an indigenous community in India,\nprimarily located in the state of Nagaland. Represented by the\nChang Wedoshi Setshang (CWS), the group is known for advocat-\ning for their rights and addressing local grievances, particularly\nin the educational sector. They have been involved in protests to\ndemand better resources and support from the government, as seen\nin their actions to secure transportation for Sao Chang College.\nThe group’s activities underscore their active role in seeking im-\nproved living and educational conditions for their community.\nSD: Solidarity Party The SD: Solidarity Party, also known as Solidariedade, is a politi-\ncal organization based in Brazil that is categorized as a political\nmilitia. It is known for its involvement in violent actions against\ncivilians, often linked to political motives. The party has been\nassociated with political figures in vulnerable positions, such as\nJosé Erlânio Firmiano, a city councilor who was assassinated in\nAlagoas. The Solidarity Party remains active in Brazilian politics,\nhighlighting ongoing challenges related to political violence in the\nregion.\nLos Motonetos Gang The Los Motonetos Gang is a political militia group operating\nprimarily in Mexico, known for using violence to further their\npolitical aims. The gang gained notoriety for its involvement in\nriots and for the use of high-caliber weapons, which has resulted\nin significant unrest and necessitated interventions by local and\nnational security forces, including the Municipal Police, State Pre-\nventive Police, and the Mexican Army. The group’s influence and\noperational capacity were highlighted following the assassination\nof their presumed leader, Juan Hernández López, also known as\nEl Fayo, which led to armed protests and heightened security mea-\nsures in the region of San Cristóbal de las Casas, Chiapas.\nMebri Tribal Group The Mebri Tribal Group is an indigenous community in Indone-\nsia, specifically located in Papua. They are actively involved in\nadvocating for the recognition and protection of their ancestral\nland rights. The group is known for organizing protests to demand\nfair compensation for the use of their land by government projects,\nsuch as healthcare infrastructure. They emphasize negotiation and\ndialogue with government authorities to resolve land disputes, as\nexemplified by their demands directed at the Indonesian Ministry\nof Health regarding land claims in areas under development.\nTable 13: 20 entities in L EMONADE entity database – Part 4\n26\n--- Page 27 ---\nEntity Name Entity Description\nAra Communal Group The Ara Communal Group is a communal entity based in the town\nof Ara, located in the western countryside of As-Suwayda, Syria.\nFormed in 2024, the group is involved in regional socio-political\nactivism and has participated in significant anti-Hayat Tahrir al-\nSham protests across Idlib and Aleppo. These protests have called\nfor political changes including the resignation of the group’s leader\n“al-Jolani,\" the release of detainees, and the dismantling of the\nGeneral Security Apparatus. The group has also been linked to\nincidents of remote violence, such as assassination attempts using\nexplosive devices, amidst a backdrop of security instability and\nweak law enforcement in areas controlled by regime forces. The\nAra Communal Group remains active and continues to influence\npolitical dynamics in the region.\nBack the Blue “Back the Blue” is a slogan and movement within the United States\nthat expresses support for law enforcement officers. It is often used\nby individuals and groups, including political supporters, during\nprotests and public demonstrations to show solidarity with police\nforces. The phrase is commonly associated with conservative and\npro-law enforcement sentiments, frequently appearing in contexts\nwhere participants oppose policies perceived as critical of the\npolice or supportive of police reform. “Back the Blue” can also\nsignify a broader political stance that emphasizes law and order.\nNalia Communal Group The Nalia Communal Group is a factional community group based\nin Nalia village, located in the Lohagara Upazila of Narail, India. It\nis characterized by internal conflict, with power struggles between\ndifferent factions, notably those led by Shaukat Khan and Ravi\nKhan. The group has been involved in violent clashes, often\nrequiring police intervention to restore order. These conflicts are\nprimarily driven by issues of dominance within the community,\nand the group remains active in its region.\nZPR: For Justice and Order ZPR: For Justice and Order, also known as Za Pravdu i Red, is a\npolitical militia operating in Bosnia and Herzegovina since 2020.\nIt is involved in political activities and protests, aiming to address\nissues of governance and electoral integrity. The group is led\nby Nebojša Vukanovi ´c and has been active in organizing demon-\nstrations against political corruption and foreign exploitation of\nnatural resources. ZPR is also linked to political candidates in\nregional elections, such as Slaviša Pavlovi ´c, whose affiliation with\nthe group highlights its engagement in local politics.\nTable 14: 20 entities in L EMONADE entity database – Part 5\n27\n--- Page 28 ---\nMobViolence(\n    location=Location(\n        country='Bangladesh',\n        address='Madar Bux Hall of Rajshahi University'),\n    crowd_size='group',\n    fatalities=None,\n    targets_civilians=True,\n    group_1=[],\n    group_2=[],\n    targets_local_administrators=False,\n    women_targeted=[]\n)A group of leaders and activists of the ruling \nAwami League-backed student or ganisation \nBangladesh Chhatra League allegedly \ntortur ed two students, including a leader of \nthe Jatiyatabadi Chhatra Dal, student wing of \nthe main opposition Bangladesh Nationalist Party , \nat Madar Bux Hall of Rajshahi University on Monday night.\nMobViolence(\n    location=Location(\n        country='Bangladesh',\n        address='..., Rajshahi, Bangladesh'),\n    crowd_size='A group',\n    fatalities=None,\n    targets_civilians=True,\n    group_1=[' BCL: Bangladesh Chhatra League '],\n    group_2=[],\n    targets_local_administrators=False,\n    women_targeted=[]\n)MobViolence(\n    location=Location(\n        country='Bangladesh',\n        address='Rajshahi, Bangladesh'),\n    crowd_size=None,\n    fatalities=0,\n    targets_civilians=True,\n    group_1=[\n        ' BCL: Bangladesh Chhatra League ',\n        'Rioters', 'Students' ],\n    group_2=[\n        'Civilians', 'Students',\n        ' JCD: Bangladesh Jatiotabadi Chatra Dal '],\n    targets_local_administrators=False,\n    women_targeted=[] )\nMobViolence(\n    location=Location(\n        country='Bangladesh',\n        address='..., Rajshahi, Bangladesh'),\n    crowd_size='A group of leaders and activists',\n    fatalities=0,\n    targets_civilians=True,\n    group_1=[' BCL: Bangladesh Chhatra League '],\n    group_2=[' JCD: Bangladesh Jatiotabadi Chatra Dal '],\n    targets_local_administrators=False,\n    women_targeted=[]\n)GoLLIE + OneNet\nGPT-4o + OneNetGroundT ruth\nZestFigure 6: Example 2.\nNone Valid EAE Result Detected2024年 5月 22 日上午 9 点 30 分，四川绵阳锦旗哥冯勇军\n被控寻衅滋事罪一案，在成都市邛崃市人民法院\n第七审判庭开庭审理。据称，法庭内外现场便衣特警众多，\n只给家属 2 个旁听名额。有一名网友前去旁听，\n被警察带走后关进黑屋；还有一名网友在现场用手机\n拍摄视频，被抢走手机后强制删除\nAbductionOrForcedDisappearance(\n    location=Location(\n        country='China', address='Chengdu, Sichuan, China'),\n    targets_local_administrators=False,\n    women_targeted=[],\n    abductor=[],\n    abductee=[]\n)AbductionOrForcedDisappearance(\n    location=Location(\n        country='China', address='Qionglai City, Sichuan, China'),\n    targets_local_administrators=False,\n    women_targeted=[],\n    abductor=[' Police Forces of China '],\n    abductee=['Civilians'])\nAbductionOrForcedDisappearance(\n    location=Location(\n        country='China', address='Chengdu, Sichuan, China'),\n    targets_local_administrators=False,\n    women_targeted=[],\n    abductor=[' Police Forces of China '],\n    abductee=['Protestors']\n)GoLLIE + OneNet\nGPT-4o + OneNetZestGroundT ruth\nFigure 7: Example 3. The input text is in Chinese and translates as follows: “On the morning of May 22, 2024, at\n9:30 AM, the case of Feng Yongjun, known as the ‘Banner Brother’ from Mianyang, Sichuan, who was charged\nwith the crime of provoking trouble, was heard in the seventh courtroom of the Qionglai City People’s Court in\nChengdu. It is reported that numerous plainclothes special police officers were present both inside and outside the\ncourtroom, and only two seats were allocated for family members to attend the hearing. One netizen who went to\nobserve the trial was taken away by the police and detained in a dark room. Another netizen who was recording a\nvideo on their phone at the scene had their phone confiscated and the video forcibly deleted.”\n28\n--- Page 29 ---\nPeacefulProtest(\n    location=Location(country=' 山东省 ', address=' 烟台市 '),\n    crowd_size=' 工人 ',\n    protestors=[],\n    counter_protestors=[])在山东省烟台市，一建筑项目因拖欠工资引发工人讨薪。\n工人们表示，中油一建拖欠农民工工资，且无人管理此事。\n抗议活动中，工人们一早上将大门堵上，\n表达对欠薪的强烈不满。\n参与人数在 1 到 100 人之间，行业涉及建筑业。\nPeacefulProtest(\n    location=Location(\n        country='China', address='Yantai, Shandong'),\n    crowd_size='1 to 100',\n    protestors=[],\n    counter_protestors=[]\n)PeacefulProtest(\n    location=Location(\n        country='China', address='Shandong, China'),\n    crowd_size=None,\n    protestors=[\n        'Labor Group',\n        'Protestors '\n    ],\ncounter_protestors=[])\nPeacefulProtest(\n    location=Location(\n        country='China', address='Yantai, Shandong, China'),\n    crowd_size='1 to 100',\n    protestors=[' Protestors '],\n    counter_protestors=[]\n)GoLLIE + OneNet\nGPT-4o + OneNetZestGroundT ruthFigure 8: Example 4. The input text is in Chinese and translates as follows: “In Yantai City, Shandong Province, a\nconstruction project has sparked a wage dispute due to unpaid wages. The workers stated that China Petroleum First\nConstruction Corporation has been delaying the payment of wages to migrant workers, and no one is addressing the\nissue. During the protest, the workers blocked the entrance early in the morning to express their strong dissatisfaction\nwith the unpaid wages. The number of participants ranged from 1 to 100 people, and the industry involved is\nconstruction.”\n# instruction\nYou are tasked with determining the best matching Event types for a given news article. You will be\nprovided with annotation guidelines and a news article to analyze. Your goal is to identify\nthe most relevant event types and rank them in order of their match to the article content.\n# input\nHere is the news article you need to analyze:\n{{ article }}\nNow, carefully review the annotation guidelines for various event types:\n{%\n[{{ loop.index }}] \"{{ ed[0] }}\": {{ ed[1] }}\n{%\n1. For each event type, determine how well it matches the article content. Consider the following\nfactors:\n- How closely the event description aligns with the main focus of the article\n- The presence of key actors or entities mentioned in the event type description\n- The occurrence of specific actions or outcomes associated with the event type\n2. Rank the event types based on their relevance to the article content. Only include event types\nthat have a meaningful connection to the article.\n3. Output your results using the following format:\n- List the relevant event types in descending order of match quality\n- Use the \">\" symbol to separate the event types\nYour output should look like this:\n[Explain your reasoning for the event types you decide to include, and their order]\nevent_type_1 > event_type_2 > ...\nProvide only the ranked list of event types in your final answer.\nTable 15: Prompt for event detection (ED).\n29\n--- Page 30 ---\nYou will be given a news article about an event. Your task is to identify all potential Entities\nwho are directly or indirectly involved in the event. Then, write a very short Wikipedia\nparagraph describing each entity in the general sense.\nAn Entity is defined as an individual, group, collective, or organization involved in an event.\nThis includes:\n* Organized armed groups with political purposes (e.g. \"Hezbollah\", \"ISIS\")\n* Organizations, governments, and political parties (e.g. \"BJP: Bharatiya Janata Party\", \"\nGovernment of India\", \"Democratic Party of U.S.\")\n* Ethnic, religious, social or occupational groups (e.g. \"Jewish Group\", \"Muslim Group\", \"Women\",\n\"Students\", \"Farmers\", \"Journalists\", \"Teachers\", \"Lawyers\")\n* General terms describing people involved (e.g., \"Rioters\", \"Protestors\", \"Civilians\", \"Labor\nGroup\")\nWhen identifying Entities, follow these guidelines:\n1. Be as thorough as possible. Think about what groups are implicitly or indirectly involved in the\nevent. Ask yourself:\n- Can the identity group (religion, gender, occupation etc.) of the victims or perpetrators be\ninferred? If so, you should create an entity for that group.\n- Does the event involve workers or unions, or is it a labor issue? If so, you should add \"Labor\nGroup\" as an entity.\n- Does the event in any way involve students, school or university? If so, you should add \"\nStudents\" as an entity.\n- Does the event involve women in any way? If so, you should add \"Women\" as an entity.\n- Does the event involve civilians? If so, you should add \"Civilians\" as an entity.\n- Is the event a protest or a riot? If so, you should add \"Protestors\" or \"Rioters\" as an entity.\n- Does the event involve an unknown or unspecified group? If so, you should add one of \"\nUnidentified Armed Group\", \"Unidentified Gang\", \"Unidentified Communal Group\" etc. as an\nentity.\n- Given the country the event is taking place in, what are the major political parties, religious\ngroups, armed groups, or social movements that could be involved? Consider cultural context\nof the region, like common religions, ethnicities etc.\n- And the like.\n2. Include alternative names or spellings of each entity if mentioned in the article\n3. For individuals, infer their role, affiliation, or social group as explained above.\n4. For each entity you identify, think about its affiliated, parent or member groups. For example,\nif a politician is mentioned, think about their political party or any other group they are\nassociated with. If a union is mentioned, think about the workers or labor groups it\nrepresents.\nUse a scratchpad to think through your process:\n<scratchpad>\n[Your thought process here, including your answer to the above questions]\n</scratchpad>\nThen, present your output in the following JSON format. Output as many entities as you can possibly\nthink of.\n<entity_list>\n{\n\"entity 1\": \"Wikipedia paragraph 1\",\n\"entity 2\": \"Wikipedia paragraph 2\",\n...\n}\n</entity_list>\n# input\nArticle: {{ article }}\nTable 16: Prompt for the first stage Z EST, to generate queries.\n30\n--- Page 31 ---\nYou will be given a news article about an event and potential Entities who are directly or\nindirectly involved in the event. Your task is to find supporting evidence for each of the\nspecified entities in the given article.\nAn Entity is defined as an individual, group, collective, or organization involved in an event.\nThis includes:\n* Organized armed groups with political purposes (e.g. \"Hezbollah\", \"ISIS\")\n* Organizations, governments, and political parties (e.g. \"BJP: Bharatiya Janata Party\", \"\nGovernment of India\", \"Democratic Party of U.S.\")\n* Ethnic, religious, social or occupational groups (e.g. \"Jewish Group\", \"Muslim Group\", \"Women\",\n\"Students\", \"Farmers\", \"Journalists\", \"Teachers\", \"Lawyers\")\n* General terms describing people involved (e.g., \"Rioters\", \"Protestors\", \"Civilians\", \"Labor\nGroup\")\nFollow these steps carefully:\n1. First, you will be provided with the full text of the news article. Read the article carefully\nto understand the context of the event.\n2. Next, you will be given a list of entities involved with the event.\n3. Identify all supporting evidence of each given entity. Each evidence should be a short span from\nthe article that has one of the following:\n- Contains the entity name, abbreviation or variations of its name\n- Implies the entity indirectly. For example \"Madrasa\" could be an evidence for \"Muslim Group\".\n- Mentions an affiliated group or organization of the entity.\n4. If there are multiple evidence for the involvement of an entity, output one of them. If no\nevidence is found for an entity, respond with a mostly empty `EntitySpan `and only fill the `\nexplanation `field.\n5. For each evidence you find for an entity, provide your answer in the provided JSON format.\nInclude the original entity name in the `entity_name `field to denote which entities the\nevidence is for.\n6. If unsure, err on the side of including the span as evidence.\n# input\n<article>\nCountry of event: {{ country }}\n{{ article }}\n</article>\n<entities>\n{%\n- {{ e.name }}\n{{ e.description }}\n{%\n</entities>\nTable 17: Prompt for the second stage of Z EST.\n31\n--- Page 32 ---\nYou will be given a news article, and structured information about a {{ event_type }} event.\nA {{ event_type }} {{ event_type_definition }}.\nGiven a list of Entities that are involved in the event, your task is to assign each entity to the\ncorrect field.\nAn Entity is defined as an individual, group, collective, or organization involved in an event.\nThis includes:\n* Organized armed groups with political purposes (e.g. \"Hezbollah\", \"ISIS\")\n* Organizations, governments, and political parties (e.g. \"BJP: Bharatiya Janata Party\", \"\nGovernment of India\", \"Democratic Party of U.S.\")\n* Ethnic, religious, social or occupational groups (e.g. \"Jewish Group\", \"Muslim Group\", \"Women\", \"\nStudents\", \"Farmers\", \"Journalists\", \"Teachers\", \"Lawyers\")\n* General terms describing people involved (e.g., \"Rioters\", \"Protestors\", \"Civilians\", \"Labor\nGroup\")\nPossible fields are:\n{{ possible_fields }}\nTo complete this task, follow these steps:\n1. Analyze the news article and the {{ event_type }} event carefully.\n2. For each entity in the provided list, determine their appropriate field based on the information\nin the news article.\n3. Assign each entity to the most appropriate field. Try to assign all entities, event if their\ninvolvement in the event is very indirect. For example, \"Government of India\" is still an\nactor if the Indian congress is involved in the event.\n4. If a field doesn 't have a corresponding entity, leave it as an empty list.\nOutput the assignment of entities to fields in the following JSON format. Note that you should\nalways include the full name of the entities without change.\n{\n\"field_name 1\" : [\"entity 1\", \"entity 2\", ...],\n\"field_name 2\" : [\"entity 3\", \"entity 4\", ...],\n}\n# input\n<news_article>\n{{ article }}\n</news_article>\n<event>\n{{ event_with_empty_entities }}\n</event>\nHere is the list of entities and their definitions.\n<entities>\n{%\n- {{ e.name }}: {{ e.description }}\n{%\n</entities>\nTable 18: Prompt used in the third stage of ZESTfor assigning entities to their correct event argument. A Pydantic\nschema is also passed to the model to follow.\n32\n--- Page 33 ---\nYou are an AI assistant tasked with extracting event arguments from a given news article. You will\nbe provided with annotation guidelines for an event type and a news article to analyze.\nExtract the arguments of the main event in the article, which is of type {{ event_type }}.\n{{ event_type }}: {{ event_type_definition }}\nWhen extracting event arguments, only pay attention to the main event in the article. Do not\ninclude any background information or other previous events that may be mentioned in the\narticle.\n# input\n{{ article }}\nTable 19: Prompt used for Abstract Code4Struct\n7B model, which is based on CodeLLaMA (Roz-\nière et al., 2023). For zero-shot experiments, we\nprovide GoLLIE with event descriptions format-\nted similarly to its original instruction-tuning data.\nSpecifically, we define each event type as a Python\nclass, including the event type description in the\ndocstring and typical trigger words in class com-\nments.\nFor the Event Detection (ED) subtask, GoLLIE\npredicts both the event type and its trigger span.\nFor Event Argument Extraction (EAE), GoLLIE\npredicts the event type, trigger, and associated ar-\nguments. We discard the trigger span predictions.\nTo more closely match GoLLIE’s instruction-\ntuning data, and to keep the instructions similarly\nshort, we implement a two-stage event detection\napproach using GoLLIE. Initially, we predict\none of six general event categories: Battle ,\nProtest ,Riot ,ExplosionOrRemoteViolence ,\nViolenceAgainstCivilians , and\nStrategicDevelopment . After predicting\nthe general event category, we further use GoLLIE\nto predict the corresponding subtype. Subse-\nquently, Event Argument Extraction (EAE) is\nperformed based on the predicted subtype.\nOneNet OneNet is originally based on the 7B-\nparameter Zephyr model (Tunstall et al., 2023), an\ninstruction-tuned version of Mistral (Jiang et al.,\n2023). In our preliminary experiments, OneNet\nperformed poorly on LEMONADE . Therefore, we\nreplaced Zephyr with a stronger LLM (GPT-4o).\nWe refer to this improved version as OneNet (GPT-\n4o).\nSince OneNet expects entity spans as input, we\nfirst perform EAE using GoLLIE to obtain entity\nargument spans. Following the original OneNet\nsetting, we retrieve 64 candidate entities for eachentity span and then use GPT-4o instead of Zephyr\nfor improved performance.\nBoth OneNet and ZEST include an en-\ntity retrieval component. We use the\ngte-multilingual-base model from Zhang et al.\n(2024b) to generate dense embeddings for entities\nbased on their names and descriptions.\nFollowing Logeswaran et al. (2019a), we ini-\ntially reduce the candidate entities by selecting the\ntop 64 most relevant entities for each argument\nmention. We then use the LLM to evaluate each\ncandidate entity individually, given the contextual\ninformation, resulting in a refined set of potential\nentities.\nIn the dual-perspective entity linking stage of\nOneNet, we leverage the LLM to perform entity\nlinking from two complementary perspectives: con-\ntextual analysis and prior knowledge. For each\nperspective, the LLM selects the most appropri-\nate entity from the previously filtered set. In the\ncontextual linking approach, the LLM is provided\nwith both the context and the argument mention,\nenabling context-aware predictions. Conversely, in\nthe prior knowledge approach, the LLM receives\nonly the argument mention, relying solely on its\ninherent knowledge. The final merging stage in-\nvolves using the LLM to select the final entity from\nthe two candidates identified in the previous stage.\nAfter EAE, we adopt a similar framework to\nOneNet for linking arguments to entities in the\ndatabase. OneNet introduces an innovative ap-\nproach using a fixed LLM to perform entity linking\nthrough few-shot prompting. The original frame-\nwork comprises three distinct stages: entity reduc-\ntion, dual-perspective entity linking, and merging\nlinked entities. We closely follow this three-stage\nmethod, with minor modifications. Specifically,\nduring the entity reduction stage, we first generate\n33\n--- Page 34 ---\nconcise summaries for each entity description.\nH Supplementary Experiments\nFigure 9 shows the performance of the best fine-\ntuned model (Aya Expanse) compared to ZESTand\nOneNet. ZESTand Aya Expanse, perform better on\nmore common entities. OneNet (GPT-4o) models\nslightly outperform ZESTon very rare entities (less\ncommon than 20th and 60th percentiles), but ZEST\noutperforms them on more frequent entities, and\non average.\nFigure 9: AEL F1 as a function of how common entities\nare in the ACLED data.\nH.1 The Effect of Input Length\nLEMONADE has the longest average input text\namong document-level event datasets (Table 9.\nHere, we analyze whether tackling this dataset re-\nquires using the entire documents. We use the best\nsupervised model, and run truncated documents\nfrom the test set through the model. The perfor-\nmance of this model in the end-to-end setting drops\nto 55.9, 60.9, 69.2, 72.6 for truncations to 32, 64,\n128, 256 tokens respectively. This indicates that\nmany examples in LEMONADE require the infor-\nmation from all parts of the document, not just the\nbeginning.\nI Full Schema of L EMONADE\nThe following is the full schema of LEMONADE , af-\nter conversion to Python code, in Pydantic (Colvin\net al., 2024) format. Abstract classes (denoted\nbyABCare only meant to group event types to-\ngether and store common event arguments, are not\ncounted as an event type, and are not used by ZEST.\nDocstrings are adapted from the ACLED code-\nbook (ACLED, 2023). WomenTargetedCategory\nandLocation are two additional classes.class Battle(ACLEDEvent, ABC):\n\"\"\"\nA \"Battle\" event is defined as a violent interaction\nbetween two organized armed groups at a particular\ntime and location. \"Battle\" can occur between armed\nand organized state, non-state, and external groups,\nand in any combination therein. There is no fatality\nminimum necessary for inclusion. Civilians can be\nharmed in the course of larger \"Battle\" events if they\nare caught in the crossfire, for example, or affected\nby strikes on military targets, which is commonly\nreferred to as \"collateral damage\" (for more, see\nIndirect Killing of Civilians). When civilians are\nharmed in a \"Battle\" event, they are not recorded as\nan \"Actor\", nor is a separate civilian-specific event\nrecorded. If any civilian fatalities are reported as\npart of a battle, they are aggregated in the \"\nFatalities\" field for the \"Battle\" event.\nThe specific elements of the definition of a \"Battle\"\nevent are as follows:\nViolent interaction: the exchange of armed force, or the\nuse of armed force at close distance, between armed\ngroups capable of inflicting harm upon the opposing\nside.\nOrganized armed groups: collective actors assumed to be\noperating cohesively around an agenda, identity, or\npolitical purpose, using weapons to inflict harm.\nThese groups frequently have a designated name and\nstated agenda.\nThe \"Battle\" event type may include: ground clashes\nbetween different armed groups, ground clashes between\narmed groups supported by artillery fire or\nairstrikes, ambushes of on-duty soldiers or armed\nmilitants, exchanges of artillery fire, ground attacks\nagainst military or militant positions, air attacks\nwhere ground forces are able to effectively fire on\nthe aircraft, and air-to-air combat.\nCases where territory is regained or overtaken without\nresistance or armed interaction are not recorded as \"\nBattle\" events. Instead, they are recorded as \"\nNonStateActorOvertakesTerritory\" under the \"\nStrategicDevelopment\" event type\n\"Battle\" event type has the following subtypes:\n- GovernmentRegainsTerritory: Government forces or their\naffiliates regain control of a location from\ncompeting state forces or non-state groups through\narmed interaction.\n- NonStateActorOvertakesTerritory: A non-state actor or\nforeign state actor captures territory from an\nopposing government or non-state actor through armed\ninteraction, establishing a monopoly of force within\nthat territory.\n- ArmedClash: Armed, organized groups engage in a battle\nwithout significant changes in territorial control.\n\"\"\"\nlocation: Location = Field(..., description=\"Location\nwhere the event takes place\")\nfatalities: Optional[ int] = Field(\n...,\ndescription=\"Total number of fatalities, if known\",\n)\nclass GovernmentRegainsTerritory(Battle):\n\"\"\"\nIs a type of \"Battle\" event. This event type is used\nwhen government forces or their affiliates that are\nfighting against competing state forces or against a\nnon-state group regain control of a location through\narmed interaction. This event type is only recorded\nfor the re-establishment of government control and not\nfor cases where competing non-state actors exchange\ncontrol. Short-lived and/or small-scale territorial\nexchanges that do not last for more than one day are\nrecorded as \"ArmedClash\".\n\"\"\"\ngovernment_force: List[ str] = Field(\n...,\ndescription=\"The government forces or their\naffiliates that regain control of the territory\",\nis_entity_field=True,\n)\nadversary: List[ str] = Field(\n...,\n34\n--- Page 35 ---\ndescription=\"The competing state forces or non-state\ngroup that lose control of the territory. Can be\nState Forces, Rebel Groups, Political Militias,\nIdentity Militias or External Forces\",\nis_entity_field=True,\n)\nclass NonStateActorOvertakesTerritory(Battle):\n\"\"\"\nIs a type of \"Battle\" event. This event type is used\nwhen a non-state actor (excluding those operating\ndirectly on behalf of the government) or a foreign\nstate actor, through armed interaction, captures\nterritory from an opposing government or non-state\nactor; as a result, they are regarded as having a\nmonopoly of force within that territory. Short-lived\nand/or small-scale territorial exchanges that do not\nlast for more than one day are recorded as \"ArmedClash\n\" events. In cases where non-state forces fight with\nopposing actors in a location many times before\ngaining control, only the final territorial\nacquisition is recorded as \"Non-state actor overtakes\nterritory\". All other battles in that location are\nrecorded as \"ArmedClash\".\n\"\"\"\nnon_state_actor: List[ str] = Field(\n...,\ndescription=\"The non-state actor overtaking\nterritory. Can be Rebel Groups, Political Militias,\nIdentity Militias or External Forces\",\nis_entity_field=True,\n)\nadversary: List[ str] = Field(\n...,\ndescription=\"The opposing government or non-state\nactor from whom the territory was taken. Can be State\nForces, Rebel Groups, Political Militias, Identity\nMilitias or External Forces\",\nis_entity_field=True,\n)\nclass ArmedClash(Battle):\n\"\"\"\nIs a type of \"Battle\" event. This event type is used\nwhen two organized groups like State Forces, Rebel\nGroups, Political Militias, Identity Militias or\nExternal Forces engage in a battle, and no reports\nindicate a significant change in territorial control.\n`side_1 `and `side_2 `denote the two sides of the armed\nclash.\nExcludes demonstrations that turn violent, riots, and\nother forms of violence that are not organized armed\nclashes.\n\"\"\"\nside_1: List[ str] = Field(\n...,\ndescription=\"Groups involved in the clash. Can be\nState Forces, Rebel Groups, Political Militias,\nIdentity Militias or External Forces\",\nis_entity_field=True,\n)\nside_2: List[ str] = Field(\n...,\ndescription=\"Groups involved in the clash. Can be\nState Forces, Rebel Groups, Political Militias,\nIdentity Militias or External Forces\",\nis_entity_field=True,\n)\ntargets_local_administrators: bool = Field(\n...,\ndescription=\"Whether this violent event is affecting\ncurrent local government officials and administrators\n- including governors, mayors, councilors, and other\ncivil servants.\",\n)\nwomen_targeted: List[WomenTargetedCategory] = Field(\n...,\ndescription=\"The category of violence against women,\nif any. If this violence is not targeting women, this\nshould be an empty list.\",\n)class Protest(ACLEDEvent, ABC):\n\"\"\"\nA \"Protest\" event is defined as an in-person public\ndemonstration of three or more participants in which\nthe participants do not engage in violence, though\nviolence may be used against them. Events include\nindividuals and groups who peacefully demonstrate\nagainst a political entity, government institution,\npolicy, group, tradition, business, or other private\ninstitution. The following are not recorded as \"\nProtest\" events: symbolic public acts such as displays\nof flags or public prayers (unless they are\naccompanied by a demonstration); legislative protests,\nsuch as parliamentary walkouts or members of\nparliaments staying silent; strikes (unless they are\naccompanied by a demonstration); and individual acts\nsuch as self-harm actions like individual immolations\nor hunger strikes.\nProtestor are noted by generic actor name \"Protestor\".\nIf they are representing a group, the name of that\ngroup is also recorded in the field.\n\"Protest\" event type has the following subtypes:\n- ExcessiveForceAgainstProtestors: Peaceful protestor\nare targeted with lethal violence or violence\nresulting in serious injuries by state or non-state\nactors.\n- ProtestWithIntervention: A peaceful protest is\nphysically dispersed or suppressed without serious\ninjuries, or protestor interact with armed groups or\nrioters without serious harm, or protestors are\narrested.\n- PeacefulProtest: Demonstrators gather for a protest\nwithout engaging in violence or rioting and are not\nmet with force or intervention.\n\"\"\"\nlocation: Location = Field(..., description=\"Location\nwhere the event takes place\")\ncrowd_size: Optional[ str] = Field(\n...,\ndescription=\"Estimated size of the crowd. It can be\nan exact number, a range, or a qualitative description\nlike 'small '.\",\n)\nprotestors: List[ str] = Field(\n...,\ndescription=\"List of protestor groups or individuals\ninvolved in the protest\",\nis_entity_field=True,\n)\nclass ExcessiveForceAgainstProtestors(Protest):\n\"\"\"\nIs a type of \"Protest\" event (Protest events include\nindividuals and groups who peacefully demonstrate\nagainst a political entity, government institution,\npolicy, group, tradition, business, or other private\ninstitution.) This event type is used when individuals\nare engaged in a peaceful protest and are targeted\nwith lethal violence or violence resulting in serious\ninjuries (e.g. requiring hospitalization). This\nincludes situations where remote explosives, such as\nimprovised explosive devices, are used to target\nprotestors, as well as situations where non-state\nactors, such as rebel groups, target protestors.\n\"\"\"\nperpetrators: List[ str] = Field(\n...,\ndescription=\"Entities perpetrating the violence. Can\nbe State Forces, Rebel Groups, Political Militias,\nIdentity Militias, External Forces\",\nis_entity_field=True,\n)\ntargets_civilians: bool = Field(\n...,\ndescription=\"Indicates if the '\nExcessiveForceAgainstProtestors 'event is mainly or\nonly targeting civilians. E.g. state forces using\nlethal force to disperse peaceful protestors.\",\n)\nfatalities: Optional[ int] = Field(\n...,\n35\n--- Page 36 ---\ndescription=\"Total number of fatalities, if known\",\n)\nclass ProtestWithIntervention(Protest):\n\"\"\"\nIs a type of \"Protest\" event. This event type is used\nwhen individuals are engaged in a peaceful protest\nduring which there is a physically violent attempt to\ndisperse or suppress the protest, which resulted in\narrests, or minor injuries . If there is intervention,\nbut not violent, the event is recorded as \"\nPeacefulProtest\" event type.\n\"\"\"\nperpetrators: List[ str] = Field(\n...,\ndescription=\"Group(s) or entities attempting to\ndisperse or suppress the protest\",\nis_entity_field=True,\n)\nfatalities: Optional[ int] = Field(\n...,\ndescription=\"Total number of fatalities, if known\",\n)\nclass PeacefulProtest(Protest):\n\"\"\"\nIs a type of \"Protest\" event (Protest events include\nindividuals and groups who peacefully demonstrate\nagainst a political entity, government institution,\npolicy, group, tradition, business, or other private\ninstitution.) This event type is used when\ndemonstrators gather for a protest and do not engage\nin violence or other forms of rioting activity, such\nas property destruction, and are not met with any sort\nof violent intervention.\n\"\"\"\ncounter_protestors: List[ str] = Field(\n...,\ndescription=\"Groups or entities engaged in counter\nprotest, if any\",\nis_entity_field=True,\n)\nclass Riot(ACLEDEvent, ABC):\n\"\"\"\n\"Riot\" are violent events where demonstrators or mobs of\nthree or more engage in violent or destructive acts,\nincluding but not limited to physical fights, rock\nthrowing, property destruction, etc. They may engage\nindividuals, property, businesses, other rioting\ngroups, or armed actors. Rioters are noted by generic\nactor name \"Rioters\". If rioters are affiliated with a\nspecific group - which may or may not be armed - or\nidentity group, that group is recorded in the\nrespective \"Actor\" field. Riots may begin as peaceful\nprotests, or a mob may have the intention to engage in\nviolence from the outset.\n\"Riot\" event type has the following subtypes:\n- ViolentDemonstration: Demonstrators engage in violence\nor destructive activities, such as physical clashes,\nvandalism, or road-blocking, regardless of who\ninitiated the violence.\n- MobViolence: Rioters violently interact with other\nrioters, civilians, property, or armed groups outside\nof demonstration contexts, often involving disorderly\ncrowds with the intention to cause harm or disruption.\n\"\"\"\nlocation: Location = Field(..., description=\"Location\nwhere the event takes place\")\ncrowd_size: Optional[ str] = Field(\n...,\ndescription=\"Estimated size of the crowd. It can be\nan exact number, a range, or a qualitative description\nlike 'small '.\",\n)\nfatalities: Optional[ int] = Field(\n...,\ndescription=\"Total number of fatalities, if known\",)\ntargets_civilians: bool = Field(\n...,\ndescription=\"Indicates if the 'Riot 'event is mainly\nor only targeting civilians. E.g. a village mob\nassaulting another villager over a land dispute.\",\n)\ngroup_1: List[ str] = Field(\n...,\ndescription=\"Group or individual involved in the\nviolence\",\nis_entity_field=True,\n)\ngroup_2: List[ str] = Field(\n...,\ndescription=\"The other group or individual involved\nin the violence, if any\",\nis_entity_field=True,\n)\ntargets_local_administrators: bool = Field(\n...,\ndescription=\"Whether this violent event is affecting\ncurrent local government officials and administrators\n- including governors, mayors, councilors, and other\ncivil servants.\",\n)\nwomen_targeted: List[WomenTargetedCategory] = Field(\n...,\ndescription=\"The category of violence against women,\nif any. If this violence is not targeting women, this\nshould be an empty list.\",\n)\nclass ViolentDemonstration(Riot):\n\"\"\"\nIs a type of \"Riot\" event. This event type is used when\ndemonstrators engage in violence and/or destructive\nactivity. Examples include physical clashes with other\ndemonstrators or government forces; vandalism; and\nroad-blocking using barricades, burning tires, or\nother material. The coding of an event as a \"Violent\ndemonstration\" does not necessarily indicate that\ndemonstrators initiated the violence and/or\ndestructive actions.\nExcludes events where a weapon is drawn but not used, or\nwhen the situation is de-escalated before violence\noccurs.\n\"\"\"\nclass MobViolence(Riot):\n\"\"\"\nIs a type of \"Riot\" event. A mob is considered a crowd\nof people that is disorderly and has the intention to\ncause harm or disruption through violence or property\ndestruction. Note that this type of violence can also\ninclude spontaneous vigilante mobs clashing with other\narmed groups or attacking civilians. While a \"Mob\nviolence\" event often involves unarmed or crudely\narmed rioters, on rare occasions, it can involve\nviolence by people associated with organized groups\nand/or using more sophisticated weapons, such as\nfirearms.\n\"\"\"\nclass ExplosionOrRemoteViolence(ACLEDEvent, ABC):\n\"\"\"\n\"ExplosionOrRemoteViolence\" is defined as events as\nincidents in which one side uses weapon types that, by\ntheir nature, are at range and widely destructive.\nThe weapons used in \"ExplosionOrRemoteViolence\" events\nare explosive devices, including but not limited to:\nbombs, grenades, improvised explosive devices (IEDs),\nartillery fire or shelling, missile attacks, air or\ndrone strikes, and other widely destructive heavy\nweapons or chemical weapons. Suicide attacks using\nexplosives also fall under this category. When an \"\nExplosionOrRemoteViolence\" event is reported in the\ncontext of an ongoing battle, it is merged and\nrecorded as a single \"Battles\" event. \"\nExplosionOrRemoteViolence\" can be used against armed\nagents as well as civilians.\n36\n--- Page 37 ---\n\"ExplosionOrRemoteViolence\" event type has the following\nsubtypes:\n- ChemicalWeapon: The use of chemical weapons in warfare\nwithout any other engagement.\n- AirOrDroneStrike: Air or drone strikes occurring\nwithout any other engagement, including attacks by\nhelicopters.\n- SuicideBomb: A suicide bombing or suicide vehicle-\nborne improvised explosive device (SVBIED) attack\nwithout an armed clash.\n- ShellingOrArtilleryOrMissileAttack: The use of long-\nrange artillery, missile systems, or other heavy\nweapons platforms without any other engagement.\n- RemoteExplosiveOrLandmineOrIED: Detonation of remotely-\nor victim-activated devices, including landmines and\nIEDs, without any other engagement.\n- Grenade: The use of a grenade or similar hand-thrown\nexplosive without any other engagement.\n\"\"\"\nlocation: Location = Field(..., description=\"Location\nwhere the event takes place\")\ntargets_civilians: bool = Field(\n...,\ndescription=\"Indicates if the '\nExplosionOrRemoteViolence 'event is mainly or only\ntargeting civilians. E.g. a landmine killing a farmer.\n\",\n)\nfatalities: Optional[ int] = Field(\n...,\ndescription=\"Total number of fatalities, if known\",\n)\nattackers: List[ str] = Field(\n...,\ndescription=\"Entities conducting the violence\",\nis_entity_field=True,\n)\ntargeted_entities: List[ str] = Field(\n...,\ndescription=\"Entities or actors being targeted\",\nis_entity_field=True,\n)\ntargets_local_administrators: bool = Field(\n...,\ndescription=\"Whether this violent event is affecting\ncurrent local government officials and administrators\n- including governors, mayors, councilors, and other\ncivil servants.\",\n)\nwomen_targeted: List[WomenTargetedCategory] = Field(\n...,\ndescription=\"The category of violence against women,\nif any. If this violence is not targeting women, this\nshould be an empty list.\",\n)\nclass ChemicalWeapon(ExplosionOrRemoteViolence):\n\"\"\"\nIs a type of \"ExplosionOrRemoteViolence\" event. This\nevent type captures the use of chemical weapons in\nwarfare in the absence of any other engagement. ACLED\nconsiders chemical weapons as all substances listed as\nSchedule 1 of the Chemical Weapons Convention,\nincluding sarin gas, mustard gas, chlorine gas, and\nanthrax. Napalm and white phosphorus, as well as less-\nlethal crowd control substances - such as tear gas -\nare not considered chemical weapons within this event\ntype.\n\"\"\"\nclass AirOrDroneStrike(ExplosionOrRemoteViolence):\n\"\"\"\nIs a type of \"ExplosionOrRemoteViolence\" event. This\nevent type is used when air or drone strikes take\nplace in the absence of any other engagement. Please\nnote that any air-to-ground attacks fall under this\nevent type, including attacks by helicopters that do\nnot involve exchanges of fire with forces on the\nground.\n\"\"\"\nclass SuicideBomb(ExplosionOrRemoteViolence):\n\"\"\"Is a type of \"ExplosionOrRemoteViolence\" event. This\nevent type is used when a suicide bombing occurs in\nthe absence of an armed clash, such as an exchange of\nsmall arms fire with other armed groups. It also\nincludes suicide vehicle-borne improvised explosive\ndevice (SVBIED) attacks. Note that the suicide bomber\nis included in the total number of reported fatalities\ncoded for such events.\n\"\"\"\nclass ShellingOrArtilleryOrMissileAttack(\nExplosionOrRemoteViolence):\n\"\"\"\nIs a type of \"ExplosionOrRemoteViolence\" event. This\nevent type captures the use of long-range artillery,\nmissile systems, or other heavy weapons platforms in\nthe absence of any other engagement. When two armed\ngroups exchange long-range fire, it is recorded as an\n\"ArmedClash\". \"ShellingOrArtilleryOrMissileAttack\"\nevents include attacks described as shelling, the use\nof artillery and cannons, mortars, guided missiles,\nrockets, grenade launchers, and other heavy weapons\nplatforms. Crewed aircraft shot down by long-range\nsystems fall under this event type. Uncrewed armed\ndrones that are shot down, however, are recorded as\ninterceptions under \"DisruptedWeaponsUse\" because\npeople are not targeted (see below). Similarly, an\ninterception of a missile strike itself (such as by\nthe Iron Dome in Israel) is also recorded as \"\nDisruptedWeaponsUse\".\n\"\"\"\nclass RemoteExplosiveOrLandmineOrIED(\nExplosionOrRemoteViolence):\n\"\"\"\nIs a type of \"ExplosionOrRemoteViolence\" event. This\nevent type is used when remotely- or victim-activated\ndevices are detonated in the absence of any other\nengagement. Examples include landmines, IEDs - whether\nalone or attached to a vehicle, or any other sort of\nremotely detonated or triggered explosive. Unexploded\nordnances (UXO) also fall under this category.\nSVBIEDs are recorded as \"Suicide bomb\" events, while the\nsafe defusal of an explosive or its accidental\ndetonation by the actor who planted it (with no other\ncasualties reported) is recorded under \"\nDisruptedWeaponsUse\".\n\"\"\"\nclass Grenade(ExplosionOrRemoteViolence):\n\"\"\"\nIs a type of \"ExplosionOrRemoteViolence\" event. This\nevent type captures the use of a grenade or any other\nsimilarly hand-thrown explosive, such as an IED that\nis thrown, in the absence of any other engagement.\nEvents involving so-called \"crude bombs\" (such as\nMolotov cocktails, firecrackers, cherry bombs, petrol\nbombs, etc.) as well as \"stun grenades\" are not\nrecorded in this category, but are included under\neither \"Riot\" or \"StrategicDevelopment\" depending on\nthe context in which they occurred.\n\"\"\"\nclass ViolenceAgainstCivilians(ACLEDEvent, ABC):\n\"\"\"\nACLED defines \"ViolenceAgainstCivilians\" as violent\nevents where an organized armed group inflicts\nviolence upon unarmed non-combatants. By definition,\ncivilians are unarmed and cannot engage in political\nviolence. Therefore, the violence is understood to be\nasymmetric as the perpetrator is assumed to be the\nonly actor capable of using violence in the event. The\nperpetrators of such acts include state forces and\ntheir affiliates, rebels, militias, and external/other\nforces.\nIn cases where the identity and actions of the targets\nare in question (e.g. the target may be employed as a\npolice officer), ACLED determines that if a person is\nharmed or killed while unarmed and unable to either\nact defensively or counter-attack, this is an act of \"\nViolenceAgainstCivilians\". This includes extrajudicial\nkillings of detained combatants or unarmed prisoners\n37\n--- Page 38 ---\nof war.\n\"ViolenceAgainstCivilians\" also includes attempts at\ninflicting harm (e.g. beating, shooting, torture, rape,\nmutilation, etc.) or forcibly disappearing (e.g.\nkidnapping and disappearances) civilian actors. Note\nthat the \"ViolenceAgainstCivilians\" event type\nexclusively captures violence targeting civilians that\ndoes not occur concurrently with other forms of\nviolence - such as rioting - that are coded higher in\nthe ACLED event type hierarchy. To get a full list of\nevents in the ACLED dataset where civilians were the\nmain or only target of violence, users can filter on\nthe \"Civilian targeting\" field.\n\"ViolenceAgainstCivilians\" event type has the following\nsubtypes:\n- SexualViolence: Any event where an individual is\ntargeted with sexual violence, including but not\nlimited to rape, public stripping, and sexual torture,\nwith the gender identities of victims recorded when\nreported.\n- Attack: An event where civilians are targeted with\nviolence by an organized armed actor outside the\ncontext of other forms of violence, including severe\ngovernment overreach by law enforcement.\n- AbductionOrForcedDisappearance: An event involving the\nabduction or forced disappearance of civilians\nwithout reports of further violence, including arrests\nby non-state groups and extrajudicial detentions by\nstate forces, but excluding standard judicial arrests\nby state forces.\n\"\"\"\nlocation: Location = Field(..., description=\"Location\nwhere the event takes place\")\ntargets_local_administrators: bool = Field(\n...,\ndescription=\"Whether this violent event is affecting\ncurrent local government officials and administrators\n- including governors, mayors, councilors, and other\ncivil servants.\",\n)\nwomen_targeted: List[WomenTargetedCategory] = Field(\n...,\ndescription=\"The category of violence against women,\nif any. If this violence is not targeting women, this\nshould be an empty list.\",\n)\nclass SexualViolence(ViolenceAgainstCivilians):\n\"\"\"\nIs a type of \"ViolenceAgainstCivilians\" event. This\nevent type is used when any individual is targeted\nwith sexual violence. SexualViolence is defined\nlargely as an action that inflicts harm of a sexual\nnature. This means that it is not limited to solely\npenetrative rape, but also includes actions like\npublic stripping, sexual torture, etc. Given the\ngendered nature of sexual violence, the gender\nidentities of the victims - i.e. \"Women\", \"Men\", and \"\nLGBTQ+\", or a combination thereof - are recorded in\nthe \"Associated Actor\" field for these events when\nreported. Note that it is possible for sexual violence\nto occur within other event types such as \"Battle\"\nand \"Riot\".\n\"\"\"\nfatalities: Optional[ int] = Field(\n...,\ndescription=\"Total number of fatalities, if known\",\n) # Is very very rare, only 7 events in English for\n2024\nperpetrators: List[ str] = Field(\n...,\ndescription=\"The attacker(s) entity or actor\",\nis_entity_field=True,\n)\nvictims: List[ str] = Field(\n...,\ndescription=\"The entity or actor(s) that is the\ntarget or victim of the SexualViolence event\",\nis_entity_field=True,\n)\nclass Attack(ViolenceAgainstCivilians):\n\"\"\"Is a type of \"ViolenceAgainstCivilians\" event. This\nevent type is used when civilians are targeted with\nviolence by an organized armed actor outside the\ncontext of other forms of violence like ArmedClash,\nProtests, Riots, or ExplosionOrRemoteViolence.\nViolence by law enforcement that constitutes severe\ngovernment overreach is also recorded as an \"Attack\"\nevent.\nAttacks of a sexual nature are recorded as\nSexualViolence.\nIf only property is attacked and not people, the event\nshould be recorded as LootingOrPropertyDestruction\nevent type.\nExcludes discovery of mass graves, which are recorded as\n\"OtherStrategicDevelopment\" events.\n\"\"\"\nfatalities: Optional[ int] = Field(\n...,\ndescription=\"Total number of fatalities, if known\",\n)\nattackers: List[ str] = Field(\n...,\ndescription=\"The attacker entity or actor(s)\",\nis_entity_field=True,\n)\ntargeted_entities: List[ str] = Field(\n...,\ndescription=\"The entity or actor(s) that is the\ntarget of the attack\",\nis_entity_field=True,\n)\nclass AbductionOrForcedDisappearance(\nViolenceAgainstCivilians):\n\"\"\"\nIs a type of \"ViolenceAgainstCivilians\" event. This\nevent type is used when an actor engages in the\nabduction or forced disappearance of civilians,\nwithout reports of further violence. If fatalities or\nserious injuries are reported during the abduction or\nforced disappearance, the event is recorded as an \"\nAttack\" event instead. If such violence is reported in\nlater periods during captivity, this is recorded as\nan additional \"Attack\" event. Note that multiple\npeople can be abducted in a single \"Abduction/forced\ndisappearance\" event.\nArrests by non-state groups and extrajudicial detentions\nby state forces are considered \"Abduction/forced\ndisappearance\". Arrests conducted by state forces\nwithin the standard judicial process are, however,\nconsidered \"Arrest\".\n\"\"\"\nabductor: List[ str] = Field(\n...,\ndescription=\"The abductor person or group(s)\",\nis_entity_field=True,\n)\nabductee: List[ str] = Field(\n...,\ndescription=\"People or group(s) that were abducted\nor disappeared. Note that multiple people can be\nabducted in a single AbductionOrForcedDisappearance\nevent\",\nis_entity_field=True,\n)\nclass StrategicDevelopment(ACLEDEvent, ABC):\n\"\"\"\nThis event type captures contextually important\ninformation regarding incidents and activities of\ngroups that are not recorded as \"Political violence\"\nor \"Demonstration\" events, yet may trigger future\nevents or contribute to political dynamics within and\nacross states. The inclusion of such events is limited,\nas their purpose is to capture pivotal events within\nthe broader political landscape. They typically\ninclude a disparate range of events, such as\nrecruitment drives, looting, and incursions, as well\nas the location and date of peace talks and the\narrests of high-ranking officials or large groups.\nWhile it is rare for fatalities to be reported as a\nresult of such events, they can occur in certain cases\n38\n--- Page 39 ---\n- e.g. the suspicious death of a high-ranking\nofficial, the accidental detonation of a bomb\nresulting in the bomber being killed, etc.\nDue to their context-specific nature, \"\nStrategicDevelopment\" are not collected and recorded\nin the same cross-comparable fashion as \"Political\nviolence\" and \"Demonstration\" events. As such, the \"\nStrategicDevelopment\" event type is primarily a tool\nfor understanding particular contexts.\n\"StrategicDevelopment\" event type has the following\nsubtypes:\n- Agreement: Records any agreement between different\nactors, such as peace talks, ceasefires, or prisoner\nexchanges.\n- Arrest: Used when state forces or controlling actors\ndetain a significant individual or conduct politically\nimportant mass arrests.\n- ChangeToArmedGroup: Records significant changes in the\nactivity or structure of armed groups, including\ncreation, recruitment, movement, or absorption of\nforces.\n- DisruptedWeaponsUse: Captures instances where an\nexplosion or remote violence event is prevented, or\nwhen significant weapons caches are seized.\n- BaseEstablished: Used when an organized armed group\nestablishes a permanent or semi-permanent base or\nheadquarters.\n- LootingOrPropertyDestruction: Records incidents of\nlooting or seizing goods/property outside the context\nof other forms of violence or destruction.\n- NonViolentTransferOfTerritory: Used when actors\nacquire control of a location without engaging in\nviolent interaction with another group.\n- OtherStrategicDevelopment: Covers significant\ndevelopments that don 't fall into other Strategic\nDevelopment event types, such as coups or population\ndisplacements.\n\"\"\"\nlocation: Location = Field(..., description=\"Location\nwhere the event takes place\")\nclass Agreement(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used to record any sort of agreement between\ndifferent armed actors (such as governments and rebel\ngroups). Examples include peace agreements/talks,\nceasefires, evacuation deals, prisoner exchanges,\nnegotiated territorial transfers, prisoner releases,\nsurrenders, repatriations, etc.\nExcludes agreements between political parties, trade\nunions, or other non-armed actors like protestors.\n\"\"\"\ngroup_1: List[ str] = Field(\n...,\ndescription=\"Group or individual involved in the\nagreement\",\nis_entity_field=True,\n)\ngroup_2: List[ str] = Field(\n...,\ndescription=\"The other group or individual involved\nin the agreement\",\nis_entity_field=True,\n)\nclass Arrest(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used when state forces or other actors\nexercising de facto control over a territory either\ndetain a particularly significant individual or engage\nin politically significant mass arrests. This\nexcludes arrests of individuals for common crimes,\nsuch as theft or assault, unless the individual is a\nhigh-ranking official or the arrest is politically\nsignificant.\n\"\"\"\ndetainers: List[ str] = Field(\n...,\ndescription=\"The person or group(s) who detains or\njails the detainee(s)\",is_entity_field=True,\n)\ndetainees: List[ str] = Field(\n...,\ndescription=\"The person or group(s) being detained\nor jailed\",\nis_entity_field=True,\n)\nclass ChangeToArmedGroup(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used to record significant changes in the\nactivity or structure of armed groups. It can cover\nanything from the creation of a new rebel group or a\nparamilitary wing of the security forces, \"voluntary\"\nrecruitment drives, movement of forces, or any other\nnon-violent security measures enacted by armed actors.\nThis event type can also be used if one armed group\nis absorbed into a different armed group or to track\nlarge-scale defections.\n\"\"\"\narmed_group: List[ str] = Field(\n...,\ndescription=\"The name of armed group that underwent\nchange\",\nis_entity_field=True,\n)\nother_actors: List[ str] = Field(\n...,\ndescription=\"Other actors or groups involved. E.g.\nthe government that ordered a change to its army.\",\nis_entity_field=True,\n)\nclass DisruptedWeaponsUse(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used to capture all instances in which an\nevent of \"ExplosionOrRemoteViolence\" is prevented from\noccurring, or when armed actors seize significant\ncaches of weapons. It includes the safe defusal of an\nexplosive, the accidental detonation of explosives by\nthose allegedly responsible for planting it, the\ninterception of explosives in the air, as well as the\nseizure of weapons or weapons platforms such as jets,\nhelicopters, tanks, etc. Note that in cases where a\ngroup other than the one that planted an explosive is\nattempting to render an explosive harmless and it goes\noff, this is recorded under the \"\nExplosionOrRemoteViolence\" event type, as the\nexplosive has harmed an actor other than the one that\nplanted it.\n\"\"\"\nattackers: List[ str] = Field(\n...,\ndescription=\"The entity or actor(s) responsible for\nthe remote violence\",\nis_entity_field=True,\n)\ndisruptors: List[ str] = Field(\n...,\ndescription=\"The entity or actor(s) disrupting the\nexplosion or remote violence\",\nis_entity_field=True,\n)\ntargets_local_administrators: bool = Field(\n...,\ndescription=\"Whether this violent event is affecting\ncurrent local government officials and administrators\n- including governors, mayors, councilors, and other\ncivil servants.\",\n)\nwomen_targeted: List[WomenTargetedCategory] = Field(\n...,\ndescription=\"The category of violence against women,\nif any. If this violence is not targeting women, this\nshould be an empty list.\",\n)\nclass BaseEstablished(StrategicDevelopment):\n\"\"\"\n39\n--- Page 40 ---\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used when an organized armed group establishes\na permanent or semi-permanent base or headquarters.\nThere are few cases where opposition groups other than\nrebels can also establish a headquarters or base (e.g.\nAMISOM forces in Somalia).\n\"\"\"\ngroup: List[ str] = Field(\n...,\ndescription=\"Entity or group(s) establishing the\nbase\",\nis_entity_field=True,\n)\nclass LootingOrPropertyDestruction(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used when actors engage in looting or seizing\ngoods or property outside the context of other forms\nof violence or destruction, such as rioting or armed\nclashes. This excludes the seizure or destruction of\nweapons or weapons systems, which are captured under\nthe \"DisruptedWeaponsUse\" event type. This can occur\nduring raiding or after the capture of villages or\nother populated places by armed groups that occur\nwithout reported violence.\n\"\"\"\nperpetrators: List[ str] = Field(\n...,\ndescription=\"The group or entity that does the\nlooting or seizure\",\nis_entity_field=True,\n)\nvictims: List[ str] = Field(\n...,\ndescription=\"The group or entity that was the target\nof looting or seizure\",\nis_entity_field=True,\n)\ntargets_local_administrators: bool = Field(\n...,\ndescription=\"Whether this violent event is affecting\ncurrent local government officials and administrators\n- including governors, mayors, councilors, and other\ncivil servants.\",\n)\nwomen_targeted: List[WomenTargetedCategory] = Field(\n...,\ndescription=\"The category of violence against women,\nif any. If this violence is not targeting women, this\nshould be an empty list.\",\n)\nclass NonViolentTransferOfTerritory(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used in situations in which rebels,\ngovernments, or their affiliates acquire control of a\nlocation without engaging in a violent interaction\nwith another group. Rebels establishing control of a\nlocation without any resistance is an example of this\nevent.\n\"\"\"\nactors_taking_over: List[ str] = Field(\n...,\ndescription=\"The entity or actor(s) establishing\ncontrol.\",\nis_entity_field=True,\n)\nactors_giving_up: List[ str] = Field(\n...,\ndescription=\"The entity or actor(s) giving up\nterritory, if known.\",\nis_entity_field=True,\n)\nclass OtherStrategicDevelopment(StrategicDevelopment):\n\"\"\"\nIs a type of \"StrategicDevelopment\" event. This event\ntype is used to cover any significant development that\ndoes not fall into any of the other \"StrategicDevelopment\" event types. Includes the\noccurrence of a coup, the displacement of a civilian\npopulation as a result of fighting, and the discovery\nof mass graves.\n\"\"\"\ngroup_1: List[ str] = Field(\n...,\ndescription=\"Group or individual involved in the\nStrategicDevelopment\",\nis_entity_field=True,\n)\ngroup_2: List[ str] = Field(\n...,\ndescription=\"The other group or individual involved\nin the violence, if any\",\nis_entity_field=True,\n)\nclass WomenTargetedCategory( str, Enum):\nCANDIDATES_FOR_OFFICE = \"Women who are running in an\nelection to hold a publicly elected government\nposition\"\nPOLITICIANS = \"Women who currently serve in an elected\nposition in government\"\nPOLITICAL_PARTY_SUPPORTERS = \"political party supporters\n\"\nVOTERS = \"Women who are registering to vote or are\ncasting a ballot in an election\"\nGOVERNMENT_OFFICIALS = \"Women who work for the local,\nregional, or national government in a non-partisan\ncapacity\"\nACTIVISTS_HRD_SOCIAL_LEADERS = (\n\"Women who are activists/human rights defenders/\nsocial leaders\"\n)\nRELATIVES_OF_TARGETED_GROUPS = \"Women who are subject to\nviolence as a result of who they are married to, the\ndaughter of, related to, or are otherwise personally\nconnected to (e.g. candidates, politicians, social\nleaders, armed actors, voters, party supporters, etc.)\n\"\nACCUSED_OF_WITCHCRAFT = \"Women accused of witchcraft or\nsorcery, or other mystical or spiritual practices that\nare typically considered taboo or dangerous within\nsome societies (excluding women who serve as religious\nleaders in religious structures that are typically\nnot viewed as taboo or dangerous, such as nuns, female\npriests, or shamans)\"\nGIRLS = \"Girls who are under the age of 18; they may be\nspecifically referred to by age or explicitly referred\nto as a child/girl\"\nclass Location(BaseModel):\n\"\"\"\nThe most specific location for an event. Locations can\nbe named populated places, geostrategic locations,\nnatural locations, or neighborhoods of larger cities.\nIn selected large cities with activity dispersed over\nmany neighborhoods, locations are further specified to\npredefined subsections within a city. In such cases,\nCity Name - District name (e.g. Mosul - Old City) is\nrecorded in \"specific_location\". If information about\nthe specific neighborhood/district is not known, the\nlocation is recorded at the city level (e.g. Mosul).\n\"\"\"\ncountry: str = Field(\n...,\ndescription=\"Name of the country in English. Example:\nUnited States\",\n)\naddress: str = Field(\n...,\ndescription=\"Comma-separated address in order from\nneighborhood level to village/city, district, county,\nprovince, region, and country, if available. Excludes\nstreet names, buildings, and other specific landmarks.\nExample: Mosul, Old City, Nineveh, Nineveh, Iraq\",\n)\n40",
  "text_length": 166201
}