{
  "id": "http://arxiv.org/abs/2506.01190v1",
  "title": "Culturally-Grounded Chain-of-Thought (CG-CoT):Enhancing LLM Performance\n  on Culturally-Specific Tasks in Low-Resource Languages",
  "summary": "Large Language Models (LLMs) struggle with culturally-specific reasoning\ntasks, particularly in low-resource languages, hindering their global\napplicability. Addressing this gap is crucial for equitable AI deployment. We\nintroduce Culturally-Grounded Chain-of-Thought (CG-CoT), a novel prompting\nstrategy that combines dense vector retrieval of cultural context with explicit\nreasoning sequences. Our extensive experiments on Yoruba proverb interpretation\ndemonstrate that CG-CoT provides significantly higher culturally-aligned\naccuracy and depth than traditional prompting methods, validated through both\nautomated metrics and LLM-based evaluations. Notably, we uncover stark\ndisparities between token-level translation metrics like BLEU and human-judged\ncultural relevance, suggesting a rethinking of evaluation approaches for\nlow-resource NLP.",
  "authors": [
    "Madhavendra Thakur"
  ],
  "published": "2025-06-01T21:57:02Z",
  "updated": "2025-06-01T21:57:02Z",
  "categories": [
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.01190v1",
  "full_text": "--- Page 1 ---\narXiv:2506.01190v1  [cs.CL]  1 Jun 2025Culturally-Grounded Chain-of-Thought (CG-CoT):\nEnhancing LLM Performance on Culturally-Specific Tasks in\nLow-Resource Languages\nMadhavendra Thakur\nIndependent\nmt3890@columbia.edu\nAbstract\nLarge Language Models (LLMs) strug-\ngle with culturally-specific reasoning tasks,\nparticularly in low-resource languages, hin-\ndering their global applicability. Address-\ning this gap is crucial for equitable AI\ndeployment. We introduce Culturally-\nGrounded Chain-of-Thought (CG-CoT), a\nnovel prompting strategy that combines\ndense vector retrieval of cultural context\nwith explicit reasoning sequences. Our\nextensive experiments on Yoruba proverb\ninterpretation demonstrate that CG-CoT\nprovides significantly higher culturally-\naligned accuracy and depth than tra-\nditional prompting methods, validated\nthrough both automated metrics and\nLLM-based evaluations. Notably, we un-\ncover stark disparities between token-level\ntranslation metrics like BLEU and human-\njudged cultural relevance, suggesting a re-\nthinking of evaluation approaches for low-\nresource NLP.\n1 Introduction\nLarge Language Models (LLMs) have demon-\nstrated remarkable capabilities in a range of natu-\nral language understanding and generation tasks.\nHowever, their performance often deteriorates\nwhen applied to culturally nuanced or low-resource\nlanguage settings. This limitation arises from the\nanglocentric nature of most pretraining corpora,\nwhich insufficiently represent the sociocultural dy-\nnamics, idioms, and metaphorical language of di-\nverse linguistic communities. The implications of\nthese limitations are substantial: misinterpreta-\ntions of culturally rich language not only impair\nperformance but risk reinforcing marginalization\nand misinformation in digital ecosystems.\nTo address these challenges, we propose a\nmethod called Culturally-Grounded Chain-of-\nThought (CG-CoT). CG-CoT augments large\nlanguage models with explicit cultural context\nvia retrieval-augmented generation, interleaved\nwith reasoning steps inspired by chain-of-thought\nprompting. This approach reflects how humansinterpret proverbs—by drawing upon lived cul-\ntural knowledge and reasoning through metaphor-\nical meaning in context. Our hypothesis is that\nsuch grounding mechanisms not only boost trans-\nlation fidelity but also recover cultural nuance oth-\nerwise lost in surface-level lexical matching.\nWe evaluate CG-CoT on the task of translat-\ning Yoruba proverbs—a domain rich in metaphor,\nsymbolism, and social wisdom. Our experi-\nments compare CG-CoT against four strong base-\nlines: Zero-Shot prompting, Zero-Shot Chain-of-\nThought (CoT), traditional Few-Shot prompting,\nand Retrieval-Augmented Few-Shot (RAG). We\ndemonstrate that CG-CoT leads to measurable im-\nprovements in both accuracy and cultural depth,\nand that these gains are not reflected in conven-\ntional metrics such as BLEU or BERTScore, high-\nlighting a significant blind spot in existing evalua-\ntion pipelines.\n2 Related Work\nMultilingual NLP has advanced significantly in re-\ncent years, yet performance on low-resource and\nculturally-specific languages remains a persistent\nchallenge [Cahyawijaya et al., 2024]. Many meth-\nods rely on cross-lingual transfer or translation-\nbased approaches, which often fall short when id-\nioms and cultural knowledge diverge significantly\nfrom English norms [Deshpande et al., 2024, Tan-\nwar et al., 2023].\nEfforts to inject cultural grounding into mod-\nels include curated corpora [Shi et al., 2024], fine-\ntuning with value-aligned data [Li et al., 2024],\nand retrieval-based methods that augment gener-\nation with external knowledge [Lewis et al., 2021].\nHowever, few methods have explored interleaving\ncultural retrieval and reasoning in stepwise fash-\nion, as humans often do in cultural interpretation.\nOur work builds on this foundation by proposing a\nmodular approach that alternates between cultural\nrecall and reasoning, using CG-CoT to bridge the\ngap between linguistic fluency and cultural under-\nstanding.\n--- Page 2 ---\n3 Background\n3.1 Chain-of-Thought Prompting\nChain-of-Thought (CoT) prompting is a technique\nwhere models are encouraged to reason through\ntasks step-by-step [Wei et al., 2022]. By explicitly\nprompting models to ”think out loud,” CoT has\nimproved performance on arithmetic, logic, and\ncommonsense reasoning tasks. However, its suc-\ncess in culturally-specific or multilingual domains\nhas been limited, as reasoning without appropriate\ncontext can lead to confidently wrong conclusions.\n3.2 Retrieval-Augmented Generation\nRAG [Lewis et al., 2021] enhances language mod-\nels with access to external documents via vec-\ntor similarity search. By embedding both input\nqueries and candidate documents into a shared\nvector space, RAG retrieves contextually relevant\ntext that is then passed to the language model for\ngeneration. While powerful, RAG by itself does\nnot enforce structured reasoning or ensure cultural\nalignment. Our method leverages RAG’s retrieval\nstrength, augmenting it with CoT-style reason-\ning tailored to low-resource, culturally-specific do-\nmains.\n4 Method\nWe evaluate five prompting strategies:\n4.1 Zero-Shot Prompting\nThe model is directly prompted with a Yoruba\nproverb and tasked with producing its English\ngloss without additional context or examples. This\nsetup tests the LLM’s implicit cultural knowledge\nacquired during pretraining.\n4.2 Zero-Shot Chain-of-Thought (CoT)\nHere, the same task is posed, but the prompt in-\ncludes a chain-of-thought trigger (e.g., ”Let’s think\nthrough this step-by-step”) to encourage explicit\nreasoning. While this often improves performance\non logic tasks, it provides limited benefit when the\ncultural context is entirely latent.\n4.3 Few-Shot Prompting\nThis method provides several example Yoruba\nproverbs with their English interpretations directly\nin the prompt. Although more helpful than Zero-\nShot, token-based similarity limits its scalability\nand semantic precision, especially when proverb\nvariability is high.\n4.4 RAG Few-Shot Prompting\nThe model uses FAISS-indexed dense embed-\ndings to semantically retrieve contextually similar\nYoruba proverbs from a curated cultural corpus.\nRetrieved phrases are injected into the prompt.This approach improves semantic matching over\nlexical similarity and supports more grounded in-\nterpretations.\n4.5 Culturally-Grounded\nChain-of-Thought (CG-CoT)\nCG-CoT combines RAG-style retrieval with it-\nerative reasoning. At each step, the model is\nprompted with a proverb, semantically similar ex-\nemplars retrieved via vector search, and a multi-\nstep reasoning prompt. The format encourages the\nmodel to first consider symbolic and social imagery\nfrom similar cultural phrases before arriving at a\nfinal interpretation.\n5 Experimental Setup\nWe evaluate all methods on a test set of 400 Yoruba\nproverbs paired with expert-generated English\nglosses. We use BLEU and BERTScore for auto-\nmatic evaluation and solicit LLM-based judgments\n(via GPT-4.1 and Claude 3.5) for accuracy and cul-\ntural depth. The cultural corpus used for RAG-\nbased methods is embedded with SentenceTrans-\nformer (paraphrase-multilingual-MiniLM) and in-\ndexed via FAISS.\n6 Results\nMethod Accuracy Cultural Depth BLEU BERTScore\nZero-Shot 0.56 2.98 12.84 0.90\nZero-Shot-CoT 0.56 3.15 13.00 0.90\nFew-Shot 0.59 2.71 14.49 0.90\nRAG Few-Shot 0.66 3.53 15.76 0.90\nCG-CoT 0.65 3.77 12.68 0.89\nTable 1: Performance comparison of prompting\nmethods across all evaluation metrics. CG-CoT\nleads in cultural depth and human-assessed accu-\nracy, while RAG performs strongest on BLEU.\nCG-CoT outperformed all non-retrieval methods\nin both cultural depth and LLM-assessed accuracy\n(0.65), despite scoring lower on BLEU than RAG.\nThis highlights that lexical overlap fails to reflect\ncultural fidelity. RAG Few-Shot achieved the best\nBLEU (15.76), indicating strong surface transla-\ntion, but it lagged behind CG-CoT in human-\nassessed accuracy.\n7 Discussion\n7.1 Qualitative Case Study\nConsider the proverb ”A ki i je ata, a ki i je\niyo, ki omi o maa ye ni loju”. This phrase, lit-\nerally referencing spicy pepper, salt, and water,\nmetaphorically conveys that choices have conse-\nquences. Zero-shot methods offered shallow trans-\nlations such as “We do not eat pepper or salt so\nwater does not fill our eyes,” which preserve lexi-\ncal form but lose metaphorical weight. CG-CoT,\n--- Page 3 ---\nin contrast, inferred the proverb’s social commen-\ntary by drawing upon culturally aligned phrases\nretrieved through vector similarity, yielding inter-\npretations like “Our actions, whether harsh or gen-\ntle, will inevitably affect others.”\nThis illustrates how cultural retrieval scaffolds\nmore accurate and insightful reasoning, enabling\nmodels to transcend literalism.\n7.2 Ablation Insights\nTo better understand the contribution of each com-\nponent in CG-CoT, we conduct comparative abla-\ntions against two relevant baselines:\n•CG-CoT vs. RAG Few-Shot : This com-\nparison evaluates the impact of adding step-\nwise reasoning to cultural retrieval. While\nRAG Few-Shot achieves slightly higher accu-\nracy (0.66 vs. 0.65), CG-CoT outperforms it\nin cultural depth (3.77 vs. 3.53). This sug-\ngests that reasoning improves the semantic\nrichness of outputs, even when retrieval is al-\nready strong.\n•CG-CoT vs. Zero-Shot-CoT : This eval-\nuates the benefit of adding cultural retrieval\nto chain-of-thought prompting. CG-CoT im-\nproves both accuracy (0.65 vs. 0.56) and cul-\ntural depth (3.77 vs. 3.15), indicating that cul-\ntural grounding substantially enhances inter-\npretive reasoning.\nThese results suggest that retrieval and reason-\ning are synergistic: retrieval alone improves sur-\nface fidelity, while reasoning alone adds structure;\nonly their combination enables nuanced, culturally\nfaithful interpretation.\n7.3 Evaluating with LLM Judges\nWe employ GPT-4.1 and Claude 3.5 as automated\njudges to evaluate outputs on two dimensions: ac-\ncuracy (correctness of interpretation) and cultural\ndepth (richness and contextual fidelity, on a scale\nof 1 to 5). LLM-based evaluation offers scalability\nand reproducibility, and in prior studies has shown\nhigh correlation with human judgment on semantic\ntasks.\nHowever, there are important caveats:\n•Bias toward fluency : LLMs may favor flu-\nent but shallow translations, potentially over-\nlooking deeper cultural fidelity.\n•Training set overlap : Since the evaluators\nare large models themselves, there is a risk of\nalignment artifacts if generation and evalua-\ntion prompts are structurally similar.\n•Cultural blind spots : LLMs may not faith-\nfully reflect the lived understanding of native\nspeakers, particularly for underrepresented\ncultures like Yor` ub´ a.Despite these limitations, we find LLM judges\nuseful for identifying trends across methods. In fu-\nture work, we plan to validate these findings with\nnative speaker evaluations and human cultural ex-\nperts to ensure interpretive reliability.\n7.4 Limitations\nSome CG-CoT outputs still suffered from overgen-\neralization or hallucination, often when retrieval\nsurfaced tangential rather than truly analogous\nexamples. Improvements may include richer cor-\npus annotation, refinement of embedding granu-\nlarity, or adaptive retrieval filtering. Further, hu-\nman evaluations were simulated using GPT-4.1\nand Claude 3.5; incorporating real native speak-\ners would provide stronger validity.\n7.5 Evaluation Blind Spots\nThe divergence between BLEU and cultural depth\nexposes the inadequacy of current benchmarks for\nlow-resource cultural tasks. BLEU penalizes para-\nphrasing and metaphor, often rewarding shallow\nliteralism. This underscores the need for new met-\nrics sensitive to semantic and cultural fidelity.\n8 Code and Data Access\nAll code, data, prompts, and evaluation scripts\nused in this study are openly available at:\nhttps://github.com/Ilovenewyork/ccgot_\nstudy\n9 Conclusion and Future Work\nThis work introduces CG-CoT, a retrieval-\naugmented chain-of-thought prompting technique\nfor culturally nuanced low-resource NLP tasks.\nOur results on Yoruba proverbs reveal that com-\nbining semantic retrieval with reasoning produces\nsignificantly richer, more culturally faithful inter-\npretations than conventional methods.\nFuture work includes scaling CG-CoT to addi-\ntional low-resource languages, experimenting with\ndynamic retrieval-triggered reasoning, integrating\nstructured cultural ontologies into the RAG cor-\npus, and validating outputs with native speaker\npanels. This approach holds promise for democra-\ntizing language technology by aligning models not\njust with words, but with worlds.\nAcknowledgments\nI thank the Stanford NLP Group for their support\nand intellectual environment, which helped inspire\nand shape this work.\n--- Page 4 ---\nReferences\nS. Cahyawijaya et al. Cross-lingual in-context\nlearning for low-resource languages: Chal-\nlenges and benchmarks. arXiv preprint\narXiv:2402.03435 , 2024.\nA. Deshpande et al. Chain-of-translation prompt-\ning improves multilingual llms. arXiv preprint\narXiv:2404.09061 , 2024.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus,\nFabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich K¨ uttler, Mike Lewis, Wen tau\nYih, Tim Rockt¨ aschel, Sebastian Riedel, and\nDouwe Kiela. Retrieval-augmented generation\nfor knowledge-intensive nlp tasks, 2021. URL\nhttps://arxiv.org/abs/2005.11401 .\nA. Li et al. Culturellm: Aligning language\nmodels with cultural values. arXiv preprint\narXiv:2403.01510 , 2024.\nJ. Shi et al. Culturebank: A benchmark for eval-\nuating cultural understanding in language mod-\nels.arXiv preprint arXiv:2402.04141 , 2024.\nA. Tanwar et al. Multilingual in-context learn-\ning with better exemplars. arXiv preprint\narXiv:2307.08163 , 2023.\nJ. Wei et al. Chain-of-thought prompting elicits\nreasoning in large language models. In NeurIPS ,\n2022.",
  "text_length": 13808
}