{
  "id": "http://arxiv.org/abs/2506.00943v1",
  "title": "Legal Compliance Evaluation of Smart Contracts Generated By Large\n  Language Models",
  "summary": "Smart contracts can implement and automate parts of legal contracts, but\nensuring their legal compliance remains challenging. Existing approaches such\nas formal specification, verification, and model-based development require\nexpertise in both legal and software development domains, as well as extensive\nmanual effort. Given the recent advances of Large Language Models (LLMs) in\ncode generation, we investigate their ability to generate legally compliant\nsmart contracts directly from natural language legal contracts, addressing\nthese challenges. We propose a novel suite of metrics to quantify legal\ncompliance based on modeling both legal and smart contracts as processes and\ncomparing their behaviors. We select four LLMs, generate 20 smart contracts\nbased on five legal contracts, and analyze their legal compliance. We find that\nwhile all LLMs generate syntactically correct code, there is significant\nvariance in their legal compliance with larger models generally showing higher\nlevels of compliance. We also evaluate the proposed metrics against properties\nof software metrics, showing they provide fine-grained distinctions, enable\nnuanced comparisons, and are applicable across domains for code from any\nsource, LLM or developer. Our results suggest that LLMs can assist in\ngenerating starter code for legally compliant smart contracts with strict\nreviews, and the proposed metrics provide a foundation for automated and\nself-improving development workflows.",
  "authors": [
    "Chanuka Wijayakoon",
    "Hai Dong",
    "H. M. N. Dilum Bandara",
    "Zahir Tari",
    "Anurag Soin"
  ],
  "published": "2025-06-01T10:20:13Z",
  "updated": "2025-06-01T10:20:13Z",
  "categories": [
    "cs.SE",
    "cs.AI"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00943v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00943v1  [cs.SE]  1 Jun 2025Legal Compliance Evaluation of Smart Contracts\nGenerated by Large Language Models\nChanuka Wijayakoon∗, Hai Dong∗, H.M.N. Dilum Bandara†, Zahir Tari∗, Anurag Soin‡\n∗School of Computing Technologies, RMIT University, Melbourne, Australia\nchanuka.wijayakoon@student.rmit.edu.au, hai.dong@rmit.edu.au, zahir.tari@rmit.edu.au.\n†CSIRO’s Data61, Sydney, Australia\ndilum.bandara@csiro.au.\n‡University of Technology, Sydney, Australia\nanurag.soin@student.uts.edu.au.\nAbstract —Smart contracts can implement and automate parts\nof legal contracts, but ensuring their legal compliance remains\nchallenging. Existing approaches such as formal specification,\nverification, and model-based development require expertise in\nboth legal and software development domains, as well as extensive\nmanual effort. Given the recent advances of Large Language\nModels (LLMs) in code generation, we investigate their ability\nto generate legally compliant smart contracts directly from\nnatural language legal contracts, addressing these challenges. We\npropose a novel suite of metrics to quantify legal compliance\nbased on modeling both legal and smart contracts as processes\nand comparing their behaviors. We select four LLMs, generate\n20 smart contracts based on five legal contracts, and analyze\ntheir legal compliance. We find that while all LLMs generate\nsyntactically correct code, there is significant variance in their\nlegal compliance with larger models generally showing higher\nlevels of compliance. We also evaluate the proposed metrics\nagainst properties of software metrics, showing they provide\nfine-grained distinctions, enable nuanced comparisons, and are\napplicable across domains for code from any source, LLM or\ndeveloper. Our results suggest that LLMs can assist in generating\nstarter code for legally compliant smart contracts with strict\nreviews, and the proposed metrics provide a foundation for\nautomated and self-improving development workflows.\nIndex Terms —large language models, smart contracts, legal\ncompliance, measurement, software metrics\nI. I NTRODUCTION\nBlockchains are increasingly used for multi-party business\nprocesses [1], with users making direct agreements via im-\nmutable programs known as smart contracts [2]. With the\ntokenized asset market projected to reach US $16.1 trillion\nby 2030 [3], businesses are rapidly developing smart contract-\nbased services on blockchain platforms. To avoid significant\nlegal, financial, and reputational risks, these smart contracts\nmust comply with legal constraints that arise from legal con-\ntracts between stakeholders [4], [5] and regulatory frameworks\nin the operating jurisdiction [6].\nManually implementing legally compliant code is a time-\nconsuming and error-prone process, especially for complex\nmulti-party agreements. With recent advancements in large\nlanguage models (LLMs) such as GPT-4, there has been a\ngrowing interest in using generative models to write code.\nWhile LLMs can produce syntactically correct code [7], gener-\nating smart contracts from natural-language legal agreements\nGPT-4oGemini\n1.5 ProClaude\n3.5 Sonnet\nLlama 3.1\n70b##\n#Smart \nContracts\nLLM\nPrompt#Petri NetsReachability\nGraphs\nBehavior\nComparison\nLLM-based Smart Contract GenerationLLMsLegal\nContractFig. 1. Workflow of Petri-net-based legal and smart contract behavior analysis.\nfaces questions regarding legal compliance. Existing LLM\nevaluations largely focus on syntactic quality [8] and basic\nsemantic accuracy [9]. However,, legal compliance analysis\nrequires complex semantic interpretations and has garnered\nless attention, while LLMs’ legal reasoning capabilities show\nhigh variability [10]. Furthermore, traditional source-code\nmetrics, such as Cyclomatic Complexity [11], fail to capture\ncrucial legal compliance aspects such as rights, obligations,\nand temporal constraints.\nTo address this gap, we propose a systematic evaluation of\nthe legal compliance of smart contracts generated by leading\nLLMs, as shown in Fig. 1. We focus on the alignment between\nthe behaviors captured in a natural-language legal contract\nand those expressed in the corresponding smart contract, and\nuse it as a proxy to assess LLMs’ capability to generate\nlegally compliant code. To facilitate this comparison, we adopt\na contracts-as-processes view [12], modeling both legal and\nsmart contracts as Petri Nets (PNs) [13] to analyze their\nbehaviors.\nWe introduce a novel suite of metrics for legal compliance:\n1)fitness , measuring how many behaviors from the legal con-\ntract are captured in the smart contract; 2) precision , assessing\nhow many behaviors in the smart contract are relevant to\nthe legal contract; and 3) functional equivalence score (FES),\nproviding a flexible assessment of the alignment between the\n--- Page 2 ---\ntwo contracts. These metrics allow us to quantify the degree\nof legal compliance for each LLM-generated smart contract,\noffering a nuanced understanding of how different LLMs\nperform. As the behavior analysis is independent of how a\nsmart contract is conceived, these metrics can also be applied\nto any smart contract, from an LLM or a developer.\nIn this paper, we present three primary contributions:\n1) A suite of software metrics based on behavior analysis to\nquantify the legal compliance of source code.\n2) A PN-based method to systematically calculate the met-\nrics to determine legal compliance of LLM-generated\nsmart contracts against natural-language legal contracts.\n3) A comparative evaluation of smart contracts generated\nby GPT-4o, Gemini 1.5 Pro, Llama 3.1 70b, and Claude\n3.5 Sonnet, highlighting their strengths and weaknesses\nin achieving legal compliance.\nThe paper is structured as follows: Sec. II outlines back-\nground information for our analysis. Sec. III presents the\nresearch methodology, with our metrics suite in Sec. IV.\nSec. V outlines the experimental setup and presents the results\nof our smart contract legal compliance evaluation. We discuss\nour findings and address potential threats to validity in Sec.\nVI. Sec. VII reviews related work. Concluding remarks and\nfuture directions are in Sec. VIII.\nII. P RELIMINARIES\nWe assess smart contract legal compliance by comparing\ntheir behaviors against their base legal contracts. Our ap-\nproach models both contract types as PNs, providing a formal\nframework for behavioral comparison. This section outlines\nthe theoretical foundation of our methodology.\nA. Legal Powers and Obligations\nLegal contracts are structured around fundamental legal\nconcepts such as rights, duties, powers, and obligations [14].\nThese concepts are the foundation for the behaviors that smart\ncontracts need to implement. LLMs, when generating smart\ncontracts, must correctly interpret these legal concepts from\nthe natural-language contract and encode them in code.\nIn this paper, we follow the Symboleo framework [15],\na formal specification language designed for modeling legal\ncontracts, in choosing legal concepts for analysis: power and\nobligation. A power is a legal right that enables one party to\nchange the legal positions of another party. An obligation is\na duty that requires one party to take specific actions when\ncertain conditions are met.\nB. Petri Nets\nPNs [13] provide a formal graphical representation to model\nconcurrent systems. They consist of places (ovals) representing\nresource status or conditions, transitions (rectangles) denoting\nactions or events, tokens to indicate the current state of the\nsystem, and arcs (directed edges) showing the direction of\nworkflows and token movement. Arcs only connect places to\ntransitions or transitions to places.A token in a place indicates an active resource status or a\ntrue condition. A transition is enabled if all its incoming places\n(called the preset ) have tokens. Upon firing, it consumes a\ntoken from each incoming place and puts one token each in\nits outgoing places (called the postset ). An arc with arrow\nheads on both ends denotes that an associated transition\nboth consumes and produces a token at the connected place.\nThere is also a special inhibitor arcs type that inhibits a\ntransition from firing if the connected place has a token. All\nthe possible states of the system represented by different token\nconfigurations are captured by the PN’s reachability graph\n(RG). We refer readers to Gehlot [16] for a more detailed\nintroduction to PNs.\nWe choose PNs as our modeling formalism for several key\nreasons. First, their support for concurrent execution and state\ntransitions naturally maps to legal [17] and smart contract [18]\nbehaviors, where multiple parties can independently initiate\ncontract actions. Second, powers and obligations in legal con-\ntracts can be directly represented with places and transitions\nin PNs [17], allowing intuitive modeling of legal positions\nand their state changes. Third, PNs have formal semantics\nthat enable rigorous comparison of behaviors through reach-\nability analysis [13]. Lastly, PNs’ visual nature helps bridge\ncommunication between legal and technical teams—a crucial\nadvantage when evaluating legal compliance.\nC. Events, Behaviors, and Legal Relevance\nAnevent is an immutable occurrence that happens at a\nparticular time, and a behavior is a sequence of events that\noccurs in a given contract. Events are legally relevant if they\naffect the legal positions of contract parties. As an example,\nfulfilling a payment obligation would be a legally relevant\nevent in a sales contract. In PNs, each path in a RG represents\na behavior. We consider two forms of event equivalence when\ncomparing behaviors:\n1)Strict event equivalence : each event in the ground truth\nbehavior must have one or more events that result in\na functionally equivalent outcome, in the same order\nas the ground truth. This means that for behaviors\nBp=< ep1, ep2, ...epm>from ground truth system and\nBq=< eq1, eq2, ...eqn>from candidate system, each epi\nmaps to one or more events from the sequence eq, while\npreserving the order of events. There can be extra events\nat the end of a candidate behavior after accounting for all\nevents from the ground truth behavior unless they cause\na legal state deviation.\n2)Non-strict event equivalence : allows an event in a behav-\nior of the ground truth to have no equivalent event(s) in\nthe candidate system.\nBuilding on these concepts, we next present how we derive\nand calculate the proposed compliance metrics.\nIII. M ETHODOLOGY\nFig. 1 shows our approach to analyze LLM-generated smart\ncontracts’ legal compliance. We model legal contracts as PNs\nusing CPN Tools [19] and CPN IDE [20], then generate\n--- Page 3 ---\n•By holding or using GCDC, or using any of the GCDC Services,\nyou (“you,” “your,” or “User”) agree that you have read, understood\nand accept all of the terms and conditions contained in these Terms,\nas well as our (“XYZ”) Privacy Policy, Cookie Policy and E-Sign\nConsent, and you acknowledge and agree that you will be bound by\nthese terms and policies.\n•As you have agreed to, and are subject to, the XYZ Mint account\nUser Agreement, XYZ makes available the following GCDC-related\nServices as defined in the XYZ Mint account User Agreement:\n(i) issue GCDC for USD from XYZ,\n(ii) redeem GCDC for USD from XYZ, and\n(iii) send and receive GCDC to and/or from XYZ Mint accounts\n(collectively, the “GCDC Services”).\n•GCDC is issued and redeemed in accordance with XYZ’s blacklist-\ning policy. XYZ reserves the right to block the transfer of GCDC\nto and from an address on chain as permitted under the blacklisting\npolicy.\n•We reserve the right to (i) change, suspend, or discontinue any aspect\nof the GCDC Services at any time, including hours of operation or\navailability of any feature, without notice and without liability and\n(ii) decline to process any issuance or redemption without prior\nnotice and may limit or suspend your use of one or more GCDC\nServices at any time, in our sole discretion.\nFig. 2. Excerpt from the GCDC ToS contract, adapted from [21].\ncorresponding smart contracts using four LLMs and model\nthem also as PNs. We derive RGs from these PNs to analyze\nstates and execution paths. The PNs and RGs reflect any\nsmart contract errors, which our metrics suite aims to capture.\nWe compare these graphs against the legal contract’s RG as\nground truth. The source contracts, smart contracts, and PNs\nare available online1.\nA. Petri-Net Modeling\nFollowing Symboleo [15], we consider only power and\nobligation legal positions as they are monitorable. To analyze\nthe state changes of these legal positions, we construct PNs\nfrom legal and smart contracts. For the legal contract, we\nconsider the point at which a fresh instance of the contract\nmay be initialized as the starting state of its PN. Then the\nlogical execution of legal positions is used to develop the rest\nof the PN. Similarly, each smart contract is initialized in a state\nmirroring that of the legal contract’s initial state. We use basic\nPNs without token differentiation, which limits the system to\nsingle instances of contract parties or resources.\nWe use a simplified version of the USDC stablecoin Terms\nof Service contract [21] to illustrate our analysis. This contract,\ncalled GCDC ToS (Generic Currency Digital Coin Terms of\nService) from here onwards, has no references to USDC, its\nissuing company, or related entities, so that LLMs are not\nunduly influenced by their preexisting knowledge of USDC.\nThe contract, shown in Fig. 2, is between the GCDC issuing\ncompany (XYZ) and GCDC platform user (User).\nCertain workflows were omitted from the full GCDC con-\ntract for clarity and to maintain a manageable scope. For\nexample, blacklisting, freezing, and terminating accounts lead\nto similar outcomes. Thus, blacklisting is selected as the\nrepresentative workflow excluding others.\n1https://doi.org/10.5281/zenodo.14074462TABLE I\nLEGAL POSITIONS OF THE GCDC CONTRACT\nIdentifier Legal Position\nPReqIssue User’s power to request XYZ to issue GCDC.\nPReqRedeem User’s power to request XYZ to redeem GCDC.\nPSendGCDC User’s power to send GCDC.\nPIssueGCDC XYZ’s power to issue GCDC.\nPRedeemGCDC XYZ’s power to redeem GCDC.\nPBlacklist XYZ’s power to blacklist an address.\nPPause XYZ’s power to pause smart contract functionality.\n1) Modeling Legal Contracts as PNs: Here, we first iden-\ntify the legal positions in the contract, as shown for the GCDC\nToS contract in Table I. Next, a PN is drawn considering the\nlogical execution of the contract terms, resulting in models\nsimilar to Fig. 3a. We worked with two lawyers to minimize\nerrors and ensure accurate representation of the underlying\nlegal conditions, as their models are used as the ground truth.\nDiscrepancies were resolved through discussion until lawyers\nreached consensus. We do not include behaviors that may be\nimplied beyond the explicit functional scope of the base legal\ncontract. We used CPN IDE’s simulation tool to ensure there\nare no dead transitions. RGs, similar to Fig. 3b for GCDC\nPBlacklist\nPRedeemGCDC\nPIssueGCDCPSendGCDC\nPReqIssue\nPReqRedeem\nUser redeemed\nGCDC to USDUser sent\nGCDCUser is \nblacklistedAll XYZ \nservices paused\n[LCP]XYZ issues \nGCDC to user\nXYZ redeems \nGCDC for USDXYZ blacklists \nuser's accountXYZ pauses \nall services\nUser sends \nGCDC[LCP]\nUser has\nGCDCDE\nA\nB\nCd\ncg\nrb\ne\nh\nnkjf\npPPausea\n[LCP]qs1\n111 1\n1\n(a) Petri net of GCDC contract.\nacdefhk\nacdefhjkq acegk bcdefhk\nacdefhjkpqs acdefhjknqr\nacegjkq bcdefhjkqbcegk\nacdefhjknpqrs acegjkpqs bcdefhjkpqs acegjknqr bcdefhjknqr\nbcegjkq acegjknpqrs bcdefhjknpqrs bcegjkpqs bcegjknqr\nbcegjknpqrsA D E\nB C\nD EE\nC D E B D E\nE D E E E\nE1\n2\n3\n4A C E\n4 :  XYZ paused smart contract.43 :  XYZ redeemed GCDC to USD for User . 32 :  XYZ issued GCDC to User . 21 :  Start1Example Path\n(b) Reachability graph of GCDC contract.\nFig. 3. Petri net and reachability graph of the GCDC Terms of Service.\n--- Page 4 ---\nToS, are derived using CPN Tools. We manually analyze each\npath to ensure they adhere to the stipulated conditions.\n2) Modeling Smart Contracts as PNs: We systematically\ntransform smart contracts to PNs by examining logical con-\ntrol flow and variable changes, following a four step pro-\ncess. First, we identify contract ownership and initial states\nwith contextual variable interpretation. Second, we analyze\nexecution paths and branching logic through code review.\nNext, we map temporal conditions and ordering constraints\nto PN structures, with inhibitor arcs for sequential ordering.\nFinally, we handle legally irrelevant operational details, such\nas numeric arguments, file paths, and subjective multipliers,\nthrough assumptions. Empty methods representing trackable\noff-chain events are treated as functional components, and\nmissing implementations in state-critical methods are flagged\nas bugs. Temporal conditions use return arcs unless the con-\nsuming transition halts the contract, and they are modeled\nas independent behaviors only when producing operational\neffects on contract state.\nLoop control places (LCP): Some transitions both consume\nand produce a token from and to the same place, such\nas transition Aand place d,PReqIssue in Fig. 3a. These\ntransition-place pairs create self-loops that can fire repeatedly\nbut yield no new information after first execution. To limit\nthem, we introduced a loop-control place in their postset to\nflag the initial firing, connecting it to the transition with an\ninhibitor arc, similar to place q. These flag places are initially\nempty, but receive a token at the first firing of the associated\ntransition, preventing subsequent firings due to inhibitor arcs.\nB. Smart Contract Petri Nets Analysis\nTaking the legal contract’s RG as the ground truth, we\ncompare each of its paths against those in the smart contracts’\nRGs. Because both contract forms are initialized in equivalent\nstates, their RGs are derived from equivalent initial markings.\nEach path in the legal contract’s RG, as seen in Fig. 3b for\nthe GCDC contract, represents a distinct sequence of events,\ni.e., a behavior, through which legal positions change their\nstates. Considering these behaviors, we calculate the proposed\ncompliance metrics.\nIV. M ETRICS FOR LEGAL COMPLIANCE\nWe propose a metric suite designed to measure legal compli-\nance between a legal contract (serving as the ground truth) and\nits smart contract implementation, based on their exhibited be-\nhavior sets. While the legal contract exists in natural language,\nsmart contracts are written in imperative programming lan-\nguages and may implement the same functionality differently.\nThough we focus on LLM-generated smart contracts, these\nmetrics are applicable to any smart contract implementation,\ngenerated automatically or coded manually. While we choose\nPNs for reasons stated in Sec. II-B, behavior modeling may\nbe done with other suitable formalisms.\nAs shown in Fig. 4, a legal contract exhibits a range\nof behaviors (set A) comprising of explicitly defined terms\n(setR) and logically inferred behaviors, with ambiguous\nLegal Contract\nLC\nProcess Model\n(Petri Net PNLC)Smart Contract\nSC\nProcess Model\n(Petri Net PNSC)\nA(Reachability graph\nof PNLC)(Reachability graph\nof PNSC)\nUQMW\nST\nRU All possible behaviors\nA All behaviors (both explicit and implicit through logical\ninference) enabled by the legal contract\nR Behaviors in the legal contract’s Petri net\nQ Behaviors in the smart contract’s Petri net\nM Behaviors in both the legal and smart contracts’ Petri nets\nS Behaviors only in the legal contract’s Petri net\nT Behaviors in the smart contract’s Petri net that are implicitly\namong those of the legal contract\nW Behaviors in the smart contract’s Petri net that are not in\nthat of the legal contract, even implicitly\nFig. 4. Possible behaviors of a legal contract and its smart contract.\nboundaries due to interpretation challenges [15]. A smart\ncontract implementation may capture some legal behaviors (set\nM) while introducing behaviors that deviate from but do not\nviolate the legal contract (set T), or are entirely unrelated (set\nW). Our proposed metrics account for these varying behavior\ntypes, recognizing that compliance requirements may range\nfrom implementing a single legal behavior to capturing all\nspecified behaviors.\nWe propose three metrics to evaluate the legal compliance\nof smart contracts: fitness, precision, and functional equiva-\nlence score (FES). All of them expect legal equivalence —the\nequivalence of states of powers and obligations—at the end of\neach behavior. The goal is to compare the outputs from each\nLLM and determine which LLM produces a smart contract\nmost aligned with the legal ground truth.\nA. Fitness\nThe fitness metric measures how closely the behaviors of\na smart contract (SC) match those of the legal contract (LC).\nFitness is a strict metric that evaluates the completeness of the\nsmart contract’s inclusion of behaviors from the legal contract,\nbased on strict event equivalence.\nFor each behavior Bpin the legal contract, we check\nif there exists a functionally equivalent behavior Bqin the\nsmart contract, where every event in Bphas a corresponding\nevent in the same order in Bq. We identify one exception\nto this requirement: the passing of time, such as deadline\nexpiry, may not be captured explicitly in a smart contract.\nThus, temporal events (and associated changes of legal powers\nand obligations) are exempt from the strict event equivalence\nrequirement given that they may be realized without any\ncode execution. Event ordering must still be preserved, and\n--- Page 5 ---\nthe contracts must reach legally equivalent states at the end.\nAdditionally, when multiple behaviors in a smart contract map\nto a behavior in the legal contract, they are counted as one.\nThe fitness F(SC, LC )of a smart contract to the legal\ncontract is defined as the ratio of behaviors that strictly match\nbetween the contracts to the total number of behaviors in the\nlegal contract. We observe its similarity to recall in infor-\nmation retrieval, which is defined as the number of relevant\ninstances retrieved from all relevant instances. With behavior\nsets (see Fig. 4) Rfrom the legal contract and Qfrom the\nsmart contract, this metric is formalized as follows:\nF(SC, LC ) =|R∩Q|\n|R|(1)\nFitness allows us to compare the accuracy of smart contracts\ngenerated by different LLMs. For example, if the fitness of a\nsmart contract generated by LLMs AandBare 0.7 and 0.5,\nrespectively, Abetter captures the set of expected behaviors\nfrom the legal contract.\nB. Precision\nPrecision measures how much extra behavior a smart con-\ntract introduces beyond those in the legal contract. It is a\nnon-strict metric (denoted by * in behavior sets) that allows\nfor partial event inclusion and focuses on the degree of over-\napproximation. The two contract forms must still reach legally\nequivalent states at the end of corresponding behaviors.\nFor each behavior in the smart contract, we check if it\ncontains events that are not strictly necessary or are absent\nin the legal contract. This allows identifying behaviors in the\nsmart contract that deviate from or go beyond the required\nlegal behaviors. Precision is defined as the ratio of behaviors\nthat match between the legal and smart contracts to the total\nnumber of behaviors in the smart contract:\nPr(SC, LC ) =|(R∩Q)∗|\n|Q|(2)\nPrecision helps compare how well each LLM-generates a\nsmart contract that remains close to the specified behaviors\nwithout introducing unnecessary or incorrect behaviors. For\ninstance, if the precision of contracts from LLM AandBare\n0.8 and 0.6, the former has fewer extraneous behaviors than\nthe latter.\nC. Functional Equivalence Score (FES)\nFES measures the overall functional similarity between the\nlegal contract and the smart contract, relaxing the strict event\nequivalence requirement of the fitness metric. It compares\nwhether at the end of corresponding behaviors, both the legal\nand smart contracts reach legally equivalent states, even if the\nevent sequences differ. It is defined as the ratio of behaviors\nin the smart contract that are functionally equivalent to those\nin the legal contract, regardless of strict event matching:\nFES (SC, LC ) =|(R∩Q)∗|\n|R|(3)TABLE II\nOVERVIEW OF LEGAL CONTRACTS\nContract Name Obligations Powers Behaviors*\nGCDC Terms of Service 0 7 12\nMeat sale 3 3 12\nPizza delivery 3 2 3\nShipper-Carrier 3 0 3\nTransactive energy 3 3 24\n* Behaviors in the reachability graph of the legal contract’s PN.\nTABLE III\nLARGE ANGUAGE MODELS AND THEIR CHARACTERISTICS\nModel Knowledge Context Max Open\nCutoff Window Output Source\nClaude 3.5 Sonnet*Apr, 2024 200K 8K No\nGemini 1.5 Pro†Oct, 2023 2M 8K No\nGPT-4o‡Oct, 2023 128K 16K No\nLlama 3.1 70b Instruct§Dec, 2023 128K 4K Yes\n* –claude-3-5-sonnet-20241022, † –gemini-1.5-pro-002, ‡ – gpt-4o-2024-\n08-06, § –llama-3.1-70b-instruct. K = 1,024 tokens, M = 1,024K tokens\nFES provides a flexible measure of how well the LLM-\ngenerated smart contract adheres to the legal contract’s intent,\neven with implementation differences. For example, a contract\nfrom LLM Amay have a perfect FES of 1, meaning every\nbehavior from the legal contract is functionally captured, even\nif the event sequences differ.\nV. E VALUATION\nA. Experimental Setup\n1) Legal Contract Selection: We adopt the natural-language\nlegal contracts used with the Symboleo framework [15] for\nour analysis. These are selected as they are monitorable,\ngeneralized versions of commonly found real-world contracts,\nrepresentative of what may be encountered in business activ-\nities. Specifically, we selected four contracts from Symboleo\ndataset with varying numbers of legal positions and the GCDC\nToS contract to evaluate different levels of complexity with the\nproposed metrics suite. An overview of the selected contracts\nis shown in Table II, and they all involve at least two parties.\n2) LLM Selection and Configuration: We selected four\nLLMs, GPT-4o [22], Gemini 1.5 Pro [23], Claude 3.5 Son-\nnet [24], and Llama 3.1 70b Instruct [25], based on their archi-\ntectural diversity (proprietary and open-source), demonstrated\nperformance in code generation and reasoning, and enterprise\nviability. GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro rep-\nresent state-of-the-art reasoning capabilities [26], and Llama\n3.1 70b represents leading open-source alternatives [25], al-\nlowing for a comprehensive evaluation. For every model, we\nset the context length to 131,072tokens, temperature to 0.8,\ntop-K to 40, and top-P to 0.9. Maximum output tokens value is\nset to the maximum of each model. A summary of the models\nis shown in Table III.\n3) Prompting Strategy: We adopt a structured zero-shot\nprompting strategy based on the Plan-and-Solve (PS) ap-\nproach [27]. Through six stepwise prompts (see Fig. 5),\nthe LLM systematically extracts key contract elements, i.e.,\n--- Page 6 ---\nYour task is to help create a Solidity smart contract based on a\nprovided legal contract. The process will involve several steps where\nyou will analyze different aspects of the legal contract, document\nkey elements and necessary assumptions, and then, in the final step,\ngenerate the Solidity code. Each step will focus on a specific part of\nthe contract to ensure clarity and manage complexity effectively.\nStep 1: Contract Parties, Powers, and Obligations\nAnalyze the provided legal contract. Identify and list:\n1) The parties involved.\n2) Their powers and obligations.\nDocument any assumptions or interpretations necessary for under-\nstanding these elements. Here is the legal contract:\n“““Legal contract text goes here. ”””\nStep 2: Triggers and Timeframes\nBased on the previously identified parties, powers and obligations,\nnow focus on:\n1) Events that trigger actions within the contract.\n2) Timeframes and deadlines relevant to these events, powers, and\nobligations. Note any interpretations or assumptions related to\nthese triggers and timeframes.\nStep 3: Penalties and Dispute Resolution\nContinuing from the triggers and timeframes, identify:\n1) Any penalties for non-compliance or breaches.\n2) Dispute resolution mechanisms specified in the contract.\nList assumptions or clarifications needed for implementing these\nfeatures in the smart contract.\nStep 4: Legal and Security Compliance\nBefore generating the code, ensure the smart contract meets legal and\nsecurity standards:\n1) Discuss potential legal issues and how they can be addressed in\nthe Solidity code.\n2) Identify necessary security features and error handling\nmechanisms to make the smart contract robust and secure.\nDocument all assumptions and legal considerations.\nStep 5: Smart Contract Generation\nNow, compile all the information and insights gathered from previous\ndiscussions into a concise and efficient Solidity smart contract. The\ncode should:\n1) Be structured clearly with defined sections for parties, powers,\nobligations, triggers, and dispute resolutions.\n2) Include essential comments that clarify sections and key\nfunctions for future reference.\n3) Ensure legal and technical compliance as discussed, focusing on\nfunctional accuracy and security features.\nGenerate the smart contract code with minimal additional commen-\ntary, keeping it focused and lean. Provide brief inline comments only\nwhere necessary to explain complex logic or important compliance\nelements.\nFig. 5. LLM Prompts for Smart Contract Generation\nparties, legal positions, triggers, time frames, and dispute\nmechanisms, before generating the smart contract code. Initial\nattempts using zero-shot Chain-of-Thought [28] and two-\nstep prompting faced timeout and information capture issues.\nThrough iterative refinement and GPT-4o’s optimization, we\ndeveloped our final PS-styled prompts that resolved these\nlimitations.\n4) Code Generation: Each model is prompted to generate\nSolidity smart contracts with the selected legal contracts. We\nlooked for trivial errors such as missing Solidity contractdefinitions and whether the code would be able to execute\nupon deployment. If any issues are found, we repeated the\ncode generation step up to three attempts. The code with least\nissues (in terms of executability and initial variable values) out\nof all attempts is taken as the model’s output for modeling.\nB. Illustrative Analysis: GCDC Contract\n1) PN Model Complexity: The GCDC legal contract PN\nserves as our baseline with 15 places and 5 transitions.\nThe PNs derived from LLM-generated smart contracts show\nvarying structural complexity: Claude Sonnet produced the\nmost complex model (10 places, 6 transitions), followed by\nGemini Pro and Llama 3.1 70b (both with 7 places, 4 tran-\nsitions), while GPT-4o yielded the simplest model (6 places,\n4 transitions). These variations provide an initial indication of\nhow differently each LLM interpreted and implemented the\ncontract requirements.\n2) Behavioral Analysis: Comparing the RGs, there are 12\nbehaviors in the legal contract’s RG, followed by 28 in Claude\nSonnet, 9 in Gemini Pro, and 4 in Llama and 3 in GPT.\nAnalyzing them, we observe:\n•Missing Behaviors: All LLM outputs except for Claude\nSonnet lack pause functionality, which is a critical feature\nof the legal contract. This deviation affects FES and\nfitness scores. Gemini Pro implemented block/unblock\nfunctionality but not pausing or blacklisting. GPT-4o has\nfreezing capabilities but lacks pausing and blacklisting.\nLlama 3.1 70b has no pause, block, blacklist, or freeze\nfunctionality.\n•Extra Behaviors: All smart contracts included various ad-\nditional behaviors, sometimes affecting legal compliance.\n•Path Analysis: Of the 12 unique paths in the legal\ncontract’s RG, only 6 are correctly implemented in smart\ncontracts, and that too only by Claude Sonnet. The other\nmodels have fewer paths, indicating they do not fully\ncapture the legal contract’s behaviors.\n3) Compliance Metrics: Table IV shows the compliance\nmetrics for selected contracts. For GCDC, we observe:\n•Claude Sonnet has the highest fitness score at 0.5, de-\nnoting the best strict event equivalence. All other models\nscore zero due to missing pause functionality, which is the\nterminating state of all behaviors from the legal contract.\nWithout this functionality, LLM outputs do not reach the\nsame final state as the legal contract.\n•Claude Sonnet also has the best functional equivalence\nscore of 0.5, indicating the best overall functional align-\nment with the legal contract. Again, the other models\nhave a score of zero due to missing pause functionality.\n•Gemini Pro has the highest precision score of one,\nindicating that all behaviors of its smart contract are\npresent in the legal contract. Claude Sonnet scores 0.43,\nindicating that only 43% of the behaviors in its smart\ncontract are found in the legal contract. Llama 3.1 70b\nscores zero due to all of its behaviors being permitted to\nbe executed by regular users, which is illegal as per the\n--- Page 7 ---\nTABLE IV\nLEGAL COMPLIANCE METRICS\nFES Fitness Precision\nContract CS GP GPT ML CS GP GPT ML CS GP GPT ML\nGCDC 0.50 0 0 0 0.50 0 0 0 0.43 1 0.67 0\nMeat sale 0.29 0.29 0.24 0.24 0.24 0.24 0.24 0.24 1 0.86 1 0.34\nPizza delivery 1 0.67 0.67 0.67 0.33 0.67 0.67 0.33 0.44 1 0.75 0.5\nShipper-carrier 1 1 1 1 1 1 1 1 0.39 1 1 0.75\nTransactive Energy 0.04 0 0 0 0.04 0 0 0 ✗ 0 0 0\nCS – Claude 3.5 Sonnet. GP – Gemini 1.5 Pro. GPT – GPT-4o. ML – Meta LLama 3.1 70b Instruct. ✗– Path explosion.\nlegal contract—smart contract actions must be initiated\nby authorized addresses.\nC. Summary of Quantitative Findings\nAcross the 20 smart contracts generated by four LLMs for\nfive legal contracts, we observe varying performance across\nour three compliance metrics, as seen in Table IV.\nFor fitness, Claude 3.5 Sonnet achieves the highest scores\non GCDC contract at 0.5, and Transactive Energy contract\nat 0.04, while performing comparably to other models on\nsimpler contracts. All LLMs achieve identical fitness scores\n(0.24) on the Meat sale contract, suggesting similar capability\nin capturing its core behaviors. Similarly, the Shipper-carrier\ncontract sees a perfect fitness score of 1 across all models.\nFor precision, Gemini 1.5 Pro generally achieves high\nscores, reaching 1 on GCDC, Pizza delivery and Shipper-\ncarrier contracts. GPT-4o shows strong precision with scores\nbetween 0.67 and 1 on all but the Transactive Energy contract.\nClaude 3.5 Sonnet demonstrates lower precision scores (0.39-\n0.44) despite higher fitness, indicating generation of additional\nbehaviors beyond the legal contract. Llama 3.1 70b shows\nvariable precision performance, ranging from 0 to 0.75. All\nmodels show poor precision scores against the Transactive\nEnergy contract.\nThe FES values are always equal to or higher than fitness,\nand they demonstrate a clear pattern based on contract com-\nplexity. The simpler Shipper-carrier contract achieves perfect\nFES of 1 across all models, while Pizza delivery shows con-\nsistent FES of 0.67 for all models except Claude 3.5 Sonnet,\nwhich achieves a perfect score. The Meat sale contract yields\nmoderate FES values between 0.24-0.29 across all models. In\ncontrast, the more complex Transactive Energy contract results\nin significantly lower scores, with Claude 3.5 Sonnet achieving\nonly 0.04 and other models scoring 0.\nVI. D ISCUSSION\nA. Comparison of LLM Outputs\n1) Coding Patterns and Implementation Approaches: We\nobserve distinct patterns in how different LLMs approach\nsmart contract generation. Claude 3.5 Sonnet, Gemini 1.5 Pro,\nand GPT-4o consistently use OpenZeppelin library contracts\nsuch as Pausable andOwnable that are widely used in\nthe Ethereum development community. This results in more\nreadable and maintainable code, as well as a higher likelihood\nof legal compliance. In contrast, Llama 3.1 70b tends towardself-implemented functionality, often producing error-prone\npartial implementations that lack robust security features.\nWhile all models generate code targeting Solidity version\n0.8.0 or higher, none fully leverage the language’s newer\nfeatures. For instance, all models continue to use the SafeMath\nlibrary despite version 0.8.0’s built-in overflow protection,\nsuggesting their training data may not fully reflect current best\npractices.\n2) Performance Patterns and Contract Complexity Effects:\nOur evaluation reveals a fundamental trade-off between preci-\nsion and coverage in LLM-generated smart contracts. Models\nachieving higher precision scores, such as Gemini 1.5 Pro and\nGPT-4o, tend to generate more focused implementations but\nsometimes miss implementing complete contract functional-\nity. Conversely, Claude 3.5 Sonnet achieves better functional\ncoverage at the cost of introducing extraneous behaviors. FES\nvalues are at least equal to fitness in all instances, as the former\nrelaxes the strict event equivalence condition of the latter.\nThe impact of contract complexity is particularly evident\nin our results. Simple contracts with fewer legal positions,\nsuch as the Shipper-carrier contract (3 obligations, no powers),\nsee consistently high performance across all metrics and\nmodels. However, common failure scenarios emerge with more\ncomplex contracts:\n•Incomplete implementation of contracts’ legal powers\nand obligations, especially noticeable in GCDC ToS (7\npowers), where only Claude 3.5 Sonnet achieved non-\nzero fitness scores.\n•Incorrect handling of administrative functionality such as\npausing and access controls, notably in Llama 3.1 70b’s\nimplementations.\nThese patterns suggest that while LLMs can generate\nsyntactically correct smart contracts, they struggle with the\nsemantic complexity of legal requirements. The Transactive\nEnergy contract (3 obligations, 3 powers) particularly demon-\nstrates this challenge; it exhibited a path explosion problem\nwith hundreds or even thousands of behaviors across LLM-\ngenerated smart contract RGs. Calculating the metrics, which\nrequires pair-wise path comparisons, quickly becomes infeasi-\nble in such cases. We optimized the analysis by identifying\nsubsequences of events with clear legality violations and\ndiscounting them from metric calculations. This speeds up\nthe analysis, but does not address the combinatorial growth\nin path comparisons. In future, we plan to explore efficient\nmethods for comparing RGs, e.g., using machine-learning\n--- Page 8 ---\ntechniques to identify common patterns and reduce the number\nof comparisons, or using LLMs to interpret individual paths\nand identify legal violations directly.\nIn summary, current LLMs are better suited for generating\ninitial implementations of simpler contracts, requiring careful\nreview and refinement for more complex scenarios.\nB. Analysis of Metrics with Properties of Software Measures\nWe evaluate the proposed metrics using Weyuker’s informal\nproperties for software measures [29], adapting them from\ntheir original purpose of evaluating syntactic complexity to\nour semantic evaluation of legal compliance. Using property\nnames from Gustafon [30], we find the distribution property\n((∃P)(∃Q)such that |P| ̸=|Q|where P, Q∈ P, programs)\nrequires different metric values for different programs, which\nour metrics satisfy as shown in Table IV. Fineness requires\nonly finite programs to have any given metric value c, which\nholds true given practical implementation limits. Coarseness\n(∃distinct programs P,Qsuch that |P|=|Q|) requires\nthat distinct programs can have the same metric value, also\ndemonstrated in Table IV. The remaining Weyuker’s properties\nprimarily concern program syntax and are thus less relevant\nfor our semantic compliance measures.\nExamining formal properties of software measurement [30],\nwe find our metrics are built on non-trivial PN models with\nmultiple possible instances and exhibit non-trivial ordering .\nAll three metrics have a ratio scale, enabling meaningful com-\nparisons of relative values (e.g., one program having double\nthe fitness of another). Therefore, these properties enable the\nmetrics to effectively compare smart contracts, making them\nuseful for choosing between LLMs for code generation.\nC. Threats to Validity\nConstruct validity . The accuracy of the proposed metrics\ndepends on the correct interpretation of legal text, which\nremains challenging. We mitigated this by independently ver-\nifying our contract interpretations with two lawyers and using\ntools such as CPN IDE to simulate PN models and catch\ninconsistencies. Some legal nuances might still be lost in the\ntranslation to PN representations.\nInternal validity . When generating smart contracts, varia-\ntions in prompts could affect the quality of the output. We\nstandardized prompts across all models and tried multiple\nprompt variants to mitigate this impact.\nExternal validity . While we studied various contract types,\nLLMs, and smart contracts, we tested only specific subsets\nof terms in some contracts, as noted with USDC Terms of\nService, to manage complexity. Additional experiments with\ncomplete contracts and a wider range of legal documents\nwould further validate generalizability of proposed metrics.\nConclusion validity . The lack of comparable frameworks\nfor nuanced legal compliance evaluation makes it difficult to\ndirectly benchmark our metrics. Alternatively, we analyze the\nmetrics against syntactic software quality properties.VII. R ELATED WORK\nWe review previous work in three key areas: LLM legal\nreasoning and code generation, formal and mixed methods\nfor smart contract testing and verification, and model-based\napproaches for legal compliance.\nLLM legal reasoning and code generation. Chen et al. [8]\nconducted extensive evaluations of LLM-generated code qual-\nity, finding that while models can generate syntactically correct\ncode, semantic correctness remains challenging. For smart\ncontracts specifically, Barbara et al. [31] demonstrated that a\ncontemporary LLM output fell short of generating production-\nready smart contracts, but did not provide a method to quantify\ncompliance. LegalBench, a benchmark for natural-language\nlegal reasoning tasks [10], notes that LLMs are particularly\nchallenged by legal-rule application and conclusion tasks, but\ndoes not evaluate coding capabilities of LLMs.\nFormal and mixed methods . Previous works have focused\non vulnerability detection through symbolic and concolic\nexecution, with tools such as Manticore [32] and Oyente [33].\nNeither legal compliance nor its measurement are explicit\ngoals of these tools, while they may be indirectly useful via\nfunctional correctness validation. The Symboleo framework\n[34] made significant advances in modeling contract behav-\nior. Their conformance checker SymboleoCC [35] points to\nthe feasibility of automated compliance verification, though\nlimited to contracts written in their specification language\nand manually written test cases. Logic-based languages [5],\n[36] and Domain-Specific Languages [37], [38] also represent\ncontract elements without quantifying compliance.\nModel-based approaches. Previous approaches have\nsought to bridge legal and programming domains [39], but\nlack systematic compliance quantification. Ladleif et al. [40]\ndeveloped a UML meta-model for legal concepts in smart\ncontracts, while Symboleo [34], [35] provides a specification\nlanguage for modeling contract lifecycles and legal positions.\nHowever, these approaches stop short of providing compre-\nhensive compliance evaluation mechanisms.\nOur approach differs from prior work in three key aspects.\nFirst, while existing LLM studies evaluate either code quality\nor legal reasoning in isolation, we bridge these aspects with\nquantitative metrics to measure legal compliance of smart con-\ntracts. Second, unlike the custom specification requirements of\ntools such as SymboleoCC, our PN-based process modeling\napproach can generically model and compare any smart con-\ntract against a legal contract. Finally, while previous model-\ning approaches lack systematic compliance measurement, our\nbehavior-based metrics suite provides a comprehensive frame-\nwork for quantifying alignment between legal intentions and\ntechnical implementations. This enables granular compliance\nassessment and comparison of different LLMs’ capabilities in\ngenerating legally compliant smart contracts.\nVIII. C ONCLUSION\nOur evaluation of 20 smart contracts from four leading\nLLMs reveals that they can generate syntactically valid code\nbut vary in their legal compliance capabilities. While Claude\n--- Page 9 ---\nSonnet offers better functional coverage with excess behaviors,\nGemini Pro and GPT-4o prioritize precision over complete-\nness. Our behavior-based measurement approach and resulting\nmetrics are applicable to both LLM-generated and manually\nwritten code, and the PN-based analysis framework enables\nformal compliance evaluation. The proposed metrics demon-\nstrate that while LLMs show promise in generating legally\ncompliant smart contracts, they face challenges in consistently\ncapturing the full scope of legal requirements and avoiding\nextraneous behaviors. These findings highlight the need for\ncareful human review prior to deploying LLM-generated smart\ncontracts. Future work could explore the relationship between\nLLM architectures, training processes, and their ability to\nmaintain legal compliance, automate compliance checking\nthrough our metrics framework, and address the state space\nexplosion challenges we observed in complex contracts.\nACKNOWLEDGEMENT\nWe gratefully acknowledge funding from the Digital Fi-\nnance CRC which is supported by the Cooperative Research\nCentres program, an Australian Government initiative. We also\nthank the Australia and New Zealand Bank for their support\nand guidance during this research.\nREFERENCES\n[1] J. Mendling et al. , “Blockchains for business process management –\nChallenges and opportunities,” ACM Trans. on Management Information\nSystems (TMIS) , vol. 9, pp. 4:1–4:16, Feb. 2018.\n[2] A. Mavridou, A. Laszka, E. Stachtiari, and A. Dubey, “Verisolid:\nCorrect-by-design smart contracts for Ethereum,” in Financial Cryp-\ntography and Data Security (I. Goldberg and T. Moore, eds.), (Cham),\npp. 446–465, Springer Inte. Publishing, 2019.\n[3] S. Kumar, R. Suresh, D. Liu, B. Kronfellner, and A. Kaul, “Relevance\nof on-chain asset tokenization in “Crypto Winter”,” Boston Consulting\nGroup , 2022.\n[4] V . Dwivedi and A. Norta, “A legal-relationship establishment in smart\ncontracts: Ontological semantics for programming-language develop-\nment,” in Advances in Computing and Data Sciences (M. Singh,\nV . Tyagi, P. K. Gupta, J. Flusser, T. ¨Oren, and V . R. Sonawane, eds.),\npp. 660–676, Springer Int. Publishing, 2021.\n[5] F. Idelberger, G. Governatori, R. Riveret, and G. Sartor, “Evaluation\nof logic-based smart contracts for blockchain systems,” in Rule Tech-\nnologies. Research, Tools, and Applications (J. J. Alferes, L. Bertossi,\nG. Governatori, P. Fodor, and D. Roman, eds.), pp. 167–183, Springer\nInt. Publishing, 2016.\n[6] R. Auer, “Embedded supervision: How to build regulation into\nblockchain finance,” Globalization and Monetary Policy Institute Work-\ning Paper , no. 371, 2019.\n[7] J. Austin et al. , “Program synthesis with large language models,” 2021.\n[8] M. Chen et al. , “Evaluating large language models trained on code,”\n2021.\n[9] J. Liu, C. S. Xia, Y . Wang, and L. Zhang, “Is your code generated by\nchatgpt really correct? Rigorous evaluation of large language models for\ncode generation,” in Advances in Neural Information Processing Systems\n(A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine,\neds.), vol. 36, pp. 21558–21572, Curran Associates, Inc., 2023.\n[10] N. Guha et al. , “Legalbench: A collaboratively built benchmark for\nmeasuring legal reasoning in large language models,” 2023.\n[11] T. J. McCabe, “A complexity measure,” IEEE Trans. on Software\nEngineering , vol. SE-2, no. 4, pp. 308–320, 1976.\n[12] A. Daskalopulu, “Modelling legal contracts as processes,” in Proc. 11th\nInt. Workshop on Database and Expert Systems Applications , pp. 1074–\n1079, IEEE, 2000.\n[13] C. Petri and W. Reisig, “Petri Net,” Scholarpedia , vol. 3, no. 4, p. 6477,\n2008.[14] W. N. Hohfeld, “Fundamental legal conceptions as applied in judicial\nreasoning,” The Yale Law J. , vol. 26, no. 8, pp. 710–770, 1917.\n[15] A. Parvizimosaed, Symboleo: Specification and verification of legal\ncontracts . PhD thesis, University of Ottawa, 2022.\n[16] V . Gehlot, “From Petri NETS to Colored Petri NETS: A tutorial\nintroduction to NETS based formalism for modeling and simulation,”\nin2019 Winter Simulation Conf. (WSC) , pp. 1519–1533, 2019.\n[17] R. W. Bons, R. M. Lee, R. W. Wagenaar, and C. D. Wrigley, “Modelling\ninter-organizational trade using documentary Petri nets,” in Proceedings\nof the Twenty-eighth Annual Hawaii Int. Conf. on System Sciences ,\nvol. 3, pp. 189–198, IEEE, 1995.\n[18] W. Duo, H. Xin, and M. Xiaofeng, “Formal analysis of smart contract\nbased on colored Petri nets,” IEEE Intelligent Systems , vol. 35, no. 3,\npp. 19–30, 2020.\n[19] M. Beaudouin-Lafon et al. , “CPN/Tools: A tool for editing and simulat-\ning coloured Petri Nets ETAPS tool demonstration related to TACAS,”\ninTools and Algorithms for the Construction and Analysis of Systems\n(T. Margaria and W. Yi, eds.), (Berlin, Heidelberg), pp. 574–577,\nSpringer Berlin Heidelberg, 2001.\n[20] E. Verbeek and D. Fahland, “CPN IDE: An extensible replacement for\nCPN tools that uses access/CPN,” in ICPM 2021 Doctoral Consortium\nand Demo Track 2021 (M. Jans, G. Janssenswillen, A. Kalenkova, and\nF. Maggi, eds.), CEUR Workshop Proc., pp. 29–30, CEUR-WS.org,\n2021.\n[21] Circle, “Circle — USDC Terms — circle.com.” https://www.circle.com/\nlegal/usdc-terms, 2024. [Accessed 01-11-2024].\n[22] OpenAI, A. Hurst, A. Lerer, A. P. Goucher, A. Perelman, A. Ramesh,\nA. Clark, et al. , “GPT-4o system card,” 2024.\n[23] G. Team, P. Georgiev, V . I. Lei, R. Burnell, L. Bai, A. Gulati, G. Tanzer,\net al. , “Gemini 1.5: Unlocking multimodal understanding across millions\nof tokens of context,” 2024.\n[24] A. AI, “Anthropic - Claude 3.5 Sonnet.” https://www.anthropic.com/\nnews/claude-3-5-sonnet. [Accessed 01-11-2024].\n[25] A. Dubey et al. , “The Llama 3 herd of models,” arXiv preprint\narXiv:2407.21783 , 2024.\n[26] A. AI, “Claude 3.5 sonnet model card addendum.” https://www-cdn.\nanthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model\nCard Claude 3Addendum.pdf, 2024.\n[27] L. Wang et al. , “Plan-and-solve prompting: Improving zero-shot chain-\nof-thought reasoning by large language models,” 2023.\n[28] J. Wei et al. , “Chain-of-thought prompting elicits reasoning in large\nlanguage models,” Advances in Neural Information Processing Systems ,\nvol. 35, pp. 24824–24837, 2022.\n[29] E. Weyuker, “Evaluating software complexity measures,” IEEE Trans.\non Software Engineering , vol. 14, no. 9, pp. 1357–1365, 1988.\n[30] D. A. Gustafson and B. Prasad, “Properties of software measures,” in\nFormal Aspects of Measurement (T. Denvir, R. Herman, and R. W.\nWhitty, eds.), (London), pp. 179–193, Springer London, 1992.\n[31] F. Barb `ara, E. A. Napoli, V . Gatteschi, and C. Schifanella, “Automatic\nsmart contract generation through llms: When the stochastic parrot fails,”\nin6th Distributed Ledger Technology Workshop , 2024.\n[32] M. Mossberg et al. , “Manticore: A user-friendly symbolic execution\nframework for binaries and smart contracts,” in 34th IEEE/ACM Int.\nConf. on Automated Software Engineering (ASE) , pp. 1186–1189, 2019.\n[33] L. Luu, D.-H. Chu, H. Olickel, P. Saxena, and A. Hobor, “Making smart\ncontracts smarter,” in Proc. 2016 ACM SIGSAC Conf. on Computer and\nCommunications Security , CCS ’16, p. 254–269, ACM, 2016.\n[34] S. Sharifi, A. Parvizimosaed, D. Amyot, L. Logrippo, and J. Mylopoulos,\n“Symboleo: Towards a specification language for legal contracts,” in\n2020 IEEE 28th Int. Requirements Engineering Conf. (RE) , pp. 364–\n369, Aug 2020.\n[35] A. Parvizimosaed, S. Sharifi, D. Amyot, L. Logrippo, and J. Mylopoulos,\n“Subcontracting, assignment, and substitution for legal contracts in\nSymboleo,” in Conceptual Modeling (G. Dobbie, U. Frank, G. Kappel,\nS. W. Liddle, and H. C. Mayr, eds.), (Cham), pp. 271–285, Springer Int.\nPublishing, 2020.\n[36] G. Governatori, F. Idelberger, Z. Milosevic, R. Riveret, G. Sartor, and\nX. Xu, “On legal contracts, imperative and declarative smart contracts,\nand blockchain systems,” Artificial Intelligence and Law , vol. 26,\npp. 377–409, 2018.\n[37] C. K. Frantz and M. Nowostawski, “From institutions to code: Towards\nautomated generation of smart contracts,” in IEEE 1st Int. Workshops on\nFoundations and Applications of Self* Systems (FAS*W) , pp. 210–215,\n2016.\n--- Page 10 ---\n[38] X. He, B. Qin, Y . Zhu, X. Chen, and Y . Liu, “SPESC: A Specifica-\ntion Language for Smart Contracts,” in IEEE 42nd Annual Computer\nSoftware and Applications Conf. (COMPSAC) , vol. 01, pp. 132–137,\n2018.\n[39] F. Amato, G. Cozzolino, F. Moscato, V . Moscato, and F. Xhafa, “A model\nfor verification and validation of law compliance of smart contracts in\nIoT environment,” IEEE Trans. on Industrial Informatics , vol. 17, no. 11,\npp. 7752–7759, 2021.\n[40] J. Ladleif and M. Weske, “A unifying model of legal smart contracts,”\ninConceptual Modeling (A. H. F. Laender, B. Pernici, E.-P. Lim,\nand J. P. M. de Oliveira, eds.), (Cham), pp. 323–337, Springer Int.\nPublishing, 2019.",
  "text_length": 53065
}