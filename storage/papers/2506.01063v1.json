{
  "id": "http://arxiv.org/abs/2506.01063v1",
  "title": "AI4Contracts: LLM & RAG-Powered Encoding of Financial Derivative\n  Contracts",
  "summary": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) are\nreshaping how AI systems extract and organize information from unstructured\ntext. A key challenge is designing AI methods that can incrementally extract,\nstructure, and validate information while preserving hierarchical and\ncontextual relationships. We introduce CDMizer, a template-driven, LLM, and\nRAG-based framework for structured text transformation. By leveraging\ndepth-based retrieval and hierarchical generation, CDMizer ensures a\ncontrolled, modular process that aligns generated outputs with predefined\nschema. Its template-driven approach guarantees syntactic correctness, schema\nadherence, and improved scalability, addressing key limitations of direct\ngeneration methods. Additionally, we propose an LLM-powered evaluation\nframework to assess the completeness and accuracy of structured\nrepresentations. Demonstrated in the transformation of Over-the-Counter (OTC)\nfinancial derivative contracts into the Common Domain Model (CDM), CDMizer\nestablishes a scalable foundation for AI-driven document understanding,\nstructured synthesis, and automated validation in broader contexts.",
  "authors": [
    "Maruf Ahmed Mridul",
    "Ian Sloyan",
    "Aparna Gupta",
    "Oshani Seneviratne"
  ],
  "published": "2025-06-01T16:05:00Z",
  "updated": "2025-06-01T16:05:00Z",
  "categories": [
    "cs.IR"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.01063v1",
  "full_text": "--- Page 1 ---\narXiv:2506.01063v1  [cs.IR]  1 Jun 2025AI4Contracts: LLM & RAG-Powered Encoding of Financial Derivative Contracts\nMaruf Ahmed Mridul1,Ian Sloyan2,Aparna Gupta1and Oshani Seneviratne1\n1Rensselaer Polytechnic Institute,2South Cardinal\nmridum@rpi.edu, ian@southcardinal.ie, guptaa@rpi.edu, senevo@rpi.edu\nAbstract\nLarge Language Models (LLMs) and Retrieval-\nAugmented Generation (RAG) are reshaping how\nAI systems extract and organize information from\nunstructured text. A key challenge is designing\nAI methods that can incrementally extract, struc-\nture, and validate information while preserving hi-\nerarchical and contextual relationships. We in-\ntroduce CDMizer , a template-driven, LLM, and\nRAG-based framework for structured text transfor-\nmation. By leveraging depth-based retrieval and\nhierarchical generation, CDMizer ensures a con-\ntrolled, modular process that aligns generated out-\nputs with predefined schema. Its template-driven\napproach guarantees syntactic correctness, schema\nadherence, and improved scalability, addressing\nkey limitations of direct generation methods. Ad-\nditionally, we propose an LLM-powered evalua-\ntion framework to assess the completeness and\naccuracy of structured representations. Demon-\nstrated in the transformation of Over-the-Counter\n(OTC) financial derivative contracts into the Com-\nmon Domain Model (CDM), CDMizer establishes\na scalable foundation for AI-driven document un-\nderstanding, structured synthesis, and automated\nvalidation in broader contexts.\n1 Introduction\nAdvancements in Large Language Models (LLMs) and\nRetrieval-Augmented Generation (RAG) are transforming\nhow AI systems extract and organize unstructured text. How-\never, applying these techniques to long, hierarchical, and\ndomain-specific documents remains challenging. AI methods\nmust extract key information while generating structured out-\nputs that align with predefined schema and preserve semantic\nintegrity.\nWe introduce CDMizer , a template-driven, LLM, and\nRAG-based framework for structured text transformation. By\nleveraging depth-based retrieval and hierarchical generation,\nCDMizer extracts and organizes unstructured contract text\nwhile ensuring syntactic correctness, schema adherence, and\nscalability. This process reduces manual overhead, enhances\nefficiency, and facilitates compliance in high-stakes financial\nenvironments. We also propose an LLM-powered evaluationframework to assess the structured output quality.\nStructured representations are critical in financial con-\ntracts, where unstructured text complicates automation and\ncompliance. CDM, a standardized, machine-readable, and\nmachine-executable model, represents financial products,\ntrades in those products, and the lifecycle events of those\ntrades [FINOS, 2025 ]. International Swaps and Deriva-\ntives Association (ISDA), the organization driving the de-\nvelopment of CDM at Fintech Open Source Foundation\n(FINOS) (along with International Capital Market Associa-\ntion and International Securities Lending Association), pro-\nvides legal standards for trillions of dollars of notional con-\ntracts [ISDA, 2023 ]. However, these contracts often require\nmanual processing due to their unstructured nature and com-\nplex terms. The challenge is greater for non-centrally cleared\nOTC derivatives, where counterparties handle collateral, set-\ntlement, and disputes bilaterally. While CDM offers a stan-\ndardized schema, converting complex legal agreements into\nstructured representations remains difficult due to domain-\nspecific clauses and multilayered structures.\nBy structuring contract data into CDM-aligned outputs,\nCDMizer automates and standardizes OTC derivatives pro-\ncessing, bridging the gap between unstructured financial\nagreements and machine-readable contract frameworks.\nContributions of this paper include: (1) Baseline Conver-\nsion Method: An LLM and RAG pipeline for generating\nCDM representations from unstructured derivative contracts,\nserving as a feasibility benchmark for AI-driven solutions, (2)\nTemplate Creation Framework: A deterministic method\nfor creating minimal yet comprehensive OTC derivatives tem-\nplates, retaining only essential CDM fields, (3) CDMizer :\nA structured method that builds on the templates, integrat-\ning LLMs and RAG for scalable contract-to-CDM conversion\nwhile ensuring syntactic correctness and schema adherence,\nand (4) Evaluation Framework: An LLM-driven approach\nto assess the semantic completeness and correctness of gen-\nerated CDM representations at scale.\n2 Background\n2.1 Common Domain Model (CDM)\nFINOS CDM, originally developed by ISDA, is a standard-\nized, machine-readable, and machine-executable blueprint\nfor how financial products are traded and managed across\nthe transaction lifecycle. It enhances efficiency, interop-\n--- Page 2 ---\nerability, and transparency in financial markets by provid-\ning a single digital processing standard, reducing reconcilia-\ntion needs, accelerating financial technology innovation, and\nenabling consistent regulatory reporting. Built on key de-\nsign principles—normalization, composability, industry for-\nmat mapping, embedded logic, and modularization—CDM\nensures a structured, adaptable framework for trade process-\ning[FINOS, 2024b ]. The CDM model, maintained in the FI-\nNOS CDM repository [FINOS, 2024a ], is the central resource\nfor defining the structure and semantics of OTC derivatives\nand other financial contracts. This repository also provides\nnumerous example contracts in CDM-compliant JSON and\nschema definitions that outline validation rules and structural\nguidelines to ensure consistency. While CDM applies to a\nwide set of financial products, this work focuses on OTC\nderivatives.\n2.2 OTC Financial Derivative Contracts\nFinancial derivatives are financial contracts defined as a de-\nrived contract on another underlying financial contract, in-\nstrument, index, or reference rate. These contracts allow\nparties to speculate on or hedge against changes in value or\nvolatility of the underlying financial contract or asset, which\nmay be an equity, commodity, bond, interest rate, currency, or\nother financial instrument. Derivatives, especially the OTC\nones, have a large variety, including forwards, swaps, and\noptions. OTC derivatives are bilaterally negotiated financial\ncontracts between two counterparties without being listed or\ntraded on an exchange. Unlike exchange-traded derivatives,\nwhich are standardized, OTC derivatives are customized to\nmeet counterparties’ specific risk management needs. These\ncustomized contracts are constructed on a wide range of asset\nclasses, such as fixed income, equity, foreign exchange, com-\nmodity, credit instruments, etc, and are often used for hedging\nrisk or speculating on market movement and volatility.\n3 Related Work\nRecent advances in reg-tech and financial automation have\ndemonstrated the potential of LLMs and RAG in streamlining\ncomplex processes. While several studies emphasize stan-\ndardized formats, few directly address converting unstruc-\ntured OTC derivative contracts into structured representa-\ntions. The following works highlight key developments and\ngaps in this domain.\nEarly Automated Frameworks for OTC Derivatives:\n[Fries and Kohl-Landgraf, 2018 ]proposed automating ter-\nmination procedures in collateralized OTC transactions but\nrelied on structured contract terms. Similarly, [Armitage,\n2022 ]explored transforming the ISDA Master Agreement\ninto a smart contract, emphasizing systematic structures but\nnot AI-driven free-text conversion.\nToward Smart Contract Implementations: [Oluwajebe et\nal., 2020 ]demonstrated smart contract automation for inter-\nest rate swaps (IRS), underscoring the need for standardized\ntemplates. Formal methods in [Clack and Vanca, 2018 ]re-\ninforced the importance of clear semantics for legal enforce-\nability. However, these works assume structured inputs, over-\nlooking challenges in extracting structured data from unstruc-\ntured legal text.LLMs, Code Generation, and Interoperability: [Kang\net al. , 2024; Van Woensel et al. , 2023 ]showed how LLMs\ngenerate smart contracts from health insurance policy doc-\numents but did not address complex financial agreements.\nSolMover [Karanjai et al. , 2024 ]tackled blockchain con-\ntract translation, leveraging structured representations. Ad-\nditionally, [Sorensen, 2024 ]highlighted AI-induced failures\nin smart contracts, stressing the need for precise definitions.\nDecentralized Finance and Retrieval-Based Methods:\n[Singh et al. , 2024 ]examined decentralized exchanges and\nhow inconsistent contract specifications hinder large-scale\nadoption. [Vaithilingam et al. , 2022 ]emphasized hu-\nman oversight in LLM-driven code generation, while RED-\nCODER [Parvez et al. , 2021 ]demonstrated how retrieval-\naugmented generation enhances coherence and correctness,\nmaking it relevant for contract standardization.\nEvaluating Large-Scale AI-Driven Translation: A key\nchallenge in contract standardization is evaluating AI-\ngenerated structured outputs. Many AI-driven translation\nefforts [Kang et al. , 2024; Van Woensel et al. , 2023;\nVaithilingam et al. , 2022; Parvez et al. , 2021; Liu et al. , 2024;\nLiet al. , 2022 ]rely on test-based evaluations, which are im-\npractical for complex financial contracts. While round-trip\ncorrectness (RTC) [Allamanis et al. , 2024 ]aids in code eval-\nuation, it remains unsuitable for contract standardization due\nto legal nuances. Developing robust evaluation metrics re-\nmains an open challenge.\nIn summary, most existing solutions assume structured in-\nputs or focus on narrow contract components, leaving the\ntransformation of full-length OTC derivative contracts unre-\nsolved. This paper addresses this gap by introducing the CD-\nMizer, and a robust evaluation framework.\n4 Data Collection and Synthesis\nThe first step in generating CDM representations is acquiring\nthe necessary data. However, real-world OTC derivative con-\ntracts are often proprietary and confidential, limiting access\nto diverse examples that capture the full complexity and vari-\nability of real agreements. This constraint poses a significant\nchallenge, as synthetic samples may fail to reflect the nuanced\nlanguage and edge cases present in actual contracts, hinder-\ning the development of robust automation solutions. Never-\ntheless, we were able to collect the following data:\n•Natural Language Contracts (Term Sheets): Two con-\ntract examples from RBCCapitalMarkets [RBC Capital\nMarkets, 2024 ]and JPMorgan [J.P. Morgan, 2024 ].\n•CDM Examples: 858 structured CDM instances sourced\nfrom the FINOS CDM repository [FINOS, 2024a ].\nAlthough the CDM repository provides structured JSON\nexamples, natural language contract descriptions remain\nscarce. Notably, while CDM representations exist, corre-\nsponding real-world contract descriptions in natural language\nare not readily available. Since our objective is to convert nat-\nural language descriptions into CDM format, obtaining such\ndescriptions is a prerequisite.\nTo address this gap, we leveraged an LLM to generate syn-\nthetic contract descriptions from existing CDM representa-\ntions. To enhance the quality of these generated descriptions,\n--- Page 3 ---\nwe provided the two collected natural language examples as\nreference inputs. While synthetic descriptions may not fully\ncapture the complexity of real-world contracts, they serve as\nan initial dataset for training and model development.\nFor experimentation purposes and convenience, we catego-\nrized the collected and generated data into six contract types:\nInterest Rate Swap ,Equity Swap ,Equity Option ,Commod-\nity Option ,Foreign Exchange Derivatives, and Credit Default\nSwap . This classification was guided by the collected CDM\nexamples, each of which explicitly specifies its contract type,\nreflecting the primary categories represented in the available\nstructured data.\n5 Baseline Method\nThe baseline method, illustrated in Figure 1, evaluates how\nwell LLMs can generate CDM representations directly from\nOTC derivative contract descriptions. The process involves\nfine-tuning an LLM on contract-to-CDM mappings and inte-\ngrating RAG for enhanced accuracy. The steps are as follows:\nFigure 1: Workflow of directly generating a CDM representation\nfrom a given contract description using an LLM and RAG.\n•Contract Input : The first step is to input the contract into\nthe system. This is a raw contract description in natural\nlanguage extracted from sources such as PDFs.\n•LLM Fine-tuning : An LLM is fine-tuned using the pre-\nviously discussed synthetic dataset consisting of contract\ndescriptions paired with CDM examples. The fine-tuning\nleverages Parameter-Efficient Fine-Tuning (PEFT) tech-\nniques, including LoRA (Low-Rank Adaptation) with 4-bit\nquantization, to optimize specific parts of the model. This\napproach allows for efficient training while ensuring the\nmodel can accurately generate CDM representations from\ncontract descriptions.\n•CDM Generation : The contract is processed by a fine-\ntuned LLM to generate its CDM representation using a\nstructured prompt specifically designed for contract-to-\nCDM conversion. To enhance accuracy and consistency,\nwe integrate RAG. A structured knowledge base, built from\nrelevant examples in the CDM repository, is preprocessed\ninto retrievable chunks. The LLM retrieves the most rel-\nevant examples using semantic similarity and incorporates\nthem into the input prompt, ensuring better alignment with\nCDM schema definitions. This combination of structured\nprompting and retrieved contextual knowledge guides the\nmodel in producing a well-formed CDM JSON represen-\ntation. However, for experimental purposes, we evaluate\nboth settings - CDM generation with and without RAG in-\ntegration - to assess their comparative effectiveness. Theevaluation procedure is discussed in detail in a later section\nof this paper.\n6CDMizer : A More Deterministic Approach\nfor CDM Generation\nWhile the baseline approach provides an initial evaluation of\nLLM capabilities, it lacks determinism and may introduce in-\nconsistencies in CDM representations. Moreover, due to the\nlarge size of the contracts and the potential for their CDM rep-\nresentations to span thousands of lines, the baseline method\nstruggles to consistently generate complete JSON, hindered\nby token limitations and contract complexities. To address\nthese limitations, we propose CDMizer , a more structured and\ndeterministic method for converting contract descriptions into\nCDM representations.\nCDMizer deterministically creates CDM templates and\npopulates them using an LLM integrated with RAG. The\nCDM schema’s complexity, with deeply nested structures and\ninterdependencies, makes direct generation from natural lan-\nguage unreliable, often leading to syntactic errors, schema\nnon-compliance, or hallucinated fields. Templates enforce\n100% schema adherence and correctness by providing a fixed\nstructure, enabling component-wise generation where sub-\nstructures are populated iteratively. By retaining only relevant\nfields, templates also mitigate token constraints and reduce\ncomplexity, ensuring a scalable and reliable CDM generation\nprocess.\nBesides, existing methods [Choudhury et al. , 2018;\nTateishi et al. , 2019; Marchesi et al. , 2022; Allouche et al. ,\n2021; Frantz and Nowostawski, 2016 ]for generating domain-\nspecific code, especially smart contracts, show the effective-\nness of the usage of templates for domain-specific tasks.\nGiven these advantages, we design minimal yet compre-\nhensive templates for different contract types by leverag-\ning the CDM schema and available examples. These tem-\nplates are then populated with extracted contract details using\nLLMs, ensuring structured and more reliable CDM represen-\ntations. Note that these templates are designed solely to facil-\nitate CDMizer ’s generation process and are not intended as a\nfeature of the CDM.\n6.1 Template Creation\nThe process of template creation involves several structured\nsteps to ensure the relevance and usability of the resulting\ntemplates:\nSchema Parsing: While CDM is published in many differ-\nent formats and programming languages, the CDM JSON\nschema can be viewed as a collection of interconnected JSON\nfiles, each defining objects and their properties. Many prop-\nerties reference other schema files via $ref , forming a hier-\narchical structure. While comprehensive, parsing the entire\nschema generates an impractically large representation (e.g.,\nexceeding four million lines of JSON). To manage this com-\nplexity, we focus on extracting only the fields necessary for\nthe specific use case.\nCDM Example Analysis: To identify relevant fields, we an-\nalyze example CDM representations of contracts of a specific\ntype. These examples specify concrete instances of contract\ndata and implicitly define the paths that should be preserved\n--- Page 4 ---\nin the template.\nAlgorithm 1 Template Creation for CDM Representation\nInput: Root schema file R, Schema directory D, Example folder E\nOutput: Pruned template T\n1:Step 1: Extract Relevant Keys\n2: Initialize K← ∅\n3:foreach example file e∈Edo\n4: Load eas a JSON object\n5: Flatten eto extract dot-separated keys and add to K\n6:end for\n7:Step 2: Traverse Schema and Build Parse Tree\n8:T←TRAVERSE SCHEMA (R, D, K, \"\")\n9:Subroutine: T RAVERSE SCHEMA\n10: Load schema SfromR\n11: Initialize T← {}\n12:foreach property p∈S.properties do\n13: Update path :\nifcurrent path is empty thenpath←p\nelsepath←path +\".\"+p\n14: ifpath /∈Kthen\n15: Skip p\n16: end if\n17: ifpreferences another schema ( $ref )then\n18: Resolve reference refas the file path for p.$ref\n19: T[p]←TRAVERSE SCHEMA (ref, D, K, path )\n20: else if pis an array with a referenced schema then\n21: Resolve the reference ref as the file path for\np.items.$ref\n22: T[p]←[TRAVERSE SCHEMA (ref, D, K, path )]\n23: else\n24: Add placeholder for ptoT\n25: end if\n26: Add S.description toT[p]if available\n27:end for\n28:return T\n29:Output: T\nKey Extraction: A critical step involves flattening and ex-\ntracting all keys from the examples into a dot-separated for-\nmat. This enables efficient matching between example data\nand schema paths. Only fields traversed in at least one exam-\nple are retained in the template.\nRecursive Schema Traversal: The schema is recursively\ntraversed from the root, resolving properties that reference\nother schema ( $ref ) and parsing the referenced structures.\nIf a property path matches a key in the flattened example set,\nit is retained in the template, while unrelated properties are\npruned. Additionally, field descriptions from the schema def-\ninition are included to provide semantic context.\nDescription Fields: Each retained field in the template is an-\nnotated with a description key derived from the schema\ndefinition. It provides context about the field’s purpose and\nsemantics and facilitates downstream tasks such as populat-\ning the template with natural language descriptions.\nPlaceholder Insertion: Placeholder values are inserted for\neach field based on its data type: Strings- \"\", Arrays- [],\nObjects- {}and Dates- YYYY-MM-DD . These placeholders\nallow the template to be easily populated with actual data.\nPruning Irrelevant Fields: After traversing the schema,\nfields not referenced in the examples are removed. Addi-tionally, empty or unused structures are cleaned to produce\na concise template.\nThe structured steps for template creation, as outlined\nabove, are formally detailed in Algorithm 1.\n6.2 Populating the Template\nOnce a contract-specific template is defined, it is populated\nwith relevant information extracted from the natural language\ncontract description, forming its CDM representation. This\nprocess leverages template traversal, context-aware prompt-\ning, and Retrieval-Augmented Generation (RAG) to ensure\nsemantic accuracy. The workflow is illustrated in Figure 2.\nTemplate Traversal and Depth Evaluation\nThe population process begins with a recursive traversal of\nthe template’s JSON tree. During this traversal, the algorithm\ncalculates the depth of the deepest subtree for each node.\nDepth Threshold ( d):This parameter balances efficiency\nand accuracy by limiting processing to substructures with\ndepth≤d, preventing token overflows and ensuring incre-\nmental processing of smaller, manageable substructures. Lit-\nerature [Karanjai et al. , 2024 ]suggests that they operate more\neffectively when presented with smaller, well-defined sub-\ntasks. Limiting the scope of the prompt to localized sub-\nstructures improves the precision and relevance of the out-\nputs. Treated as a hyperparameter, dis optimized through\nexperimentation to achieve the best trade-off between accu-\nracy and efficiency in generating semantically aligned CDM\nrepresentations.\nConstructing Context-Rich Prompts for Objects\nFor each selected object, the process involves constructing a\ndetailed prompt to guide the LLM in generating the appropri-\nate content. The prompt includes the following components:\n•Current Object Structure: The structure of the\nobject being populated, including placeholders (e.g.,\n\"assignedIdentifier\": {...}).\n•Object Definition: A description extracted from the ob-\nject’s schema (e.g., ”A class to specify the identifier value\nand its associated version”).\n•Traversal Context: The hierarchical path leading to\nthe current object (e.g., trade.tradeIdentifier ),\nwhich situates the object within the broader template struc-\nture.\nEnhancing Prompts with RAG-Based Contextual\nGuidance\nTo improve the LLM’s accuracy, the methodology inte-\ngrates Retrieval-Augmented Generation (RAG), leveraging\nreal-world examples as a knowledge base. First, examples of\nCDM representations for the given contract type are prepro-\ncessed and segmented into smaller chunks while preserving\nlogical structures, forming a structured knowledge-base, as il-\nlustrated in Figure 2. During inference, a query is formulated\nbased on the structure and description of the current object,\nretrieving semantically and structurally relevant chunks from\nthe knowledge base. These retrieved examples are then in-\ncorporated into the prompt, providing contextual guidance to\nthe LLM and ensuring that the generated content aligns more\nclosely with established CDM representations.\n--- Page 5 ---\n- \nLLMObject:  “assignedIdentifier”: {...} \nObject Definition:  “A class to specify the \nidentifier value and its associated version” \nPrior Context:  trade.tradeIdentifier \nContract Description RAG Query Response RAG Query to retrieve similar \nchunks  to object \n“assignedIdentifier”: {...}   \nd = 3 \nCDM Template for Contract Type XRAG Knowledge Base \n(Chunked CDM Examples) \nCDM Examples (Contract Type X)\nOutput:  Populated Object \nSystem \nPrompt \nCreate Prompt with \nInstructions \nPrompt \nValidator \nFigure 2: CDMizer Workflow. Recursive traversal, governed by a depth threshold ( d), selects substructures (e.g., assignedIdentifier )\nwhere the deepest subtree has a depth ≤d. This ensures manageable task sizes for efficiency and accuracy. Context-aware prompts,\nincorporating object definitions, traversal paths, and RAG-retrieved examples, guide the LLM in populating fields, which are then validated.\nRecursive traversal ensures the entire structure is systematically completed.\nPrompt Submission and LLM Response\nThe fully constructed prompt is submitted to the LLM, which\ngenerates the populated object. The prompt includes:\n•Explicit Instructions: Clear directives on how to populate\nthe object, including required data types, formats, and con-\ntextual considerations.\n•Auxiliary Knowledge: Examples retrieved through RAG\nillustrate expected field content and structure.\n•System Prompt: Along with the constructed prompt,\na system-level prompt is employed to establish general\nguidelines and expectations for the LLM, ensuring consis-\ntent outputs across various object populations.\nAs shown in Figure 2, the LLM uses this comprehen-\nsive prompt to populate fields like identifier.value\nandidentifier.value.meta.scheme within the\nassignedIdentifier object.\nValidation\nAfter receiving the LLM’s response, the output undergoes a\nvalidation that ensures that the populated object has the exact\nsame structure as the input object conforming to the schema.\nRecursive Traversal and CDM Finalization\nThe traversal proceeds recursively, applying this process to\neach object having depth ≤dwithin the JSON tree. The\nrecursive nature of the traversal ensures that all fields are pro-\ncessed systematically, maintaining hierarchical consistency.\nAfter populating all the objects, the template goes through a\ncleaning step, during which any empty field is removed. This\ncleaning step finally yields the CDM representation for the\ngiven natural language contract description.7 Experimental Evaluation\nTo evaluate the effectiveness of the proposed approaches, we\nconducted experiments on a sample of 30 contracts from the\nsynthetic dataset, with five contracts selected from each of\nsix contract type categories. These 30 contracts were tested\nacross four configurations: Baseline w/o RAG ,Baseline w/\nRAG ,CDMizer w/o RAG , and CDMizer w/ RAG . How-\never, fine-tuning was excluded from the baseline configura-\ntions due to critical limitations when applied to the contracts:\n•Token Limitations: Contract descriptions and their\nCDM representations are lengthy, with fields such as\nglobalKey ,meta , andidentifiers consuming sig-\nnificant token space without contributing meaningful infor-\nmation. This often led to truncation and incomplete out-\nputs.\n•Strict Fine-Tuning Behavior: Fine-tuned models rigidly\nmimicked dataset examples, generating metadata-heavy\nCDMs that prioritized non-critical fields. This exacerbated\ntoken limitations by leaving insufficient room for essential\ncontract details.\n•Trade-offs Between Token Limits and Inference Time:\nWhile increasing the token limit enabled more complete\noutputs, it resulted in prohibitively long inference times.\nReducing the token limit caused incomplete representa-\ntions, making fine-tuning impractical for evaluating longer\ncontracts effectively.\n7.1 Evaluation Framework\nThe generated CDM representations are assessed using pre-\ndefined evaluation metrics:\nSyntactical Correctness : Measures the proportion of gen-\nerated keys that exist in the official CDM schema.\n--- Page 6 ---\nSchema Adherence : Evaluates whether the generated\nCDM structure conforms strictly to the CDM schema. The\nprocess involves traversing the generated JSON tree and com-\nparing it with the CDM schema to identify which keys match\nand which do not.\nSemantic Coverage : Determines how comprehensively the\ngenerated CDM captures the contract description’s key de-\ntails while identifying irrelevant or missing information.\nWe explored multiple approaches to assess semantic cov-\nerage, including direct LLM-based assessment, n-gram anal-\nysis, and cosine similarity between key terms. Initially, we\nconsidered direct LLM-based scoring, where the LLM was\nprompted to provide a holistic coverage score by comparing\nthe contract description and the generated CDM. However,\nthis approach proved unreliable, as the scores were often in-\nconsistent and did not accurately reflect the degree of cover-\nage. Next, we attempted n-gram analysis to extract key terms\nfrom the contract text by breaking it into token sequences.\nHowever, LLMs proved more effective at this task, as they\ncan capture multi-word expressions and nuanced relation-\nships that n-grams often miss. Cosine similarity was also con-\nsidered for matching extracted key terms to CDM fields, but it\noften produced high scores for semantically unrelated terms,\nsimply due to shared structures or numerical formats, leading\nto overestimated coverage, making this approach unsuitable\nfor our evaluation framework. Ultimately, we found out that\nthe most effective evaluation method was guiding an LLM by\nstructuring its task as a step-by-step process that mimics how\na human would systematically compute coverage. Instead of\ndirectly asking the LLM to estimate a coverage score, we de-\nsigned a structured prompt that provides explicit step-by-step\nrules. These rules instruct the LLM to sequentially process\nthe contract description, extract key details sentence by sen-\ntence, and compare them against the generated CDM. The\nLLM then categorizes information into three lists:\n•Captured Information: Contains correctly captured infor-\nmation in the CDM representation.\n•Uncaptured Information: Contains information that is\npresent in the contract description but not in the CDM rep-\nresentation.\n•Extraneous Information: Additional content in the CDM\nrepresentation that does not correspond to the contract de-\nscription.\nBy explicitly defining the comparison process in the\nprompt and enforcing a structured methodology, we ensure\nthat the LLM follows a deterministic approach, leading to\nmore accurate and consistent evaluations of semantic cover-\nage.\nFinally, we compute the coverage score using the follow-\ning formula:\nCoverageScore =C×100\nC+µ×U+ϵ×E(1)\nwhere C,UandErepresent the total number of captured ,\nuncaptured , and extraneous elements, respectively.\nThe weighting factors µandϵare introduced to adjust for\npotential noise in the evaluation.\nµ: Uncaptured elements may include details that are contex-\ntually relevant but not strictly contract-specific, as synthetic\nFigure 3: Mean semantic coverage scores for different methods\nacross contract types. Highlights CDMizer ’s consistently improved\nperformance over the baseline. This is more clearly visible (last set\nof bars) when the mean is calculated over the combined set of test\ncontracts from all of the types.\ncontract descriptions were generated using two real contract\nexamples as references, and LLM might copy information\nfrom those. To adjust for this, we reduce the weight of U\nusing the coefficient µ.\nϵ: Extraneous elements may result from fine-tuning and\nRAG-based retrieval, introducing information not explicitly\npresent in the contract. To minimize their impact, we scale\ndown the weight of Eusing the coefficient ϵ.\nThese weighted adjustments ensure a more balanced cov-\nerage score by reducing the influence of non-essential or ex-\nternally introduced elements.\n7.2 Results and Discussion\nFor generating the results, we set the depth threshold to\nd= 4, with weighting factors µ= 0.3andϵ= 0.1to bal-\nance the impact of uncaptured and extraneous elements in the\nsemantic coverage evaluation. These values were chosen af-\nter testing different configurations and comparing the result-\ning scores to human evaluations, ensuring the final setup cap-\ntured contract details accurately while minimizing the impact\nof minor, contextually irrelevant elements.\nAs shown in Table 1, CDMizer , both with and without\nRAG, achieved 100% syntactical correctness and schema ad-\nherence across all contract types. This outcome is expected\ndue to its template-driven approach, which ensures strict\ncompliance with the CDM schema. In contrast, Baseline w/o\nRAG performed poorly, while Baseline w/ RAG showed no-\nticeable improvements but struggled with schema adherence,\nunderscoring the challenges of generating structured JSON\ndirectly from contract descriptions.\nSemantic coverage, illustrated in Figure 3, provides fur-\nther insight into how effectively the generated CDM repre-\nsentations capture key contract details. In general, CDMizer\noutperformed the baseline methods, and w/ RAG methods\nachieved higher semantic coverage than w/o RAG for both\nthe baseline and CDMizer , indicating the overall benefit of\nretrieval augmentation. However, there were instances where\nthew/o RAG variant performed better than w/ RAG —notably\n--- Page 7 ---\nContract TypeMean Syntactical Correctness (%) Mean Schema Adherence (%)\nBaseline\nw/o RAGBaseline\nw/ RAGCDMizerBaseline\nw/o RAGBaseline\nw/ RAGCDMizer\nInterest Rate Swap 46.80 (±28.01) 84.50 (±6.03) 100 24.79 (±16.65) 85.44 (±1.67) 100\nEquity Swap 54.99 (±24.41) 84.05 (±11.49) 100 35.87 (±21.22) 84.81 (±11.89) 100\nEquity Option 58.27 (±19.32) 94.45 (±2.95) 100 43.14 (±25.92) 91.52 (±3.20) 100\nForeign Exchange Derivatives 64.61 (±7.52) 88.34 (±6.26) 100 34.66 (±13.49) 87.67 (±6.38) 100\nCommodity Option 60.54 (±11.28) 87.14 (±5.46) 100 49.56 (±7.96) 93.02 (±3.59) 100\nCredit Default Swap 63.82 (±10.78) 79.64 (±5.09) 100 49.02 (±17.95) 80.59 (±7.25) 100\nTable 1: Comparison of mean syntactical correctness and schema adherence scores across different methods for each contract type (5 contracts\nfor each type). Subscript values indicate Standard Deviations . As the approach suggests, CDMizer (both with or without RAG versions)\nguarantees a score of 100%.\ninEquity Swap and Credit Default Swap for the baseline\nmethod and in Commodity Option derivatives for CDMizer .\nThis suggests that the LLM may have learned more about\nthe CDM structure from the retrieved examples rather than\ncontract-specific information in some cases. Additionally,\nRAG may introduce contextual information that was not ex-\nplicitly stated in the contract, leading to the inclusion of extra-\nneous details in the generated CDM. Despite these variations,\nwhen results were aggregated across all contract types, CD-\nMizer significantly outperformed the baseline methods, and\nretrieval augmentation generally proved beneficial.\nThese results were obtained using Llama-3.1-8B-Instruct ,\nthe best-performing LLM for consistency and accuracy. Ta-\nble 2 presents a comparison of different LLMs for this task.\nSince most LLMs failed to generate complete JSON repre-\nsentations in the baseline configurations, the LLM evaluation\nwas conducted only on CDMizer . As shown in the table,\nLlama-3.1-8B-Instruct achieved the highest semantic cov-\nerage, demonstrating its superior ability to handle complex\nschema while maintaining contextual accuracy.\nLLMMean Semantic\nCoverage (%)\nw/o RAG w/ RAG\nLlama3.1-8B-Instruct 89.40 91.40\nDeepseek-coder-6.7B-Instruct 86.31 85.89\nMistral-7B-Instruct-v0.3 83.32 85.19\nLlama3.2-3B-Instruct 84.13 84.70\nTable 2: Mean Semantic Coverage overall test contracts across dif-\nferent LLMs with and without RAG for CDMizer .\nWhile our experiments primarily used synthetic contracts\ngenerated from CDM examples, we expect reasonable gen-\neralization to real contracts, given the structural consistency\nenforced by the CDM schema. However, real contracts of-\nten contain nuanced language, implicit cross-references, and\ncomplex conditional clauses, like the nested conditions and\ncontext-dependent triggers in, “The issuer may, at its op-\ntion, for each period from and including the period start-\ning 26 November 2009, upon giving 5 business days’ no-\ntice, irrevocably switch the coupon of the notes to a fixed rate\n3.00% per annum. ” Capturing such dependencies requires adeeper understanding of temporal context and broader finan-\ncial terms, which can lead to incomplete or contextually in-\naccurate mappings. Additionally, real contracts vary signif-\nicantly in structure and terminology, creating challenges in\naligning their content with predefined CDM templates. De-\nspite these challenges, the template-driven nature of CDMizer\nguarantees 100% syntactical correctness and schema adher-\nence, though it does not fully address potential semantic inac-\ncuracies. Future work should include testing on a broader set\nof real contracts and may require fine-tuning, domain adap-\ntation, or more advanced prompt engineering to handle these\ncomplexities.\n8 Conclusion and Future Directions\nThis paper introduced a comprehensive framework for con-\nverting unstructured OTC financial derivative contracts into\nCommon Domain Model (CDM) representations. We de-\nveloped a baseline LLM-based pipeline, a deterministic\ntemplate-driven approach ( CDMizer ), and an LLM-based\nevaluation framework. CDMizer ensured schema adherence\nand scalability, outperforming direct generation methods, es-\npecially with retrieval augmentation. Experimental evalu-\nation demonstrated the effectiveness of structured genera-\ntion and the impact of model selection, with Llama-3.1-\n8B-Instruct achieving the best performance. Challenges re-\nmain in capturing legal nuances, refining evaluations, and en-\nabling enforceability. To address these limitations and fur-\nther advance the automation of OTC contract processing, sev-\neral avenues for future exploration are proposed: (i) inte-\ngrating more features from the ISDA Master Agreement\nand legal documentation [Agreement, 2002 ]to capture non-\noperational aspects (e.g., bankruptcy, mergers) by applying\nCDMizer to ISDA contracts as covered by the legal agree-\nment section of the CDM, (ii) converting CDM into exe-\ncutable smart contracts for automated validation and en-\nforceability, (iii) developing more robust evaluation meth-\nodsbeyond LLM-based validation, and (iv) leveraging real-\nworld contract examples to critically assess the framework’s\nperformance in complex legal contexts and iteratively en-\nhance its robustness based on empirical insights. By address-\ning these challenges and advancing these research directions,\nwe move closer to a fully automated, reliable, and enforceable\nframework for OTC contract processing, bridging the gap be-\ntween financial standardization and real-world applicability.\n--- Page 8 ---\nAcknowledgments\nWe acknowledge the support from NSF IUCRC CRAFT cen-\nter research grant (CRAFT Grant #22018) for this research.\nThe opinions expressed in this publication do not necessar-\nily represent the views of NSF IUCRC CRAFT. We are also\ngrateful for the advice and resources from our CRAFT Indus-\ntry Board members in shaping this work.\nReferences\n[Agreement, 2002 ]ISDA Master Agreement. 2002 isda master\nagreement. https://www.isda.org/book/2002-isda-master-agr\neement-mylibrary/, 2002.\n[Allamanis et al. , 2024 ]Miltiadis Allamanis, Sheena Panthap-\nlackel, and Pengcheng Yin. Unsupervised evaluation of code llms\nwith round-trip correctness. arXiv preprint arXiv:2402.08699 ,\n2024.\n[Allouche et al. , 2021 ]Mohamed Allouche, Mihai Mitrea, Alexan-\ndre Moreaux, and Sang-Kyun Kim. Automatic smart contract\ngeneration for internet of media things. ICT Express , 7(3):274–\n277, 2021.\n[Armitage, 2022 ]Matthew Armitage. Trust, confidence, and au-\ntomation: The isda master agreement as a smart contract. Busi-\nness Law Review , 43(2), 2022.\n[Choudhury et al. , 2018 ]Olivia Choudhury, Nolan Rudolph, Issa\nSylla, Noor Fairoza, and Amar Das. Auto-generation of smart\ncontracts from domain-specific ontologies and semantic rules.\nIn2018 IEEE International Conference on Internet of Things\n(iThings) and IEEE Green Computing and Communications\n(GreenCom) and IEEE Cyber, Physical and Social Computing\n(CPSCom) and IEEE Smart Data (SmartData) , pages 963–970.\nIEEE, 2018.\n[Clack and Vanca, 2018 ]Christopher D Clack and Gabriel Vanca.\nTemporal aspects of smart contracts for financial derivatives. In\nLeveraging Applications of Formal Methods, Verification and\nValidation. Industrial Practice: 8th International Symposium,\nISoLA 2018, Limassol, Cyprus, November 5-9, 2018, Proceed-\nings, Part IV 8 , pages 339–355. Springer, 2018.\n[FINOS, 2024a ]FINOS. Common domain model. https://github.c\nom/finos/common-domain-model, 2024. Accessed: 2025-05-09.\n[FINOS, 2024b ]FINOS. Overview of the finos cdm. https://cdm.\nfinos.org/docs/cdm-overview/#purpose, 2024.\n[FINOS, 2025 ]FINOS. common-domain-model. https://cdm.finos\n.org/, 2025.\n[Frantz and Nowostawski, 2016 ]Christopher K Frantz and Mariusz\nNowostawski. From institutions to code: Towards automated\ngeneration of smart contracts. In 2016 IEEE 1st International\nWorkshops on Foundations and Applications of Self* Systems\n(FAS* W) , pages 210–215. IEEE, 2016.\n[Fries and Kohl-Landgraf, 2018 ]Christian P Fries and Peter Kohl-\nLandgraf. Smart derivative contracts (detaching transactions\nfrom counterparty credit risk: Specification, parametrisation, val-\nuation). Available at SSRN 3163074 , 2018.\n[ISDA, 2023 ]ISDA. Key trends in the size and composition of otc\nderivatives markets in the first half of 2023. https://www.isda.o\nrg/2023/12/07/key-trends-in-the-size-and-composition-of-otc-d\nerivatives-markets-in-the-first-half-of-2023, 2023.\n[J.P. Morgan, 2024 ]J.P. Morgan. Usd/inr irs disclosure. https://ww\nw.jpmorgan.com/content/dam/jpm/global/disclosures/IN/usd-inr\n-irs.pdf, 2024. Accessed: 2025-05-09.[Kang et al. , 2024 ]Inwon Kang, William Van Woensel, and Oshani\nSeneviratne. Using large language models for generating smart\ncontracts for health insurance from textual policies. In AI for\nHealth Equity and Fairness: Leveraging AI to Address Social\nDeterminants of Health , pages 129–146. Springer, 2024.\n[Karanjai et al. , 2024 ]Rabimba Karanjai, Lei Xudagger, and Wei-\ndong Shi. Solmover: Feasibility of using llms for translating\nsmart contracts. In 2024 IEEE International Conference on\nBlockchain and Cryptocurrency (ICBC) , pages 1–3. IEEE, 2024.\n[Liet al. , 2022 ]Yujia Li, David Choi, Junyoung Chung, Nate\nKushman, Julian Schrittwieser, R ´emi Leblond, Tom Eccles,\nJames Keeling, Felix Gimeno, Agustin Dal Lago, et al.\nCompetition-level code generation with alphacode. Science ,\n378(6624):1092–1097, 2022.\n[Liuet al. , 2024 ]Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang,\nand Lingming Zhang. Is your code generated by chatgpt really\ncorrect? rigorous evaluation of large language models for code\ngeneration. Advances in Neural Information Processing Systems ,\n36, 2024.\n[Marchesi et al. , 2022 ]Lodovica Marchesi, Katiuscia Mannaro,\nMichele Marchesi, and Roberto Tonelli. Automatic generation\nof ethereum-based smart contracts for agri-food traceability sys-\ntem. Ieee Access , 10:50363–50383, 2022.\n[Oluwajebe et al. , 2020 ]Olusegun Oluwajebe, Mary Duah, and\nPolina Golnikova. Smart derivatives contracting: Automating in-\nterest rate swaps in the over-the-counter (otc) market with the\ndaml. Available at SSRN 3750089 , 2020.\n[Parvez et al. , 2021 ]Md Rizwan Parvez, Wasi Uddin Ahmad,\nSaikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. Re-\ntrieval augmented code generation and summarization. arXiv\npreprint arXiv:2108.11601 , 2021.\n[RBC Capital Markets, 2024 ]RBC Capital Markets. Structured\nrates presentation or document. https://www.rbccm.com/stru\ncturedrates/file-566984.pdf, 2024. Accessed: 2025-05-09.\n[Singh et al. , 2024 ]Srisht Fateh Singh, Panagiotis Michalopoulos,\nand Andreas Veneris. Option contracts in the defi ecosys-\ntem: Motivation, solutions, & technical challenges. In 2024\nIEEE International Conference on Blockchain and Cryptocur-\nrency (ICBC) , pages 1–7. IEEE, 2024.\n[Sorensen, 2024 ]Derek Sorensen. (in) correct smart contract spec-\nifications. In 2024 IEEE International Conference on Blockchain\nand Cryptocurrency (ICBC) , pages 567–575. IEEE, 2024.\n[Tateishi et al. , 2019 ]Takaaki Tateishi, Sachiko Yoshihama, Naoto\nSato, and Shin Saito. Automatic smart contract generation us-\ning controlled natural language and template. IBM Journal of\nResearch and Development , 63(2/3):6–1, 2019.\n[Vaithilingam et al. , 2022 ]Priyan Vaithilingam, Tianyi Zhang, and\nElena L Glassman. Expectation vs. experience: Evaluating the\nusability of code generation tools powered by large language\nmodels. In Chi conference on human factors in computing sys-\ntems extended abstracts , pages 1–7, 2022.\n[Van Woensel et al. , 2023 ]William Van Woensel, Manan Shukla,\nand Oshani Seneviratne. Translating clinical decision logic\nwithin knowledge graphs to smart contracts. In SeWeBMeDA@\nESWC , 2023.",
  "text_length": 43361
}