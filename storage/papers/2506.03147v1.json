{
  "id": "http://arxiv.org/abs/2506.03147v1",
  "title": "UniWorld: High-Resolution Semantic Encoders for Unified Visual\n  Understanding and Generation",
  "summary": "Although existing unified models deliver strong performance on\nvision-language understanding and text-to-image generation, their models are\nlimited in exploring image perception and manipulation tasks, which are\nurgently desired by users for wide applications. Recently, OpenAI released\ntheir powerful GPT-4o-Image model for comprehensive image perception and\nmanipulation, achieving expressive capability and attracting community\ninterests. By observing the performance of GPT-4o-Image in our carefully\nconstructed experiments, we infer that GPT-4o-Image leverages features\nextracted by semantic encoders instead of VAE, while VAEs are considered\nessential components in many image manipulation models. Motivated by such\ninspiring observations, we present a unified generative framework named\nUniWorld based on semantic features provided by powerful visual-language models\nand contrastive semantic encoders. As a result, we build a strong unified model\nusing only 1% amount of BAGEL's data, which consistently outperforms BAGEL on\nimage editing benchmarks. UniWorld also maintains competitive image\nunderstanding and generation capabilities, achieving strong performance across\nmultiple image perception tasks. We fully open-source our models, including\nmodel weights, training and evaluation scripts, and datasets.",
  "authors": [
    "Bin Lin",
    "Zongjian Li",
    "Xinhua Cheng",
    "Yuwei Niu",
    "Yang Ye",
    "Xianyi He",
    "Shenghai Yuan",
    "Wangbo Yu",
    "Shaodong Wang",
    "Yunyang Ge",
    "Yatian Pang",
    "Li Yuan"
  ],
  "published": "2025-06-03T17:59:33Z",
  "updated": "2025-06-03T17:59:33Z",
  "categories": [
    "cs.CV",
    "cs.AI",
    "cs.CL"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.03147v1"
}