{
  "id": "http://arxiv.org/abs/2506.00998v1",
  "title": "LoRA-BAM: Input Filtering for Fine-tuned LLMs via Boxed Abstraction\n  Monitors over LoRA Layers",
  "summary": "Fine-tuning large language models (LLMs) improves performance on\ndomain-specific tasks but can lead to overfitting, making them unreliable on\nout-of-distribution (OoD) queries. We propose LoRA-BAM - a method that adds OoD\ndetection monitors to the LoRA layer using boxed abstraction to filter\nquestions beyond the model's competence. Feature vectors from the fine-tuning\ndata are extracted via the LLM and clustered. Clusters are enclosed in boxes; a\nquestion is flagged as OoD if its feature vector falls outside all boxes. To\nimprove interpretability and robustness, we introduce a regularization loss\nduring fine-tuning that encourages paraphrased questions to stay close in the\nfeature space, and the enlargement of the decision boundary is based on the\nfeature variance within a cluster. Our method complements existing defenses by\nproviding lightweight and interpretable OoD detection.",
  "authors": [
    "Changshun Wu",
    "Tianyi Duan",
    "Saddek Bensalem",
    "Chih-Hong Cheng"
  ],
  "published": "2025-06-01T12:58:32Z",
  "updated": "2025-06-01T12:58:32Z",
  "categories": [
    "cs.LG"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00998v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00998v1  [cs.LG]  1 Jun 2025LoRA-BAM: Input Filtering for Fine-tuned LLMs via Boxed Abstraction\nMonitors over LoRA Layers\nChangshun Wu1, Tianyi Duan2, Saddek Bensalem3, Chih-Hong Cheng2,4*\n1Université Grenoble Alpes, Grenoble, France\n2Chalmers University of Technology, Gothenburg, Sweden\n3CSX-AI, Grenoble, France\n4University of Gothenburg, Gothenburg, Sweden\nAbstract\nFine-tuning large language models (LLMs) im-\nproves performance on domain-specific tasks\nbut can lead to overfitting, making them un-\nreliable on out-of-distribution (OoD) queries.\nWe propose LoRA-BAM - a method that adds\nOoD detection monitors to the LoRA layer us-\ning boxed abstraction to filter questions beyond\nthe model’s competence. Feature vectors from\nthe fine-tuning data are extracted via the LLM\nand clustered. Clusters are enclosed in boxes;\na question is flagged as OoD if its feature vec-\ntor falls outside all boxes. To improve inter-\npretability and robustness, we introduce a reg-\nularization loss during fine-tuning that encour-\nages paraphrased questions to stay close in the\nfeature space, and the enlargement of the deci-\nsion boundary is based on the feature variance\nwithin a cluster. Our method complements ex-\nisting defenses by providing lightweight and\ninterpretable OoD detection.\n1 Overview\nRecent developments in Large Language Models\n(LLMs) (Achiam et al., 2023; Yang et al., 2024;\nMesnard et al., 2024) have led to impressive perfor-\nmance across a broad spectrum of natural language\nprocessing tasks. To align these general-purpose\nmodels with the specific demands of downstream\napplications, fine-tuning techniques such as Low-\nRank Adaptation (LoRA) (Hu et al., 2022) are es-\nsential; it enables adaptation to specialized tasks,\nenforces controlled style and tone, and ultimately\nenhances contextual relevance and user satisfac-\ntion. However, they may produce confident yet in-\ncorrect answers when fine-tuned models encounter\nout-of-distribution (OoD) input, i.e., questions or\ninstructions beyond their intended scope. This\nbehavior poses serious risks, especially in safety-\ncritical applications, where LLMs should ideally\n*The first two authors contributed to the work equally.MedQA Anatomy Biology Nutrition Law CS20406080\nID Near OoD Far OoDRejection Rate (%)Rejection Rate across Domains\nLoRA-BAM\nMahalanobis Distance\nCosine Similarity\nFigure 1: Domain-wise rejection rate comparison across\nID, near-OoD, and far-OoD datasets. Under the same\nFPR95 setting, LoRA-BAM achieves higher rejection\nrates on OoD inputs while maintaining low rejection for\nin-distribution paraphrased MedQA queries.\nabstain from answering outside their fine-tuned\nboundaries.\nIn this paper, we propose LoRA-BAM (Boxed\nAbstraction Monitor for LoRA), a lightweight\nframework for OoD detection for fine-tuned LLMs\nutilizing LoRA or its quantized version. Our ap-\nproach focuses on extracting meaningful represen-\ntations directly from the LoRA layers (the vector\nA⃗ vinin Fig. 2a), which are the primary carriers of\ndomain-specific adaptations. OoD detection has\nbeen a relatively mature topic in image classifica-\ntion and object detection (Hendrycks and Gimpel,\n2017; Lee et al., 2018; Liang et al., 2018; Sun\net al., 2022; Olber et al., 2023; Wu et al., 2024),\nand recent work also considers LLMs with built-in\ncapabilities in rejecting OoD inputs utilizing tech-\nniques such as Mahalanobis distance (Salimbeni\net al., 2024) or cosine similarity (Zhang et al., 2023;\nLiu et al., 2024). However, within the recent work\nin OoD detection of LLMs (Salimbeni et al., 2024;\nLiu et al., 2024), the decision boundary is inher-\n1\n--- Page 2 ---\nPretrained\nWeights\nW∈Rd×d\nA∈Rr×d\nB∈Rd×r\nΣ\n1\nα\nr\n⃗ vin\n⃗ vout\nA⃗ vin(a)⃗ v1⃗ v2\n(b)\nFigure 2: LoRA and extracting fracture vectors A⃗ vinfor\nconstructing OoD detectors (a), and an illustrative ex-\nample indicating the decision boundary between LoRA-\nBAM (two boxes) and Mahalanobis distance (one el-\nlipse) when enclosing the feature vectors (b)\nently a convex set (an ellipsoid or spherical cap),\nmaking existing methods inherently limited in their\ndetection power. Contrarily, the decision boundary\nin LoRA-BAM is based on a finite union of boxes\n(illustrated in Fig. 2b), thereby being non-convex in\nnature. We not only enclose the vectors using tight\nboxes, but also properly enlarge the boxes utilizing\nthe variance in the clustered vectors.\nFinally, to improve robustness against para-\nphrased questions where we expect the monitor\nnot to reject them, we introduce a regularization\nloss during fine-tuning that encourages paraphrased\nquestions to stay close in the feature space. This\nis inspired by recent development of OoD detec-\ntion techniques in classification or object detection,\nwhere the training is adjusted for enabling better\nOoD detection (Du et al., 2022; Xu et al., 2024;\nLu et al., 2024; Gong et al., 2025; He et al., 2025).\nIn our case, introducing such a loss function effec-\ntively limits the degree of box enlargement, making\nthe method more sensitive to OoD input.\nThe main results, as illustrated in Fig. 1, indicate\nthat compared to the state-of-the-art method (Sal-\nimbeni et al., 2024) with their provided benchmark,\nLoRA-BAM has substantially improved the OoD\ndetection rate.\n2 Monitor Construction Techniques\nThis section explains key components we use in\nLoRA-BAM to create efficient OoD detectors.\nClustering and Boxed Abstraction Given a\nLoRA fine-tuned model f, letDtraindef:={(q, r)}\nbe the fine-tuning data set of query-response pairs.\nGiven (q, r)∈ D train, let fA(q)∈Rdre-\nturn the LoRA feature vector of interest follow-ing the concept in Fig. 2a, and consider Xdef:=\n{fA(q)|(q, r)∈ D train}. We apply k-means\nclustering (Sinaga and Yang, 2020) to partition the\nsetXintomclusters:\nX=m[\ni=1Ci, C i∩Cj=∅fori̸=j.\nFor each cluster Ci⊂Rk, we define a bound-\ning box Bias the axis-aligned box enclosing all\npoints in Ci. Specifically, for each dimension\nj= 1, . . . , k , let\nℓi,j= min\nx∈Cixj, u i,j= max\nx∈Cixj.\nThen the box Biis defined using Eq. (1), where\nrepresenting each Bionly requires recording the\nassociated minimum and maximum value in each\ndimension.\nBi=n\nz∈Rk\f\f\fℓi,j≤xj≤ui,jfor all jo\n(1)\nAsBihas a strict enclosure, it can reject seman-\ntically equivalent paraphrased queries. Therefore,\nit is necessary to enlarge the box, i.e., to replace\nℓi,jandui,jbyℓi,j−∆i,jandui,j+ ∆ i,j. The\ndecision of ∆i,jcan be done multiple ways, where\napart from setting a hard threshold relative to the\nlength ui,j−ℓi,jsuch as 1.05(i.e.,5%increase), in\nour implementation, each box Biis enlarged along\nevery dimension with different ratio. For each di-\nmension j= 1, . . . , d , we compute the standard\ndeviation σi,jof the j-th coordinate over all vectors\n⃗ z∈Ci. Given a hyperparameter ∆>0, we ex-\npand the box Biby∆·σi,jin both directions along\ndimension j. The enlarged bounds are defined as:\n˜ℓi,j=ℓi,j−∆·σi,j,˜ui,j=ui,j+ ∆·σi,j.\nThe enlarged box is then given by:\n˜Bi=n\nx∈Rd\f\f\f˜ℓi,j≤xj≤˜ui,jfor all jo\nWhile ∆is a hyperparameter, to enable fair\ncomparison with other techniques, the criterion\nof FPR95 (false positive rate at 95% true positive\nrate) is used. This means that ∆is adjusted on the\nID-only calibration dataset where the OoD filter\nachieves a 95% success rate in “not to consider an\nID input as OoD”. Such a technique is commonly\nused in OoD detection to decide the threshold.\n2\n--- Page 3 ---\nRegularization for Paraphrasing Although the\nbox construction can lead to extremely tight filter-\ning of OoD samples, it is also highly desirable to\nensure that in-distribution samples, such as para-\nphrased questions, would be accepted. Observe\nthat in the standard fine-tuning process, it is pos-\nsible that the feature distance vectors fA(q)and\nfA(qp)are very distant, thereby causing the moni-\ntor to trigger false alarms. Therefore, we consider\nfurther improving the fine-tuning process to en-\nable better monitorability. Given a query-response\npair(q, r), apart from ensuring the correctness of\nLLM generating rwhen inputting q(normally via\ncross-entropy loss), we also wish the q-rephrased\nquestion qpto have a small distance in the LoRA\nfeature space1. This is achieved via introducing\na new Euclidean Distance Loss ||fA(q), fA(q′)||2,\nwhere pairs of data points are fed into the fine-\ntuning pipeline. This is analogous to learning\ndomain-invariant representations in a hyperspheri-\ncal space (Bai et al., 2024).\nOoD Query At inference time, a query q′is\nconsidered as OoD if its transformed representa-\ntionfA(q′)lies outside all the predefined enlarged\nboxes ˜Bi, where checking the box containment\namounts to checking if the vector falls inside range\nof the associated minimum and maximum value,\nwhich has total time complexity of O(md).\n3 Experiments\n3.1 Experimental Setup\nModels and Datasets In our experiments, we use\nQwen 2.5 model family (Yang et al., 2024), where\nwe fine-tune Qwen2.5-0.5B-Instruct on a domain-\nspecific question-answering dataset using LoRA\n(rank=32) and standard cross-entropy loss using the\nhuggingface peft library2. To enhance robustness to\ninput variation, we introduced paraphrased versions\nof the original queries and applied our dual-loss\nobjective, combining cross-entropy with a seman-\ntic alignment loss. Specifically, we compute the\nEuclidean distance between the hidden representa-\ntions of the original and rephrased inputs extracted\nfrom the LoRA-modified projection layer. We fol-\nlow the experimental protocol introduced in (Salim-\nbeni et al., 2024), where the MedMCQA (Pal et al.,\n2022) dataset serves as the ID domain. MedMCQA\nis a large-scale multiple-choice question dataset\n1In our implementation, we use another LLM to perform\nparaphrasing of questions.\n2https://huggingface.co/docs/peft/indexfocused on medical entrance exams. To construct\nOoD datasets, we follow the domain structure of\nthe MMLU benchmark (Hendrycks et al., 2021).\nSpecifically, we select Anatomy, Biology, and Nu-\ntrition as domains that are semantically related to\nmedicine, forming our near-OoD datasets. In con-\ntrast, Law and Computer Science are used as far-\nOoD datasets, representing subject areas unrelated\nto the medical domain. This setup allows us to\nassess the sensitivity of OoD detection methods\nunder varying degrees of distributional shift.\nOoD detection methods We evaluate three OoD\ndetection methods. The first is Mahalanobis Dis-\ntance (MD) (Lee et al., 2018), which fits a Gaussian\ndistribution to ID features and uses the distance to\nthis distribution as the OoD score. The second is a\ncosine similarity–based method (Nguyen and Bai,\n2010) that computes the mean ID representation\nand scores test samples by their cosine similarity\nto this mean. The third is our proposed method,\nLoRA-BAM, which was introduced in the previous\nsection.\n3.2 Results\nEffectiveness in filtering out pure OoD sam-\nples As shown in Table 1, our proposed LoRA-\nBAM method consistently achieves superior per-\nformance across a range of OoD datasets. On\ntwo representative near-OoD domains—Anatomy\nand Nutrition—LoRA-BAM rejects 55% and 91%\nof OoD samples, significantly outperforming the\nMahalanobis-based detector, which rejects only\n25% and 35% on the same tasks. These results\nindicate that LoRA-BAM is markedly more sen-\nsitive to subtle distributional shifts. On far-OoD\ndatasets, LoRA-BAM remains highly competitive,\ntrailing the best-performing method by only 2%\non the Law domain, while exceeding performance\non the other far-OoD case. The performance gains\nof LoRA-BAM can be attributed in large part to\nthe regularization strategy employed during fine-\ntuning. When this regularization is removed—i.e.,\nwithout aligning original and paraphrased samples\nin the LoRA space—the effectiveness of BAM de-\ngrades substantially. As shown in the upper half\nof Table 1, the unregularized BAM struggles with\nboth near- and far-OoD detection, particularly un-\nder stricter margin settings (e.g., ∆ = 1 ), where re-\njection accuracy drops significantly across all OoD\ndomains. These findings highlight the necessity\nof our proposed regularization term for shaping\na more discriminative and robust representation\n3\n--- Page 4 ---\nModel: Qwen2.5-0.5B-Instruct fine-tuned on MedQA Dataset (100 Q-A, denoted as Q(Med))\nMethod Para. In-Distribution Near OoD Far OoD\nMedQA\n(Test)Anatomy\n(100 Q-A)Biology\n(100 Q-A)Nutrition\n(100 Q-A)Law\n(100 Q-A)Computer Science\n(100 Q-A)\nLoRA-BAM ( ∆ = 0 .2) 64.4% 84% 95% 95% 92% 99%\nLoRA-BAM ( ∆ = 0 .4) 45.4% 70% 87% 82% 86% 94%\nLoRA-BAM ( ∆ = 0 .8) 16% 39% 53% 52% 68% 68%\nLoRA-BAM ( ∆ = 1 ) 9% 22% 34% 39% 55% 54%\nMahalanobis Distance (TPR = 95 %) 6% 24% 52% 35% 81% 97%\nCosine Similarity (TPR = 95%) 5% 2% 29% 9% 67% 96%\nModel: Qwen2.5-0.5B-Instruct fine-tuned on paraphrased MedQA Dataset (100 Q-A, denoted as Q*(Med-P)), using new loss\nMethod Para. In-Distribution Near OoD Far OoD\nMedQA\n(Test)Anatomy\n(100 Q-A)Biology\n(100 Q-A)Nutrition\n(100 Q-A)Law\n(100 Q-A)Computer Science\n(100 Q-A)\nLoRA-BAM ( ∆ = 0 .2) 77% 99% 99% 100% 99% 100%\nLoRA-BAM ( ∆ = 0 .4) 63% 99% 98% 100% 99% 100%\nLoRA-BAM ( ∆ = 0 .8) 48% 93% 96% 99% 99% 100%\nLoRA-BAM ( ∆ = 1 ) 40% 90% 95% 99% 98% 98%\nLoRA-BAM (TPR = 95%) 3% 55% 58% 91% 95% 84%\nMahalanobis Distance (TPR = 95%) 7% 25% 49% 35% 96% 77%\nCosine Similarity (TPR = 95%) 9% 17% 41% 26% 97% 81%\nTable 1: Comparison of OoD detection methods evaluated on two fine-tuned models: one trained directly on MedQA\nand the other with paraphrase-aware regularization loss. For the first column (in-distribution), smaller values imply\nsuperiority; for the rest, larger values imply superiority.\nspace, essential for reliable OoD detection.3\nRobustness against paraphrased ID samples\nWhile existing methods perform well in filtering\nout pure OoD inputs, they often overlook a crit-\nical aspect: whether semantically valid ID varia-\ntions, such as paraphrased questions, are also in-\nadvertently rejected. Our findings reveal that Ma-\nhalanobis distance and cosine similarity baselines\nreject up to 7%and9%of paraphrased ID ques-\ntions, respectively, which can negatively impact\nuser-facing reliability in real-world applications. In\ncontrast, our proposed LoRA-BAM method main-\ntains stronger robustness to such natural ID vari-\nations, with a rejection rate as low as 3%. These\nresults suggest that LoRA-BAM not only achieves\nstrong OoD discrimination but also better preserves\ncoverage over valid but rephrased ID inputs, strik-\ning a more favorable balance between selectivity\nand inclusiveness.\n3In our evaluation, we found that adding the regularization\nloss (for paraphrased questions) to the existing cross-entropy\nloss introduces another hyperparameter λto decide the con-\ntribution of the regularization loss. Our initial result with\nQWen2.5 model showed that λplays a less critical role; we\nevaluated against λ∈ {0.1,0.5,1,5,7,10}and LoRA-BAM\nis always better than the other two methods. The result in\nFig. 1 is based on setting λ= 5.4 Concluding Remarks\nA key strength of LoRA-BAM is its complemen-\ntarity to other assurance techniques, such as out-\nput confidence calibration (Geng et al., 2023), en-\nsemble methods (Dietterich, 2000), and retrieval-\naugmented generation (Gao et al., 2023). This mod-\nularity makes it an attractive choice for deployment\nin real-world systems requiring multiple layers of\ndefense. We consider future work by introducing\ndimensionality reduction techniques such as PCA,\nwhere, by using geometric structures (i.e., boxes)\nin a well-defined, low-dimensional space, users and\ndevelopers can visualize the scope of a fine-tuned\nmodel’s capabilities.\nLimitations\nThere remain several limitations in our experi-\nments, and we plan to address these in future work.\nFirst, our main experiments are currently limited\nto Qwen2.5:0.5B, and we intend to scale our exper-\niments to larger models of up to 70B parameters\nand different model architectures. Next, the fine-\ntuning dataset is restricted to the one used in prior\nwork (Salimbeni et al., 2024) and our newly gen-\n4\n--- Page 5 ---\nerated ones, and we plan to introduce additional\nones in future work. Finally, we only conduct our\nexperiment with limited random seeds, and more\nrandom seeds can be introduced to strengthen the\nempirical evidence of our results.\nReferences\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama\nAhmad, Ilge Akkaya, Florencia Leoni Aleman,\nDiogo Almeida, Janko Altenschmidt, Sam Altman,\nShyamal Anadkat, and 1 others. 2023. GPT-4 techni-\ncal report. arXiv preprint arXiv:2303.08774 .\nHaoyue Bai, Yifei Ming, Julian Katz-Samuels, and\nYixuan Li. 2024. HYPO: Hyperspherical out-of-\ndistribution generalization. In International Con-\nference on Learning Representations (ICLR) .\nThomas G Dietterich. 2000. Ensemble methods in ma-\nchine learning. In International workshop on multi-\nple classifier systems , pages 1–15. Springer.\nXuefeng Du, Zhaoning Wang, Mu Cai, and Sharon Li.\n2022. VOS: Learning what you don’t know by virtual\noutlier synthesis. In International Conference on\nLearning Representations (ICLR) .\nYunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,\nJinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen\nWang, and Haofen Wang. 2023. Retrieval-augmented\ngeneration for large language models: A survey.\narXiv preprint arXiv:2312.10997 , 2:1.\nJiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl,\nPreslav Nakov, and Iryna Gurevych. 2023. A sur-\nvey of confidence estimation and calibration in large\nlanguage models. arXiv preprint arXiv:2311.08298 .\nMingrong Gong, Chaoqi Chen, Qingqiang Sun, Yue\nWang, and Hui Huang. 2025. Out-of-distribution de-\ntection with prototypical outlier proxy. In AAAI Con-\nference on Artificial Intelligence (AAAI) , volume 39,\npages 16835–16843.\nWeicheng He, Changshun Wu, Chih-Hong Cheng, Xi-\naowei Huang, and Saddek Bensalem. 2025. Mitigat-\ning hallucinations in YOLO-based object detection\nmodels: A revisit to out-of-distribution detection.\narXiv preprint arXiv:2503.07330 .\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and Jacob Steinhardt.\n2021. Measuring massive multitask language under-\nstanding. In International Conference on Learning\nRepresentations (ICLR) .\nDan Hendrycks and Kevin Gimpel. 2017. A baseline for\ndetecting misclassified and out-of-distribution exam-\nples in neural networks. In International Conference\non Learning Representations (ICLR) .Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-\nZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu\nChen. 2022. LoRA: Low-rank adaptation of large\nlanguage models. In International Conference on\nLearning Representations (ICLR) .\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin.\n2018. A simple unified framework for detecting\nout-of-distribution samples and adversarial attacks.\nAdvances in neural information processing systems\n(NeurIPS) , 31.\nShiyu Liang, Yixuan Li, and R. Srikant. 2018. Enhanc-\ning the reliability of out-of-distribution image detec-\ntion in neural networks. In International Conference\non Learning Representations (ICLR) .\nBo Liu, Li-Ming Zhan, Zexin Lu, Yujie Feng, Lei Xue,\nand Xiao-Ming Wu. 2024. How good are LLMs at\nout-of-distribution detection? In Joint International\nConference on Computational Linguistics, Language\nResources and Evaluation (LREC-COLING) , pages\n8211–8222.\nHaodong Lu, Dong Gong, Shuo Wang, Jason Xue, Lina\nYao, and Kristen Moore. 2024. Learning with mix-\nture of prototypes for out-of-distribution detection.\nInInternational Conference on Learning Representa-\ntions (ICLR) .\nThomas Mesnard, Cassidy Hardin, Robert Dadashi,\nSurya Bhupatiraju, Shreya Pathak, Laurent Sifre,\nMorgane Rivière, Mihir Sanjay Kale, Juliette Love,\nand 1 others. 2024. Gemma: Open models based\non gemini research and technology. arXiv preprint\narXiv:2403.08295 .\nHieu V Nguyen and Li Bai. 2010. Cosine similarity\nmetric learning for face verification. In Asian Con-\nference on Computer Vision (ACCV) , pages 709–720.\nSpringer.\nBartłomiej Olber, Krystian Radlak, Adam Popowicz,\nMichal Szczepankiewicz, and Krystian Chachuła.\n2023. Detection of out-of-distribution samples using\nbinary neuron activation patterns. In IEEE/CVF Con-\nference on Computer Vision and Pattern Recognition\n(CVPR) , pages 3378–3387.\nAnkit Pal, Logesh Kumar Umapathi, and Malaikannan\nSankarasubbu. 2022. Medmcqa: A large-scale multi-\nsubject multi-choice dataset for medical domain ques-\ntion answering. In Conference on Health, Inference,\nand Learning (CHIL) , pages 248–260. PMLR.\nEtienne Salimbeni, Francesco Craighero, Renata\nKhasanova, Milos Vasic, and Pierre Vandergheynst.\n2024. Beyond fine-tuning: LoRA modules boost\nnear-ood detection and llm security. In ICLR 2024\nWorkshop on Secure and Trustworthy Large Lan-\nguage Models .\nKristina P Sinaga and Miin-Shen Yang. 2020. Unsu-\npervised k-means clustering algorithm. IEEE access ,\n8:80716–80727.\n5\n--- Page 6 ---\nYiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li.\n2022. Out-of-distribution detection with deep nearest\nneighbors. In International Conference on Machine\nLearning (ICML) , pages 20827–20840. PMLR.\nChangshun Wu, Weicheng He, Chih-Hong Cheng, Xi-\naowei Huang, and Saddek Bensalem. 2024. BAM:\nbox abstraction monitors for real-time OoD detection\nin object detection. In 2024 IEEE/RSJ International\nConference on Intelligent Robots and Systems (IROS) ,\npages 2632–2638. IEEE.\nKai Xu, Rongyu Chen, Gianni Franchi, and Angela Yao.\n2024. Scaling for training time and post-hoc out-of-\ndistribution detection enhancement. In International\nConference on Learning Representations (ICLR) .\nAn Yang, Baosong Yang, Beichen Zhang, Binyuan\nHui, Bo Zheng, Bowen Yu, Chengyuan Li, Day-\niheng Liu, Fei Huang, Haoran Wei, and 1 others.\n2024. Qwen2.5 technical report. arXiv preprint\narXiv:2412.15115 .\nJinsong Zhang, Qiang Fu, Xu Chen, Lun Du, Zelin Li,\nGang Wang, xiaoguang Liu, Shi Han, and Dongmei\nZhang. 2023. Out-of-distribution detection based\non in-distribution data patterns memorization with\nmodern hopfield energy. In International Conference\non Learning Representations (ICLR) .\n6",
  "text_length": 21972
}