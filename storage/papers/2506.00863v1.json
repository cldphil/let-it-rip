{
  "id": "http://arxiv.org/abs/2506.00863v1",
  "title": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with\n  Synthetic Annotations using CoTR prompting and Large Language Models",
  "summary": "Emotion recognition in low-resource languages like Marathi remains\nchallenging due to limited annotated data. We present L3Cube-MahaEmotions, a\nhigh-quality Marathi emotion recognition dataset with 11 fine-grained emotion\nlabels. The training data is synthetically annotated using large language\nmodels (LLMs), while the validation and test sets are manually labeled to serve\nas a reliable gold-standard benchmark. Building on the MahaSent dataset, we\napply the Chain-of-Translation (CoTR) prompting technique, where Marathi\nsentences are translated into English and emotion labeled via a single prompt.\nGPT-4 and Llama3-405B were evaluated, with GPT-4 selected for training data\nannotation due to superior label quality. We evaluate model performance using\nstandard metrics and explore label aggregation strategies (e.g., Union,\nIntersection). While GPT-4 predictions outperform fine-tuned BERT models,\nBERT-based models trained on synthetic labels fail to surpass GPT-4. This\nhighlights both the importance of high-quality human-labeled data and the\ninherent complexity of emotion recognition. An important finding of this work\nis that generic LLMs like GPT-4 and Llama3-405B generalize better than\nfine-tuned BERT for complex low-resource emotion recognition tasks. The dataset\nand model are shared publicly at https://github.com/l3cube-pune/MarathiNLP",
  "authors": [
    "Nidhi Kowtal",
    "Raviraj Joshi"
  ],
  "published": "2025-06-01T07:01:34Z",
  "updated": "2025-06-01T07:01:34Z",
  "categories": [
    "cs.CL",
    "cs.LG"
  ],
  "pdf_url": "http://arxiv.org/pdf/2506.00863v1",
  "full_text": "--- Page 1 ---\narXiv:2506.00863v1  [cs.CL]  1 Jun 2025L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with\nSynthetic Annotations using CoTR prompting and Large Language Models\nNidhi Kowtal1, Raviraj Joshi2,3\n1Pune Institute of Computer Technology, Pune, Maharashtra India\n2Indian Institute of Technology Madras, Chennai, Tamil Nadu India\n3L3Cube Labs, Pune\n{kowtalnidhi, ravirajoshi }@gmail.com\nAbstract\nEmotion recognition in low-resource languages\nlike Marathi remains challenging due to lim-\nited annotated data. We present L3Cube-\nMahaEmotions, a high-quality Marathi emo-\ntion recognition dataset with 11 fine-grained\nemotion labels. The training data is synthet-\nically annotated using large language mod-\nels (LLMs), while the validation and test\nsets are manually labeled to serve as a reli-\nable gold-standard benchmark. Building on\nthe MahaSent dataset, we apply the Chain-\nof-Translation (CoTR) prompting technique,\nwhere Marathi sentences are translated into En-\nglish and emotion labeled via a single prompt.\nGPT-4 and Llama3-405B were evaluated, with\nGPT-4 selected for training data annotation due\nto superior label quality. We evaluate model\nperformance using standard metrics and ex-\nplore label aggregation strategies (e.g., Union,\nIntersection). While GPT-4 predictions outper-\nform fine-tuned BERT models, BERT-based\nmodels trained on synthetic labels fail to sur-\npass GPT-4. This highlights both the impor-\ntance of high-quality human-labeled data and\nthe inherent complexity of emotion recogni-\ntion. An important finding of this work is\nthat generic LLMs like GPT-4 and Llama3-\n405B generalize better than fine-tuned BERT\nfor complex low-resource emotion recognition\ntasks. The dataset and model are shared pub-\nlicly at https://github.com/l3cube-pune/\nMarathiNLP .\n1 Introduction\nRecent advances in NLP have mainly benefited\nhigh-resource languages like English and Chi-\nnese, which have ample data and annotations\n(Thabah and Purkayastha, 2021). Low-resource\nlanguages, however, face challenges due to limited\nhigh-quality data and complex grammar, leading\nto poor model performance (Yang et al., 2023).\nEven multilingual LLMs, effective in translation,\nstruggle with direct prompts in these languages(Luong et al., 2023; Xiang Zhang, 2023). We focus\non Marathi, spoken by about 83 million people,\nwhich remains underrepresented in NLP due to\nscarce tools and datasets (Joshi, 2022b; Narzary\net al., 2022; Joshi, 2022a). Its syntactic complexity\nadds to the modeling difficulty (Luong et al., 2023).\nTo overcome these challenges, we created\nan emotion classification dataset for Marathi\nby leveraging the capabilities of large language\nmodels like GPT-4 and Llama3-405B. A key\nlimitation in emotion classification for Marathi\nis the lack of labeled emotional datasets. Man-\nual labeling is expensive and time-consuming,\nwhich makes progress in low-resource languages\nslower. To address this, we combined manual\nvalidation with annotation using LLMs to produce\na high-quality dataset efficiently. We manually\nlabeled the validation and test sets to ensure a\ngold-standard benchmark and also annotated these\nsets using GPT-4 and Llama3-405B to evaluate\ntheir performance. Since GPT produced more\naccurate results, we used it to annotate the training\nset as well, accelerating progress for Marathi NLP\nthrough the strategic use of LLMs.\nInterestingly, we observe that GPT-4 signifi-\ncantly outperforms BERT-based models trained\non its own generated labels. This indicates\nthat fine-tuning smaller models on noisy or\nautomatically annotated data does not necessarily\nlead to better performance than the original LLM.\nThe results underscore the inherent complexity\nof multi-label emotion recognition—an intricate\ntask where generic LLMs like GPT-4 are better\nequipped to capture subtle emotional cues than\nfine-tuned, smaller models. This contrasts\nwith findings from (Jadhav et al., 2024), where\nBERT models trained on clean, high-quality\ndata were shown to outperform LLMs in low-\nresource scenarios. In our case, the presence\n--- Page 2 ---\nof residual noise in the training labels or the\ncomplexity of the task itself likely hinders the abil-\nity of BERT-based models to generalize effectively.\nWe use a prompting technique called Chain-of-\nTranslation Prompting (CoTR) to improve the qual-\nity of emotion annotation for a low-resource lan-\nguage like Marathi (Deshpande et al., 2024). The\nCoTR approach, illustrated in Figure 1, has been\nshown to outperform standard prompting strate-\ngies, and is adopted in this study for its effective-\nness. Given the scarcity of Marathi training data,\nLLMs may struggle to accurately predict emotion\nlabels directly from Marathi sentences. To address\nthis, we translate Marathi inputs into English and\nthen generate emotion labels using the translated\ntext. This enables LLMs to leverage their stronger\nEnglish language understanding. CoTR leads to\nmore reliable emotion classification while preserv-\ning the intent of the original Marathi content. We\nindependently validate its effectiveness on the Ma-\nhaEmotions dataset.\nThe main contributions of this work are as fol-\nlows:\n•We curate MahaEmotions *†, a new Marathi\nEmotion Classification dataset‡annotated\nwith eleven emotion categories, containing\nboth model-generated and human annotated\nlabels to ensure good annotation quality. The\ndataset consists of (12k, 1.5k, 1.5k) train, test,\nand validation samples, respectively.\n•We use Chain-of-Translation (CoTR) as an ef-\nfective prompting strategy to use multilingual\nLLMs for emotion tagging. Instead of direct\ncategorization in Marathi, CoTR translates\nMarathi input into English before labeling the\ndata, considerably enhancing the tagging ac-\ncuracy. Notably, we observe an absolute 6%\nimprovement in the GPT-4 performance using\nCoTR prompting.\n•We benchmark the performance of multi-\nple models on this task, including GPT-4,\nLLaMA3-405B, and a fine-tuned MahaBERT-\n*https://github.com/l3cube-pune/MarathiNLP/\ntree/main/L3Cube-MahaEmotions\n†https://huggingface.co/l3cube-pune/\nmarathi-emotion-detect\n‡https://huggingface.co/datasets/l3cube-pune/\nMahaEmotionsV2 model. Our results show that GPT-4\noutperforms LLaMA-3, which in turn out-\nperforms fine-tuned MahaBERT-V2, both in\nterms of accuracy and F1-score.\n•We manually annotate a high-quality test set\nto evaluate how the LLMs perform on the\ntagging task.\n2 Related Work\nLow-resource languages have consistently faced\nchallenges in NLP due to the lack of sufficient\nlinguistic resources, standardized benchmarks,\nand annotated corpora. As a result, they remain\nsignificantly underrepresented in mainstream\nNLP research (Alexandre Magueresse, 2020).\nThe emergence of multilingual pretrained lan-\nguage models has helped address some of these\nissues through cross-lingual transfer, enabling bet-\nter performance across languages with limited data.\nMultilingual architectures such as mBERT, mT5,\nand XLM-R have shown reasonable zero-shot\nand few-shot performance on downstream tasks\nin low-resource settings (Luong et al., 2023;\nKelechi Ogueji, 2021). Prompt-based learning\ntechniques have also proven effective in adapting\npretrained models to new tasks, particularly in\nscenarios where task-specific fine-tuning is not\nfeasible due to data scarcity (Yang et al., 2023).\nRecent advances like L3Cube-MahaNLP and\nMahaBERT have boosted research in syntactic\nparsing, classification, and sentiment analysis for\nMarathi by providing large monolingual datasets\nand transformer models (Joshi, 2022b,a; Pingle\net al., 2023; Kulkarni et al., 2021; Velankar et al.,\n2022). However, there’s still limited work on\ndeeper tasks like emotion recognition. Marathi’s\ncomplex grammar and differences from English\nmake it hard to directly apply models trained on\nhigh-resource languages. Similar trends appear in\nother low-resource languages like Khasi, where\nencoder-decoder transformers have improved tasks\nlike translation despite limited data (Thabah and\nPurkayastha, 2021).\nIn the broader NLP community, there has been\ngrowing interest in emotion recognition, especially\nin the context of multilingual and multimodal\nsystems. However, similar advancements for\nMarathi are still quite limited. In comparison,\n--- Page 3 ---\nsignificant progress has been made for Hindi\nand Hindi-English code-mixed text, with several\nemotion classification models and datasets\navailable (Kumar and andf Girish Sharma, 2023;\nAnshul Wadhawan, 2021; Singh et al., 2022).\nA good example is the EmoInHindi corpus, a\nlow-resource benchmark that provides multi-label\nemotion annotations along with dialogue-level\ncontext (Singh et al., 2022). Recent surveys also\nhighlight the importance of using customized\nmodel architectures, cross-lingual transfer, and\ndomain adaptation techniques for improving\nemotion classification in low- and mid-resource\nlanguages (Shabnam Tafreshi, 2024).\nAdditionally, research on LLMs’ reliability\nfor non-English inputs is ongoing. Zhang et al.\n(Xiang Zhang, 2023) critically assess GPT-4 and\nother LLMs, showing performance drops for\nunderrepresented, morphologically rich languages\nlike Marathi. This questions whether such models\ncan be directly used for low-resource emotion\nrecognition without translation or augmentation.\nPrompt engineering adapted to linguistic traits\n(Patel et al., 2024) offers a practical way to\novercome these limits. In multilingual contexts,\ntranslation-based prompting notably improves\nsemantic understanding and emotion consistency.\nIn this study, we expand on these discoveries and\nprovide a Chain-of-Translation (CoTR) prompting\narchitecture for Marathi text emotion recognition\nthat makes use of multilingual language models\n(Deshpande et al., 2024). Our method uses a single\nprompt that first translates the Marathi sentence\ninto English and then predicts the emotion using\nEnglish-based prompt templates.\n3 Methodology\nOur methodology involves curating a high-quality\nMarathi emotion dataset, applying Chain-of-\nTranslation (CoTR) prompting for emotion tag-\nging using both human annotators and multilingual\nLLMs, and training a classifier on the annotated\ndata. As shown in Figure 2, the process includes\ndataset preprocessing, CoTR-based emotion label-\ning, model comparisons, and final evaluation using\nstandard classification metrics.3.1 Dataset Description\nFor this study, we have used the publicly available\nL3Cube’s MahaSent-GT dataset (Joshi, 2022b), a\nsentiment analysis corpus in Marathi. The dataset\ncontains textual content primarily sourced from\nTwitter. Each sentence is originally labeled with\nsentiment (Positive, Negative, Neutral), and we\nextend this dataset by introducing emotion labels.\nThe dataset contains a total of 15,000 Marathi sen-\ntences. It provides a suitable foundation for emo-\ntion classification tasks due to its coverage of real-\nworld, emotion-rich textual inputs. The distribution\nof emotion labels across the train, validation, and\ntest sets, along with example sentences, is shown\nin Table 1.\n3.2 Emotion Label Taxonomy and Annotation\nScheme\nWe utilize a fixed set of eleven basic emotion\nlabels: Happiness, Sadness, Anger, Fear, Surprise,\nDisgust, Excitement, Pride, Respect, Sarcasm , and\nNeutral . A careful selection process was used to\nensure that this set of emotions was both simple\nenough to allow for consistent classification over a\nlarge number of phrases and expressive enough to\nreflect a wide range of sentiments.\nA label is assigned to each sentence in the\ndataset according to the primary emotion it\nconveys. Although this set of emotion labels\nis based on popular psychological models like\nEkman’s basic emotions and Plutchik’s emotion\nwheel, it is a simplified version made for practical\nuse. Marathi is a diverse language, with many\nemotional states that are hard to define in a\npre-defined set of categories.\nEmotions such as Trust ,Anticipation/Hope ,\nContempt ,Curiosity ,Inspiration ,Disappoint-\nment ,Deep yearning ,Gentle sorrow ,Emotional\noverwhelm ,Helplessness ,Separation-induced\nlonging ,Contentment ,Melancholy , and Deep\ninner experience are a few complex emotions\nthat are subtle, context-dependent, making them\ndifficult to represent in standard NLP frameworks.\nAlthough these could theoretically be classified\nas distinct emotion categories, we chose to\nconcentrate on a more manageable and useful set\nof labels. After carefully reviewing the dataset and\nperforming manual analysis and preprocessing,\nwe selected emotion categories that were most\n--- Page 4 ---\nFigure 1: Chain of Translation Prompting (CoTR)\nFigure 2: Emotion Tagging using Human and LLMs (CoTR)\n--- Page 5 ---\nfrequently observed in day-to-day usage and could\nbe annotated consistently at scale.\nSince there are not many extensive emotion\ndatasets for Marathi, we used this set of eleven\nemotions to enable consistent and scalable annota-\ntion. Both language models and human annotators\nbenefit from this fixed list since it helps them con-\ncentrate on distinct, non-overlapping categories.\nThe primary emotion that each sentence in the sam-\nple conveys is labeled. The strongest or most ob-\nvious emotion is selected when a text comprises\nmultiple emotions.\n3.3 Prompt-Based Annotation Strategy\nWe designed a structured prompt to guide the lan-\nguage model during tagging. Since most large lan-\nguage models (LLMs) are trained primarily on En-\nglish, we include translation in the same prompt.\nThe Marathi sentence is first translated to English,\nand then the model predicts the emotion from a\npredefined set of categories: Fear, Sadness, Anger,\nSurprise, Disgust, Excitement, Pride, Respect, Hap-\npiness, Sarcasm , and Neutral . If a sentence con-\ntains more than one emotion, the most prominent\none is assigned to it. If no emotion is clearly ex-\npressed, the sentence is labeled as Neutral .\n3.4 Models Used\n1.GPT-4o:\nGPT-4o is developed by OpenAI, with 1.8\ntrillion parameters (unofficial). It is a closed-\nsource model and accessible through APIs\nprovided by OpenAI. GPT-4o builds on the ad-\nvancements of its previous versions, offering\nenhanced capabilities in natural language un-\nderstanding, generation, and reasoning across\na wide range of tasks.\n2.Llama 3.1 405B:\nLlama 3.1 (Large Language Model for Multi-\nlingual Applications) is the third iteration in\nthe Meta Llama series, designed with multiple\nvariants, including a 405 billion parameter ver-\nsion and an 8 billion parameter version. These\nmodels are typically open-source. Llama3\nmodels are optimized for multilingual tasks,\nincorporating vast and diverse datasets to im-\nprove performance across different languages.\n3.MahaBERT-V2:\nMahaBERT-V2 is a transformer-based lan-\nguage model pre-trained specifically on alarge corpus of Marathi text. It captures rich\nmorphological and syntactic patterns of the\nMarathi language, making it well-suited for\ndownstream NLP tasks in Marathi. Despite be-\ning domain-specific, its performance on emo-\ntion classification was moderate, with an ac-\ncuracy of 63% and an F1 score of 0.47.\n4.MuRIL:\nMuRIL (Multilingual Representations for In-\ndian Languages) is a multilingual BERT\nmodel developed by Google, trained on 17\nIndian languages including Marathi. It sup-\nports both transliterated and native scripts,\nand enables zero-shot and multilingual trans-\nfer learning. In our experiments, MuRIL\nachieved an accuracy of 60% and an F1 score\nof 0.42, slightly underperforming compared\nto MahaBERT-V2, likely due to its generaliza-\ntion across many languages rather than spe-\ncialization in Marathi.\n4 Results\n4.1 Gold Test Set\nWe manually annotated test and validation sets con-\ntaining 1500 sentences each. These human annota-\ntions are treated as the ground truth for evaluating\nmodel performance.\n4.2 GPT-4 vs Llama3-405B\nWe evaluated the performance of GPT-4 and Llama-\n405B by prompting each model individually to clas-\nsify the same set of sentences. The classification\nwas performed after translating the Marathi inputs\ninto English. A model’s prediction was consid-\nered correct only if it matched the human-provided\nlabel.\nWe considered multiple evaluation scenarios:\n•Correct Prediction: The model label\nmatches the human-annotated gold label.\n•Disagreement Resolution: If both models\ngave labels different from the human label, no\ncredit was given to either.\n•Overlap Analysis: We analyzed agreement\nand disagreement patterns, including cases\nwhere both models were correct, only one was\ncorrect, or both were incorrect.\nBased on the comparative analysis of these mod-\nels, we found GPT-4 to be the more consistent and\n--- Page 6 ---\nTable 1: Number of samples per emotion label in the train, validation, and test sets, along with example sentences\nStatistics Validation\nSetTest Set\nGPT-4 Correct 1265 1284\nLlama Correct 962 1051\nLlama Correct,\nGPT-4 Incorrect106 100\nGPT-4 Correct,\nLlama Incorrect409 333\nBoth Correct 856 951\nAt Least One Cor-\nrect1371 1384\nBoth Incorrect 129 116\nTable 2: Model performance statistics for validation and\ntest sets (each containing 1500 sentences)\naccurate model. Since the performance of GPT-4\nalone was comparable to the combination of GPT-4\nand Llama3-405B, we chose GPT-4 for the large-\nscale annotation of the training dataset.We evaluated the performance of GPT-4 and\nLlama3-405B on both the validation and test\ndatasets, each consisting of 1500 Marathi sentences.\nTable 2 summarizes the correctness statistics across\nboth models.\nGPT-4 consistently outperformed Llama in both\nvalidation and test set. On the test set, GPT-4 cor-\nrectly classified 1284 sentences, while Llama cor-\nrectly classified 1051. GPT-4 showed better accu-\nracy, with 333 instances where GPT-4 was correct\nand Llama was incorrect, compared to only 100\ninstances where Llama was correct and GPT-4 was\nwrong.\nGiven the OR of both models’ predictions is\nsimilar with GPT-4’s performance (1384 for OR\nvs. 1284 for GPT), we decided to tag the training\ndata exclusively using GPT-4 for the final classifier\nmodel.\nAfter annotation, we trained a classifier on the\nGPT-labeled dataset. The overall performance of\n--- Page 7 ---\nModel Accuracy Precision Recall F1 Score\nMahaBERT-V2 0.63 0.45 0.50 0.47\nMuRIL 0.59 0.40 0.48 0.42\nGPT-4 0.83 0.85 0.82 0.83\nGPT-4 (CoTR) 0.86 0.88 0.85 0.86\nLlama3-405B\n(CoTR)0.70 0.74 0.70 0.70\nTable 3: Evaluation metrics for different models on the MahaEmotions test set (Weighted metrics). Note that Anger\nand Disgust are merged into a single class during both training and evaluation.\nFigure 3: Confusion matrix for MahaEmotions classification task using L3Cube’s MahaBERT-V2\nthis classifier on the test set is shown in Table 3. It\nachieved an accuracy of 63%, with a precision of\n0.45, a recall of 0.50, and an F1 score of 0.47. The\ndetailed confusion matrix is presented in Figure 3,\nwhich shows the classification behavior across all\nemotion categories.\nThe confusion matrix in Figure 3 shows that the\nclassifier misclassifies various emotion classes as\nNeutral . For example, out of 68 total Surprise sam-\nples, 20 were predicted as Neutral . Similarly, for\nExcitement , 9 out of 45 instances were misclassi-\nfied as Neutral , and in Anger/Disgust , where 48\nsamples were misclassified as Neutral .\nThese results point to the classifier’s difficulty in\ndistinguishing subtle emotional expressions from\ntruly neutral content. Many Marathi sentences\ncarry emotional nuances that may not be overtly\nvisible. This can lead to confusion with neutral\nstatements. This issue is particularly critical in low-\nresource languages like Marathi, where emotionalsubtleties often rely on cultural or contextual cues\nrather than explicit linguistic markers. Therefore,\nimproving classification of these subtle emotions\nis a key area for future work.\n4.3 Chain of Translation Prompting (CoTR)\nvs Non-CoTR Approach\nAs shown in Table 3, using CoTR leads to con-\nsistent improvements in accuracy, precision, recall,\nand F1 score. By translating Marathi inputs into En-\nglish, multilingual LLMs can more effectively ap-\nply their English-language capabilities, enhancing\nemotion classification performance in low-resource\nlanguages like Marathi.\n5 Future Work and Conclusion\nIn this work, we focused on the task of emotion\nclassification for Marathi, a low-resource language.\nWe created a high-quality dataset by combining\npredictions from large language models (LLMs)\n--- Page 8 ---\nlike GPT-4 and Llama-405B with manual checks.\nTo improve accuracy, we used a method called\nChain-of-Translation (CoTR), where Marathi\nsentences were first translated to English before\nlabeling. GPT-4 showed consistent and reliable\nresults, which made it suitable for large-scale\nannotation.\nIn the future, we plan to improve this work by\ntraining LLMs on more Marathi-specific emotion\ndata to better understand the language and its ex-\npressions. We also aim to include sentences which\nshow complex emotions. Another important direc-\ntion is testing our method on more LLMs, such as\nGemma, Grok, DeepSeek, and Mistral, to check\nhow well it works across different models. Lastly,\nour approach can be extended to other Indian lan-\nguages that also lack emotion datasets, helping\nbuild better NLP tools for a wider range of users.\nThis approach can further be used for other low-\nresource Indic languages.\nAcknowledgments\nThis work was done under the mentorship of Mr.\nRaviraj Joshi (Mentor, L3Cube Pune). I would\nlike to express our gratitude towards him for his\ncontinuous support and encouragement.\nReferences\nEvan Heetderks Alexandre Magueresse, Vincent Carles.\n2020. Low-resource languages: A review of past\nwork and future challenges.\nAkshita Aggarwal Anshul Wadhawan. 2021. Towards\nemotion recognition in hindi-english code-mixed\ndata: A transformer based approach. In Computation\nand Language .\nDr.R.R.Deshmukh Bharati Borade. 2023. Emotional\nspeech recognition for marathi language.\nTejas Deshpande, Nidhi Kowtal, and Raviraj Joshi.\n2024. Chain-of-translation prompting (cotr): A novel\nprompting technique for low resource languages.\narXiv preprint arXiv:2409.04512 .\nKishor Bhangale; Dipali Dhake; Rupali Kawade;\nTriveni Dhamale; Vaishnavi Patil; Nehul Gupta. 2023.\nDeep learning-based analysis of affective computing\nfor marathi corpus. In 2023 3rd International Con-\nference on Intelligent Technologies (CONIT) .\nSuramya Jadhav, Abhay Shanbhag, Amogh Thakurde-\nsai, Ridhima Sinare, and Raviraj Joshi. 2024. On\nlimitations of llm as annotator for low resource lan-\nguages. arXiv preprint arXiv:2411.17637 .Charibeth Cheng Jan Christian Blaise Cruz. 2020. Es-\ntablishing baselines for text classification in low-\nresource languages.\nRaviraj Joshi. 2022a. L3cube-mahacorpus and ma-\nhabert: Marathi monolingual corpus, marathi bert\nlanguage models, and resources. In Proceedings\nof the WILDRE-6 Workshop within the 13th Lan-\nguage Resources and Evaluation Conference , pages\n97–101.\nRaviraj Joshi. 2022b. L3cube-mahanlp: Marathi natural\nlanguage processing datasets, models, and library.\narXiv preprint arXiv:2205.14728 .\nJimmy Lin Kelechi Ogueji, Yuxin Zhu. 2021. Small\ndata? no problem! exploring the viability of\npretrained multilingual language models for low-\nresourced languages. ACL Anthology .\nRonak Kosti, Jose M. Alvarez, Adria Recasens, and\nAgata Lapedriza. 2017. Emotion recognition in con-\ntext. In Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR) .\nA. Kołakowska, A. Landowska, M. Szwoch, W. Sz-\nwoch, and M. R. Wr ´obel. 2014. Emotion recognition\nand its applications. In Proceedings of the 13th In-\nternational Joint Conference on Natural Language\nProcessing and the 3rd Conference of the Asia-Pacific\nChapter of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) .\nAtharva Kulkarni, Meet Mandhane, Manali Likhitkar,\nGayatri Kshirsagar, and Raviraj Joshi. 2021.\nL3cubemahasent: A marathi tweet-based sentiment\nanalysis dataset. In Proceedings of the Eleventh\nWorkshop on Computational Approaches to Subjec-\ntivity, Sentiment and Social Media Analysis , pages\n213–220.\nTapesh Kumar and Mehul Mahrishi andf Girish Sharma.\n2023. Emotion recognition in hindi text using multi-\nlingual bert transformer.\nMinh-Thang Luong, Quoc V . Le, and Thang Luong.\n2023. Multilingual neural machine translation with\na special focus on low-resource languages. Transac-\ntions of the Association for Computational Linguis-\ntics (TACL) .\nSanjib Narzary, Maharaj Brahma, and Mwnthai Narzary.\n2022. Generating monolingual dataset for low re-\nsource language bodo from old books using google\nkeep. In Proceedings of ACL .\nKrish Patel, Gaurav Keshari, Dhaval Powle, Saad\nAnsari, Tejaswini Chavan, and Anindita Khade. 2024.\nHybrid nlp model for multilingual sentiment and\nemotion analysis in poetry. In 2024 International\nConference on Artificial Intelligence and Quantum\nComputation-Based Sensor Application (ICAIQSA) ,\npages 1–8. IEEE.\nPravin K. Patil and Satish R. Kolhe. 2024. Sarcasm\ndetection for marathi and the role of emoticons.\n--- Page 9 ---\nAabha Pingle, Aditya Vyawahare, Isha Joshi, Rahul\nTangsali, and Raviraj Joshi. 2023. L3cube-mahasent-\nmd: A multi-domain marathi sentiment analysis\ndataset and transformer models. In Proceedings of\nthe 37th Pacific Asia Conference on Language, Infor-\nmation and Computation , pages 274–281.\nMona Diab Shabnam Tafreshi, Shubham Vatsal. 2024.\nEmotion classification in low and moderate resource\nlanguages. arxiv .\nGopendra Vikram Singh, Priyanshu Priya, Mauajama\nFirdaus, Asif Ekbal, and Pushpak Bhattacharyya.\n2022. Emoinhindi: A multi-label emotion and in-\ntensity annotated dataset in hindi for emotion recog-\nnition in dialogues. LREC 2022 .\nN. Donald Jefferson Thabah and Bipul Syam\nPurkayastha. 2021. Low resource neural machine\ntranslation from english to khasi: A transformer-\nbased approach. In Low Resource Neural Machine\nTranslation from English to Khasi: A Transformer-\nBased Approach .\nAbhishek Velankar, Hrushikesh Patil, and Raviraj Joshi.\n2022. L3cube-mahahate: A tweet-based marathi hate\nspeech detection dataset and bert models. Aggression\nand Cyberbullying (TRAC 2022) , page 1.\nBradley Hauer Xiang Zhang, Senyu Li. 2023. Don’t\ntrust chatgpt when your question is not in english: A\nstudy of multilingual abilities and types of llms. In\nProceedings of the 2023 Conference on Empirical\nMethods in Natural Language Processing . Associa-\ntion for Computational Linguistics.\nYuqing Yang, Jie Fu, and Pascal Poupart. 2023. Prompt\nlearning for low-resource language understanding\nwith pretrained models. In Proceedings of the An-\nnual Meeting of the Association for Computational\nLinguistics (ACL) .",
  "text_length": 26547
}