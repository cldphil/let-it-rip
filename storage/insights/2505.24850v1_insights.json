{
  "paper_id": "http://arxiv.org/abs/2505.24850v1",
  "extraction_timestamp": "2025-06-03 04:30:32.462483",
  "extraction_version": "1.0",
  "key_findings": [
    "The paper proposes a new method called Reinforcement Distillation (REDI) for improving the reasoning abilities of large language models (LLMs) on tasks like mathematics, by leveraging both positive and negative examples during the distillation process.",
    "REDI outperforms baseline methods like Rejection Sampling Supervised Fine-Tuning (SFT) and SFT combined with DPO/SimPO on mathematical reasoning tasks.",
    "The Qwen-REDI-1.5B model, post-trained on just 131k positive and negative examples from the open Open-R1 dataset, achieves an 83.1% score on the MATH-500 benchmark (pass@1), matching or surpassing the performance of a model post-trained on 800k proprietary data.",
    "REDI establishes a new state-of-the-art for 1.5B models post-trained offline with openly available data on various mathematical reasoning benchmarks.",
    "Unlike computationally intensive reinforcement learning approaches that require strong base models, REDI can effectively distill reasoning abilities into weaker base models using a relatively small amount of data."
  ],
  "main_contribution": "The paper introduces Reinforcement Distillation (REDI), a novel method that leverages both positive and negative examples during the distillation process to effectively instill advanced reasoning abilities, such as mathematical reasoning, into large language models. REDI outperforms baseline approaches and achieves state-of-the-art performance on various benchmarks, even with a relatively small am",
  "limitations": [
    "The paper does not provide details on the computational resources required for training REDI models."
  ],
  "future_work": [
    "Exploring the application of REDI to other domains beyond mathematical reasoning."
  ],
  "study_type": "empirical",
  "industry_applications": [
    "education",
    "finance"
  ],
  "techniques_used": [
    "fine_tuning",
    "reinforcement_learning",
    "prompt_engineering"
  ],
  "implementation_complexity": "medium",
  "resource_requirements": {
    "team_size": "small_team",
    "estimated_time_weeks": 4,
    "compute_requirements": null,
    "data_requirements": "131k examples",
    "budget_tier": null,
    "special_hardware": [],
    "cloud_services": []
  },
  "success_metrics": [],
  "problem_addressed": "Improving the reasoning abilities of large language models on complex tasks like mathematics.",
  "prerequisites": [
    "Python",
    "Deep Learning frameworks (e.g., PyTorch, TensorFlow)",
    "GPU access"
  ],
  "comparable_approaches": [
    "Reinforcement Learning",
    "Supervised Fine-Tuning"
  ],
  "real_world_applications": [
    "educational applications",
    "financial modeling"
  ],
  "evidence_strength": 0.8,
  "practical_applicability": 0.7,
  "extraction_confidence": 0.8,
  "has_code_available": false,
  "has_dataset_available": true,
  "reproducibility_score": null,
  "industry_validation": false
}