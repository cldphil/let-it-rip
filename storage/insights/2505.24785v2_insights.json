{
  "paper_id": "http://arxiv.org/abs/2505.24785v2",
  "extraction_timestamp": "2025-06-03 02:41:30.425169",
  "extraction_version": "1.0",
  "key_findings": [
    "EXP-Bench is a novel benchmark designed to evaluate AI agents on their ability to conduct complete AI research experiments, including formulating hypotheses, designing experiments, implementing code, executing experiments, and analyzing results.",
    "EXP-Bench curated 461 AI research tasks from 51 top-tier AI research papers, using a semi-autonomous pipeline to extract and structure experimental details from the papers and their associated open-source code.",
    "Leading AI agents like OpenHands and IterativeAgent achieved scores of 20-35% on individual aspects like experiment design or implementation correctness, but the success rate for complete, executable experiments was only 0.5%.",
    "The benchmark identifies bottlenecks in AI agents' ability to conduct end-to-end AI research experiments and provides realistic step-by-step procedures to help improve this capability.",
    "EXP-Bench serves as a vital tool for future AI agents to enhance their ability to conduct AI research experiments, potentially accelerating scientific progress in the field."
  ],
  "main_contribution": "EXP-Bench is a novel benchmark that systematically evaluates AI agents on their ability to conduct complete AI research experiments, from formulating hypotheses to implementing code, executing expe...",
  "limitations": [],
  "future_work": [],
  "study_type": "empirical",
  "industry_applications": [],
  "techniques_used": [],
  "implementation_complexity": "high",
  "resource_requirements": {
    "team_size": "medium_team",
    "estimated_time_weeks": 12,
    "compute_requirements": "",
    "data_requirements": "",
    "budget_tier": null,
    "special_hardware": [],
    "cloud_services": []
  },
  "success_metrics": [],
  "problem_addressed": "Evaluating the ability of AI agents to conduct complete AI research experiments, including formulating hypotheses, designing experiments, implementing code, executing experiments, and analyzing results.",
  "prerequisites": [],
  "comparable_approaches": [],
  "real_world_applications": [],
  "evidence_strength": 0.8,
  "practical_applicability": 0.7,
  "extraction_confidence": 0.8,
  "has_code_available": true,
  "has_dataset_available": true,
  "reproducibility_score": null,
  "industry_validation": false
}