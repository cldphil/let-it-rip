{
  "paper_id": "http://arxiv.org/abs/2506.06279v1",
  "extraction_timestamp": "2025-06-10T01:10:59.940527",
  "extraction_version": "1.0",
  "key_findings": [
    "LVLMs exhibit bimodal attention distribution that progressively neglects middle visual content as context expands, creating a fundamental architectural limitation inherited from LLM designs that impacts multimodal processing effectiveness.",
    "Conventional positional encoding schemes fail to preserve vital 2D structural relationships when processing dynamic high-resolution images, leading to suboptimal spatial understanding in vision-language tasks.",
    "CoMemo introduces a dual-path architecture combining Context image path with image Memory path for visual processing, effectively alleviating visual information neglect through specialized pathways that maintain comprehensive visual understanding across extended contexts.",
    "RoPE-DHR positional encoding mechanism employs thumbnail-based positional aggregation to maintain 2D spatial awareness while mitigating remote decay in extended sequences. This novel approach preserves spatial relationships crucial for high-resolution image processing and enables better handling of dynamic visual content across varying resolutions and contexts.",
    "Evaluations across seven benchmarks including long-context comprehension, multi-image reasoning, and visual question answering demonstrate CoMemo's superior performance compared to conventional LVLM architectures."
  ],
  "limitations": [
    "Limited details provided about computational overhead and training requirements",
    "Insufficient information about scalability and deployment considerations"
  ],
  "future_work": [],
  "study_type": "empirical",
  "techniques_used": [
    "attention_mechanisms",
    "other"
  ],
  "implementation_complexity": "high",
  "resource_requirements": {
    "compute_requirements": null,
    "data_requirements": null,
    "budget_tier": null,
    "special_hardware": [],
    "cloud_services": []
  },
  "success_metrics": [],
  "problem_addressed": "Visual information neglect in Large Vision-Language Models due to bimodal attention distribution and inadequate 2D spatial encoding",
  "prerequisites": [
    "Large Language Model infrastructure",
    "High-resolution image processing capabilities",
    "Multimodal training datasets"
  ],
  "comparable_approaches": [],
  "real_world_applications": [
    "Long-context visual comprehension",
    "Multi-image reasoning tasks",
    "Visual question answering systems"
  ],
  "total_author_hindex": 50,
  "has_conference_mention": true,
  "author_hindices": {
    "Shi Liu": 15,
    "Weijie Su": 26,
    "Xizhou Zhu": 1,
    "Wenhai Wang": 3,
    "Jifeng Dai": 5
  },
  "extraction_confidence": 0.7,
  "has_code_available": true,
  "has_dataset_available": false,
  "reproducibility_score": null
}